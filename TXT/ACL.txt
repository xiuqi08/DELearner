FN Clarivate Analytics Web of Science
VR 1.0
PT B
AU Klein, D
   Manning, CD
AF Klein, D
   Manning, CD
GP ACL
TI Accurate unlexicalized parsing
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We demonstrate that an unlexicalized PCFG can parse much more accurately than previously shown, by making use of simple, linguistically motivated state splits, which break down false independence assumptions latent in a vanilla treebank grammar. Indeed, its performance of 86.36% (LP/LR F-1) is better than that of early lexicalized PCFG models, and surprisingly close to the current state-of-the-art. This result has potential uses beyond establishing a strong lower bound on the maximum possible accuracy of unlexicalized models: an unlexicalized PCFG is much more compact, easier to replicate, and easier to interpret than more complex lexical models, and the parsing algorithms are simpler, more widely understood, of lower asymptotic complexity, and easier to optimize.
C1 Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
CR Baker J., 1979, 97 M AC SOC AM, P547
   Charniak E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1031
   CHARNIAK E, 2000, NAACL, V1, P132
   CHARNIAK E, 2001, ACL, V39
   Charniak E., 1998, P 6 WORKSH VER LARG, P127
   Collins Michael, 1999, THESIS U PENNSYLVANI
   COLLINS MJ, 1996, ACL, V34, P184
   EISNER J, 1999, ACL, V37, P457
   GILDEA D, 2001, 2001 C EMP METH NAT
   Hindle D., 1993, Computational Linguistics, V19, P103
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Kaplan R. M., 1982, MENTAL REPRESENTATIO, P727
   KLEIN D, 2001, ACL, V39
   MAGERMAN DM, 1995, ACL, V33, P276
   Noam Chomsky, 1965, ASPECTS THEORY SYNTA
   Radford A, 1988, TRANSFORMATIONAL GRA
   RON D, 1994, ADV NEURAL INFORMATI, V6, P176
   SHARON A, 1998, COMPUTATIONAL LINGUI, V24, P275
   TAYLOR L, 1973, IEEE T COMPUTERS C, V22, P442
NR 19
TC 347
Z9 353
U1 0
U2 9
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 423
EP 430
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500054
DA 2019-06-15
ER

PT B
AU Turian, J
   Ratinov, L
   Bengio, Y
AF Turian, Joseph
   Ratinov, Lev
   Bengio, Yoshua
GP Assoc Computat Linguist
TI Word representations: A simple and general method for semi-supervised
   learning
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih & Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize. com/projects/wordreprs/
C1 [Turian, Joseph; Bengio, Yoshua] Univ Montreal, DIRO, Montreal, PQ H3T 1J4, Canada.
   [Ratinov, Lev] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
RP Turian, J (reprint author), Univ Montreal, DIRO, Montreal, PQ H3T 1J4, Canada.
EM turian@iro.umontreal.ca; ratinov2@uiuc.edu; bengioy@iro.umontreal.ca
CR Ando R. K., 2005, ACL
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Bengio Y., 2008, SCHOLARPEDIA, V3, P3881
   Bengio Y., 2001, NIPS
   Bengio Y., 2009, ICML
   BENGIO Y, 2003, AISTATS
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Candito M., 2009, IWPT, P138
   Collobert  R., 2008, ICML
   Deschacht K., 2009, EMNLP, P21
   Dumais S. T., 1988, SIGCHI C HUM FACT CO, P281
   ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4
   Goldberg Y., 2009, EACL
   Honkela T., 1997, P INT ICSC S SOFT CO
   Honkela T., 1995, ICANN
   Huang F., 2009, ACL
   Kaski S, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P413, DOI 10.1109/IJCNN.1998.682302
   Koo T., 2008, ACL, P595
   Krishnan V., 2006, COLING ACL
   Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028
   Li W., 2005, AAAI
   Liang P, 2005, THESIS
   Lin D., 2009, P JOINT C 47 ANN M A, V2, P1030
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   LUND K, 1995, COGNITIVE SCI P, P660
   Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9
   Miller S, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P337
   Mnih A., 2009, NIPS, P1081
   Mnih Andriy, 2007, ICML
   Morin F, 2005, AISTATS
   Pereira F., 1993, ACL, P183, DOI DOI 10.3115/981574.981598
   Ratinov L., 2009, CONLL
   Rehurek  R., 2010, LREC
   RITTER H, 1989, BIOL CYBERN, V61, P241, DOI 10.1007/BF00203171
   Sahlgren M., 2001, P SEM KNOWL ACQ CAT
   Sahlgren M., 2006, THESIS
   Sahlgren  M., 2005, METH APPL SEM IND WO
   SCHWENK H, 2002, ACOUST SPEECH SIG PR, P765
   Sha F., 2003, HLT NAACL
   Spitkovsky V. I., 2010, NAACL HLT
   Suzuki J., 2009, EMNLP
   Suzuki J., 2008, ACL, P665
   Tjong Kim Sang E. F., 2000, CONLL
   Turian J., 2009, NIPS WORKSH GRAMM IN
   Turney Peter D., 2010, J ARTIFICIAL INTELLI
   Ushioda A., 1996, COLING, P1159
   Vayrynen J., 2005, AKRR 05 INT INT C AD
   Vayrynen J. J., 2007, P WORKSH SEM CONT AC
   Vayrynen J. J., 2004, P STEPS 2004 COGN CY, P173
   Zhang T., 2003, CONLL
   Zhao H., 2009, CONLL, P55
NR 52
TC 327
Z9 354
U1 2
U2 4
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 384
EP 394
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300040
DA 2019-06-15
ER

PT B
AU Och, FJ
AF Och, FJ
GP ACL
TI Minimum error rate training in statistical machine translation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Often, the training procedure for statistical machine translation models is based on maximum likelihood or related criteria. A general problem of this approach is that there is only a loose relation to the final translation quality on unseen text. In this paper, we analyze various training criteria which directly optimize translation quality. These training criteria make use of recently proposed automatic evaluation metrics. We describe a new algorithm for efficient training an unsmoothed error count. We show that significantly better results can often be obtained if the final evaluation criterion is taken directly into account as part of the training procedure.
C1 Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
CR BANGALORE S, 2000, P INT C NAT LANG GEN
   DODDINGTON G, 2002, P ARPA WORKSH HUM LA
   Duda RO, 1973, PATTERN CLASSIFICATI
   FRANZ JO, 1999, P JOINT SIGD C EMP M, P20
   GOODMAN J, 1996, P 34 ANN M ASS COMP, P177
   Juang B.-H., 1995, SPEECH RECOGNITION C
   KISHORE A, 2001, RC22176 TJ WATS RES
   KISHORE A, 1997, EUR C SPEECH COMM TE, P1435
   KUMAR S, 2002, P C EMP METH NAT LAN
   Niessen S, 2000, P 2 INT C LANG RES E, P39
   OCH FJ, 2002, P 40 ANN M ASS COMP
   PACIOREK C, 2000, NIST DARPA SPEECH TR
   PAPINENI KA, 1999, P 1999 IEEE INT C AC
   Press W. H., 2002, NUMERICAL RECIPES C
   Schluter R, 2001, IEEE SIGNAL PROC LET, V8, P131, DOI 10.1109/97.917693
   Tillmann C., 1997, EUR C SPEECH COMM TE, P2667
   Ueffing N, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P156
NR 17
TC 182
Z9 194
U1 0
U2 3
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 160
EP 167
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500021
DA 2019-06-15
ER

PT B
AU Teh, YW
AF Teh, Yee Whye
GP COLING
TI A Hierarchical Bayesian Language Model based on Pitman-Yor Processes
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We propose a new hierarchical Bayesian n-gram model of natural languages. Our model makes use of a generalization of the commonly used Dirichlet distributions called Pitman-Yor processes which produce power-law distributions more closely resembling those in natural languages. We show that an approximation to the hierarchical Pitman-Yor language model recovers the exact formulation of interpolated Kneser-Ney, one of the best smoothing methods for n-gram language models. Experiments verify that our model gives cross entropy results superior to interpolated Kneser-Ney and comparable to modified Kneser-Ney.
C1 Natl Univ Singapore, Sch Comp, Singapore 117543, Singapore.
RP Teh, YW (reprint author), Natl Univ Singapore, Sch Comp, 3 Sci Dr 2, Singapore 117543, Singapore.
EM tehyw@comp.nus.edu.sg
CR Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Chen SF, 1998, TR1098 HARV U COMP S
   Gelman A., 1995, BAYESIAN DATA ANAL
   Ghahramani Z., 2005, UAI C
   GOLDWATER S, 2006, ADV NEURAL INFORM PR, V18
   Goodman J, 2004, P ANN M ASS COMP LIN
   Goodman J. T., 2001, MSRTR200172
   Ishwaran H, 2001, J AM STAT ASSOC, V96, P161, DOI 10.1198/016214501750332758
   Jordan M., 2005, NIPS C
   MACKAY DJC, 1994, NATURAL LANGUAGE ENG
   NADAS A, 1984, IEEE T ACOUST SPEECH, V32, P859, DOI 10.1109/TASSP.1984.1164378
   Neal R. M., 1993, CRGTR931 U TOR DEP C
   Ney H, 1995, P IEEE INT C AC SPEE, V1
   Pitman J, 1997, ANN PROBAB, V25, P855
   PITMAN J, 2002, LECT NOTES ST FLOUR
   Rosenfeld R., 2000, P IEEE, V88
   TEH Y, 2006, TRA206 NAT U SING SC
   TEH YW, 2006, J AM STAT A IN PRESS
NR 18
TC 118
Z9 118
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 985
EP 992
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200124
DA 2019-06-15
ER

PT B
AU Wu, F
   Weld, DS
AF Wu, Fei
   Weld, Daniel S.
GP Assoc Computat Linguist
TI Open Information Extraction usingWikipedia
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Information-extraction (IE) systems seek to distill semantic relations from naturallanguage text, but most systems use supervised learning of relation-specific examples and are thus limited by the availability of training data. Open IE systems such as TextRunner, on the other hand, aim to handle the unbounded number of relations found on the Web. But how well can these open systems perform?
   This paper presents WOE, an open IE system which improves dramatically on TextRunner's precision and recall. The key to WOE's performance is a novel form of self-supervised learning for open extractors -using heuristic matches between Wikipedia infobox attribute values and corresponding sentences to construct training data. Like TextRunner, WOE's extractor eschews lexicalized features and handles an unbounded set of semantic relations. WOE can operate in two modes: when restricted to POS tag features, it runs as quickly as TextRunner, but when set to use dependency-parse features its precision and recall rise even higher.
C1 [Wu, Fei; Weld, Daniel S.] Univ Washington, Seattle, WA 98195 USA.
RP Wu, F (reprint author), Univ Washington, Seattle, WA 98195 USA.
EM wufei@cs.washington.edu; weld@cs.washington.edu
CR Agichtein E., 2000, ICDL
   Akbik Alan, 2009, WWWW WORKSH
   Auer Soren, 2007, ESWC
   Banko M., 2007, P IJCAI
   Bunescu R., 2005, HTL EMNLP
   Bunescu R. C., 2005, NIPS
   CHARNIAK E, 2005, ACL
   Craven M., 1998, AAAI
   Davidov Dmitry, 2007, ACL
   Davidov Dmitry, 2008, ACL
   De Marneffe M.-C., 2008, STANFORD TYPED DEPEN
   Gangemi A., 2005, IJCAI
   Hoffmann R., 2010, ACL
   Jiang Jing, 2007, HLT NAACL
   Kotaro Nakayama T. H., 2008, CEUR WORKSH
   McCallum Andrew Kachites, 2002, MALLET MACHINE LEARN
   Mintz Mike, 2009, ACL IJCNLP
   Ng A. Y., 2005, NIPS
   Nguyen Dat P.T, 2007, IJCA107 TEXTLINKWS
   Pasca M., 2008, AAAI
   PENG F, 2004, HLT NAACL
   Poon Hoifung, 2008, AAAI
   Shinyama Y., 2006, HLT NAACL
   Suchanek F.M., 2007, WWW
   Van Durme Benjamin, 2008, STEP
   Wang Mengqiu, 2008, IJC NLP
   Weld Daniel S., 2007, CIKM
   Wu Fei, 2008, KDD
   Zhang Min, 2006, ACL
   Zhao S., 2005, ACL
   Zhu Jun, 2009, WWW
NR 31
TC 92
Z9 92
U1 1
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 118
EP 127
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300013
DA 2019-06-15
ER

PT B
AU Pantel, P
   Pennacchiotti, M
AF Pantel, Patrick
   Pennacchiotti, Marco
GP COLING
TI Espresso:Leveraging Generic Patterns for Automatically Harvesting
   Semantic Relations
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper, we present Espresso, a weakly-supervised, general-purpose, and accurate algorithm for harvesting semantic relations. The main contributions are: i) a method for exploiting generic patterns by filtering incorrect instances using the Web; and ii) a principled measure of pattern and instance reliability enabling the filtering algorithm. We present an empirical comparison of Espresso with various state of the art systems, on different size and genre corpora, on extracting various general and specific relations. Experimental results show that our exploitation of generic patterns substantially increases system recall with small effect on overall precision.
C1 [Pantel, Patrick] Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Pantel, P (reprint author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way, Marina Del Rey, CA 90292 USA.
EM pantel@isi.edu; pennacchiotti@info.uniroma2.it
CR Berland M., 1999, P 37 ANN M ASS COMP, V37, P57
   Brown T. L., 2003, CHEM CENTRAL SCI
   Caraballo S, 1999, P 37 ANN M ASS COMP, P120
   Cover T. M., 1991, ELEMENTS INFORM THEO
   DAY D, 1997, P ANLP 97 WASH DC
   DOWNEY D, 2005, P 19 INT JOINT C ART, P1034
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   FELLBAUM C, 1998, WORDLVEL ELECT LEXIC
   GEFFET M, 2005, P ACL 2005 ANN ARB M
   Girju R, 2006, COMPUT LINGUIST, V32, P83, DOI 10.1162/089120106776173075
   Hearst M.A., 1992, P 14 INT C COMP LING, P539, DOI DOI 10.3115/992133.992154
   Hindle D., 1990, P 28 ANN M ASS COMP, P268
   JUSTESON JS, 1995, P ICCL 95 NANT FRANC
   LIN CY, 2000, P COLING 00 SAARBR G
   LIN D, 2002, P 19 INT C COMP LING, P577
   Mann G., 2002, P SEMANET 02 BUILD U
   PANTEL P, 2004, P 20 INT C COMP LING
   PANTEL P, 2004, P HUM LANG TECHN N A, P321
   PASCA M, 2001, P NAACL 2001 WORKSH, P138
   RAVICHANDRAN D, 2002, P 40 ANN M ASS COMP, P41, DOI DOI 10.3115/1073083.1073092
   RILOFF E, 1997, P EMNLP 97
   Siegel S, 1988, NONPARAMETRIC STAT B
   SZPEKTOR I, 2004, P EMNLP 04 BARC SPAI
NR 23
TC 85
Z9 85
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 113
EP 120
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200015
DA 2019-06-15
ER

PT J
AU Roark, B
   Saraclar, M
   Collins, M
AF Roark, Brian
   Saraclar, Murat
   Collins, Michael
TI Discriminative n-gram language modeling
SO COMPUTER SPEECH AND LANGUAGE
LA English
DT Article; Proceedings Paper
CT 42nd Annual Meeting of the Association-for-Computational-Linguistics
CY 2004
CL Barcelona, SPAIN
SP Assoc Computat Linguist
ID SPEECH RECOGNITION
AB This paper describes discriminative language modeling for a large vocabulary speech recognition task. We contrast two parameter estimation methods: the perceptron algorithm, and a method based on maximizing the regularized conditional toe-likelihood. The models are encoded as deterministic weighted finite state automata, and are applied by intersecting the automata with word-lattices that are the output from a baseline recognizer. The perceptron algorithm has the benefit of automatically selecting a relatively small feature set in just a couple of passes over the training data. We describe a method based on regularized likelihood that makes use of the feature set given by the perceptron algorithm, and initialization with the perceptron's weights; this method gives an additional 0.5% reduction in word error rate (WER) over training with the perceptron alone. The final system achieves a 1.8% absolute reduction in WER for a baseline first-pass recognition system (from 39.2% to 37.4%), and a 0.9% absolute reduction in WER for a multi-pass recognition system (from 28.9% to 28.0%). (c) 2006 Elsevier Ltd. All rights reserved.
C1 Oregon Hlth Sci Univ, Sch Sci & Engn, Ctr Spoken Language Understanding, Beaverton, OR 97006 USA.
   Bogazici Univ, TR-34342 Istanbul, Turkey.
   MIT, CSAIL, EECS Stata Ctr, Cambridge, MA 02139 USA.
RP Roark, B (reprint author), Oregon Hlth Sci Univ, Sch Sci & Engn, Ctr Spoken Language Understanding, 20000 NW Walker Rd, Beaverton, OR 97006 USA.
EM roark@eslu.ogi.edu; murat.saraclar@boun.edu.tr; mcollins@csail.mit.edu
RI Saraclar, Murat/E-8640-2010
OI Saraclar, Murat/0000-0002-7435-8510
CR ALLAUZEN C, 2003, P 41 ANN M ASS COMP, P40
   Bacchiani M, 2006, COMPUT SPEECH LANG, V20, P41, DOI 10.1016/j.csl.2004.12.12.001
   Bacchiani M., 2004, P HUM LANG TECHN C H, P21
   Bahl LR, 1993, IEEE T SPEECH AUDI P, V1, P77, DOI 10.1109/89.221369
   BALAY S, 2002, ANL9511
   Banerjee S., 2003, P 2 INT C APPL ART I
   BENSON SJ, 2002, ANLACSP909901 ARG NA
   BENSON SJ, 2002, ANLMCSTM242 ARG NAT
   Chen Z., 2000, P 6 INT C SPOK LANG
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Collins M., 2005, P ACL, P507
   COLLINS M, 2004, NEW DEV PARSING TECH
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Goel V, 2000, COMPUT SPEECH LANG, V14, P115, DOI 10.1006/csla.2000.0138
   JELINCK F, 1996, ACOUSTIC SENSITIVE L
   Johnson Mark, 1999, P 37 ANN M ASS COMP, P535
   Khudanpur S, 2000, COMPUT SPEECH LANG, V14, P355, DOI 10.1006/csla.2000.0149
   KUO HKJ, 2002, P INT C AC SPEECH SI
   Lafferty J. D., 2001, P 18 INT C MACH LEAR, P282
   LJOJE A, 2003, DARPA RICH WORKSH BO
   Malouf R., 2002, P 6 C NAT LANG LEARN, P49, DOI DOI 10.3115/1118853.1118871
   Mangu L, 2000, COMPUT SPEECH LANG, V14, P373, DOI 10.1006/csla.2000.0152
   MANGU L, 2001, P INT C AC SPEECH SI
   MCCALLUM A, 2003, 7 C NAT LANG LEARN
   Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184
   *NIST, 2000, SPEECH REC SCOR TOOL
   Pinto D., 2003, P ACM SIGIR
   POVEY D, 2002, P ICASSP, P105
   Ratnaparkhi A., 1994, P INT C SPOK LANG PR, P803
   RINGGER EK, 1996, P INT C AC SPEECH SI
   Roark B., 2004, P ICASSP, P749
   Roark Brian, 2004, P 42 ANN M ASS COMP
   Rosenfeld R, 2001, COMPUT SPEECH LANG, V15, P55, DOI 10.1006/csla.2000.0159
   SHA F, 2003, P HTL NAACL EDM CAN
   Stolcke A., 2000, P NIST SPEECH TRANSC
   STOLCKE A, P 9 HUB 5 CONV SPEEC
   TASKAR B, 2003, P NIPS 2003
   WAINWRIGHT MJ, 2002, 649 UC BERK DEP STAT
   WALLACH H, 2002, THESIS U EDINBURGH
   WOODLAND PC, 2000, P ISCA ITRW ASR2000, P7
NR 40
TC 84
Z9 86
U1 0
U2 20
PU ACADEMIC PRESS LTD ELSEVIER SCIENCE LTD
PI LONDON
PA 24-28 OVAL RD, LONDON NW1 7DX, ENGLAND
SN 0885-2308
J9 COMPUT SPEECH LANG
JI Comput. Speech Lang.
PD APR
PY 2007
VL 21
IS 2
BP 373
EP 392
DI 10.1016/j.csl.2006.06.006
PG 20
WC Computer Science, Artificial Intelligence
SC Computer Science
GA 111YM
UT WOS:000242491800008
DA 2019-06-15
ER

PT B
AU Saraclar, M
   Sproat, R
AF Saraclar, M
   Sproat, R
GP acl
TI Lattice-based search for spoken utterance retrieval
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
ID SPEECH
AB Recent work on spoken document retrieval has suggested that it is adequate to take the single-best output of ASR, and perform text retrieval on this output. This is reasonable enough for the task of retrieving broadcast news stories, where word error rates are relatively low, and the stories are long enough to contain much redundancy. But it is patently not reasonable if one's task is to retrieve a short snippet of speech in a domain where WER's can be as high as 50%; such would be the situation with teleconference speech, where one's task is to find if and when a participant uttered a certain phrase. In this paper we propose an indexing procedure for spoken utterance retrieval that works on lattices rather than just single-best text. We demonstrate that this procedure can improve F scores by over five points compared to single-best retrieval on tasks with poor WER and low redundancy. The representation is flexible so that we can represent both word lattices, as well as phone lattices, the latter being important for improving performance when searching for phrases containing OOV words.
C1 AT&T Labs Res, Florham Pk, NJ 07932 USA.
RP Saraclar, M (reprint author), AT&T Labs Res, 180 Pk Ave, Florham Pk, NJ 07932 USA.
RI Saraclar, Murat/E-8640-2010
OI Saraclar, Murat/0000-0002-7435-8510
CR Amir A., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P580
   Brown M. G., 1996, Proceedings ACM Multimedia 96, P307, DOI 10.1145/244130.244232
   Cox RV, 1998, P IEEE, V86, P755, DOI 10.1109/5.664272
   GAROFOLO J, 2000, P RECH INF ASS ORD C
   HIRSCHBERG J, 2001, P EUR C SPEECH COMM
   JAMES DA, 1995, THESIS U CAMBRIDGE
   JONES GJF, 1996, P 19 ANN INT ACM SIG, P30
   KENNEY N, 2000, THESIS MIT
   LJOLJE A, 2002, P RT02 WORKSH VIENN
   LOGAN B, 2002, P INT C SPOK LANG PR
   LOGAN B, 2002, P HLT
   Makhoul J, 2000, P IEEE, V88, P1338, DOI 10.1109/5.880087
   Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184
   Saraclar M., 2002, P INT C SPOK LANG PR
   Siegler M. A., 1999, THESIS CARNEGIE MELL
   Srinivasan S., 2000, P 23 ANN INT ACM SIG, P81
   Wechsler M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P20, DOI 10.1145/290941.290950
   WECHSLER M, 1998, THESIS ETH ZURICH
   WITBROCK M, 1997, 2 ACM INT C DIG LIB, P30
   Woodland P. C., 2000, P SIGIR ATH GREEC, P372
   Yazgan A., 2004, P IEEE INT C AC SPEE
NR 21
TC 79
Z9 81
U1 0
U2 2
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 129
EP 136
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100017
DA 2019-06-15
ER

PT B
AU Paltoglou, G
   Thelwall, M
AF Paltoglou, Georgios
   Thelwall, Mike
GP Assoc Computat Linguist
TI A study of Information Retrieval weighting schemes for sentiment
   analysis
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Most sentiment analysis approaches use as baseline a support vector machines (SVM) classifier with binary unigram weights. In this paper, we explore whether more sophisticated feature weighting schemes from Information Retrieval can enhance classification accuracy. We show that variants of the classic tf.idf scheme adapted to sentiment analysis provide significant increases in accuracy, especially when using a sublinear function for term frequency weights and document frequency smoothing. The techniques are tested on a wide selection of data sets and produce the best accuracy to our knowledge.
C1 [Paltoglou, Georgios; Thelwall, Mike] Wolverhampton Univ, Wolverhampton, W Midlands, England.
RP Paltoglou, G (reprint author), Wolverhampton Univ, Wolverhampton, W Midlands, England.
EM g.paltoglou@wlv.ac.uk; m.thelwall@wlv.ac.uk
RI Thelwall, Mike/C-1449-2013
OI Thelwall, Mike/0000-0001-6065-205X
CR Abbasi A, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1361684.1361685
   Armstrong T. G., 2009, CIKM 2009, P601, DOI [10.1145/1645953.1646031, DOI 10.1145/1645953.1646031]
   Aue Anthony, 2005, P REC ADV NAT LANG P
   Blitzer J., 2007, ANN M ASS COMP LING, V7, P440, DOI DOI 10.1109/IRPS.2011.5784441
   Bo Pang, 2004, P ACL, P271
   Bo Pang, 2002, P 2002 C EMP METH NA
   Devitt A., 2007, P 45 ANN M ASS COMP, P984
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Frank E., 1999, DATA MINING PRACTICA
   Greene S., 2009, P HUM LANG TECHN 200, P503
   Lin C., 2009, P 18 ACM C INF KNOWL, P375, DOI DOI 10.1145/1645953.1646003
   Lin Wei-Hao, 2006, P C NAT LANG LEARN C
   Liu Hugo, 2004, TECHNICAL REPORT
   Macdonald C., 2006, DCS TECHNICAL REPORT
   Manning C. D., 2008, INTRO INFORM RETRIEV
   Martin J. R., 2005, LANGUAGE EVALUATION
   Martineau J., 2009, P 3 AAAI INT C WEBL
   McCallum A., 1998, COMP EVENT MODELS NA
   Mishne G., 2005, 1 WORKSH STYL AN TEX
   MULLEN T, 2004, P C EMP METH NAT LAN, P412
   Osgood Charles E, 1967, MEASUREMENT MEANING
   OUNIS I, 2008, 17 TEXT RETRIEVAL C
   Pang Bo, 2008, OPINION MINING SENTI
   Prabowo R, 2009, J INFORMETR, V3, P143, DOI 10.1016/j.joi.2009.01.003
   ROBERTSON S, 2004, CIKM 04, P42
   Robertson S E, 1996, NATL FARMERS UNI MAY, P21
   Robertson S. E., 1994, TREC
   Salton G., 1987, TECHNICAL REPORT
   Salton G, 1971, SMART RETRIEVAL SYST
   Salton G., 1986, INTRO MODERN INFORM
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Singhal A., 1995, TECHNICAL REPORT
   Sparck-Jones K, 2000, INFORM PROCESS MANAG, V36, P779, DOI 10.1016/S0306-4573(00)00015-7
   Thomas Matt, 2006, CORR
   Turney Peter D, 2002, ACL 02, P417
   WHITELAW C, 2005, CIKM, P625, DOI DOI 10.1145/1099554.1099714
   Wilson T, 2005, P HUM LANG TECHN C C
   Wright A, 2009, NY TIMES
   Zaidan OF, 2007, COMPUT LINGUIST, V260, P260
   Zobel J., 1998, SIGIR Forum, V32, P18
NR 40
TC 70
Z9 70
U1 2
U2 5
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1386
EP 1395
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300141
DA 2019-06-15
ER

PT B
AU Petrov, S
   Barrett, L
   Thibaux, R
   Klein, D
AF Petrov, Slav
   Barrett, Leon
   Thibaux, Romain
   Klein, Dan
GP COLING
TI Learning Accurate, Compact, and Interpretable Tree Annotation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present an automatic approach to tree annotation in which basic nonterminal symbols are alternately split and merged to maximize the likelihood of a training treebank. Starting with a simple X-bar grammar, we learn a new grammar whose nonterminals are subsymbols of the original nonterminals. In contrast with previous work, we are able to split various terminals to different degrees, as appropriate to the actual complexity in the data. Our grammars automatically learn the kinds of linguistic distinctions exhibited in previous work on manual tree annotation. On the other hand, our grammars are much more compact and substantially more accurate than previous work on automatic annotation. Despite its simplicity, our best grammar achieves an F(1) of 90.2% on the Penn Treebank, higher than fully lexicalized systems.
C1 [Petrov, Slav; Barrett, Leon; Thibaux, Romain; Klein, Dan] Univ Calif Berkeley, Dept EECS, Div Comp Sci, Berkeley, CA 94720 USA.
RP Petrov, S (reprint author), Univ Calif Berkeley, Dept EECS, Div Comp Sci, Berkeley, CA 94720 USA.
EM petrov@eecs.berkeley.edu; lbarrett@eecs.berkeley.edu;
   thibaux@eecs.berkeley.edu; klein@eecs.berkeley.edu
CR BALL G, 1967, BEHAV SCI
   CARABALLO S, 1998, COMPUTATIONAL LINGUS, P275
   Charniak E., 2005, ACL 05, P173
   Charniak E., 2000, NAACL 1, P132
   CHARNIAK E, 1996, AAAI 96, P1031
   CHIANG D, 2002, COMPUTATIONAL LINGUI
   Chomsky Noam, 1965, ASPECTS THEORY SYNTA
   Collins Michael, 1999, THESIS U PENNSYLVANI
   GOODMAN J, 1996, ACL 34, P177
   Henderson J., 2004, ACL 04
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Klein D., 2003, ACL, P423, DOI DOI 10.3115/1075096.1075150
   MATSUZAKI T, 2005, ACL 05, P75
   Pereira F.C.N., 1992, ACL 30, P128
   Prescher D., 2005, ECML 05
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Sekine Satoshi, 1997, EVALB BRACKET SCORIN
   SIMAAN K, 1992, GRAMMARS, V5, P125
   Stolcke A., 1994, Grammatical Inference and Applications. Second International Colloquium, ICGI-94 Proceedings, P106
NR 19
TC 70
Z9 70
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 433
EP 440
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200055
DA 2019-06-15
ER

PT B
AU Navigli, R
   Ponzetto, SP
AF Navigli, Roberto
   Ponzetto, Simone Paolo
GP Assoc Computat Linguist
TI BabelNet: Building a Very Large Multilingual Semantic Network
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID WIKIPEDIA
AB In this paper we present BabelNet - a very large, wide-coverage multilingual semantic network. The resource is automatically constructed by means of a methodology that integrates lexicographic and encyclopedic knowledge from WordNet and Wikipedia. In addition Machine Translation is also applied to enrich the resource with lexical information for all languages. We conduct experiments on new and existing gold-standard datasets to show the high quality and coverage of the resource.
C1 [Navigli, Roberto] Sapienza Univ Roma, Dipartimento Informat, Rome, Italy.
   [Ponzetto, Simone Paolo] Heidelberg Univ, Dept Computat Linguist, D-69115 Heidelberg, Germany.
RP Navigli, R (reprint author), Sapienza Univ Roma, Dipartimento Informat, Rome, Italy.
EM navigli@di.uniroma1.it; ponzetto@cl.uni-heidelberg.de
CR Atserias J., 2004, P 2 INT WORDNET C, P80
   Auer S., 2007, P 6 INT SEM WEB C 2, P722, DOI DOI 10.1007/978-3-540-76298-0_52
   Benoit Sagot, 2008, P ONT 2008 WORKSH
   Black W., 2006, P 3 INT WORDNET C, P295
   Bunescu R. C., 2006, P EACL, V6, P9
   Callison-Burch C., 2009, P 2009 C EMP METH NA, P286
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Cuadros M., 2006, P 2006 C EMP METH NA, P534
   De Melo G., 2009, P 18 ACM C INF KNOWL, P513, DOI DOI 10.1145/1645953.1646020
   Etzioni Oren, 2007, P MACH TRANSL SUMM
   FEI W, 2007, P CIKM 07, P41
   FELLBAUM CHRISTIANE, 1998, WORDNET ELECT DATABA
   FUNG P, 1995, P 33 ANN M ASS COMP, P236
   Gabrilovich E, 2006, AAAI, V6, P1301
   Gale W. A., 1993, Computational Linguistics, V19, P75
   Giles J, 2005, NATURE, V438, P900, DOI 10.1038/438900a
   Haghighi A., 2008, ACL, P771
   HARABAGIU S, 2000, P 9 TEXT RETR C TREC, P479
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   KOEHN P, 2005, P MACH TRANSL SUMM
   Kunze C., 2002, P 3 INT C LANG RES E, P1485
   Lefever Els, 2009, P WORKSH SEM EV REC, P82
   LENCI A, 2000, INT J LEXICOGR, V13, P249
   Mausam, 2009, P JOINT C 47 ANN M A, P262
   Medelyan O, 2009, INT J HUM-COMPUT ST, V67, P716, DOI 10.1016/j.ijhcs.2009.05.004
   Miller G. A., 1993, P WORKSH HUM LANG TE, P303, DOI DOI 10.3115/1075671.1075742
   Nastase V., 2008, P C EMP METH NAT LAN, P763
   Navigli R., 2009, P 12 C EUR CHAPT ASS, P594
   Navigli R, 2010, IEEE T PATTERN ANAL, V32, P678, DOI 10.1109/TPAMI.2009.36
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Ng Hwee Tou, 1996, P 34 ANN M ACL, P40
   Pianta E., 2002, P 1 INT C GLOB WORDN, P21
   Ponzetto S., 2007, P 22 NAT C ART INT A, P1440
   Ponzetto SP, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2083
   Ponzetto Simone Paolo, 2010, P ACL 10
   REITER N, 2008, RES COMPUTATIONAL SE, V1, P381
   Ruiz- Casado Maria, 2005, LECT NOTES COMPUTER, V3528
   Sammer Marcus, 2007, P MACH TRANSL SUMM
   Snow R, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P801
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Tufis D., 2004, ROM J INF SCI TECH, V7, P9
   von Ahn Luis, 2006, IEEE COMPUT, V6, P92
   Vossen P., 1998, EUROWORDNET MULTILIN
   Yarowsky D., 2002, Natural Language Engineering, P293, DOI 10.1017/S135132490200298X
   YOKOI T, 1995, COMMUN ACM, V38, P42, DOI 10.1145/219717.219752
NR 45
TC 65
Z9 65
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 216
EP 225
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300023
DA 2019-06-15
ER

PT B
AU Zhang, M
   Zhang, J
   Su, J
   Zhou, GD
AF Zhang, Min
   Zhang, Jie
   Su, Jian
   Zhou, Guodong
GP COLING
TI A Composite Kernel to Extract Relations between Entities with both Flat
   and Structured Features
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper proposes a novel composite kernel for relation extraction. The composite kernel consists of two individual kernels: an entity kernel that allows for entity-related features and a convolution parse tree kernel that models syntactic information of relation examples. The motivation of our method is to fully utilize the nice properties of kernel methods to explore diverse knowledge for relation extraction. Our study illustrates that the composite kernel can effectively capture both flat and structured features without the need for extensive feature engineering, and can also easily scale to include more features. Evaluation on the ACE corpus shows that our method outperforms the previous best-reported methods and significantly outperforms previous two dependency tree kernels for relation extraction.
C1 [Zhang, Min; Zhang, Jie; Su, Jian; Zhou, Guodong] Inst Infocomm Res, Singapore 119613, Singapore.
RP Zhang, M (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.
EM mzhang@i2r.a-star.edu.sg; zhangjie@i2r.a-star.edu.sg;
   sujian@i2r.a-star.edu.sg; zhougd@i2r.a-star.edu.sg
CR ACE, 2002, AUT CONT EXTR PROJ
   BASILI R, 2005, SEMANTIC KERNEL CLAS
   BUNESCU RC, 2005, SHORTEST PATH DEPEND
   CHARNIAK E, 2001, IMMEDIATE HEAT PARSI
   Collins M., 2001, CONVOLUTION KERNELS
   Culotta A., 2004, DEPENDENCY TREE KERN
   Haussler D., 1999, UCSCRL9910
   Joachims  T., 1998, TEXT CATEGORIZATION
   Kambhatla Nanda, 2004, COMBINING LEXICAL SY
   Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687
   MILLER S, 2000, NOVEL USE STAT PARSI
   MOSCHITTI A, 2004, STUDY CONVOLUTION KE
   SCHOLKOPF B, 2001, LEARNING KERNELS SVM, P407
   SUZUKI J, 2003, HIERARCHICAL DIRECTE
   Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205
   ZHAO S, 2005, EXTRACTING RELATIONS
   Zhou. G, 2005, EXPLORING VARIOUS KN
NR 17
TC 54
Z9 55
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 825
EP 832
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200104
DA 2019-06-15
ER

PT B
AU Snow, R
   Jurafsky, D
   Ng, AY
AF Snow, Rion
   Jurafsky, Daniel
   Ng, Andrew Y.
GP COLING
TI Semantic Taxonomy Induction from Heterogenous Evidence
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We propose a novel algorithm for inducing semantic taxonomies. Previous algorithms for taxonomy induction have typically focused on independent classifiers for discovering new single relationships based on hand-constructed or automatically discovered textual patterns. By contrast, our algorithm flexibly incorporates evidence from multiple classifiers over heterogenous relationships to optimize the entire structure of the taxonomy, using knowledge of a word's coordinate terms to help in determining its hypernyms, and vice versa. We apply our algorithm on the problem of sense-disambiguated noun hyponym acquisition, where we combine the predictions of hypernym and coordinate term classifiers with the knowledge in a preexisting semantic taxonomy (WordNet 2.1). We add 10, 000 novel synsets to WordNet 2.1 at 84% precision, a relative error reduction of 70% over a non-joint algorithm using the same component classifiers. Finally, we show that a taxonomy built using Our algorithm shows a 23% relative F-score improvement over WordNet 2.1 on an independent testset of hypernym pairs.
C1 [Snow, Rion; Ng, Andrew Y.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Snow, R (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM rion@cs.stanford.edu; jurafsky@stanford.edu; ang@cs.stanford.edu
CR Buitelaar P., 2005, FRONTIERS ARTIFICIAL, V123
   Caraballo S. A., 2001, THESIS BROWN U
   Cederberg S., 2003, P 7 C NAT LANG LEARN, V4, P111
   Chklovski T., 2004, P EMNLP 2004
   Ciaramita M., 2003, P EMNLP 2003
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   FLEISCHMAN M, 2002, P COLING 02
   Girju R., 2003, P HLT 03
   Hearst M., 1992, P COLING 92
   HINDLE D, 1990, P ACL 90
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   Lin D., 2003, P IJCAI 03
   LIN DK, 1998, WORKSH EV PARS SYST
   Pasca M, 2005, LECT NOTES COMPUT SC, V3406, P280
   Ravichandran D., 2002, P ACL 2002
   RILOFF E, 1997, P EMNLP 1997
   ROARK B, 1998, P ACL 1998
   SNOW R, 2005, NIPS 2005
   Turney Peter D., 2003, P INT C REC ADV NAT, P482
NR 20
TC 53
Z9 53
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 801
EP 808
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200101
DA 2019-06-15
ER

PT J
AU Mendonca, EA
   Haas, J
   Shagina, L
   Larson, E
   Friedman, C
AF Mendonca, EA
   Haas, J
   Shagina, L
   Larson, E
   Friedman, C
TI Extracting information on pneumonia in infants using natural language
   processing of radiology reports
SO JOURNAL OF BIOMEDICAL INFORMATICS
LA English
DT Article; Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
DE natural language processing; surveillance; infectious diseases; infants
ID VENTILATOR-ASSOCIATED PNEUMONIA; BIRTH-WEIGHT INFANTS; NOSOCOMIAL
   INFECTIONS; BACTERIAL PNEUMONIA; CONTROLLED TRIAL; SYSTEM; SURVEILLANCE;
   DIAGNOSIS; PATIENT; PREVENTION
AB Natural language processing (NLP) is critical for improvement of the healthcare process because it can encode clinical data in patient documents. Many clinical applications such as decision support require coded data to function appropriately. However, in order to be applicable for healthcare, performance must be adequate. A valuable automated application is the detection of infectious diseases, such as surveillance of pneumonia in newborns (e.g., neonates) because the disease produces significant rates of morbidity and mortality, and manual surveillance is challenging. Studies have demonstrated that automated surveillance using NLP is a useful adjunct to manual surveillance and an effective tool for infection control practitioners. This paper presents a study evaluating the feasibility of an NLP-based monitoring system to screen for healthcare-associated pneumonia in neonates. We estimated sensitivity, specificity, and positive predictive value by comparing results with clinicians ' judgments. Sensitivity was 71% and specificity was 99%. Our results demonstrated that the automated method was feasible. (c) 2005 Elsevier Inc. All rights reserved.
C1 Columbia Univ, Dept Biomed Informat, New York, NY 10032 USA.
   New York Presbyterian Hosp, Dept Epidemiol, New York, NY USA.
   Columbia Univ, Sch Nursing, New York, NY 10032 USA.
RP Mendonca, EA (reprint author), Columbia Univ, Dept Biomed Informat, New York, NY 10032 USA.
EM mendonca@dbmi.columbia.edu
RI Mendonca, Eneida/J-8895-2016
OI Mendonca, Eneida/0000-0003-4297-9221
FU NINR NIH HHS [R01 NR005197, 1 R01 NR05197-01A1, R01 NR005197-03]; NLM
   NIH HHS [LM06274]
CR *AHRQ, 2002, EVID REP TECHNOL ASS, P1
   Aronson AR, 1994, P RIAO, P197
   BAUD RH, 1995, METHOD INFORM MED, V34, P176
   Bonten MJM, 1999, DIAGN MICR INFEC DIS, V34, P199, DOI 10.1016/S0732-8893(99)00040-1
   Cordero L, 2000, AM J INFECT CONTROL, V28, P333, DOI 10.1067/mic.2000.109884
   Cordero L, 2002, AM J INFECT CONTROL, V30, P32, DOI 10.1067/mic.2002.119995
   Cote RA, 1993, SYSTEMATIZED NOMENCL
   Craven DE, 1998, NEW HORIZ-SCI PRACT, V6, pS30
   Dexter PR, 2001, NEW ENGL J MED, V345, P965, DOI 10.1056/NEJMsa010181
   Fiszman M, 2000, J AM MED INFORM ASSN, V7, P593, DOI 10.1136/jamia.2000.0070593
   Flanagan PG, 1999, J HOSP INFECT, V41, P87, DOI 10.1016/S0195-6701(99)90045-2
   Friedman C, 1999, J AM MED INFORM ASSN, P256
   Friedman C, 1999, J AM MED INFORM ASSN, V6, P76, DOI 10.1136/jamia.1999.0060076
   FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161, DOI 10.1136/jamia.1994.95236146
   FRIEDMAN C, 2001, P AMIA S, V1, P189
   FRIEDMAN C, 1998, METHOD INFORM MED, V37, P311
   FRIEDMAN C, 2004, J AM MED INFORM ASS
   Gaynes RP, 1996, PEDIATRICS, V98, P357
   Gundersen ML, 1996, COMPUT BIOMED RES, V29, P351, DOI 10.1006/cbmr.1996.0026
   HAUG PJ, 1990, RADIOLOGY, V174, P543, DOI 10.1148/radiology.174.2.2404321
   Heyland DK, 1999, AM J RESP CRIT CARE, V159, P1249, DOI 10.1164/ajrccm.159.4.9807050
   HRIPCSAK G, 1995, ANN INTERN MED, V122, P681, DOI 10.7326/0003-4819-122-9-199505010-00007
   HRIPCSAK G, 1994, COMPUT BIOMED RES, V27, P291, DOI 10.1006/cbmr.1994.1023
   Hripcsak G, 1996, COMPUT BIOMED RES, V29, P194, DOI 10.1006/cbmr.1996.0016
   HRIPCSAK G, 1990, P 14 ANN S COMP APPL, P200
   Ide N, 1998, COMPUT LINGUIST, V24, P1
   Knirsch CA, 1998, INFECT CONT HOSP EP, V19, P94
   Kuperman GJ, 1999, J AM MED INFORM ASSN, V6, P512, DOI 10.1136/jamia.1999.0060512
   LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281
   Nadkarni P, 2001, J AM MED INFORM ASSN, V8, P80, DOI 10.1136/jamia.2001.0080080
   Richards C, 2001, AM J INFECT CONTROL, V29, P400, DOI 10.1067/mic.2001.118408
   RIND DM, 1994, ARCH INTERN MED, V154, P1511, DOI 10.1001/archinte.154.13.1511
   SAGER N, 1995, METHOD INFORM MED, V34, P140
   THACKER SB, 1986, AM J PREV MED, V2, P345
   Wilcox A, 2000, J AM MED INFORM ASSN, P923
   Xu H, 2004, STUD HEALTH TECHNOL, V107, P565
   ZANGWILL KM, 1920, MMMWR CDC SURVEILL S, V41, P25
NR 37
TC 47
Z9 48
U1 0
U2 5
PU ACADEMIC PRESS INC ELSEVIER SCIENCE
PI SAN DIEGO
PA 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
SN 1532-0464
EI 1532-0480
J9 J BIOMED INFORM
JI J. Biomed. Inform.
PD AUG
PY 2005
VL 38
IS 4
BP 314
EP 321
DI 10.1016/j.jbi.2005.02.003
PG 8
WC Computer Science, Interdisciplinary Applications; Medical Informatics
SC Computer Science; Medical Informatics
GA 959JO
UT WOS:000231514200009
PM 16084473
OA Bronze
DA 2019-06-15
ER

PT B
AU Lavergne, T
   Cappe, O
   Yvon, F
AF Lavergne, Thomas
   Cappe, Olivier
   Yvon, Francois
GP Assoc Computat Linguist
TI Practical very large scale CRFs
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Conditional Random Fields (CRFs) are a widely-used approach for supervised sequence labelling, notably due to their ability to handle large description spaces and to integrate structural dependency between labels. Even for the simple linear-chain model, taking structure into account implies a number of parameters and a computational effort that grows quadratically with the cardinality of the label set. In this paper, we address the issue of training very large CRFs, containing up to hundreds output labels and several billion features. Efficiency stems here from the sparsity induced by the use of a l(1) penalty term. Based on our own implementation, we compare three recent proposals for implementing this regularization strategy. Our experiments demonstrate that very large CRFs can be trained efficiently and that very large models are able to improve the accuracy, while delivering compact parameter sets.
C1 [Lavergne, Thomas] CNRS, LIMSI, F-75700 Paris, France.
   [Cappe, Olivier] Telecom Paris Tech, CNRS, LTCI, Paris, France.
   [Yvon, Francois] Univ Paris Sud 11, CNRS, LIMSI, Orsay, France.
RP Lavergne, T (reprint author), CNRS, LIMSI, F-75700 Paris, France.
EM lavergne@limsi.fr; cappe@enst.fr; yvon@limsi.fr
OI YVON, Francois/0000-0002-7972-7442
CR Andrew G., 2007, P 24 INT C MACH LEAR, V24, P33, DOI DOI 10.1145/1273496.1273501
   Bottou L, 2004, LECT NOTES ARTIF INT, V3176, P146
   Bottou L., 2007, STOCHASTIC GRADIENT
   Chen Stanley F., 2009, P HLT NAACL, P450
   COHN T, 2006, P 17 EUR C MACH LEAR, P606
   Dietterich Thomas G., 2004, P INT C MACH LEARN R
   Dudik M, 2004, LECT NOTES COMPUT SC, V3120, P472, DOI 10.1007/978-3-540-27819-1_33
   Finkel J. R., 2008, P 46 ANN M ASS COMP, V46, P959
   Friedman J, 2008, TECHNICAL REPORT
   Gao G, 2007, P 45 ANN M ASS COMP, V45, P824
   Jeong M., 2009, P C SHORT ACL IJCNLP, P281
   Kazama J, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P137
   Kudo T, 2005, CRF YET ANOTHER CRF
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Liang Percy, 2008, P 25 INT C MACH LEAR, P592
   Lin D., 2004, P 2004 C EMP METH NA, P174
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Mcdonald Ryan, 2009, ADV NEURAL INFORM PR, P1231
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Okazaki N., 2007, CRFSUITE FAST IMPLEM
   Pal C., 2006, P INT C AC SPEECH SI
   Perkins S., 2003, Journal of Machine Learning Research, V3, P1333, DOI 10.1162/153244303322753698
   Punyakanok V, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1124
   Qian X., 2009, P 26 ANN INT C MACH, P849
   Rozenknop A., 2002, THESIS
   Sejnowski T. J., 1987, COMPLEX SYSTEMS, V1
   Shen L., 2007, ANN M ASS COMP LING, V45, P760
   Sokolovska Nataliya, 2010, IEEE SELECTED TOPICS
   Sutton C, 2006, INTRO STAT RELATIONA
   Suzuki J., 2008, P ACL HLT 08, P665
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267
   TOUTANOVA K, 2003, P 2003 C N AM CHAPT, P173, DOI DOI 10.3115/1073445.1073478
   Tsuruokas Y., 2009, P JOINT C 47 ANN M A, V1, P477
   Vishwanathan S., 2006, P 23 INT C MACH LEAR, P969, DOI DOI 10.1145/1143844.1143966
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 36
TC 42
Z9 42
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 504
EP 513
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300052
DA 2019-06-15
ER

PT B
AU Nenkova, A
   Passonneau, R
AF Nenkova, A
   Passonneau, R
GP acl
TI Evaluating content selection in summarization: The pyramid method
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We present an empirically grounded method for evaluating content selection in summarization. It incorporates the idea that no single best model summary for a collection of documents exists. Our method quantifies the relative importance of facts to be conveyed. We argue that it is reliable, predictive and diagnostic, thus improves considerably over the shortcomings of the human evaluation method currently used in the Document Understanding Conference.
C1 Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
RP Nenkova, A (reprint author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
EM ani@cs.columbia.edu; becky@cs.columbia.edu
CR Dixon W. J., 1969, INTRO STAT ANAL
   HALTEREN H, 2003, HLT NAACL DUC WORKSH
   JING HY, 1998, AAAI S INT SUMM
   KLAVANS J, 2003, SIGIR WORKSH SEM WEB
   Krippendorff K., 1980, CONTENT ANAL INTRO I
   Lin C.-Y., 2002, P WORKSH AUT SUMM PO
   Papineni K., 2002, ACL
   PASSONNEAU RJ, 2004, P 4 INT C LANG RES E
   PASSONNEAU RJ, 2003, CUCS02503
   Radev D. R, 2003, ACL
   Rath G. J., 1961, AM DOC, V2, P139
NR 11
TC 41
Z9 42
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 145
EP 152
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100019
DA 2019-06-15
ER

PT B
AU Liu, Y
   Liu, Q
   Lin, SX
AF Liu, Yang
   Liu, Qun
   Lin, Shouxun
GP COLING
TI Tree-to-String Alignment Template for Statistical Machine Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a novel translation model based on tree-to-string alignment template (TAT) which describes the alignment between a source parse tree and a target string. A TAT is capable of generating both terminals and non-terminals and performing reordering at both low and high levels. The model is linguistically syntax-based because TATs are extracted automatically from word-aligned, source side parsed parallel texts. To translate a source sentence, we first employ a parser to produce a source parse tree and then apply TATs to transform the tree into a target string. Our experiments show that the TAT-based model significantly outperforms Pharaoh, a state-of-the-art decoder for phrase-based models.
C1 [Liu, Yang; Liu, Qun; Lin, Shouxun] Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
RP Liu, Y (reprint author), Chinese Acad Sci, Inst Comp Technol, 6 Kexueyuan S Rd, Beijing 100080, Peoples R China.
EM yliu@ict.ac.cn; liuqun@ict.ac.cn; sxlin@ict.ac.cn
CR Alshawi H, 2000, COMPUT LINGUIST, V26, P45, DOI 10.1162/089120100561629
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHEN SF, 1998, TR1098 HARV U CTR RE
   Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Ding Y., 2005, P 43 ANN M ASS COMP, P541, DOI DOI 10.3115/1219840.1219907
   GALLEY M, 2004, P HUM LANG TECHN C N, P273
   GRAEHL J, 2004, P HUM LANG TECHN C N, P105
   KOEHN P, 2003, P HLT NAACL, P127
   Koehn P., 2004, P 6 C ASS MACH TRANS, P115
   Liu Y, 2005, P 43 ANN M ASS COMP, P459
   Marcu D, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P133
   MELAMED D, 2004, P ACL, P653
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Och F. J., 2002, P 40 ANN M ASS COMP, P295
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Quirk Chris, 2005, P 43 ANN M ASS COMP, P271, DOI DOI 10.3115/1219840.1219874
   Stolcke A., 2002, P INT C SPOK LANG PR, P901
   VENUGOPAL A, 2005, P 10 C EUR ASS MACH
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   XIONG DY, 2005, P IJCNLP 2005, P70
   YAMADA K, 2001, P 39 ANN M ASS COMP, P523
   Zhang Y., 2004, P 4 INT C LANG RES E, P2051
NR 24
TC 39
Z9 39
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 609
EP 616
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200077
DA 2019-06-15
ER

PT B
AU Peng, FC
   McCallum, A
AF Peng, FC
   McCallum, A
GP acl
TI Accurate information extraction from research papers using conditional
   random fields
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB With the increasing use of research paper search engines, such as CiteSeer, for both literature search and hiring decisions, the accuracy of such systems is of paramount importance. This paper employs Conditional Random Fields (CRFs) for the task of extracting various common fields from the headers and citation of research papers. The basic theory of CRFs is becoming well-understood, but best-practices for applying them to real-world data requires additional exploration. This paper makes an empirical exploration of several factors, including variations on Gaussian, exponential and hyperbolic-L, priors for improved regularization, and several classes of features and Markov order. On a standard benchmark data set, we achieve new state-of-the-art performance, reducing error in average F1 by 36%, and word error rate by 78% in comparison with the previous best SVM results. Accuracy compares even more favorably against HMMs.
C1 Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA.
RP Peng, FC (reprint author), Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA.
CR Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452
   GOODMAN J, 2003, EXPONENTIAL PRIORS M
   Han H., 2003, P JOINT C DIG LIB
   Lafferty J, 2001, P INT C MACH LEARN 2
   LAWRENCE S, 1999, IEEE COMPUT, V32, P67
   MALOUF R, 2002, P 6 C NAT LANG LEARN
   McCallum A., 2003, P C UNC ART INT UAI
   McCallum A., 2003, P 7 C NAT LANG LEARN
   McCallum AK, 2000, INFORM RETRIEVAL, V3, P127, DOI 10.1023/A:1009953814988
   NEY H, 1995, IEEE T PATTERN ANAL, V17, P1202, DOI 10.1109/34.476512
   PIETRA S, 1995, IEEE T PATTERN ANAL, V19
   PINTO D, 2003, P 26 ANN INT ACM SIG
   Seymore K., 1999, P AAAI 99 WORKSH MAC
   SHA F, 2003, P HUM LANG TECHN C N
   TAKASU A, 2003, P JOINT C DIG LIB
NR 15
TC 38
Z9 40
U1 0
U2 2
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 329
EP 336
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100042
DA 2019-06-15
ER

PT B
AU Kate, RJ
   Mooney, RJ
AF Kate, Rohit J.
   Mooney, Raymond J.
GP COLING
TI Using String-Kernels for Learning Semantic Parsers
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a new approach for mapping natural language sentences to their formal meaning representations using string-kernel-based classifiers. Our system learns these classifiers for every production in the formal language grammar. Meaning representations for novel natural language sentences are obtained by finding the most probable semantic parse using these string classifiers. Our experiments on two real-world data sets show that this approach compares favorably to other existing systems and is particularly robust to noise.
C1 [Kate, Rohit J.; Mooney, Raymond J.] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.
RP Kate, RJ (reprint author), Univ Texas Austin, Dept Comp Sci, 1 Univ Stn C0500, Austin, TX 78712 USA.
EM rjkate@cs.utexas.edu; mooney@cs.utexas.edu
CR CHEN M, 2003, USERS MANUAL ROBOCUP
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Earley J, 1970, COMMUN ACM, V6, P451
   Kate R. J., 2005, P 20 NAT C ART INT A, V20, P1062
   KATE RJ, 2005, UTAI05326
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687
   MILLER S, 1996, P 34 ANN M ASS COMP, P55
   Mooney R. J., 2005, P 9 C COMP NAT LANG, P9
   Mooney R. J., 2001, P 12 EUR C MACH LEAR, P466
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   POPESCU A, 2004, P 20 INT C COMP LING
   PRICE P, 1990, P DARPA SPEECH NAT L, P91
   STOLCKE A, 1995, COMPUT LINGUIST, V21, P165
   WONG YW, 2006, P HUM LANG IN PRESS
   Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050
   Zettlemoyer L. S., 2005, P 21 C UNC ART INT U
   Zue VW, 2000, P IEEE, V88, P1166, DOI 10.1109/5.880078
NR 18
TC 35
Z9 35
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 913
EP 920
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200115
DA 2019-06-15
ER

PT B
AU Xiong, DY
   Liu, Q
   Lin, SX
AF Xiong, Deyi
   Liu, Qun
   Lin, Shouxun
GP COLING
TI Maximum Entropy Based Phrase Reordering Model for Statistical Machine
   Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We propose a novel reordering model for phrase-based statistical machine translation (SMT) that uses a maximum entropy (MaxEnt) model to predicate reorderings of neighbor blocks (phrase pairs). The model provides content-dependent, hierarchical phrasal reordering with generalization based on features automatically learned from a real-world bitext. We present an algorithm to extract all reordering events of neighbor blocks from bilingual data. In our experiments on Chinese-to-English translation, this MaxEnt-based reordering model obtains significant improvements in BLEU score on the NIST MT-05 and IWSLT-04 tasks.
C1 [Xiong, Deyi; Liu, Qun; Lin, Shouxun] Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
RP Xiong, DY (reprint author), Chinese Acad Sci, Inst Comp Technol, Beijing 100080, Peoples R China.
EM dyxiong@ict.ac.cn; liuqun@ict.ac.cn; sxlin@ict.ac.cn
CR Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   FOX HJ, 2002, P EMNLP 2002
   Knight Kevin, 1999, COMPUTATIONAL LINGUI, V25
   Koehn P., 2003, P HLT NAACL
   Koehn P, 2005, INT WORKSH SPOK LANG
   Koehn P., 2004, P 6 C ASS MACH TRANS, P115
   Kumar S., 2005, P HLT EMNLP
   Liang Huang, 2005, P 9 INT WORKSH PARS, P53
   MALOUF R, 2002, P 6 C NAT LANG LEARN
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   OCH FJ, 2004, NIST MACH TRANSL EV
   OCH FJ, 2003, THESIS
   QUINLAN JR, 1993, C4 5 PROGARMS MACHIN
   Sumita E., 2004, P 20 INT C COMP LING, P205
   Tillmann C., 2005, P 43 ANN M ASS COMP, P557
   TILLMANN C, 2004, HLT NAACL BOST MA US
   VENUGOPAL A, 2005, P EAMT 05 BUD HUNG M
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   WU D, 1996, P ACL 1996
   Zhang Y., 2004, P 4 INT C LANG RES E, P2051
NR 22
TC 35
Z9 35
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 521
EP 528
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200066
DA 2019-06-15
ER

PT B
AU Wiebe, J
   Mihalcea, R
AF Wiebe, Janyce
   Mihalcea, Rada
GP COLING
TI Word Sense and Subjectivity
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Subjectivity and meaning are both important properties of language. This paper explores their interaction, and brings empirical evidence in support of the hypotheses that (1) subjectivity is a property that can be associated with word senses, and (2) word sense disambiguation can directly benefit from subjectivity annotations.
C1 [Wiebe, Janyce] Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA.
RP Wiebe, J (reprint author), Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA.
EM wiebe@cs.pitt.edu; rada@cs.unt.edu
CR DAVE K, 2003, P WWW 2003 BUD HUNG
   Esuli A., 2005, P CIKM 2005
   Hatzivassiloglou V., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640
   Heise D.R., 2001, ELECT J SOCIOLOGY, V5
   Hu M., 2004, P ACM SIGKDD
   Jiang J. J., 1997, P INT C RES COMP LIN
   KAMPS J, 2002, P 1 INT WORDNET C
   KIM SM, 2004, P COL 2004
   LEE YK, 2002, P EMNLP 2002
   LEWIS D, 1992, P ACM SIGIR
   Lin D., 1998, P COLING ACL MONTR C
   McCarthy D., 2004, P ACL 2004
   Mihalcea R., 2004, P ACL SIGLEX SENS 3
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   NG HT, 1996, P ACL 1996
   Pang B., 2004, P ACL 2004
   POPESCU A, 2005, P HLT EMNLP 2005
   Quirk R., 1985, COMPREHENSIVE GRAMMA
   RILOFF E, 2005, P AAAI 2005
   Riloff E., 2003, P EMNLP 2003
   STOYANOV V, 2005, P HLT EMNLP 2005
   Turney P.D., 2002, P ACL 2002
   Wiebe J., 2000, P AAAI 2000
   Wiebe J., 2005, LANGUAGE RESOURCES E, V1
   YI J, 2003, P ICDM 2003
   Yu H., 2003, P EMNLP 2003
NR 26
TC 32
Z9 32
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1065
EP 1072
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200134
DA 2019-06-15
ER

PT B
AU Barzilay, R
   Lee, L
AF Barzilay, R
   Lee, L
GP acl
TI Catching:the drift: Probabilistic content models, with applications to
   generation and summarization
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We consider the problem of modeling the content structure of texts within a specific domain, in terms of the topics the texts address and the order in which these topics appear. We first present an effective knowledge-lean method for learning content models from unannotated documents, utilizing a novel adaptation of algorithms for Hidden Markov Models. We then apply our method to two complementary tasks: information ordering and extractive summarization. Our experiments show that incorporating content models in these applications yields substantial improvement over previously-proposed methods.
C1 MIT, Comp Sci & AI Lab, Cambridge, MA 02139 USA.
RP Barzilay, R (reprint author), MIT, Comp Sci & AI Lab, Cambridge, MA 02139 USA.
EM regina@csail.mit.edu; llee@cs.cornell.edu
CR AMBOW O, 1990, 5 INT WORKSH NAT LAN, P87
   [Anonymous], 1999, P EUROSPEECH, P2167
   Bartlett F. C., 1932, REMEMBERING STUDY EX
   Barzilay R, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P16
   Beeferman D., 1997, P 2 C EMP METH NAT L, P35
   CHEN SF, 1998, P ICASSP 98, V2, P681
   DEJONG G, 1982, STRATEGIES NATURAL L, P149
   Duboue PA, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P121
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   Florian Radu, 1999, P ACL, P167
   Harris Z, 1982, SUBLANGUAGE STUDIES, P231
   HEARST MA, 1994, P 32 ANN M ASS COMP, P9
   Iyer R, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P236, DOI 10.1109/ICSLP.1996.607085
   JONES DR, 2003, P CONLL, P135
   Kittredge R., 1991, Computational Intelligence, V7, P305, DOI 10.1111/j.1467-8640.1991.tb00403.x
   Kupiec J, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P55
   LAPATA M, 2003, P 41 M ASS COMP LING, P545
   Mann W, 1988, TEXT, V8, P243, DOI DOI 10.1515/TEXT.1.1988.8.3.243
   MARCU D, 1997, P 35 ANN M ASS COMP, P96
   McKeown KR, 1985, TEXT GENERATION USIN
   Press W, 1997, NUMERICAL RECIPES C
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Radev DR, 1998, COMPUT LINGUIST, V24, P469
   Reynar J. C., 1997, P 5 C APPL NAT LANG, P16
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   SORICUT R, 2003, P 1 HUM LANG TECHN C, P228
   WHITE M, 2001, P HLT C, P263
   Wray A., 2002, FORMULAIC LANGUAGE L
   WU J, 2002, P ICASSP, V1, P777
NR 29
TC 32
Z9 32
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 113
EP 120
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100015
DA 2019-06-15
ER

PT B
AU Wei, W
   Gulla, JA
AF Wei, Wei
   Gulla, Jon Atle
GP Assoc Computat Linguist
TI Sentiment Learning on Product Reviews via Sentiment Ontology Tree
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Existing works on sentiment analysis on product reviews suffer from the following limitations: (1) The knowledge of hierarchical relationships of products attributes is not fully utilized. (2) Reviews or sentences mentioning several attributes associated with complicated sentiments are not dealt with very well. In this paper, we propose a novel HL-SOT approach to labeling a product's attributes and their associated sentiments in product reviews by a Hierarchical Learning (HL) process with a defined Sentiment Ontology Tree (SOT). The empirical analysis against a human-labeled data set demonstrates promising and reasonable performance of the proposed HL-SOT approach. While this paper is mainly on sentiment analysis on reviews of one product, our proposed HL-SOT approach is easily generalized to labeling a mix of reviews of more than one products.
C1 [Wei, Wei; Gulla, Jon Atle] Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, Trondheim, Norway.
RP Wei, W (reprint author), Norwegian Univ Sci & Technol, Dept Comp & Informat Sci, Trondheim, Norway.
EM wwei@idi.ntnu.no; jag@idi.ntnu.no
CR Andreevskaia Alina, 2006, P 11 C EUR CHAPT ASS
   Cesa-Bianchi N, 2006, J MACH LEARN RES, V7, P31
   DAVE K, 2003, P 12 INT WORLD WID W
   Devitt A., 2007, P 45 ANN M ASS COMP
   Ding Xiaowen, 2007, P 30 ANN INT ACM SPE
   Esuli A., 2006, P 5 INT C LANG RES E
   Esuli Andrea, 2005, P 14 ACM C INF KNOWL
   Hatzivassiloglou V., 1997, P 35 ANN M ASS COMP
   Hu M., 2004, P 10 ACM SIGKDD C KN
   Kamps J., 2004, P 4 INT C LANG RES E
   Li Zhuang, 2006, P 15 ACM INT C INF K
   Liu B., 2005, P 14 INT WORLD WID W
   Liu Yang, 2007, P 30 ANN INT ACM SPE
   Lu Y., 2008, P 17 INT WORLD WID W
   Lu Y., 2009, P 18 INT WORLD WID W
   Popescu A. -M., 2005, P HUM LANG TECHN C E
   Titov I., 2008, P 17 INT WORLD WID W
   Turney P., 2002, P 40 ANN M ASS COMP
   Whitelaw C., 2005, P 14 ACM C INF KNOWL
   Wiebe J. M., 2000, P 18 INT C COMP LING
   WILSON T., 2005, P HUM LANG TECHN C E
   Yu H., 2003, P 8 C EMP METH NAT L
   Zhou L, 2008, J AM SOC INF SCI TEC, V59, P98, DOI 10.1002/asi.20735
NR 23
TC 31
Z9 31
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 404
EP 413
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300042
DA 2019-06-15
ER

PT B
AU Galley, M
   Graehl, J
   Knight, K
   Marcu, D
   DeNeefe, S
   Wang, W
   Thayer, I
AF Galley, Michel
   Graehl, Jonathan
   Knight, Kevin
   Marcu, Daniel
   DeNeefe, Steve
   Wang, Wei
   Thayer, Ignacio
GP COLING
TI Scalable Inference and Training of Context-Rich Syntactic Translation
   Models
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Statistical NIT has made great progress in the last few years, but current translation models are weak on re-ordering and target language fluency. Syntactic approaches seek to remedy these problems. In this paper, we take the framework for acquiring multi-level syntactic translation rules of (Galley et al., 2004) from aligned tree-string pairs, and present two main extensions of their approach: first, instead of merely computing a single derivation that minimally explains a sentence pair, we construct a large number of derivations that include contextually richer rules, and account for multiple interpretations of unaligned words. Second, we propose probability estimates and a training procedure for weighting these rules. We contrast different approaches on real examples, show that our estimates based on multiple derivations favor phrasal re-orderings that are linguistically better motivated, and establish that our larger rules provide a 3.63 BLEU point increase over minimal rules.
C1 [Galley, Michel] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
RP Galley, M (reprint author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
EM galley@cs.columbia.edu; graehl@isi.edu; knight@isi.edu; marcu@isi.edu;
   sdeneefe@isi.edu; wwang@languageweaver.com; thayer@google.com
CR CHIANG D, 2005, P ACL
   Fox HJ, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P304
   GALLEY M, 2004, P HLT NAACL 04
   GRAEHL J, 2004, P HUM LANG TECHN C N, P105
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Poutsma A, 2000, P 18 INT C COMP LING, P635
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   YAMADA K, 2001, P 39 ANN M ASS COMP, P523
   Zhang Hao, 2006, P HLT NAACL
NR 9
TC 31
Z9 31
U1 0
U2 3
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 961
EP 968
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200121
DA 2019-06-15
ER

PT B
AU McClosky, D
   Charniak, E
   Johnson, M
AF McClosky, David
   Charniak, Eugene
   Johnson, Mark
GP COLING
TI Reranking and Self-Training for Parser Adaptation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Statistical parsers trained and tested on the Penn Wall Street Journal (WSJ) treebank have shown vast improvements over the last 10 years. Much of this improvement, however, is based upon an ever-increasing number of features to be trained on (typically) the WSJ treebank data. This has led to concern that such parsers may be too finely tuned to this corpus at the expense of portability to other genres. Such worries have merit. The standard "Charniak parser" checks in at a labeled precision-recall f-measure of 89.7% on the Penn WSJ test set, but only 82.9% on the test set from the Brown treebank corpus.
   This paper should allay these fears. In particular, we show that the reranking parser described in Charniak and Johnson (2005) improves performance of the parser on Brown to 85.2%. Furthermore, use of the self-training techniques described in (MeClosky et al., 2006) raise this to 87.8% (an error reduction of 28%) again without any use of labeled Brown data. This is remarkable since training the parser and reranker on labeled Brown data achieves only 88.4%.
C1 [McClosky, David; Charniak, Eugene; Johnson, Mark] Brown Univ, BLLIP, Providence, RI 02912 USA.
RP McClosky, D (reprint author), Brown Univ, BLLIP, Providence, RI 02912 USA.
EM dmcc@cs.brown.edu; ec@cs.brown.edu; mj@cs.brown.edu
OI Johnson, Mark/0000-0003-4809-8441
CR Bacchiani M, 2006, COMPUT SPEECH LANG, V20, P41, DOI 10.1016/j.csl.2004.12.12.001
   Charniak E, 2005, P 43 ANN M ASS COMP, P173, DOI DOI 10.3115/1219840.1219862
   CLEGG AB, 2005, P ACL WORKSH SOFTW
   Cohen P. R., 1995, EMPIRICAL METHODS AR
   COLLINS M, 2000, MACH LEARN, P175
   Francis W. Nelson, 1979, MANUAL INFORM ACCOMP
   GILDEA D, 2001, EMPIRICAL METHODS NA, P167
   Graff David, 1995, LDC95T21
   HWA R, 1999, P 37 ANN M ASS COMP, P72
   LEASE M, 2005, 2 INT JOINT C NAT LA
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   MCCLOSKY D, 2006, P HLT NAACL 2006
   Ratnaparkhi A, 1999, MACH LEARN, V34, P151, DOI 10.1023/A:1007502103375
   Sekine Satoshi, 1997, P 5 C APPL NAT LANG, P96
   STEEDMAN M, 2003, P 11 C EUR CHAPT ASS, P331
NR 15
TC 31
Z9 31
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 337
EP 344
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200043
DA 2019-06-15
ER

PT B
AU Chiticariu, L
   Krishnamurthy, R
   Li, YY
   Raghavan, S
   Reiss, FR
   Vaithyanathan, S
AF Chiticariu, Laura
   Krishnamurthy, Rajasekar
   Li, Yunyao
   Raghavan, Sriram
   Reiss, Frederick R.
   Vaithyanathan, Shivakumar
GP Assoc Computat Linguist
TI SystemT: An Algebraic Approach to Declarative Information Extraction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB As information extraction (IE) becomes more central to enterprise applications, rule-based IE engines have become increasingly important. In this paper, we describe SystemT, a rule-based IE system whose basic design removes the expressivity and performance limitations of current systems based on cascading grammars. SystemT uses a declarative rule language, AQL, and an optimizer that generates high-performance algebraic execution plans for AQL rules. We compare SystemT's approach against cascading grammars, both theoretically and with a thorough experimental evaluation. Our results show that SystemT can deliver result quality comparable to the state-of-theart and an order of magnitude higher annotation throughput.
C1 [Chiticariu, Laura; Krishnamurthy, Rajasekar; Li, Yunyao; Raghavan, Sriram; Reiss, Frederick R.; Vaithyanathan, Shivakumar] IBM Res Almaden, San Jose, CA 95120 USA.
RP Chiticariu, L (reprint author), IBM Res Almaden, San Jose, CA 95120 USA.
EM chiti@us.ibm.com; sekar@us.ibm.com; yunyaoli@us.ibm.com;
   rsriram@us.ibm.com; frreiss@us.ibm.com; vaithyan@us.ibm.com
CR Appelt D., 1998, TIPSTER WORKSH
   Boguraev Branimir, 2003, RANLP, P61
   Chamberlin D. D., 1981, VLDB
   Chandel A., 2006, ICDE
   Codd E. F, 1990, RELATIONAL MODEL DAT
   CUNNINGHAM H, 2002, P 40 ANN M ASS COMP, P168, DOI DOI 10.3115/1073083.1073112
   Cunningham H., 2000, CS0010 U SHEFF
   Cunningham Hamish, 2010, DEV LANGUAGE PROCESS, P01
   Doan AnHai, 2008, SIGMOD RECORD, V37
   DROZDZYNSKI W, 2004, KUNSTLICHE INTELLIGE, V1, P17
   Grishman R, 1996, P INT C COMP LING CO, P466, DOI DOI 10.3115/992628.992709
   IBM, 2010, IBM LANGUAGEWARE
   Ipeirotis P. G., 2006, SIGMOD
   Jain A., 2009, ICDE
   MAYNARD D, 2003, RECENT ADV NATURAL L
   MINKOV E, 2005, HLT EMNLP
   NIST, 2005, ACE EV PLAN
   Ramakrishnan G., 2006, EMNLP
   Ramakrishnan Ganesh, 2008, INFOSCALE
   Reiss F, 2008, PROC INT CONF DATA, P933, DOI 10.1109/ICDE.2008.4497502
   SAP, 2010, INX THINGFINDER
   SAS, 2010, TEXT MIN SAS TEXT MI
   Shen W., 2007, VLDB
   SystemT, 2010, AQL MAN
   Thompson Ken, 1968, REGULAR EXPRESSION S, P419
NR 25
TC 30
Z9 30
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 128
EP 137
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300014
DA 2019-06-15
ER

PT B
AU Malioutov, I
   Barzilay, R
AF Malioutov, Igor
   Barzilay, Regina
GP COLING
TI Minimum Cut Model for Spoken Lecture Segmentation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID TEXT SEGMENTATION
AB We consider the task of unsupervised lecture segmentation. We formalize segmentation as a graph-partitioning task that optimizes the normalized cut criterion. Our approach moves beyond localized comparisons and takes into account long-range cohesion dependencies. Our results demonstrate that global analysis improves the segmentation accuracy and is robust in the presence of speech recognition errors.
C1 [Malioutov, Igor; Barzilay, Regina] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
RP Malioutov, I (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
EM igorm@csail.mit.edu; regina@csail.mit.edu
CR Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214
   Choi F., 2000, P 1 N AM CHAPT ASS C, P26
   Choi FYY, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P109
   Church K. W., 1993, P 31 ANN M ASS COMP, P1
   GALLEY M, 2003, P 41 ANN M ASS COMP, P562
   Glass JR, 2003, COMPUT SPEECH LANG, V17, P137, DOI 10.1016/S0885-2308(03)00006-8
   GRUENSTEIN A, 2005, P 6 SIGDIAL WORKSH D, P117
   Halliday M. A. K., 1976, COHESION ENGLISH
   HEARST MA, 1994, P 32 ANN M ASS COMP, P9
   JI X, 2003, P 26 ANN INT ACM SIG, P322
   Kehagias A., 2003, P 10 C EUR CHAPT ASS, P171
   Leeuwis E., 2003, P ICASSP
   Pevzner L, 2002, COMPUT LINGUIST, V28, P19, DOI 10.1162/089120102317341756
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   REYNAR J., 1998, THESIS U PENNSYLVANI
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615
   Utiyama M., 2001, P 39 ANN M ASS COMP, P499, DOI DOI 10.3115/1073012.1073076
NR 19
TC 30
Z9 30
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 25
EP 32
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200004
DA 2019-06-15
ER

PT B
AU Beaufort, R
   Roekhaut, S
   Cougnon, LA
   Fairon, C
AF Beaufort, Richard
   Roekhaut, Sophie
   Cougnon, Louise-Amelie
   Fairon, Cedrick
GP Assoc Computat Linguist
TI A hybrid rule/model-based finite-state framework for normalizing SMS
   messages
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In recent years, research in natural language processing has increasingly focused on normalizing SMS messages. Different well-defined approaches have been proposed, but the problem remains far from being solved: best systems achieve a 11% Word Error Rate. This paper presents a method that shares similarities with both spell checking and machine translation approaches. The normalization part of the system is entirely based on models trained from a corpus. Evaluated in French by 10-fold-cross validation, the system achieves a 9.3% Word Error Rate and a 0.83 BLEU score.
C1 [Beaufort, Richard; Cougnon, Louise-Amelie; Fairon, Cedrick] Catholic Univ Louvain, CENTAL, B-1348 Louvain La Neuve, Belgium.
   [Roekhaut, Sophie] Univ Mons, TCTS Lab, B-7000 Mons, Belgium.
RP Beaufort, R (reprint author), Catholic Univ Louvain, CENTAL, B-1348 Louvain La Neuve, Belgium.
EM richard.beaufort@uclouvain.be; sophie.roekhaut@umons.ac.be;
   louise-amelie.cougnon@uclouvain.be; cedrick.fairon@uclouvain.be
CR Aw AiTi, 2006, P COLING ACL 2006
   Bangalore S., 2002, P 19 INT C COMP LING, P1
   Beaufort Richard, 2008, THESIS
   Bieswanger Markus, 2007, TEXAS LINGUISTICS FO, V50
   Chomsky Noam, 1968, SOUND PATTERN ENGLIS
   Choudhury M, 2007, INT J DOC ANAL RECOG, V10, P157, DOI 10.1007/s10032-007-0054-0
   Colotte V., 2005, P INT 2005, P2549
   Cook P., 2009, P WORKSH COMP APPR L, P71
   Cougnon Louise- Amelie, 2009, P ELEXICOGR IN PRESS
   de Neef Emilie Guimier, 2007, ACT C TRAIT AUT LANG, P123
   Fairon Cedrick, 2006, LANGAGE SMS ETUDE CO
   Fairon Cedrick, 2006, P LREC 2006 MAY
   Goodman Joshua, 1998, 1098 HARV U COMP SCI
   Johnson CD, 1972, FORMAL ASPECTS PHONO
   Kobus C., 2008, ACT C TRAIT AUT LANG, P128
   Kobus Catherine, 2008, P 22 INT C COMP LING, P441
   Kohavi R., 1995, P 14 INT JOINT C ART, P1137
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Mohri M, 2001, LECT NOTES COMPUT SC, V2088, P230
   Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6
   Mohri M., 1997, P EUROSPEECH 97, P131
   Mohri M, 1996, P 34 ANN M ASS COMP, P231
   PAPINENI K, 2001, P 40 ANN M ASS COMP, P311
   Roche E, 1997, FINITE STATE LANGUAG
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sproat R, 2000, COMPUT SPEECH LANG, V15, P287
   Thurlow C, 2003, DISCOURSE ANAL ONLIN, V1, P1
   TOUTANOVA K, 2002, P 40 ANN M ASS COMP, P144
   Yvon Francois, 2008, REORTHOGRAPHY SMS ME
NR 29
TC 29
Z9 29
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 770
EP 779
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300079
DA 2019-06-15
ER

PT B
AU Chen, HH
   Lin, MS
   Wei, YC
AF Chen, Hsin-Hsi
   Lin, Ming-Shun
   Wei, Yu-Chuan
GP COLING
TI Novel Association Measures Using Web Search with Double Checking
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID SEMANTIC SIMILARITY
AB A web search with double checking model is proposed to explore the web as a live corpus. Five association measures including variants of Dice, Overlap Ratio, Jaccard, and Cosine, as well as Co-Occurrence Double Check (CODC), are presented. In the experiments on Rubenstein-Goodenough's benchmark data set, the CODC measure achieves correlation coefficient 0.8492, which competes with the performance (0.8914) of the model using WordNet. The experiments on link detection of named entities using the strategies of direct association, association matrix and scalar association matrix verify that the double-check frequencies are reliable. Further study on named entity clustering shows that the five measures are quite useful. In particular, CODC measure is very stable on word-word and name-name experiments. The application of CODC measure to expand community chains for personal name disambiguation achieves 9.65% and 14.22% increase compared to the system without community expansion. All the experiments illustrate that the novel model of web search with double checking is feasible for mining associations from the web.
C1 [Chen, Hsin-Hsi; Lin, Ming-Shun; Wei, Yu-Chuan] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.
RP Chen, HH (reprint author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.
EM hhchen@csie.ntu.edu.tw; mslin@nlg.csie.ntu.edu.tw;
   ycwei@nlg.csie.ntu.edu.tw
CR Bagga A., 1998, P 36 ANN M ASS COMP, P79
   Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604
   Li YH, 2003, IEEE T KNOWL DATA EN, V15, P871, DOI 10.1109/TKDE.2003.1209005
   Lin Dekang, 1998, P 15 INT C MACH LEAR, P296
   LIN HC, 2004, P 16 ROCLING C, P89
   LIN MS, 2005, P 17 ROCLING C, P361
   LIN MS, 2006, P 5 INT C LANG RES E
   MATSUO Y, 2004, P 16 EUR C ART INT, P510
   Resnik P, 2003, COMPUT LINGUIST, V29, P349, DOI 10.1162/089120103322711578
   Resnik P., 1995, P 14 INT JOINT C ART, P448
   Rodriguez MA, 2003, IEEE T KNOWL DATA EN, V15, P442, DOI 10.1109/TKDE.2003.1185844
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   WEI YC, 2006, THESIS NATL TAIWAN U
NR 13
TC 28
Z9 28
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1009
EP 1016
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200127
DA 2019-06-15
ER

PT B
AU Daume, H
   Marcu, D
AF Daume, Hal, III
   Marcu, Daniel
GP COLING
TI Bayesian Query-Focused Summarization
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present BAYESUM (for "Bayesian summarization"), a model for sentence extraction in query-focused summarization. BAYESUM leverages the common case in which multiple documents are relevant to a single query. Using these documents as reinforcement for query terms, BAYESUM is not afflicted by the paucity of information in short queries. We show that approximate inference in BAYESUM is possible on large data sets and results in a state-of-the-art summarization system. Furthermore, we show how BAYESUM can be understood as a justified query expansion technique in the language modeling for IR framework.
C1 [Daume, Hal, III; Marcu, Daniel] Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Daume, H (reprint author), Inst Informat Sci, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
EM me@ha13.name; marcu@isi.edu
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   BUCKLEY C, 1995, P C RES DEV INF RETR
   Callan J. P., 1992, P 3 INT C DAT EXP SY
   DAUME H, 2005, DOCUMENT UNDERSTANDI
   DAUME H, 2005, ACL 2005 WORKSH INTR
   LAFFERTY J, 2001, P C RES DEV INF RETR
   LAVRENKO V, 2002, P C RES DEV INF RETR
   LIU XY, 2002, PROC C INF KNOWL MAN
   MINKA T, 2003, P C UNC ART INT UAI
   Minka T. P., 2001, THESIS MIT CAMBRIDGE
   MURDOCK V, 2005, P HLT EMNLP, P684
   OTTERBACHER J, 2005, P JOINT C HUM LANG T
   PONTE JM, 1998, P C RES DEV INF RETR
   Wallach H., 2006, P INT C MACH LEARN I
   ZHANG Y, 2002, P C RES DEV INF RETR
NR 15
TC 27
Z9 27
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 305
EP 312
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200039
DA 2019-06-15
ER

PT B
AU Purver, M
   Kording, KP
   Griffiths, TL
   Tenenbaum, JB
AF Purver, Matthew
   Koerding, Konrad P.
   Griffiths, Thomas L.
   Tenenbaum, Joshua B.
GP COLING
TI Unsupervised Topic Modelling for Multi-Party Spoken Discourse
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID TEXT SEGMENTATION
AB We present a method for unsupervised topic modelling which adapts methods used in document classification (Blei et al., 2003; Griffiths and Steyvers, 2004) to unsegmented multi-party discourse transcripts. We show how Bayesian inference in this generative model can be used to simultaneously address the problems of topic segmentation and topic identification: automatically segmenting multi-party meetings into topically coherent segments with performance which compares well with previous unsupervised segmentation-only methods (Galley et al., 2003) while simultaneously extracting topics which rate highly when assessed for coherence by human judges. We also show that this method appears robust in the face of off-topic dialogue and speech recognition errors.
C1 [Purver, Matthew] Stanford Univ, Stanford, CA 94305 USA.
RP Purver, M (reprint author), Stanford Univ, Stanford, CA 94305 USA.
EM mpurver@stanford.edu; kording@mit.edu; tom_griffiths@brown.edu;
   jbt@mit.edu
RI Kording, Konrad/A-1233-2007
OI Kording, Konrad/0000-0001-8408-4499; Purver, Matthew/0000-0003-2297-1273
CR BANERJEE S, 2005, P 10 INT C HUM COMP
   BANERJEE S, 2004, P 8 INT C SPOK LANG
   Barzilay R, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P113
   Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   BLEI DM, 2001, P 24 ANN INT ACM SIG, P343
   DIELMANN A, 2004, P IEEE INT C AC SPEE
   GALLEY M, 2003, P 41 ANN M ASS COMP, P562
   Gilks W., 1996, MARKOV CHAIN MONTE C
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hearst Marti A., 1994, P 32 M ASS COMP LING
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   IMAI T, 1997, P INT C AC SPEECH SI, P727
   JANIN A, 2003, P ICASSP, P364
   LISOWSKA A, 2004, P 4 INT C LANG RES E
   MASKEY S, 2003, EUROSPEECH 2003
   Pevzner L, 2002, COMPUT LINGUIST, V28, P19, DOI 10.1162/089120102317341756
   REITER S, 2004, P INT C PATT REC
   Reynar Jeffrey C, 1999, P 37 ANN M ASS COMP, V20, P357
NR 19
TC 27
Z9 27
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 17
EP 24
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200003
DA 2019-06-15
ER

PT B
AU Galley, M
   Hopkins, M
   Knight, K
   Marcu, D
AF Galley, M
   Hopkins, M
   Knight, K
   Marcu, D
GP acl
TI What's in a translation rule?
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We propose a theory that gives formal semantics to word-level alignments defined over parallel corpora. We use our theory to introduce a linear algorithm that can be used to derive from word-aligned, parallel corpora the minimal set of syntactically motivated transformation rules that explain human translation data.
C1 Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
RP Galley, M (reprint author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
CR Charniak E, 2003, P MT SUMM 9
   Collins Michael, 1999, THESIS U PENNSYLVANI
   EISNER J, 2003, P 41 M ASS COMP LING
   Fox H. J., 2002, P C EMP METH NAT LAN
   GILDEA D, 2003, P 41 ANN C ASS COMP
   Koehn P., 2003, P HLT NAACL
   Ney Hermann, 2000, P 38 ANN M ASS COMP
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   YAMADA K, 2001, ACL, P523
NR 10
TC 27
Z9 31
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 273
EP 280
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100035
DA 2019-06-15
ER

PT B
AU Galley, M
   McKeown, K
   Fosler-Lussier, E
   Jing, HY
AF Galley, M
   McKeown, K
   Fosler-Lussier, E
   Jing, HY
GP ACL
TI Discourse segmentation of multi-party conversation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
ID TEXT SEGMENTATION
AB We present a domain-independent topic segmentation algorithm for multi-party speech. Our feature-based algorithm combines knowledge about content using a text-based algorithm as a feature and about form using linguistic and acoustic cues about topic shifts extracted from speech. This segmentation algorithm uses automatically induced decision rules to combine the different features. The embedded text-based algorithm builds on lexical cohesion and has performance comparable to state-of-the-art algorithms based on lexical information. A significant error reduction is obtained by combining the two knowledge sources.
C1 Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
CR Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214
   CHOI, 2000, P NAACL 00
   COCHRAN WG, 1950, BIOMETRIKA, V37, P256, DOI 10.1093/biomet/37.3-4.256
   GROSZ B, 1986, COMPUTATIONAL LINGUI, P12
   GROSZ B, 1992, P INT C SPOK LANG PR, P429
   HAJIME M, 1998, COLING ACL, P881
   HEARST MA, 1994, P ACL
   Hirschberg J., 1993, Computational Linguistics, V19, P501
   HIRSCHBERG J, 1998, P ICSLP
   HIRSCHBERG J, 1996, P ACL
   JANIN A, 2003, IN PREXS P ICASSP 03
   KAN M, 1998, P 6 WORKSH VER LARG
   KOZIMA H, 1993, P ACL
   Levinson Stephen C., 1983, PRAGMATICS
   LITMAN DJ, 1995, P ACL
   Morris J., 1991, Computational Linguistics, V17, P21
   NAKATANI C, 1995, AAAI 95 S EMPIRICAL
   PASSONEAU R, 1993, P ACL
   Passonneau RJ, 1997, COMPUT LINGUIST, V23, P103
   Pevzner L, 2002, COMPUT LINGUIST, V28, P19, DOI 10.1162/089120102317341756
   Quinlan R., 1993, C4 5 PROGRAMS MACHIN
   REYNAR J, 1994, P ACL
   REYNAR J, 1999, P ACL
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Tur G, 2001, COMPUT LINGUIST, V27, P31, DOI 10.1162/089120101300346796
   UTIYAMA M, 2001, P ACL
   Xu JX, 1998, ACM T INFORM SYST, V16, P61, DOI 10.1145/267954.267957
NR 27
TC 27
Z9 27
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 562
EP 569
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500071
DA 2019-06-15
ER

PT B
AU Elson, DK
   Dames, N
   McKeown, KR
AF Elson, David K.
   Dames, Nicholas
   McKeown, Kathleen R.
GP Assoc Computat Linguist
TI Extracting Social Networks from Literary Fiction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a method for extracting social networks from literature, namely, nineteenth-century British novels and serials. We derive the networks from dialogue interactions, and thus our method depends on the ability to determine when two characters are in conversation. Our approach involves character name chunking, quoted speech attribution and conversation detection given the set of quotes. We extract features from the social networks and examine their correlation with one another, as well as with metadata such as the novel's setting. Our results provide evidence that the majority of novels in this time period do not fit two characterizations provided by literacy scholars. Instead, our results suggest an alternative explanation for differences in social networks.
C1 [Elson, David K.; McKeown, Kathleen R.] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
   [Dames, Nicholas] Columbia Univ, Dept English, New York, NY 10027 USA.
RP Elson, DK (reprint author), Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
EM delson@cs.columbia.edu; nd122@columbia.edu; kathy@cs.columbia.edu
CR Bakhtin Mikhail Mikhailovic., 1981, DIALOGIC IMAGINATION, P84
   Burrows J., 2004, COMPANION DIGITAL HU
   CHAMBERS N., 2008, P 46 ANN M ASS COMP, P789
   Cho WKT, 2010, J POLIT, V72, P124, DOI 10.1017/S002238160999051X
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Davis P. T., 2003, P 3 ACM IEEE JOINT C
   Eagleton Terry, 2005, ENGLISH NOVEL INTRO
   Elson David K., 2010, P 24 AAAI C ART INT
   Finkel J. R., 2005, P 43 ANN M ASS COMP, P363, DOI DOI 10.3115/1219840.1219885
   Halpin Harry, 2004, P C EMP METH NAT LAN
   Haythornthwaite C., 2008, INT NETW SOC NETW AN
   Lee John, 2007, P 45 ANN M ASS COMP, P472
   McCallum A, 2007, J ARTIF INTELL RES, V30, P249, DOI 10.1613/jair.2229
   Moretti F., 1999, ATLAS EUROPEAN NOVEL
   Moretti Franco, 2005, GRAPHS MAPS TREES AB
   Mostellar Frederick, 1984, APPL BAYESIAN CLASSI
   Strassel, 2004, P 4 INT C LANG RES E, P837
   Williams Raymond, 1975, COUNTRY CITY
NR 18
TC 26
Z9 26
U1 2
U2 4
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 138
EP 147
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300015
DA 2019-06-15
ER

PT B
AU Ng, V
AF Ng, Vincent
GP Assoc Computat Linguist
TI Supervised Noun Phrase Coreference Research: The First Fifteen Years
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID ANAPHORA RESOLUTION
AB The research focus of computational coreference resolution has exhibited a shift from heuristic approaches to machine learning approaches in the past decade. This paper surveys the major milestones in supervised coreference research since its inception fifteen years ago.
C1 [Ng, Vincent] Univ Texas Dallas, Human Language Technol Res Inst, Richardson, TX 75083 USA.
RP Ng, V (reprint author), Univ Texas Dallas, Human Language Technol Res Inst, Richardson, TX 75083 USA.
EM vince@hlt.utdallas.edu
CR Aone C., 1995, P 33 ANN M ASS COMP, P122
   Bagga A., 1998, P 1 INT C LANG RES E, P563
   Bansal N, 2002, ANN IEEE SYMP FOUND, P238, DOI 10.1109/SFCS.2002.1181947
   Barbu C, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P34
   Bean D, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P297
   Bean D., 1999, P 37 ANN M ASS COMP, P373, DOI [10.3115/1034678.1034737, DOI 10.3115/1034678.1034737]
   Bengtson Eric, 2008, P C EMP METH NAT LAN, P294
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Bergsma S., 2008, P 46 ANN M ASS COMP, P10
   Bergsma S, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P33
   Byron DK, 2001, COMPUT LINGUIST, V27, P569, DOI 10.1162/089120101753342671
   Calhoun Sasha, LANGUAGE RE IN PRESS
   Cardie C., 1999, P 1999 JOINT SIGDAT, P82
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Castano Jose, 2002, P 2002 INT S REF RES
   Charniak E, 2009, P 12 C EUR CHAPT ASS, P148
   Charniak Eugene, 1972, 266 AITR MIT
   Cherry Colin, 2005, P 9 C COMP NAT LANG, P88
   Chomsky N., 1988, LANGUAGE PROBLEMS KN
   Cohen W., 1995, P 12 INT C MACH LEAR, P115
   Connolly D, 1997, NEW METHODS LANGUAGE, P133
   Connolly D., 1994, P INT C NEW METH LAN, P255
   Converse S.P., 2006, THESIS
   Culotta  A., 2007, HUM LANG TECHN C N A, P81
   Daelemans W., 2005, MEMORY BASED LANGUAG
   Dagan I., 1990, P 13 INT C COMP LING, P330
   Daume H., 2005, P HUM LANG TECHN C C, P97
   DEMPSTER AP, 1968, J ROY STAT SOC B, V30, P205
   Denis P., 2007, HUMAN LANGUAGE TECHN, P236
   Denis P, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1588
   Denis Pascal, 2008, P 2008 C EMP METH NA, P660
   Evans R., 2001, Literary & Linguistic Computing, V16, P45, DOI 10.1093/llc/16.1.45
   Finkel J. R., 2008, P ACL 08 HLT COL OH, P45
   Finley T., 2005, P 22 INT C MACH LEAR, P217
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Garera N., 2006, P 10 C COMP NAT LANG, P37
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   Grosz B. J., 1983, P 21 ANN M ASS COMP, P44
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   Grosz BJ, 1977, P 5 INT JOINT C ART, P67
   Haghighi Aria, 2007, ANN M ASS COMP LING, P848
   Haghighi Aria, 2010, P HUM LANG TECHN 201
   Haghighi Aria, 2009, P 2009 C EMP METH NA, P1152
   Hajic Jan, 2006, LINGUISTIC DATA CONS
   HEEMAN PA, 1995, TRAINS SPOKEN DIALOG
   Hirst G, 1981, COMPUTATIONAL LINGUI, V7, P85
   HOBBS JR, 1978, LINGUA, V44, P311, DOI 10.1016/0024-3841(78)90006-2
   Hoste V., 2005, THESIS
   Hoste Veronique, 2005, P ICML WORKSH MET
   Hovy E., 2006, P HUM LANG TECHN C N, P57
   Huang Zhiheng, 2009, P 2009 C EMP METH NA, P1232
   Ide Nancy, 2000, P 38 M ASS COMP LING, P416
   Iida R., 2009, P JOINT C 47 ANN M A, P647
   Iida R., 2007, P LING ANN WORKSH, P132
   Iida R., 2003, P EACL WORKSH COMP T
   Iida R, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P625
   Iida Ryu, 2007, THESIS
   Iida Ryu, 2007, ACM T ASIAN LANGUAGE, V6
   Ji Heng, 2005, P HUM LANG TECHN C C, P17
   Joachims Thorsten, 1999, ADV KERNEL METHODS S, P44
   Kehler A, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P289
   Kehler A, 1997, P 2 C EMP METH NAT L, P163
   Kehler Andrew, 2004, P HLT NAACL 2004, P33
   Kennedy C., 1996, P 16 INT C COMP LING, P113, DOI 10.3115/992628.992651
   Klenner M., 2009, P EACL 09, P442
   Klenner  M., 2008, P 2 WORKSH AN RES WA, P31
   Klenner Manfred, 2007, P REC ADV NAT LANG P
   Kong Fang, 2009, P 2009 C EMP METH NA, P987
   Kubler Sandra, 2004, P 4 INT C LANG RES E, P2229
   Lappin S., 1994, Computational Linguistics, V20, P535
   Luo X, 2004, P 42 ANN M ASS COMP, P135, DOI DOI 10.3115/1218955.1218973
   Luo X., 2005, P C HUM LANG TECHN E, P25, DOI DOI 10.3115/1220575.1220579
   Luo X., 2007, HLT NAACL, P73
   Luo Xiaoqiang, 2005, P HUM LANG TECHN C C, P660
   Maiorano S, 2001, P 2 M N AM CHAPT ASS, P55
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Markert K, 2005, COMPUT LINGUIST, V31, P367, DOI 10.1162/089120105774321064
   McCallum A., 2004, ADV NEURAL INFORM PR
   McCallum A., 2003, P IJCAI WORKSH INF I
   McCarthy J, 1995, P 14 INT JOINT C ART, P1050
   Mitkov R, 2001, LECT NOTES COMPUT SC, V2004, P110
   Mitkov  R., 2002, ANAPHORA RESOLUTION
   Mitkov R., 1999, TECHNICAL REPORT
   Modjeska NN, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P176
   Moschitti Alessandro, 2008, P 46 ANN M ASS COMP, P9
   MUC-6, 1995, P 6 MESS UND C
   MUC-7, 1998, P 7 MESS UND C
   Muller Christoph, 2006, P 11 C EUR CHAPT ASS, P49
   Muller Christoph, 2002, P 40 ANN M ASS COMP, P352
   Naumann Karin, 2006, P 5 ED INT C LANG RE, P1167
   Ng V, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P55
   Ng V., 2004, P 42 ANN M ASS COMP, P151, DOI [DOI 10.3115/1218955.1218975, 10.3115/1218955.1218975]
   Ng V., 2009, P NAACL HLT 2009 BOU, P575
   Ng V, 2002, P 19 INT C COMP LING, P730
   Ng V., 2007, P ASS COMP LINGUIST, P536
   Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102
   Ng V, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1689
   Nguy G. L., 2009, P SIGDIAL 2009 C LON, P276
   Nicolae C., 2006, P 2006 C EMP METH NA, P275
   Nilsson KA, 2010, THESIS
   Niyu G., 1998, P 6 WORKSH VER LARG, P161
   Ohta T, 2002, P 2 INT C HUM LANG T, P82
   Orasan C, 2007, J ARTIF INTELL RES, V29, P79, DOI 10.1613/jair.2179
   Orasan C, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P2801
   Paice C. D., 1987, Computer Speech and Language, V2, P109, DOI 10.1016/0885-2308(87)90003-9
   Poesio M., 2004, P 42 ANN M ASS COMP, P143
   Poesio M., 2004, P ACL WORKSH REF RES
   Poesio Massimo, 2007, SUMM WORKSH LANG ENG
   Poesio Massimo, 2004, P 4 INT C LANG RES E, P663
   Ponzetto S. P., 2006, P 11 M EUR CHAP ASS, P143
   Ponzetto SP, 2007, J ARTIF INTELL RES, V30, P181, DOI 10.1613/jair.2308
   Ponzetto Simone Paolo, 2006, HUM LANG TECHN C N A, P192
   Ponzetto Simone Paolo, 2009, ACL IJCNLP 2009, P6
   Poon Hoifung, 2008, P 2008 C EMP METH NA, P650
   Popescu-Belis A, 2004, P INT C LANG RES EV, P1507
   Qiu L., 2004, P 4 INT C LANG RES E, P291
   Quinlan J. R, 1993, C4 5 PROGRAMS MACHIN
   Rahman A, 2009, P 2009 C EMP METH NA, V2, P968
   Recasens M, 2009, P NAACL 2009 WORKSH, P70
   Recasens Marta, 2009, LANGUAGE RESOURCES E, V43
   Sidner C. L., 1979, THESIS
   Soon Wee Meng, 1999, P 1999 JOINT SIGDAT, P285
   Stoyanov V., 2010, P ACL 2010 C
   Stoyanov V., 2009, P JOINT C 47 ANN M A, P656
   Strube M, 2002, P 2002 C EMP METH NA, P312, DOI DOI 10.3115/1118693.1118733
   Strube Michael, 2002, ACL 2002, P124
   Strube Michael, 2009, COMPUTERLINGUISTIK S
   Tetreault Joel, 2005, THESIS
   Uryupina O., 2003, P ACL 2003 STUD WORK, P80
   Uryupina Olga, 2004, P 5 DISC AN AN RES C
   van Deemter K, 2000, COMPUT LINGUIST, V26, P629, DOI 10.1162/089120100750105966
   Versley Y., 2007, P 2007 JOINT C EMP M, P496
   Versley Y., 2008, P 22 INT C COMP LING, P961
   Versley Yannick, 2006, K VER NAT SPRACH
   Vieira Renata, 2000, CORPUS BASED COMPUTA, P189
   Vilain M., 1995, P 6 MESS UND C MUC 6, P45, DOI DOI 10.3115/1072399.1072405
   Vincent Ng, 2008, P 2008 C EMP METH NA, P640
   Walker Marilyn A., 1998, CENTERING THEORY DIS
   Wee Meng Soon, 2001, COMPUTATIONAL LINGUI, V27, P521
   Wunsch H., 2010, THESIS
   Yang X, 2003, P 41 ANN M ASS COMP, P176, DOI [10.3115/1075096.1075119, DOI 10.3115/1075096.1075119]
   Yang X., 2007, P 45 ANN M ASS COMP, P528
   YANG X, 2008, P 46 ANN M ASS COMP, P843
   Yang X., 2004, P 1 INT C MOB UB SYS, P22
   Yang X., 2005, P 43 ANN M ASS COMP, P165
   Yang XF, 2008, COMPUT LINGUIST, V34, P327, DOI 10.1162/coli.2008.07-004-R2-06-57
   Yang XF, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P41
   Yangy X., 2004, P 20 INT C COMP LING, P226
   ZELENKO D, 2004, P ACL WORKSH REF RES, P9
   ZHAO Shanheng, 2007, C EMP METH NAT LANG, P541
   Zhou G., 2009, P 2009 C EMP METH NA, P978
NR 151
TC 26
Z9 26
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1396
EP 1411
PG 16
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300142
DA 2019-06-15
ER

PT B
AU Miller, S
   Guinness, J
   Zamanian, A
AF Miller, S
   Guinness, J
   Zamanian, A
GP acl
TI Name tagging with word clusters and discriminative training
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We present a technique for augmenting annotated training data with hierarchical word clusters that are automatically derived from a large unannotated corpus. Cluster membership is encoded in features that are incorporated in a discriminatively trained tagging model. Active learning is used to select training examples. We evaluate the technique for named-entity tagging. Compared with a state-of-the-art HMM-based name finder, the presented technique requires only 13% as much annotated data to achieve the same level of performance. Given a large annotated training set of 1,000,000 words, the technique achieves a 25% reduction in error over the state-of-the-art HMM trained on the same material.
C1 BBN Technol, Cambridge, MA 02138 USA.
RP Miller, S (reprint author), BBN Technol, 10 Moulton St, Cambridge, MA 02138 USA.
CR Blum A., 1998, P WORKSH COMP LEARN
   BOSCHEE E, 2002, HLT2002
   BROWN P, 1990, COMPUTATIONAL LINGUI
   COHN DA, 1996, ADV NEURAL INFORMATI
   Collins M., 2002, EMNLP
   COLLINS M, 1997, P 35 ANN M ACL MADR
   COLLINS M, 1999, EMNLP VLC 99
   Lafferty JD, 2001, P 18 INT C MACH LEAR
   LEE L, 1999, P 37 ANN M ASS COMP, P33
   LIN W, 2003, P ICML 2003 WORKSH C
   MAGERMAN DM, 1995, STAT DECISION 3 MODE
   McCallum A., 1998, P ICML 98 15 INT C M
   Pereira Fernando, 1993, P 31 ANN M ASS COMP, P183, DOI DOI 10.3115/981574.981598
   RILOFF E, 1999, AAAI IAAI
   Sha F., 2003, P HUM LANG TECHN NAA
   YAROWSKY D, 1995, M ASS COMP LING
NR 16
TC 26
Z9 30
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 337
EP 342
PG 6
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100043
DA 2019-06-15
ER

PT B
AU Pantel, P
   Ravichandran, D
AF Pantel, P
   Ravichandran, D
GP acl
TI Automatically labeling semantic classes
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB Systems that automatically discover semantic classes have emerged in part to address the limitations of broad-coverage lexical resources such as WordNet and Cyc. The current state of the art discovers many semantic classes but fails to label their concepts. We propose an algorithm labeling semantic classes and for leveraging them to extract is-a relationships using a top-down approach.
C1 Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Pantel, P (reprint author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way, Marina Del Rey, CA 90292 USA.
EM pantel@isi.edu; ravichan@isi.edu
CR BARWISE J, 1985, PHILOS LANGUAGE, P401
   BERLAND M, 1999, ACL 1999, P57
   Church K. W., 1989, P ACL, V27, P76, DOI [DOI 10.3115/981623.981633, 10.3115/981623.981633]
   Fleischman Michael, 2003, P 41 ANN M ASS COMP, P1
   GIRJU R, 2003, P HLT NAACL 03 EDM C, P80
   HAN J, 2001, DATA MINING CONCEPTS
   HEARST MA, 1992, COLING, P539
   Hindle D., 1990, P 28 ANN M ASS COMP, P268
   Leacock C, 1998, COMPUT LINGUIST, V24, P147
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   LIN D, 2001, P 7 ACM SIGKDD INT C, P317
   LIN D, 1994, P 15 INT C COMP LING, P42
   Mann Gideon S., 2002, SEMANET 02 BUILDING
   MILLER G, 1990, INT J LEXICOGRAPHY, V3
   Pantel P., 2002, P 8 ACM SIGKDD INT C, P613
   PASCA M, 2001, P NAACL 2001 WORKSH, P138
   Riloff E, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P474
   RILOFF E, 1997, P EMNLP 1997
   SALTON G, 1983, INTRO MODERN INFORMA
   Schank R. C., 1977, SCRIPTS PLANS GOALS
   Siegel S, 1988, NONPARAMETRIC STAT B
   VOORHEES E, 2003, IN PRESS P TREC 12 C
NR 23
TC 26
Z9 26
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 321
EP 328
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100041
DA 2019-06-15
ER

PT S
AU Clark, E
   Araki, K
AF Clark, Eleanor
   Araki, Kenji
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Text normalization in social media: progress, problems and applications
   for a pre-processing system of casual English
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Natural Language Processing; Machine Translation; Social Media; Twitter;
   Text Normalization
AB The rapid expansion in user-generated content on the Web of the 2000s, characterized by social media, has led to Web content featuring somewhat less standardized language than the Web of the 1990s. User creativity and individuality of language creates problems on two levels. The first is that social media text is often unsuitable as data for Natural Language Processing tasks such as Machine Translation, Information Retrieval and Opinion Mining, due to the irregularity of the language featured. The second is that non-native speakers of English, older Internet users and non-members of the "in-group" often find such texts difficult to understand. This paper discusses problems involved in automatically normalizing social media English, various applications for its use, and our progress thus far in a rule-based approach to the issue. Particularly, we evaluate the performance of two leading open source spell checkers on data taken from the microblogging service Twitter, and measure the extent to which their accuracy is improved by pre-processing with our system. We also present our database rules and classification system, results of evaluation experiments, and plans for expansion of the project. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Clark, Eleanor; Araki, Kenji] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
EM eleanor@media.eng.hokudai.ac.jp
CR Aw A., 2006, P COLING ACL MAIN C, P33
   Choudhury M. D., 2010, P 4 INT C WEBL SOC M
   Clark A., 2003, P WORKSH SHALL PROC, P12
   Clark E, 2010, P COMP INT 2010 HAW
   Henriquez CA., 2009, P CAW2 0 MADR SPAIN, P1
   KUKICH K, 1992, COMPUT SURV, V24, P377
   Ritter A., 2010, P HLT NAACL 2010 LOS, P172
   Sproat R., 2001, Computer Speech and Language, V15, P287, DOI 10.1006/csla.2001.0169
   Wong W, 2007, P IJCAI 2007 WORKSH, P55
NR 9
TC 25
Z9 25
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 2
EP 11
DI 10.1016/j.sbspro.2011.10.577
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700001
OA Other Gold
DA 2019-06-15
ER

PT B
AU Poon, HF
   Domingos, P
AF Poon, Hoifung
   Domingos, Pedro
GP Assoc Computat Linguist
TI Unsupervised Ontology Induction from Text
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Extracting knowledge from unstructured text is a long-standing goal of NLP. Although learning approaches to many of its subtasks have been developed (e.g., parsing, taxonomy induction, information extraction), all end-to-end solutions to date require heavy supervision and/or manual engineering, limiting their scope and scalability. We present OntoUSP, a system that induces and populates a probabilistic ontology using only dependency-parsed text as input. OntoUSP builds on the USP unsupervised semantic parser by jointly forming ISA and IS-PART hierarchies of lambda-form clusters. The ISA hierarchy allows more general knowledge to be learned, and the use of smoothing for parameter estimation. We evaluate OntoUSP by using it to extract a knowledge base from biomedical abstracts and answer questions. OntoUSP improves on the recall of USP by 47% and greatly outperforms previous state-of-the-art approaches.
C1 [Poon, Hoifung; Domingos, Pedro] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.
RP Poon, HF (reprint author), Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.
EM hoifung@cs.washington.edu; pedrod@cs.washington.edu
CR Alshawi H., 1990, Computational Linguistics, V16, P133
   Bakir G., 2007, PREDICTING STRUCTURE
   Banko M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2670
   Cimiano  P., 2006, ONTOLOGY LEARNING PO
   Cui W., 2017, P 5 INT C LANG RES E, P565
   Domingos Pedro, 2009, MARKOV LOGIC INTERFA
   Dudik Miroslav, 2007, P 24 INT C MACH LEAR
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Gelman A., 2006, DATA ANAL USING REGR
   Getoor L, 2007, INTRO STAT RELATIONA
   Hearst M. A., 1992, P 14 INT C COMP LING
   Kim JD, 2003, BIOINFORMATICS, V19, pi180, DOI 10.1093/bioinformatics/btg1023
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   Lin Dekang, 2001, P ACM SIGKDD C KNOWL, P323, DOI [10.1145/502512.502559, DOI 10.1145/502512.502559]
   Maedche A., 2002, ONTOLOGY LEARNING SE
   Nigam K., 1998, INT C MACH LEARN
   Poon H., 2009, P 2009 C EMP METH NA, V1, P1, DOI DOI 10.HTTP://DL.ACM.0RG/CITATI0N.CFM?
   POON H, 2008, P C EMP METH NAT LAN, P649
   Snow Rion, 2006, P COLING ACL 2006
   Staab S., 2004, HDB ONTOLOGIES
   Suchanek Fabian, 2008, J WEB SEMANTICS
   Suchanek Fabian M., 2009, P 18 INT C WORLD WID
   Tsujii Jun-ichi, 2004, P LANG RES EV C
   Wu Fei, 2008, P 17 INT C WORLD WID
   Yates A, 2009, J ARTIFICIAL INTELLI, V34, P255
NR 25
TC 25
Z9 25
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 296
EP 305
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300031
DA 2019-06-15
ER

PT B
AU Qazvinian, V
   Radev, DR
AF Qazvinian, Vahed
   Radev, Dragomir R.
GP Assoc Computat Linguist
TI Identifying Non-explicit Citing Sentences for Citation-based
   Summarization
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Identifying background (context) information in scientific articles can help scholars understand major contributions in their research area more easily. In this paper, we propose a general framework based on probabilistic inference to extract such context information from scientific papers. We model the sentences in an article and their lexical similarities as a Markov Random Field tuned to detect the patterns that context data create, and employ a Belief Propagation mechanism to detect likely context sentences. We also address the problem of generating surveys of scientific papers. Our experiments show greater pyramid scores for surveys generated using such context information rather than citation sentences alone.
C1 [Qazvinian, Vahed; Radev, Dragomir R.] Univ Michigan, Dept EECS, Ann Arbor, MI 48109 USA.
   [Radev, Dragomir R.] Univ Michigan, Sch Informat, Ann Arbor, MI 48109 USA.
RP Qazvinian, V (reprint author), Univ Michigan, Dept EECS, Ann Arbor, MI 48109 USA.
EM vahed@umich.edu; radev@umich.edu
CR Bradshaw S., 2003, P 7 EUR C RES ADV TE
   Bradshaw S., 2002, THESIS
   Elkiss A, 2008, J AM SOC INF SCI TEC, V59, P51, DOI 10.1002/asi.20707
   Erkan G., 2004, J ARTIFICIAL INTELLI
   Kaplan D., 2009, P 2009 WORKSH TEXT C, P88
   McGlohon M, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1265
   Mei Q., 2008, P ACL, P816
   Metzler D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P472
   Metzler D, 2007, SIGIR, P311
   Metzler  D.A., 2007, CIKM 07, P253
   Mohammad S., 2009, P HUM LANG TECHN 200, P584, DOI DOI 10.3115/1620754.1620839
   Nanba H, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P926
   NANBA H, 2004, P RIAO 2004, P195
   Nanba H., 2004, P 11 SIG CLASS RES W, P117
   Newman MEJ, 2001, P NATL ACAD SCI USA, V98, P404, DOI 10.1073/pnas.021544898
   Qazvinian Vahed, 2008, COLING 2008
   Radev D. R., 2009, ACL WORKSH NAT LANG
   Romanello M., 2009, P 2009 WORKSH TEXT C, P80
   Siddharthan A., 2007, P NAACL HLT 07
   Teufel S, 2002, COMPUT LINGUIST, V28, P409, DOI 10.1162/089120102762671936
   Teufel S., 2005, COMPUTING ATTITUDE A, P159
   Teufel Simone, 2006, P EMNLP SYDN AUSTR J
   Yedidia J.S., 2003, UNDERSTANDING BELIEF, p[239, 1921, 1923]
NR 23
TC 25
Z9 26
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 555
EP 564
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300057
DA 2019-06-15
ER

PT B
AU Mani, I
   Verhagen, M
   Wellner, B
   Lee, CM
   Pustejovsky, J
AF Mani, Inderjeet
   Verhagen, Marc
   Wellner, Ben
   Lee, Chong Min
   Pustejovsky, James
GP COLING
TI Machine Learning of Temporal Relations
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper investigates a machine learning approach for temporally ordering and anchoring events in natural language texts. To address data sparseness, we used temporal reasoning as an over-sampling method to dramatically expand the amount of training data, resulting in predictive accuracy on link labeling as high as 93% using a Maximum Entropy classifier on human annotated data. This method compared favorably against a series of increasingly sophisticated baselines involving expansion of rules derived from human intuitions.
C1 [Mani, Inderjeet; Wellner, Ben] Mitre Corp, Bedford, MA 01730 USA.
RP Mani, I (reprint author), Mitre Corp, 202 Burlington Rd, Bedford, MA 01730 USA.
EM imani@mitre.org; marc@cs.brandeis.edu; wellner@mitre.org;
   cml54@georgetown.edu; jamesp@cs.brandeis.edu
CR ALLEN JF, 1984, ARTIF INTELL, V23, P123, DOI 10.1016/0004-3702(84)90008-0
   BERGLUND A, 2006, P EACL 2006
   BOGURAEV B, 2005, P 19 INT JOINT C ART, P997
   CHKLOVSKI T, 2004, P EMNLP 04
   Cohen WW, 1999, J ARTIF INTELL RES, V10, P243, DOI 10.1613/jair.587
   Hitzeman J, 1995, P 7 C EUR CHAPT ASS, P253
   HWANG C, 1992, P 30 ANN M ASS COMP, P232
   KAMP H, 1993, DISCOURSE LOGIC 2
   KEHLER A, 2000, FORMALIZING DYNAMICS
   Lapata M., 2004, P NAACL 04, P153
   LASCARIDES A, 1993, LINGUIST PHILOS, V16, P437, DOI 10.1007/BF00986208
   Li WG, 2004, PROGRESS OF MACHINING TECHNOLOGY, P582, DOI 10.3115/1218955.1219029
   Mani I, 2003, P HUM LANG TECHN C H, V2, P55
   Mani I., 2000, P ACL 2000
   Passonneau R. J., 1988, Computational Linguistics, V14, P44
   Pustejovsky J, 2003, CORPUS LINGUISTICS, P647
   Pustejovsky James, 2005, LANGUAGE TIME READER
   Sauri R., 2005, P C HUM LANG TECHN E, P700, DOI DOI 10.3115/1220575.1220663
   SCHILDER F, 2005, LANGUAGE TIME READER
   SETZER A, 2000, P 2 INT C LANG RES E, P1287
   Verhagen M., 2004, THESIS BRANDEIS U
   Vilain M., 1989, READINGS QUALITATIVE, P373
   Webber B. L., 1988, Computational Linguistics, V14, P61
NR 23
TC 25
Z9 25
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 753
EP 760
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200095
DA 2019-06-15
ER

PT B
AU Pradhan, S
   Ward, W
   Hacioglu, K
   Martin, JH
   Jurafsky, D
AF Pradhan, S
   Ward, W
   Hacioglu, K
   Martin, JH
   Jurafsky, D
GP acl
TI Shallow semantic parsing using support vector machines
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB In this paper, we propose a machine learning algorithm for shallow semantic parsing, extending the work of Gildea and Jurafsky (2002), Surdeanu et al. (2003) and others. Our algorithm is based on Support Vector Machines which we show give an improvement in performance over earlier classifiers. We show performance improvements through a number of new features and measure their ability to generalize to a new test set drawn from the AQUAINT corpus.
C1 Univ Colorado, Ctr Spoken Language Res, Boulder, CO 80303 USA.
RP Pradhan, S (reprint author), Univ Colorado, Ctr Spoken Language Res, Boulder, CO 80303 USA.
CR BLAHETA D, 2000, NAACL, P234
   CHANIAK E, 2001, ACL 01
   CHEN J, 2003, EMNLP 03
   Collins Michael, 1999, THESIS U PENNSYLVANI
   DANIEL K, 1992, COLIN 92
   Daniels K, 1999, AUST PSYCHOL, V34, P211, DOI 10.1080/00050069908257456
   FLEISCHMAN M, 2003, HLT 03
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   GILDEA D, 2000, ACL 00, P512
   GILDEA D, 2002, ACL 02
   GILDEA D, 2003, EMNLP 03
   HACIOGLU K, 2003, HLT 03
   Hacioglu Kadri, 2003, TRCSLR20031
   HOFMANN T, 1998, STAT ODELS COOCCURRE
   KINGSBURY P, 2002, HLT 02
   KUDO T, 2000, CONLL 00
   KUDO T, 2001, NAACL 01
   *LDC, 2002, AQUAINT CORP ENGL NE
   LIN DK, 1998, COLING 98
   MAGERMAN D, 1994, THESIS STANFORD U CA
   MARCUS M, 1994, PENN TREEBANK ANNOTA
   Platt J., 2000, ADV LARGE MARGIN CLA
   PRADHAN S, 2003, ICDM 03
   SURDEANU M, 2003, ACL 03
   THOMPSON CA, 2003, ECML 03
NR 25
TC 25
Z9 25
U1 1
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 233
EP 240
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100030
DA 2019-06-15
ER

PT B
AU Li, SS
   Huang, CR
   Zhou, GD
   Lee, SYM
AF Li, Shoushan
   Huang, Chu-Ren
   Zhou, Guodong
   Lee, Sophia Yat Mei
GP Assoc Computat Linguist
TI Employing Personal/Impersonal Views in Supervised and Semi-supervised
   Sentiment Classification
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID COMBINING CLASSIFIERS
AB In this paper, we adopt two views, personal and impersonal views, and systematically employ them in both supervised and semi-supervised sentiment classification. Here, personal views consist of those sentences which directly express speaker's feeling and preference towards a target object while impersonal views focus on statements towards a target object for evaluation. To obtain them, an unsupervised mining approach is proposed. On this basis, an ensemble method and a co-training algorithm are explored to employ the two views in supervised and semi-supervised sentiment classification respectively. Experimental results across eight domains demonstrate the effectiveness of our proposed approach.
C1 [Li, Shoushan; Huang, Chu-Ren; Lee, Sophia Yat Mei] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Hong Kong, Peoples R China.
   [Zhou, Guodong] Soochow Univ, Sch Comp Sci & Technol, Nat Language Proc Lab, Suzhou, Peoples R China.
RP Li, SS (reprint author), Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Hong Kong, Peoples R China.
EM shoushan.li@gmail.com; churenhuang@gmail.com; gdzhou@suda.edu.cn;
   sophiaym@gmail.com
RI Huang, Chu-Ren/A-8757-2010
OI Huang, Chu-Ren/0000-0002-8526-5520
CR Blitzer J, 2007, P ACL 07
   Blum A., 1995, P COLT 98
   Crystal D., 2003, CAMBRIDGE ENCY ENGLI
   Dasgupta S., 2009, P ACL IJCNLP 09
   Duin R.P.W., 2002, P 16 INT C PATT REC
   Durant K., 2007, PROCESSING ADV WEB M
   Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e
   Esuli A., 2005, P CIKM 05
   Fumera G, 2005, IEEE T PATTERN ANAL, V27, P942, DOI 10.1109/TPAMI.2005.109
   JOACHIMS T, 1999, ICML 1999
   Kennedy A, 2006, COMPUT INTELL-US, V22, P110, DOI 10.1111/j.1467-8640.2006.00277.x
   Kim S. M., 2004, P COLING 04, P1367
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Liu B., 2005, P WWW 05
   McDonald R., 2007, P ACL 07
   Pang B., 2002, P EMNLP 02
   Pang B., 2004, P ACL 04
   Riloff E., 2006, P EMNLP 06
   Settles B., 2009, 1648 U WISC MAD DEP
   Turney P., 2002, P ACL 02
   Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069
   Wan X., 2009, P ACL IJCNLP 09
   Wilson T, 2009, COMPUT LINGUIST, V35, P399, DOI 10.1162/coli.08-012-R1-06-90
   Yang Y., 1999, P SIGIR 99
   Zagibalov T., 2008, P COLING 08
   Zhu X., 2005, 1530 U WISC MAD
NR 26
TC 24
Z9 24
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 414
EP 423
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300043
DA 2019-06-15
ER

PT B
AU Prettenhofer, P
   Stein, B
AF Prettenhofer, Peter
   Stein, Benno
GP Assoc Computat Linguist
TI Cross-Language Text Classification using Structural Correspondence
   Learning
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a new approach to cross-language text classification that builds on structural correspondence learning, a recently proposed theory for domain adaptation. The approach uses unlabeled documents, along with a simple word translation oracle, in order to induce task-specific, cross-lingual word correspondences. We report on analyses that reveal quantitative insights about the use of unlabeled data and the complexity of interlanguage correspondence modeling.
   We conduct experiments in the field of cross-language sentiment classification, employing English as source language, and German, French, and Japanese as target languages. The results are convincing; they demonstrate both the robustness and the competitiveness of the presented ideas.
C1 [Prettenhofer, Peter; Stein, Benno] Bauhaus Univ Weimar, D-99421 Weimar, Germany.
RP Prettenhofer, P (reprint author), Bauhaus Univ Weimar, D-99421 Weimar, Germany.
EM peter.prettenhofer@uni-weimar.de; benno.stein@uni-weimar.de
CR Ando R. K., 2005, P 43 ANN M ASS COMP, P1
   Ando RK, 2005, J MACH LEARN RES, V6, P1817
   Bautin M., 2008, P INT C WEBL SOC MED, P19
   BEL N, 2003, P 7 EUR C RES ADV TE, P126
   Blitzer J., 2007, ACL, V7, P440
   Blitzer J., 2006, P 2006 C EMP METH NA, P120
   DAUME H, 2007, P 45 ANN M ASS COMP, P256
   Dumais Susan T., 1997, AAAI S CROSSLANGUAGE
   Finkel J.R., 2009, P HUM LANG TECHN 200, P602, DOI [10.3115/1620754.1620842, DOI 10.3115/1620754.1620842]
   Fortuna B., 2005, P ICML WORKSH LEARN
   Gliozzo A., 2005, P ACL WORKSH BUILD U
   Gliozzo A, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P553
   HIROSHI K, 2004, P 20 INT C COMP LING, P494
   Jiang J., 2007, P 16 ACM C INF KNOWL, P401, DOI DOI 10.1145/1321440.1321498]
   Lavrenko V., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P175
   Li Y, 2007, INFORM PROCESS MANAG, V43, P1183, DOI 10.1016/j.ipm.2006.11.005
   Ling X., 2008, P 17 INT C WORLD WID, P969
   OARD D, 1998, P 3 C ASS MACH TRANS, P472
   OLSSON JS, 2005, P 28 ANN INT ACM SIG, P645
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79
   POTTHAST M, 2008, P ECIR, P522
   QUATTONI A, 2007, P IEEE C COMP VIS PA, P1
   Rigutini L, 2005, P 2005 IEEE WIC ACM, V2005, P529
   Shalev-Shwartz S., 2007, P 24 INT C MACH LEAR, P807, DOI DOI 10.1145/1273496.1273598
   Tsuruokas Y., 2009, P JOINT C 47 ANN M A, V1, P477
   Wan X., 2009, P JOINT C 47 ANN M A, V1, P235
   Zhang T., 2004, P 21 INT C MACH LEAR, P116, DOI DOI 10.1145/1015330.1015332
NR 27
TC 24
Z9 24
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1118
EP 1127
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300114
DA 2019-06-15
ER

PT B
AU Miyao, Y
   Ohta, T
   Masuda, K
   Tsuruoka, Y
   Yoshida, K
   Ninomiya, T
   Tsujii, J
AF Miyao, Yusuke
   Ohta, Tomoko
   Masuda, Katsuya
   Tsuruoka, Yoshimasa
   Yoshida, Kazuhiro
   Ninomiya, Takashi
   Tsujii, Jun'ichi
GP COLING
TI Semantic Retrieval for the Accurate Identification of Relational
   Concepts in Massive Textbases
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID SYSTEM
AB This paper introduces a novel framework for the accurate retrieval of relational concepts from huge texts. Prior to retrieval, all sentences are annotated with predicate argument structures and ontological identifiers by applying a deep parser and a term recognizer. During the run time, user requests are converted into queries of region algebra on these annotations. Structural matching with pre-computed semantic annotations establishes the accurate and efficient retrieval of relational concepts. This framework was applied to a text retrieval system for MEDLINE. Experiments on the retrieval of biomedical correlations revealed that the cost is sufficiently small for real-time applications and that the retrieval precision is significantly improved.
C1 [Miyao, Yusuke; Ohta, Tomoko; Masuda, Katsuya; Yoshida, Kazuhiro; Tsujii, Jun'ichi] Univ Tokyo, Dept Comp Sci, Bunkyo Ku, Tokyo 1130033, Japan.
RP Miyao, Y (reprint author), Univ Tokyo, Dept Comp Sci, Bunkyo Ku, Hongo 7-3-1, Tokyo 1130033, Japan.
EM yusuke@is.s.u-tokyo.ac.jp; okap@is.s.u-tokyo.ac.jp;
   kmasuda@is.s.u-tokyo.ac.jp; tsuruoka@is.s.u-tokyo.ac.jp;
   kyoshida@is.s.u-tokyo.ac.jp; ninomi@is.s.u-tokyo.ac.jp;
   tsujii@is.s.u-tokyo.ac.jp
RI Tsuruoka, Yoshimasa/O-6842-2018
OI Tsuruoka, Yoshimasa/0000-0002-0707-1077
CR Blaschke C, 2002, IEEE INTELL SYST, V17, P14, DOI 10.1109/MIS.2002.999215
   BOAG S, 2005, XQUERY 1 0 XML QUERY
   Chun Hong-Woo, 2006, Pac Symp Biocomput, P4
   Clark J., 1999, XML PATH LANGUAGE XP
   CLARKE CLA, 1995, COMPUT J, V38, P43, DOI 10.1093/comjnl/38.1.43
   Hao Y, 2005, BIOINFORMATICS, V21, P3294, DOI 10.1093/bioinformatics/bti493
   HARA T, 2005, P IJCNLP 2005
   *IBM, 2005, UNSTR INF MAN ARCH U
   Johnson M., 2005, P ACL 2005
   KOIKE A, 2004, P HLT NAACL BIOLINK, P9
   LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281
   MASUDA K, 2006, NESTED REGION UNPUB
   Miyao Yusuke, 2005, P 43 ANN M ASS COMP, P83
   *NAT LIB MED, 2005, FACT SHEET MEDLINE
   NINOMIYA T, 2006, TRAITEMENT AUTOMATIQ, V46
   Taura K, 2004, INNOVATIVE ARCHITECTURE FOR FUTURE GENERATION HIGH-PERFORMANCE PROCESSORS AND SYSTEMS, PROCEEDINGS, P59, DOI 10.1109/IWIA.2004.10012
   *TEI CONS, 2004, TEXT ENC IN
   Tsujii J., 2005, P IJCNLP COMP, P222
   Tsuruoka Y, 2004, J BIOMED INFORM, V37, P461, DOI 10.1016/j.jbi.2004.08.003
   Tsuruolca Y., 2005, P C HUM LANG TECHN E, P467, DOI DOI 10.3115/1220575.1220634
NR 20
TC 24
Z9 24
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1017
EP 1024
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200128
DA 2019-06-15
ER

PT B
AU Celikyilmaz, A
   Hakkani-Tur, D
AF Celikyilmaz, Asli
   Hakkani-Tur, Dilek
GP Assoc Computat Linguist
TI A Hybrid Hierarchical Model for Multi-Document Summarization
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Scoring sentences in documents given abstract summaries created by humans is important in extractive multi-document summarization. In this paper, we formulate extractive summarization as a two step learning problem building a generative model for pattern discovery and a regression model for inference. We calculate scores for sentences in document clusters based on their latent characteristics using a hierarchical topic model. Then, using these scores, we train a regression model based on the lexical and structural characteristics of the sentences, and use the model to score sentences of new documents to form a summary. Our system advances current state-of-the-art improving ROUGE scores by similar to 7%. Generated summaries are less redundant and more coherent based upon manual quality evaluations.
C1 [Celikyilmaz, Asli] Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA.
   [Hakkani-Tur, Dilek] Int Comp Sci Inst, Berkeley, CA 94704 USA.
RP Celikyilmaz, A (reprint author), Univ Calif Berkeley, Dept Comp Sci, Berkeley, CA 94720 USA.
EM asli@eecs.berkeley.edu; dilek@icsi.berkeley.edu
CR Barzilay R., 2004, P HLT NAACL 04
   Blei D., 2003, NEURAL INFORM PROCES
   Blei D., 2009, J ACM
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Branavan S.R.K., 2009, J ARTIFICIAL INTELLI, V34
   Conroy J.M., 2006, P ACL 06
   DaumeIII H., 2006, P ACL 06
   Drucker H., 1997, NIPS 9
   Haghighi A., 2009, NAACL HLT 09
   Joachims T, 1999, ADV KERNEL METHODS S
   Lin C. Y., 2004, P ACL WORKSH TEXT SU
   LIN CY, 2003, P HLT NAACL EDM CAN
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Nenkova A., 2005, MSRTR2005101
   Radev D.R., 2004, INT J INFORM PROCESS
   Shen D., 2007, P IJCAI 07
   Tang J., 2009, SIAM INT C DAT MIN
   Titov I., 2008, ACL 08 HLT
   Toutanova K., 2007, P DUC
   Yeh J.Y., 2005, INFORM PROCESSING MA
NR 20
TC 23
Z9 24
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 815
EP 824
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300084
DA 2019-06-15
ER

PT B
AU Munteanu, DS
   Marcu, D
AF Munteanu, Dragos Stefan
   Marcu, Daniel
GP COLING
TI Extracting Parallel Sub-Sentential Fragments from Non-Parallel Corpora
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a novel method for extracting parallel sub-sentential fragments from comparable, non-parallel bilingual corpora. By analyzing potentially similar sentence pairs using a signal processing-inspired approach, we detect which segments of the source sentence are translated into segments in the target sentence, and which are not. This method enables us to extract useful machine translation training data even from very non-parallel corpora, which contain no parallel sentence pairs. We evaluate the quality of the extracted data by showing that it improves the performance of a state-of-the-art statistical machine translation system.
C1 [Munteanu, Dragos Stefan; Marcu, Daniel] Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Munteanu, DS (reprint author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
EM dragos@isi.edu; marcu@isi.edu
CR Brown P. F., 1993, Computational Linguistics, V19, P263
   Cheung P., 2004, LREC2004 WORKSH
   DENG YG, 2006, J NATURAL L IN PRESS
   DIAB M, 2000, RIAO 2000
   Dunning T., 1993, Computational Linguistics, V19, P61
   Fung P., 2004, EMNLP 2004, P57
   FUNG P, 1998, ACL 1998, P414
   Fung P., 2004, COLING 2004, P1051
   Gaussier E., 2004, ACL 2004, P527
   KOEHN P, 2004, EMNLP, P388
   KOEHN P, 2000, NAT C ART INT, P711
   LI S, 2004, COLING 2004, P618
   Melamed ID, 2000, COMPUT LINGUIST, V26, P221, DOI 10.1162/089120100561683
   Moore R.C, 2004, ACL 2004, P519
   MOORE RC, 2004, EMNLP 2004, P333
   MUNTEANU DS, 2005, COMPUTATIONAL LINGUI, V31
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   OGILVIE P, 2001, TREC 10, P103
   PAPINENI K, 2002, ACL, P311, DOI DOI 10.3115/1073083.1073135
   RAPP R, 1999, ACL 1999, P519
   Resnik P, 2003, COMPUT LINGUIST, V29, P349, DOI 10.1162/089120103322711578
   RESNIK P, 2001, HLT 2001
   SHINYAMA Y, 2004, COLING 2004, P848
   Utiyama M., 2003, ACL 2003, P72
   Vogel S., 2003, EACL 2003, P175
   Wu Dekai, 2005, IJCNLP 2005, P257
   Zhao B, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P745, DOI 10.1109/ICDM.2002.1184044
NR 28
TC 23
Z9 23
U1 1
U2 6
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 81
EP 88
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200011
DA 2019-06-15
ER

PT B
AU Ponzetto, SP
   Navigli, R
AF Ponzetto, Simone Paolo
   Navigli, Roberto
GP Assoc Computat Linguist
TI Knowledge-richWord Sense Disambiguation Rivaling Supervised Systems
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID WIKIPEDIA
AB One of the main obstacles to high-performance Word Sense Disambiguation ( WSD) is the knowledge acquisition bottleneck. In this paper, we present a methodology to automatically extend WordNet with large amounts of semantic relations from an encyclopedic resource, namely Wikipedia. We show that, when provided with a vast amount of high-quality semantic relations, simple knowledge-lean disambiguation algorithms compete with state-of-the-art supervised WSD systems in a coarse-grained all-words setting and outperform them on gold-standard domain-specific datasets.
C1 [Ponzetto, Simone Paolo] Heidelberg Univ, Dept Computat Linguist, D-69115 Heidelberg, Germany.
   [Navigli, Roberto] Sapienza Univ Roma, Dipartimento Informat, Rome, Italy.
RP Ponzetto, SP (reprint author), Heidelberg Univ, Dept Computat Linguist, D-69115 Heidelberg, Germany.
EM ponzetto@cl.uni-heidelberg.de; navigli@di.uniroma1.it
CR Agirre E, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P1501
   Agirre Eneko, 2004, P LREC 04
   Agirre Eneko, 2001, P 5 ACL WORKSH COMP, P15
   Banerjee S., 2003, IJCAI, V3, P805
   Bunescu R. C., 2006, P EACL, V6, P9
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Chan YS, 2007, P 4 INT WORKSH SEM E, P253
   Chen P., 2009, P HUM LANG TECHN 200, P28
   Chklovski Tim, 2002, P ACL 02 WORKSH WSD
   CHODOROW MS, 1985, P 23 ANN M ASS COMP, P299
   Cimiano P., 2004, P 13 INT C WORLD WID, P462, DOI DOI 10.1145/988672.988735
   Cuadros M., 2006, P 2006 C EMP METH NA, P534
   Cuadros M., 2008, P 22 INT C COMP LING, P161, DOI DOI 10.3115/1599081.1599102
   Edmonds P., 2000, TECHNICAL REPORT
   FELLBAUM CHRISTIANE, 1998, WORDNET ELECT DATABA
   Gabrilovich E, 2006, AAAI, V6, P1301
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1606
   Girju R, 2006, COMPUT LINGUIST, V32, P83, DOI 10.1162/089120106776173075
   Harabagiu S., 1999, P SIGLEX, P1
   Hearst M.A., 1992, P 14 INT C COMP LING, P539, DOI DOI 10.3115/992133.992154
   Kilgarriff A., 2000, COMPUTERS HUMANITIES, V34
   Koeling R., 2005, P HUM LANG TECHN C C, P419
   Koeling R., 2007, P 4 INT WORKSH SEM E, P314
   Lesk M. E., 1986, P 5 ANN INT C SYST D, P24, DOI [DOI 10.1145/318723.318728, 10.1145/318723]
   McCarthy D, 2003, COMPUT LINGUIST, V29, P639, DOI 10.1162/089120103322753365
   Mihalcea R., 2007, P NAACL HLT 2007, P196
   Mihalcea R., 2007, CIKM, V7, P233, DOI DOI 10.1145/1321440.1321475
   Miller G. A., 1993, P WORKSH HUM LANG TE, P303, DOI DOI 10.3115/1075671.1075742
   Milne D., 2008, P 17 ACM C INF KNOWL, P509, DOI DOI 10.1145/1458082.1458150
   Milne D., 2008, P AAAI WORKSH WIK AR, P25
   Nastase V., 2008, P C EMP METH NAT LAN, P763
   Nastase V., 2008, P 23 C ADV ART INT C, P1219
   Navigli R, 2005, IEEE T PATTERN ANAL, V27, P1075, DOI 10.1109/TPAMI.2005.149
   Navigli R., 2007, P 4 INT WORKSH SEM E, P30
   Navigli R., 2009, P 12 C EUR CHAPT ASS, P594
   Navigli R, 2010, IEEE T PATTERN ANAL, V32, P678, DOI 10.1109/TPAMI.2009.36
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Navigli Roberto, 2010, P ACL 10
   Pennacchiotti M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P793
   Ponzetto S., 2007, P 22 NAT C ART INT A, P1440
   Ponzetto SP, 2007, J ARTIF INTELL RES, V30, P181, DOI 10.1613/jair.2308
   Ponzetto SP, 2009, 21ST INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-09), PROCEEDINGS, P2083
   REITER N, 2008, RES COMPUTATIONAL SE, V1, P381
   Rigau G., 1998, P 17 INT C COMP LING, P1103
   Ruiz- Casado Maria, 2005, LECT NOTES COMPUTER, V3528
   Sauper C., 2009, P JOINT C 47 ANN M A, P208
   Shnarch Eyal, 2009, P ACL IJCNLP 09, P450
   Snow R, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P801
   Soroa A., 2009, P 12 C EUR CHAPT ASS, P33, DOI DOI 10.3115/1609067.1609070
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Wu F., 2007, P 16 ACM C INF KNOWL, P41, DOI DOI 10.1145/1321440.1321449
   Wu Fei, 2008, P 17 INT C WORLD WID, P635, DOI DOI 10.1145/1367497.1367583
NR 52
TC 22
Z9 22
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1522
EP 1531
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300154
DA 2019-06-15
ER

PT B
AU Harabagiu, S
   Hickl, A
AF Harabagiu, Sanda
   Hickl, Andrew
GP COLING
TI Methods for Using Textual Entailment in Open-Domain Question Answering
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Work on the semantics of questions has argued that the relation between a question and its answer(s) can be cast in terms of logical entailment. In this paper, we demonstrate how computational systems designed to recognize textual entailment can be used to enhance the accuracy of current open-domain automatic question answering (Q/A) systems. In our experiments, we show that when textual entailment information is used to either filter or rank answers returned by a Q/A system, accuracy can be increased by as much as 20% overall.
C1 [Harabagiu, Sanda; Hickl, Andrew] Language Comp Corp, Richardson, TX 75080 USA.
RP Harabagiu, S (reprint author), Language Comp Corp, 1701 N Collins Blvd, Richardson, TX 75080 USA.
EM sanda@languagecomputer.com
CR BARZILAY R, 2003, HLT NAACL
   Burger John, 2005, P ACL WORKSH EMP MOD, P49
   Dagan I., 2005, P PASCAL CHALL WORKS
   ECHIHABI A, 2003, P 41 M ASS COMP LING
   GLICKMAN O, 2005, P ACL WORKSH EMP MOD
   GROENENDIJK J, 1999, P 9 SEM LING THEOR C
   HARABAGIU S, 2005, P 14 TEXT RETRIEVAL
   HARABAGIU S, 2001, P 39 M ASS COMP LING
   Harabagiu Sanda M., 2005, P 43 ANN M ASS COMP
   Hickl A., 2006, P 2 PASCAL CHALL WOR
   LEWIS D, 1988, THEORIA, V54, P161
   MAGNINI B, 2002, P 40 ANN M ASS COMP
   MOLDOVAN D, 2002, P 40 M ASS COMP LING
   MOLDOVAN D, 2003, P HLT NAACL 2003
   Pedersen Ted, 2004, P 19 NAT C ART INT A
   Prager J., 2004, P 42 ANN M ACL, P574
NR 16
TC 22
Z9 22
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 905
EP 912
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200114
DA 2019-06-15
ER

PT B
AU Navigli, R
AF Navigli, Roberto
GP COLING
TI Meaningful Clustering of Senses Helps Boost Word Sense Disambiguation
   Performance
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Fine-grained sense distinctions are one of the major obstacles to successful Word Sense Disambiguation. In this paper, we present a method for reducing the granularity of the WordNet sense inventory based on the mapping to a manually crafted dictionary encoding sense hierarchies, namely the Oxford Dictionary of English. We assess the quality of the mapping and the induced clustering, and evaluate the performance of coarse WSD systems in the Senseval-3 English all-words task.
C1 Univ Roma La Sapienza, Dipartimento Informat, Rome, Italy.
RP Navigli, R (reprint author), Univ Roma La Sapienza, Dipartimento Informat, Rome, Italy.
EM navigli@di.uniroma1.it
CR AGIRRE E, 2003, P C REC ADV NAT LANG
   BRISCOE T, 2002, P 3 C LANG RES EV LA
   CHKLOVSKI T, 2003, P REC ADV NLP RANLP
   CHKLOVSKI T, 2002, P ACL 2002 WORKSH WS
   DECADT B, 2004, P ACL SIGLEX SENS 3
   DOLAN WB, 1994, P 15 C COMP LING COL
   Edmonds P., 1998, J NATURAL LANGUAGE E, V8
   FELL BAUM C., 2001, P NAACL WORKSH WORDN
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Lesk Michael, 1986, P 5 C SYST DOC
   MAGNINI B, 2000, P 2 C LANG RES EV LR
   MCCARTHY D, 2006, P C WORKSH MAK SENS
   Mihalcea R., 2004, P ACL SIGLEX SENS 3
   Mihalcea R., 2001, P NAACL WORKSH WORDN
   Morris J, 1991, COMPUTATIONAL LINGUI, V17
   Navigli R., 2004, COMPUTATIONAL LINGUI, V30
   NAVIGLI R, 2005, IEEE T PATTERN ANAL, V27
   Ng Hwee T, 1999, P ACL WORKSH STAND L
   PETERS W, 1998, P 1 C LANG RES EV LR
   Snyder Benjamin, 2004, P ACL 2004 SENSEVAL
   Soanes C., 2003, OXFORD DICT ENGLISH
   STOKOE C, 2005, P C EMP METH NAT LAN
   STRAPPARAVA C, 2004, P ACL SIGLEX SENS 3
   TOMURO N, 2001, P M NAACL PITTSB US
   VICKREY D, 2005, P C EMP METH NAT LAN
   YURET D, 2004, P ACL SIGLEX SENS 3
   Zhao Y, 2004, MACHINE LEARNING, V55
NR 27
TC 22
Z9 22
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 105
EP 112
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200014
DA 2019-06-15
ER

PT B
AU Peng, FC
   Schuurmans, D
   Keselj, V
   Wang, SJ
AF Peng, FC
   Schuurmans, D
   Keselj, V
   Wang, SJ
GP ACL
TI Language independent authorship attribution using character level
   language models
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We present a method for computer-assisted authorship attribution based on character-level n-gram language models. Our approach is based on simple information theoretic principles, and achieves improved performance across a variety of languages without requiring extensive pre-processing or feature selection. To demonstrate the effectiveness and language independence of our approach, we present experimental results on Greek, English, and Chinese data. We show that our approach achieves state of the art performance in each of these cases. In particular, we obtain a 18% accuracy improvement over the best published results for a Greek data set, while using a far simpler technique than previous investigations.
C1 Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
CR AIZAWA A, 2001, P 6 NLP PA RIM S NLP
   APTE C, 1994, P SIGIR 94
   Bell T., 1990, TEXT COMPRESSION
   Cavnar W., 1994, P SDAIR 94
   CHEN SF, 1998, TR1098
   EPHRATT M, 1997, P ACH ALLC 97
   Holmes D. I., 1995, LIT LINGUISTIC COMPU, V10, P111, DOI DOI 10.1093/LLC/10.2.111
   Love Harold, 2002, ATTRIBUTING AUTHORSH
   SCOTT S, 1999, P ICML 99
   Stamatatos E, 2000, COMPUT LINGUIST, V26, P471, DOI 10.1162/089120100750105920
   Stamatatos E, 2001, COMPUT HUMANITIES, V35, P193, DOI 10.1023/A:1002681919510
   STAMATATOS E, 1999, EACL 99
   WITTEN I, 1999, P IEEE DAT COMPR 97
NR 13
TC 22
Z9 22
U1 0
U2 2
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 267
EP 274
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200035
DA 2019-06-15
ER

PT B
AU Hassan, A
   Radev, D
AF Hassan, Ahmed
   Radev, Dragomir
GP Assoc Computat Linguist
TI Identifying Text Polarity Using Random Walks
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Automatically identifying the polarity of words is a very important task in Natural Language Processing. It has applications in text classification, text filtering, analysis of product review, analysis of responses to surveys, and mining online discussions. We propose a method for identifying the polarity of words. We apply a Markov random walk model to a large word relatedness graph, producing a polarity estimate for any given word. A key advantage of the model is its ability to accurately and quickly assign a polarity sign and magnitude to any word. The method could be used both in a semi-supervised setting where a training set of labeled words is used, and in an unsupervised setting where a handful of seeds is used to define the two polarity classes. The method is experimentally tested using a manually labeled set of positive and negative words. It outperforms the state of the art methods in the semi-supervised setting. The results in the unsupervised setting is comparable to the best reported values. However, the proposed method is faster and does not need a large corpus.
C1 [Hassan, Ahmed; Radev, Dragomir] Univ Michigan Ann Arbor, Ann Arbor, MI 48109 USA.
RP Hassan, A (reprint author), Univ Michigan Ann Arbor, Ann Arbor, MI 48109 USA.
EM hassanam@umich.edu; radev@umich.edu
CR Andreevskaia Alina, 2006, P 11 C EUR CHAPT ASS
   Banea C., 2008, P 6 INT LANG RES EV
   Esuli A., 2006, P 5 INT C LANG RES E, V5, P417
   Esuli A., 2005, P 14 ACM INT C INF K, P617
   HATZIVASSILOGLO.V, 2000, COLING, P299
   Hatzivassiloglou V., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640
   Hu M, 2004, P 10 ACM SIGKDD INT, V2004, P168, DOI DOI 10.1145/1014052.1014073
   Kamps J., 2004, USING WORDNET MEASUR, P1115
   Kanayama H, 2006, P 2006 C EMP METH NA, P355, DOI DOI 10.3115/1610075.1610125
   Kim S.-M., 2004, P 20 INT C COMP LING, P1367, DOI DOI 10.3115/1220355.1220555
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   MORINAGA S, 2002, KDD 2002, P341
   NASUKAWA T, 2003, K CAP 03, P70
   Norris J.R., 1997, MARKOV CHAINS
   Popescu A, 2005, HLT 05, P339
   Riloff E, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P105
   Stone P. J., 1966, GEN INQUIRER COMPUTE
   Szummer M., 2002, ADV NEURAL INFORM PR, P945
   Takamura H., 2005, ACL 05, P133
   Tong R.M., 2001, SIGIR 2001 WORKSH OP
   Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013
   Turney Peter D, 2002, ACL 02, P417
   Wiebe Janyce, 2001, P 2 SIGDIAL WORKSH D, P1
   Wiebe JM, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P735
   Yu H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P129
   Zhu X., 2003, ICML, P912
NR 26
TC 21
Z9 22
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 395
EP 403
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300041
DA 2019-06-15
ER

PT B
AU Li, M
   Zhu, MH
   Zhang, Y
   Zhou, M
AF Li, Mu
   Zhu, Muhua
   Zhang, Yang
   Zhou, Ming
GP COLING
TI Exploring Distributional Similarity Based Models for Query Spelling
   Correction
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB A query speller is crucial to search engine in improving web search relevance. This paper describes novel methods for use of distributional similarity estimated from query logs In learning improved query spelling correction models. The key to our methods is the property of distributional similarity between two terms: it is high between a frequently occurring misspelling and its correction, and low between two Irrelevant terms only with similar spellings. We present two models that are able to take advantage of this property. Experimental results demonstrate that the distributional similarity based models can significantly outperform their baseline systems in the web query spelling correction task.
C1 [Li, Mu; Zhou, Ming] Microsoft Res Asia, Beijing 100080, Peoples R China.
RP Li, M (reprint author), Microsoft Res Asia, 5F Sigma Ctr,Zhichun Rd, Beijing 100080, Peoples R China.
EM muli@microsoft.com; zhumh@ics.neu.edu.cn; yangzhang@tju.edu.cn;
   mingzhou@microsoft.com
CR Ahmad F., 2005, P C HUM LANG TECHN E, P955, DOI DOI 10.3115/1220575.1220695
   BEGER AL, 1996, COMPULATION LINGUIST, V22, P39
   BRILL E, 2000, P 38 ANN M ASS COMP, P286
   Church Kenneth, 1991, STAT COMPUT, V1, P93, DOI DOI 10.1007/BF01889984
   CUCERZAN S, 2004, P EMNLP 04, P293
   Damerau F., 1964, COMMUN ACM, V7, P659
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   ERIC S, 1997, P ICML 1997, P287
   Essen U., 1992, P ICASSP, V1, P161
   GOLDING AR, 1996, P 13 INT C MACH LEAR, P182
   KUKICH K, 1992, ACM COMPUT SURV, V24, P377
   LAWRENCE P, 1990, COMPUTER LANGUAGE, V7, P39
   Lee EA, 1999, ANN SOFTW ENG, V7, P25, DOI 10.1023/A:1018998524196
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Lillian L., 1997, P 35 ANN M ASS COMP, P56
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   MANGU L, 1997, P 14 INT C MACH LEAR, P734
   MARK D, 1990, P COLING 1990, P205
   MAYES E, 1991, INFORMATION PROCESSI, V27, P517
   Och F. J., 2002, P 40 ANN M ASS COMP, P295
   TOUTANOVA K, 2002, P 40 ANN M ASS COMP, P144
NR 21
TC 21
Z9 21
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1025
EP 1032
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200129
DA 2019-06-15
ER

PT B
AU Krishnan, V
   Manning, CD
AF Krishnan, Vijay
   Manning, Christopher D.
GP COLING
TI An Effective Two-Stage Model for Exploiting Non-Local Dependencies in
   Named Entity Recognition
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper shows that a simple two-stage approach to handle non-local dependencies in Named Entity Recognition (NER) can outperform existing approaches that handle non-local dependencies, while being much more computationally efficient. NER systems typically use sequence models for tractable inference, but this makes them unable to capture the long distance structure present in text. We use a Conditional Random Field (CRF) based NER system using local features to make predictions and then train another CRF which uses both local information and features extracted from the output of the first CRF. Using features capturing non-local dependencies from the same document, our approach yields a 12.6% relative error reduction on the F1 score, over state-of-the-art NER systems using local-information alone, when compared to the 9.3% relative error reduction offered by the best systems that exploit non-local information. Our approach also makes it easy to incorporate non-local information from other documents in the test corpus, and this gives us a 13.3% error reduction over NER systems using local-information alone. Additionally, our running time for inference is just the inference time of two sequential CRFs, which is much less than that of other more complicated approaches that directly model the dependencies and do approximate inference.
C1 [Krishnan, Vijay; Manning, Christopher D.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Krishnan, V (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM vijayk@cs.stanford.edu; manning@cs.stanford.edu
CR Borthwick A., 1999, THESIS NEW YORK U
   BUNESCU R, 2004, P 42 ANN M ASS COMP, P439
   Chieu H. L., 2002, P 19 INT C COMP LING, V1, P190
   Clark S., 2003, P 7 C NAT LANG LEARN, P164, DOI DOI 10.3115/1119176.1119200
   FINKEL J, 2005, P 42 ACL
   FREITAG D, 1999, P AAAI 99 WORKSH MAC
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Lafferty J. D., 2001, P 18 INT C MACH LEAR, P282
   Leek T. R., 1997, THESIS UC SAN DIEGO
   Malouf Robert, 2002, P CONLL 2002 TAIP TA, P187
   MCCALLUM A, 2000, P 17 ICML M KAUFM SA
   MIKHEEV A, 1999, P 9 C EUR CHAPT ASS, P1
   PEARL J, 1988, M KAUFFMANN
   SHA F, 2003, P C N AM CHAPT ASS C, P134
   SUTTON C, 2004, ICML WORKSH STAT REL
   Taskar B., 2002, P UAI 02
   YEDIDIA JS, 2000, P NEUR INF PROC SYST, P689
   Yeh A., 2000, P COLING 2000
NR 18
TC 20
Z9 20
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1121
EP 1128
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200141
DA 2019-06-15
ER

PT B
AU Clark, A
AF Clark, A
GP ACL
TI Combining distributional and morphological information for. part of
   speech induction
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB In this paper we discuss algorithms for clustering words into classes from unlabelled text using unsupervised algorithms, based on distributional and morphological information. We show how the use of morphological information can improve the performance on rare words, and that this is robust across a wide range of languages.
C1 Univ Geneva, ISSCO, TIM, UNI MAIL, CH-1211 Geneva 4, Switzerland.
CR Atwell E., 2000, ICAME J, V24, P7
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Chater N., 1992, BACKGROUND EXPT MACH, P229
   CLARK A, 2000, P CONLL 2000 LLL 200, P91
   Clark A., 2001, P NAT LANG PROC PAC, P341
   ERJAVEC T, 1998, 1 INT C LANG RES EV, P971
   FINCH S, 1992, PROCEEDINGS OF THE FOURTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P820
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   Jardino M., 1994, Grammatical Inference and Applications. Second International Colloquium, ICGI-94 Proceedings, P57
   Lamb SM, 1961, 1961 C MACH TRANSL L, V2, P674
   Martin S, 1998, SPEECH COMMUN, V24, P19, DOI 10.1016/S0167-6393(97)00062-9
   Martinez-Anaya MA, 1998, FOOD SCI TECHNOL INT, V4, P425, DOI 10.1177/108201329800400607
   Mikheev A, 1997, COMPUT LINGUIST, V23, P405
   MURAKAMI J, 1993, P EUR 93, P1327
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   Rosenfeld R., 2000, P IEEE, V88
   Schutze Hinrich, 1997, AMBIGUITY RESOLUTION
   WEBER K, 2001, 24 IDIAPRR
NR 18
TC 19
Z9 20
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 59
EP 66
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200009
DA 2019-06-15
ER

PT B
AU Surdeanu, M
   Harabagiu, S
   Williams, J
   Aarseth, P
AF Surdeanu, M
   Harabagiu, S
   Williams, J
   Aarseth, P
GP ACL
TI Using predicate-argument structures for information extraction
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB In this paper we present a novel, customizable IE paradigm that takes advantage of predicate-argument structures. We also introduce a new way of automatically identifying predicate argument structures, which is central to our IE paradigm. It is based on: (1) an extended set of features; and (2) inductive decision tree learning. The experimental results prove our claim that accurate predicate-argument structures enable high quality IE results.
C1 Language Comp Corp, Richardson, TX 75080 USA.
CR Baker C., 1998, P 17 INT C COMP LING, V1, P86, DOI DOI 10.3115/980845.980860
   Brill E., 1995, COMPUTATIONAL LINGUI
   Collins M., 1997, P 35 ANN M ASS COMP, P16
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   GILDEA D, 2002, P 40 ANN M ASS COMP, P239
   HIRSCHMAN L, 1999, HUB4 EVENT99 GEN GUI
   Hobbs JR, 1997, LANG SPEECH & COMMUN, P383
   KINGSBURY P, 2002, P HUM LANG TECHN C H, P252
   Levin B., 1993, ENGLISH VERB CLASSES
   NGAI G, 2001, P 2 ANN M N AM CHAPT, P40
   Quinlan R., 2002, DATA MINING TOOLS SE
   Riloff E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1044
   SURDEANU M, 2002, P HUM LANG TECHN C, P325
   YANGARBER R, 2000, P 18 INT C COMP LING, P940, DOI DOI 10.3115/992730.992782
NR 14
TC 19
Z9 20
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 8
EP 15
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500002
DA 2019-06-15
ER

PT S
AU Gatt, A
   Belz, A
AF Gatt, Albert
   Belz, Anja
BE Krahmer, E
   Theune, M
TI Introducing Shared Tasks to NLG: The TUNA Shared Task Evaluation
   Challenges
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
ID REFERRING EXPRESSIONS; GENERATION; INFORMATION
AB Shared Task Evaluation Challenges (STECs) have only recently begun in the field of NLG. The TUNA STECs, which focused on Referring Expression Generation (REG), have been part of this development since its inception. This chapter looks back on the experience of organising the three TUNA Challenges, which came to an end in 2009. While we discuss the role of the STECs in yielding a substantial body of research on the REG problem, which has opened new avenues for future research, our main focus is on the role of different evaluation methods in assessing the output quality of REG algorithms, and on the relationship between such methods.
C1 [Gatt, Albert] Univ Malta, Ctr Commun Technol, Inst Linguist, Msida, Malta.
   [Gatt, Albert] Tilburg Univ, Fac Arts, Commun & Cognit, NL-5000 LE Tilburg, Netherlands.
   [Belz, Anja] Brighton Univ, NLTG, Sch Comp Math & Informat Sci, Brighton, E Sussex, England.
RP Gatt, A (reprint author), Univ Malta, Ctr Commun Technol, Inst Linguist, Msida, Malta.
EM albert.gatt@um.edu.mt; asb@bton.ac.uk
OI Gatt, Albert/0000-0001-6388-8244
FU UK Engineering and Physical Sciences Research Council (epsrc)
FX Referring Expression Generation Challenges 2008 and Generation
   Challenges 2009 were organised with the financial support of the UK
   Engineering and Physical Sciences Research Council (epsrc).
CR Appelt D. E., 1987, P 10 INT JOINT C ART, P640
   APPELT DE, 1985, ARTIF INTELL, V26, P1, DOI 10.1016/0004-3702(85)90011-6
   Bard EG, 1996, LANGUAGE, V72, P32, DOI 10.2307/416793
   Belke E, 2002, EUR J COGN PSYCHOL, V14, P237, DOI 10.1080/09541440143000050
   Belz A., 2009, P 12 EUR WORKSH NAT, P16
   BELZ A, 2008, P 46 ANN M ASS COMP, P197
   BELZ A, 2006, P INLG 2006, P133
   Belz A., 2006, P 11 C EUR CHAPT ASS, P313
   BELZ A, 2007, P 2 UCNLG WORKSH LAN, P75
   BELZ A, 2005, P 10 EUR WORKSH NAT, P15
   Belz A, 2010, LECT NOTES ARTIF INT, V5790, P294, DOI 10.1007/978-3-642-15573-4_15
   Belz A, 2009, COMPUT LINGUIST, V35, P111, DOI 10.1162/coli.2009.35.1.111
   BOHNET B, 2007, P UCNLG MT LANG GEN, P84
   BOHNET B, 2005, P 19 INT JOINT C ART, P1004
   Bohnet B., 2008, P 5 INT C NAT LANG G, P207
   CAHILL A, 2006, P 21 INT C COMP LING, P1033
   Caley R., 1999, FESTIVAL SPEECH SYNT
   CALLAWAY C, 2003, P 18 INT JOINT C ART, P811
   Callaway CB, 2002, ARTIF INTELL, V139, P213, DOI 10.1016/S0004-3702(02)00230-8
   CALLISONBURCH C, 2006, P 11 C EUR CHAPT ASS, P249
   DALE R, 1995, COGNITIVE SCI, V19, P233
   DALE R, 2007, SHARED TASKS COMP EV
   Dale R., 1989, P 27 ANN M ASS COMP, P68, DOI DOI 10.3115/981623.981632
   DELUCENA D, 2008, P 5 INT C NAT LANG G, P219
   Doddington George, 2002, P 2 INT C HUM LANG T, P138, DOI DOI 10.3115/1289189.1289273
   DORR B., 2005, P ACL WORKSH INTR EX, P1
   Engelhardt PE, 2006, J MEM LANG, V54, P554, DOI 10.1016/j.jml.2005.12.009
   FABBRIZIO CD, 2008, P 12 C COMP NAT LANG, P151
   FABBRIZIO GD, 2008, P 5 INT C NAT LANG G, P211
   FOSTER ME, 2008, P 5 INT NAT LANG GEN, P95
   Galliers J. R., 1996, EVALUATING NATURAL L
   GARDENT C, 2002, P 40 ANN M ASS COMP, P96
   Gatt Albert, 2007, Journal of Logic, Language and Information, V16, P423, DOI 10.1007/s10849-007-9047-0
   GATT A, 2008, P 5 INT NAT LANG GEN, P50
   GATT A, 2009, P 12 EUR WORKSH NAT, P198
   GATT A, 2007, P 11 EUR WORKSH NAT, P45
   GATT A, 2008, P 5 INT NAT LANG GEN, P198
   Grice H. P., 1975, SYNTAX SEMANTICS SPE, V3
   GUPTA S, 2005, P 1 WORKSH US CORP N, P1
   HERVAS R, 2009, P 12 EUR WORKSH NAT, P187
   JORDAN P, 2000, P 38 ANN M ASS COMP, P142
   Jordan PW, 2005, J ARTIF INTELL RES, V24, P157
   JORDAN PW, 2000, P 38 ANN M ASS COMP
   KARASIMOS A, 2004, P 4 INT C LANG RES E
   KELLEHER J, 2008, P 5 INT C NAT LANG G, P221
   KING J, 2008, P 5 INT C NAT LANG G, P225
   KOLLER A, 2010, LNCS LNAI, V5790, P329
   Koolen Ruud, 2009, P WORKSH PROD REF EX
   Krahmer E, 2003, COMPUT LINGUIST, V29, P53, DOI 10.1162/089120103321337430
   KRONFELD A, 1989, P 27 ANN M ASS COMP, P60
   LANGKILDEGEARY I, 2002, P 2 INT C NAT LANG G
   Law Anna S, 2005, J Clin Monit Comput, V19, P183, DOI 10.1007/s10877-005-0879-3
   Lester JC, 1997, COMPUT LINGUIST, V23, P65
   LIN CY, 2003, P 2003 C N AM CHAPT, P71
   Maes A, 2004, DISCOURSE PROCESS, V37, P117, DOI 10.1207/s15326950dp3702_3
   Miyao Y., 2008, P 46 ANN M ASS COMP, P46
   PAPINENI S, 2002, P 40 ANN M ASS COMP, P311
   Passonneau Rebecca, 2006, P 5 INT C LANG RES E
   PECHMANN T, 1989, LINGUISTICS, V27, P89, DOI 10.1515/ling.1989.27.1.89
   PEREIRA DB, 2008, P 5 INT C NAT LANG G, P232
   Portet F, 2009, ARTIF INTELL, V173, P789, DOI 10.1016/j.artint.2008.12.002
   Reips UD, 2001, BEHAV RES METH INS C, V33, P201, DOI 10.3758/BF03195366
   Reiter E, 2005, ARTIF INTELL, V167, P137, DOI 10.1016/j.artint.2005.06.006
   Reiter E, 2003, ARTIF INTELL, V144, P41, DOI 10.1016/S0004-3702(02)00370-3
   REITER E, 2002, P 2 INT C NAT LANG G
   Reiter E, 2009, COMPUT LINGUIST, V35, P529, DOI 10.1162/coli.2009.35.4.35405
   SPANGER P, 2008, P UCNLG MT LANG GEN, P98
   Stock O, 2007, USER MODEL USER-ADAP, V17, P257, DOI 10.1007/s11257-007-9029-6
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   THEUNE M, 2007, P UCNLG MT LANG GEN, P95
   van Deemter K, 2002, COMPUT LINGUIST, V28, P37, DOI 10.1162/089120102317341765
   van der Sluis I, 2007, DISCOURSE PROCESS, V44, P145, DOI 10.1080/01638530701600755
   VANDEEMTER K, 2007, P 2 UCNLG WORKSH LAN
   VANDERSLUIS I, 2007, P C REC ADV NAT LANG
   Viethen J., 2006, P 4 INT C NAT LANG G, P63, DOI [10.3115/1706269.1706283, DOI 10.3115/1706269.1706283]
   Viethen J, 2007, TRAIT AUTOM LANG, V48, P141
   VONSTUTTERHEIM C, 1993, BELGIAN J LINGUISTIC, V8, P99
   WHITE M, 2007, P WORKSH US COP NLG
NR 78
TC 18
Z9 18
U1 0
U2 4
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 264
EP +
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600014
DA 2019-06-15
ER

PT B
AU Koo, T
   Collins, M
AF Koo, Terry
   Collins, Michael
GP Assoc Computat Linguist
TI Efficient Third-order Dependency Parsers
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present algorithms for higher-order dependency parsing that are "third-order" in the sense that they can evaluate substructures containing three dependencies, and "efficient" in the sense that they require only O(n(4)) time. Importantly, our new parsers can utilize both sibling-style and grandchild-style interactions. We evaluate our parsers on the Penn Treebank and Prague Dependency Treebank, achieving unlabeled attachment scores of 93.04% and 87.38%, respectively.
C1 [Koo, Terry; Collins, Michael] MIT CSAIL, Cambridge, MA 02139 USA.
RP Koo, T (reprint author), MIT CSAIL, Cambridge, MA 02139 USA.
EM maestro@csail.mit.edu; mcollins@csail.mit.edu
CR Attardi G., 2006, P 10 C COMP NAT LANG, P166
   Baker James, 1979, P 97 M AC SOC AM
   CARRERAS X, 2007, P CONLL SHAR TASK SE, P957
   Carreras Xavier, 2008, P 12 C COMP NAT LANG, P9
   Charniak Eugene, 2005, P 43 ACL
   CHU YJ, 1965, SCI SINICA, V14, P1396
   COCKE J, 1970, TECHNICAL REPORT, P77067
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Collins M, 2008, J MACH LEARN RES, V9, P1775
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Eisner J., 2000, ADV PROBABILISTIC OT, V16, P29
   Eisner J., 1996, P 16 INT C COMP LING, P340
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Hajic Jan, 2001, LDC2001T10
   Hajicova Eva, 1998, ISSUES VALENCY MEANI, P12
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Kasami T., 1965, AFCRL65758
   Koo T., 2008, P ACL 08 HLT COL OH, P595
   KOO T, 2007, P 2007 JOINT C EMP M, P141
   Koo Terry, 2010, THESIS
   Lafferty J.D., 2001, P INT C MACH LEARN, V18, P282
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Marinov Svetoslav, 2006, P 10 C COMP NAT LANG, P221
   McAllester David A., 1999, P 6 STAT AN S, P312
   McDonald R., 2005, P HUM LANG TECHN C C, P523
   McDonald R., 2005, P 43 ANN M ASS COMP, P91, DOI DOI 10.3115/1219840.1219852
   McDonald R, 2006, THESIS
   McDonald R., 2006, P 11 C EUR CHAPT ASS, V6, P81
   McDonald R., 2007, P 2007 JOINT C EMP M, P122
   McDonald Ryan, 2007, P IWPT
   Petrov S., 2007, P NAACL HLT 2007, P404
   Ratnaparkhi A., 1996, P C EMP METH NAT LAN, V1, P133
   Shen L., 2008, P ACL 08 HLT COL OH, P577
   Smith David A., 2007, P 2007 JOINT C EMP M, P132
   Suzuki J., 2009, P 2009 C EMP METH NA, V2, P551
   Taskar B, 2003, NIPS
   Yamada H., 2003, P 8 INT WORKSH PARS, V3, P195
   YOUNGER DH, 1967, INFORM CONTROL, V10, P189, DOI 10.1016/S0019-9958(67)80007-X
NR 38
TC 18
Z9 18
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1
EP 11
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300001
DA 2019-06-15
ER

PT B
AU Litvak, M
   Last, M
   Friedman, M
AF Litvak, Marina
   Last, Mark
   Friedman, Menahem
GP Assoc Computat Linguist
TI A new Approach to Improving Multilingual Summarization using a Genetic
   Algorithm
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Automated summarization methods can be defined as "language-independent," if they are not based on any language-specific knowledge. Such methods can be used for multilingual summarization defined by Mani (2001) as " processing several languages, with summary in the same language as input." In this paper, we introduce MUSE, a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. We tested our methodology on two languages-English and Hebrew-and evaluated its performance with ROUGE-1 Recall vs. stateof- the-art extractive summarization approaches. Our results show that MUSE performs better than the best known multilingual approach (TextRank(1)) in both languages. Moreover, our experimental results on a bilingual (English and Hebrew) document collection suggest that MUSE does not need to be retrained on each language and the same model can be used across at least two different languages.
C1 [Litvak, Marina; Last, Mark; Friedman, Menahem] Ben Gurion Univ Negev, Beer Sheva, Israel.
RP Litvak, M (reprint author), Ben Gurion Univ Negev, Beer Sheva, Israel.
EM litvakm@bgu.ac.il; mlast@bgu.ac.il; fmenahem@bgu.ac.il
RI LAST, MARK/F-1424-2012; Litvak, Marina/L-7078-2015
OI LAST, MARK/0000-0003-0748-7918; 
CR Arnold DV, 2002, IEEE T EVOLUT COMPUT, V6, P30, DOI 10.1109/4235.985690
   BAXENDALE PB, 1958, IBM J RES DEV, V2, P354, DOI 10.1147/rd.24.0354
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Edmundson H. P., 1969, NEW METHODS AUTOMATI, V16
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Filippova K., 2009, P 12 C EUR CHAPT ASS, P246
   Friedman M., 1994, FUNDAMENTALS COMPUTE
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Goldstein J, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P121, DOI 10.1145/312624.312665
   Gulli A., 2005, INDEXABLE WEB IS MOR
   Hassel M., 2006, P LANG RES EV
   Ishikawa K., 2002, P 2002 NTCIR 3 TSC W
   Kallel F. J., 2004, P DOC UND C
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Kupiec J., 1995, SIGIR Forum, P68
   Lin C. Y., 2003, P 2003 C N AM CHAPT, V2003, P71, DOI DOI 10.3115/1073445.1073465
   LIN C. -Y., 1997, P 5 C APPL NAT LANG, P283, DOI DOI 10.3115/974557.974599
   Lin C. Y., 2004, P WORKSH TEXT SUMM B, P25
   Litvak M., 2008, P WORKSH MULT MULT I, P17, DOI DOI 10.3115/1613172.1613178
   Liu DR, 2006, LECT NOTES COMPUT SC, V4223, P355
   Liu DX, 2006, LECT NOTES ARTIF INT, V4099, P1140
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Mani I., 2001, AUTOMATIC SUMMARIZAT
   Mihalcea R., 2005, AAAI, P1688
   Neto JL, 2000, LECT NOTES ARTIF INT, V1952, P300
   Orasan C, 2000, LECT NOTES ARTIF INT, V1835, P185
   Radev Dragomir, 2001, 1 DOC UND C
   Saggion H., 2003, EACL 03
   Salton G, 1997, INFORM PROCESS MANAG, V33, P193, DOI 10.1016/S0306-4573(96)00062-3
   SATOSHI C. N., 2001, P 2 NTCIR WORKSH, P319
   Schenker A, 2004, INT J PATTERN RECOGN, V18, P475, DOI 10.1142/S0218001404003241
   Schenker A., 2005, GRAPH THEORETIC TECH
   Steinberger J, 2004, LECT NOTES COMPUT SC, V3261, P245
   Teufel S., 1997, Intelligent Scalable Text Summarization. Proceedings of a Workshop, P58
   Turney P. D., 2000, Information Retrieval, V2, P303, DOI 10.1023/A:1009976227802
   Vanderwende L, 2007, INFORM PROCESS MANAG, V43, P1606, DOI 10.1016/j.ipm.2007.01.023
   Varga R., 1962, MATRIX ITERATIVE MET
   VIGNAUX GA, 1991, IEEE T SYST MAN CYB, V21, P445, DOI 10.1109/21.87092
   Wong K. F., 2008, P 22 INT C COMP LING, P985, DOI DOI 10.3115/1599081.1599205
   Yihong Gong, 2001, SIGIR Forum, P19
NR 40
TC 18
Z9 18
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 927
EP 936
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300095
DA 2019-06-15
ER

PT B
AU Navigli, R
   Velardi, P
AF Navigli, Roberto
   Velardi, Paola
GP Assoc Computat Linguist
TI Learning Word-Class Lattices for Definition and Hypernym Extraction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Definition extraction is the task of automatically identifying definitional sentences within texts. The task has proven useful in many research areas including ontology learning, relation extraction and question answering. However, current approaches - mostly focused on lexicosyntactic patterns - suffer from both low recall and precision, as definitional sentences occur in highly variable syntactic structures. In this paper, we proposeWordClass Lattices (WCLs), a generalization of word lattices that we use to model textual definitions. Lattices are learned from a dataset of definitions from Wikipedia. Our method is applied to the task of definition and hypernym extraction and compares favorably to other pattern generalization methods proposed in the literature.
C1 [Navigli, Roberto; Velardi, Paola] Sapienza Univ Roma, Dipartimento Informat, Rome, Italy.
RP Navigli, R (reprint author), Sapienza Univ Roma, Dipartimento Informat, Rome, Italy.
EM navigli@di.uniroma1.it; velardi@di.uniroma1.it
CR Agirre Eneko, 2000, P EUR
   Borg Claudia, 2009, P 1 WORKSH DEF EXTR
   Campbell WM, 2007, INT CONF ACOUST SPEE, P989
   Caraballo S, 1999, P 37 ANN M ASS COMP, P120
   Carpineto C, 2005, LECT NOTES ARTIF INT, V3626, P161
   COLLINS C, 2004, P 42 ANN M ASS COMP, P231
   Cormen T.H., 1990, INTRO ALGORITHMS
   Cui H, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1229179.1229182
   Degorski Lukasz, 2008, P  6 INT C LANG RES
   Del Gaudio Rosa, 2007, P TEMA WORKSH
   Dyer C, 2009, P HUM LANG TECHN 200, P406
   Dyer Christopher, 2008, P ACL 08 HLT COL OH, P1012
   Fahmi I., 2006, P EACL 2006 WORKSH L, P64
   Ferraresi A., 2008, P 4 WEB CORP WORKSH
   Gangemi Aldo, 2003, P INT C ONT DAT APPL, P820
   Hearst M.A., 1992, P 14 INT C COMP LING, P539, DOI DOI 10.3115/992133.992154
   Hovy Eduard, 2003, P 2003 ANN NAT C DIG, P1
   Iftene A., 2007, P RANLP WORKSH NAT L, P19
   Jiang W, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P385, DOI 10.1109/ICMLC.2008.4620436
   Klavans Judith, 2001, P AM MED INF ASS AMI
   Klein M. H., 2008, THESIS
   Mathias Lambert, 2006, P IEEE INT C AC SPEE
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Navigli R., 2010, P 7 INT C LANG RES E
   Navigli R., 2009, P 12 C EUR CHAPT ASS, P594
   Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355
   Navigli Roberto, 2006, P 15 INT C KNOWL ENG, P126, DOI DOI 10.1007/11891451_14
   Oakes Michael P., 2005, P WORKSH TEXT MIN RE
   Przepiorkowski A., 2007, P WORKSH BALT SLAV N, P43
   Ritter A., 2009, P AAAI 09 SPRING S L, P88
   Saggion Horacio, 2004, P 4 INT C LANG RES E
   SANFILIPPO A, 1992, P 3 C APPL NAT LANG, P80
   Schmid  H., 1995, P ACL SIGDAT WORKSH, P47
   Schroeder J., 2009, P 12 C EUR CHAPT ACL, P719
   Snow Rion, 2004, P NEUR INF PROC SYST, P1297
   Storrer Angelika, 2006, P 5 INT C LANG RES E
   Vanderwende L., 1993, P 1 C PAC ASS COMP L, P5
   Velardi P, 2008, IEEE INTELL SYST, V23, P18, DOI 10.1109/MIS.2008.88
   Westerhout E, 2009, P 1 WORKSH DEF EXTR, P61
   Westerhout Eline, 2007, P CLIN
   Zhang CX, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 2, P364, DOI 10.1109/ICCSIT.2009.5234687
   Zhong ZM, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING AND 2008 INTERNATIONAL PACIFIC WORKSHOP ON WEB MINING AND WEB-BASED APPLICATION, P275, DOI 10.1109/ISIP.2008.40
NR 42
TC 18
Z9 18
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1318
EP 1327
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300134
DA 2019-06-15
ER

PT B
AU Woodsend, K
   Lapata, M
AF Woodsend, Kristian
   Lapata, Mirella
GP Assoc Computat Linguist
TI Automatic Generation of Story Highlights
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID SENTENCE COMPRESSION
AB In this paper we present a joint content selection and compression model for single-document summarization. The model operates over a phrase-based representation of the source document which we obtain by merging information from PCFG parse trees and dependency graphs. Using an integer linear programming formulation, the model learns to select and combine phrases subject to length, coverage and grammar constraints. We evaluate the approach on the task of generating "story highlights"-a small number of brief, self-contained sentences that allow readers to quickly gather information on news stories. Experimental results show that the model's output is comparable to human-written highlights in terms of both grammaticality and content.
C1 [Woodsend, Kristian; Lapata, Mirella] Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland.
RP Woodsend, K (reprint author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9AB, Midlothian, Scotland.
EM k.woodsend@ed.ac.uk; mlap@inf.ed.ac.uk
CR Achterberg T., 2007, THESIS
   BANKO M, 2000, P 38 ANN M ASS COMP, P318
   Clarke J, 2008, J ARTIF INTELL RES, V31, P399, DOI 10.1613/jair.2433
   Cohn T, 2009, J ARTIF INTELL RES, V34, P637, DOI 10.1613/jair.2655
   Conroy J.M., 2004, DUC 2004 C P
   DAUME H, 2002, P 40 ANN M ASS COMP, P449
   Daume III H., 2006, THESIS
   JING H, 2000, P 6 C APPL NAT LANG, P310
   JING H, 2000, P 1 N AM CHAPT ASS C, P178
   Jing HY, 2002, COMPUT LINGUIST, V28, P527, DOI 10.1162/089120102762671972
   JONES KS, 1999, ADV AUTOMATIC TEXT S, P1
   Keller F, 2009, BEHAV RES METHODS, V41, P1, DOI 10.3758/BRM.41.1.12
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   Koch T., 2004, THESIS
   KUPIEC J, 1995, P 18 ANN INT ACM SIG, P68
   Lapata M., 2007, P 2007 JOINT C EMP M, P1
   Lin CL, 2003, IEEE ASME INT C ADV, P1
   LIN CY, 2003, P 2003 C N AM CHAPT, P71
   Mani I., 2001, AUTOMATIC SUMMARIZAT
   Martins T., 2009, P WORKSH INT LIN PRO, P1
   McDonald Ryan, 2007, P 29 ECIR ROM IT
   McDonald Ryan, 2006, P 11 EACL TRENT IT
   NENKOVA A, 2005, P 20 NAT C ART INT A, P1436
   Siddharthan A., 2004, P 20 INT C COMP LING, P896
   Svore K, 2007, P JOINT C EMP METH N, P448
   Wan Stephen, 2008, P 1 TAC GAITH MD
   Witten I., 1999, P 4 ACM C DIG LIB, P254, DOI DOI 10.1145/313238.313437
   Woodsend Kristian, 2009, COMPUTATIONAL OPTIMI
   Wunderling R., 1996, THESIS
   Zajic D, 2007, INFORM PROCESS MANAG, V43, P1549, DOI 10.1016/j.ipm.2007.01.016
   Zajic David, 2003, P HLT NAACL TEXT SUM, V5, P1, DOI DOI 10.3115/1119467.1119468
NR 32
TC 18
Z9 18
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 565
EP 574
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300058
DA 2019-06-15
ER

PT B
AU Goldwater, S
   Griffiths, TL
   Johnson, M
AF Goldwater, Sharon
   Griffiths, Thomas L.
   Johnson, Mark
GP COLING
TI Contextual Dependencies in Unsupervised Word Segmentation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID DISCOVERY
AB Developing better methods for segmenting continuous text into words is important for improving the processing of Asian languages, and may shed light on how humans learn to segment speech. We propose two new Bayesian word segmentation methods that assume unigram and bigram models of word dependencies respectively. The bigram model greatly outperforms the unigram model (and previous probabilistic models), demonstrating the importance of such dependencies for word segmentation. We also show that previous probabilistic models rely crucially on suboptimal search procedures.
C1 [Goldwater, Sharon; Griffiths, Thomas L.; Johnson, Mark] Brown Univ, Dept Cognit & Linguist Sci, Providence, RI 02912 USA.
RP Goldwater, S (reprint author), Brown Univ, Dept Cognit & Linguist Sci, Providence, RI 02912 USA.
EM Sharon_Goldwater@brown.edu; Tom_Griffiths@brown.edu;
   Mark_Johnson@brown.edu
OI Johnson, Mark/0000-0003-4809-8441
CR Aldous D, 1985, ECOLE ETE PROBABILIT, P1
   ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871
   BERNSTEINRATNER N, 1987, CHILDRENS LANGUAGE, V6
   Brent MR, 1999, MACH LEARN, V34, P71, DOI 10.1023/A:1007541817488
   COHEN P, 2001, P 4 S INT DAT AN
   FENG H, 2004, COMPUTATIONAL LINGUI, V30
   Gilks W., 1996, MARKOV CHAIN MONTE C
   GOLDWATER S, 2006, ADV NEURAL INFORM PR, V18
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   MACWHINNEY B, 1985, J CHILD LANG, V12, P271, DOI 10.1017/S0305000900006449
   Saffran JR, 1996, J MEM LANG, V35, P606, DOI 10.1006/jmla.1996.0032
   SUN M, 1998, P COLING ACL
   TEH Y, 2006, TRA206 NAT U SING SC
   TEH YW, 2005, ADV NEURAL INFORM PR, V17
   Venkataraman A, 2001, COMPUT LINGUIST, V27, P351, DOI 10.1162/089120101317066113
NR 15
TC 18
Z9 18
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 673
EP 680
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200085
DA 2019-06-15
ER

PT B
AU Habash, N
   Rambow, O
AF Habash, Nizar
   Rambow, Owen
GP COLING
TI MAGEAD: A Morphological Analyzer and Generator for the Arabic Dialects
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present MAGEAD, a morphological analyzer and generator for the Arabic language family. Our work is novel in that it explicitly addresses the need for processing the morphology of the dialects. MAGEAD performs an on-line analysis to or generation from a root+pattern+features representation, it has separate phonological and orthographic representations, and it allows for combining morphemes from different dialects. We present a detailed evaluation of MAGEAD.
C1 [Habash, Nizar; Rambow, Owen] Columbia Univ, Ctr Computat Learning Syst, New York, NY 10115 USA.
RP Habash, N (reprint author), Columbia Univ, Ctr Computat Learning Syst, New York, NY 10115 USA.
EM habash@cs.columbia.edu; rambow@cs.columbia.edu
CR Al-Sughaiyer IA, 2004, J AM SOC INF SCI TEC, V55, P189, DOI 10.1002/asi.10368
   Beesley K., 1989, P SEM BIL COMP AR EN
   BEESLEY KR, 1998, P WORKSH COMP APPR S, P50
   Bird S., 1994, Computational Linguistics, V20, P55
   Buckwalter T, 2002, BUCKWALTER ARABIC MO
   DARWISH K, 2003, ACL02 WORKSH COMP AP
   FERGUSON CA, 1959, WORD, V15, P325, DOI 10.1080/00437956.1959.11659702
   HABASH N, 2005, P ACL WORKSH COMP AP
   Habash N, 2004, P TRAIT AUT LANG NAT
   HABASH N, 2006, REPRESENTATION UNPUB
   KATAJA L, 1988, COLING 88, V1, P313
   Kay M, 1987, P 3 C EUR CHAPT ASS, P2
   Kiraz G. A., 2001, COMPUTATIONAL NONLIN
   Kiraz GA, 2000, COMPUT LINGUIST, V26, P77, DOI 10.1162/089120100561647
   Kornai A, 1995, FORMAL PHONOLOGY
   KOSKENNIEMI K, 1983, THESIS U HELSINKI
   Maamouri M., 2004, NEMLAR C AR LANG RES
   Maamouri M., 2006, P LREC GEN IT
   MCCARTHY JJ, 1981, LINGUIST INQ, V12, P373
   Mohri M, 1998, LECT NOTES COMPUT SC, V1436, P144
   Pulman S. G., 1993, Computer Speech and Language, V7, P333, DOI 10.1006/csla.1993.1018
   Sproat Richard, 1995, 1152295110810TM BELL
NR 22
TC 18
Z9 18
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 681
EP 688
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200086
DA 2019-06-15
ER

PT B
AU Hulth, A
   Megyesi, BB
AF Hulth, Anette
   Megyesi, Beata B.
GP COLING
TI A Study on Automatically Extracted Keywords in Text Categorization
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents a study on if and how automatically extracted keywords can be used to improve text categorization. In summary we show that a higher performance - as measured by micro-averaged F-measure on a standard text categorization collection - is achieved when the full-text representation is combined with the automatically extracted keywords. The combination is obtained by giving higher weights to words in the full-texts that are also extracted as keywords. We also present results for experiments in which the keywords are the only input to the categorizer, either represented as unigrams or intact. Of these two experiments, the unigrams have the best performance, although neither performs as well as headlines only.
C1 [Hulth, Anette; Megyesi, Beata B.] Uppsala Univ, Dept Linguist & Philol, S-75105 Uppsala, Sweden.
RP Hulth, A (reprint author), Uppsala Univ, Dept Linguist & Philol, S-75105 Uppsala, Sweden.
EM anette.hulth@gmail.com; bea@stp.lingfil.uu.se
RI Hulth, Anette/E-2162-2017
OI Hulth, Anette/0000-0002-3132-808X
CR Aizawa A., 2001, P 6 NAT LANG PROC PA, P307
   Caropreso MF, 2001, TEXT DATABASES AND DOCUMENT MANAGEMENT: THEORY AND PRACTICE, P78
   Dumais S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P148, DOI 10.1145/288627.288651
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Furnkranz J, 1998, AAAI 98 WORKSH LEARN
   Hulth A, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P216
   HULTH A, 2004, THESIS STOCKHOLM U
   Joachims T, 1999, ADV KERNEL METHODS S
   Ko Y, 2004, INFORM PROCESS MANAG, V40, P65, DOI 10.1016/S0306-4573(02)00056-0
   Kolcz A., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P365
   Lewis David D., 1997, REUTERS 21578 TEXT C
   LI C, 2003, P 20 INT C MACH LEAR
   Mihalcea R., 2004, P C EMP METH NAT LAN
   Mihalcea R., 2005, P C REC ADV NAT LANG
   MOSCHITTI A, 2004, P 26 EUR C INF RETR, P181
   OZGUR A, 2005, P 20 INT S COMP INF, V3733, P607
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Sahlgren M, 2004, P 20 INT C COMP LING, P487
   Yang Y., 1999, P 22 ANN INT ACM SIG, P42, DOI DOI 10.1145/312624.312647
NR 19
TC 18
Z9 18
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 537
EP 544
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200068
DA 2019-06-15
ER

PT B
AU Zitouni, I
   Sorensen, JS
   Sarikaya, R
AF Zitouni, Imed
   Sorensen, Jeffrey S.
   Sarikaya, Ruhi
GP COLING
TI Maximum Entropy Based Restoration of Arabic Diacritics
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Short vowels and other diacritics are not part of written Arabic scripts. Exceptions are made for important political and religious texts and in scripts for beginning students of Arabic. Script without diacritics have considerable ambiguity because many words with different diacritic patterns appear identical in a diacritic-less setting. We propose in this paper a maximum entropy approach for restoring diacritics in a document. The approach can easily integrate and make effective use of diverse types of information; the model we propose integrates a wide array of lexical, segment-based and part-of-speech tag features. The combination of these feature types leads to a state-of-the-art diacritization model. Using a publicly available corpus (LDC's Arabic Treebank Part 3), we achieve a diacritic error rate of 5.1%, a segment error rate 8.5%, and a word error rate of 17.3%. In case-ending-less setting, we obtain a diacritic error rate of 2.2%, a segment error rate 4.0%, and a word error rate of 7.2%.
C1 [Zitouni, Imed; Sorensen, Jeffrey S.; Sarikaya, Ruhi] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Zitouni, I (reprint author), IBM Corp, TJ Watson Res Ctr, 1101 Kitchawan Rd, Yorktown Hts, NY 10598 USA.
EM izitouni@us.ibm.com; sorenj@us.ibm.com; sarikaya@us.ibm.com
CR AFIFY M, 2004, RT04 WORKSH PAL NY
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BUCKWALTER T, 1996, LDC2002149
   Chen S., 2000, IEEE T SPEECH AUDIO
   DEBILI F, 2002, 17 I RECH MAGHR CONT
   El-Sadany T., 1988, 10 NC C JEDD SAUD AR
   ELIMAM Y, 2003, COMPUTER SPEECH LANG, V18, P339
   EMAM O, 2004, Patent No. 20050192809
   Florian R., 2004, P HUM LANG TECHN C N, P1
   GAL Y, 2002, ACL 02 WORKSH COMP A
   GOODMAN J, 2002, P ACL 02
   Kirchhoff K, 2005, SPEECH COMMUN, V46, P37, DOI 10.1016/j.specom.2005.01.004
   Lafferty J. O., 2001, ICML
   LEE YS, 2003, P ACL 03, P399
   McCallum A., 2000, ICML
   Nelken  R., 2005, ACL WORKSH COMP APPR, P79
   Ratnaparkhi  A., 1996, C EMP METH NAT LANG
   STANLEY F, 1999, COMPUTER SPEECH LANG, V4, P359
   Tayli M., 1990, Communications of the ACM, V33, P495, DOI 10.1145/78607.78610
   VERGYRI D, 2004, COLING WORKSH AR SCR
   Zhang T, 2002, J MACH LEARN RES, V2, P615, DOI 10.1162/153244302320884560
   Zitouni I., 2005, P ACL WORKSH COMP AP, P63
NR 22
TC 18
Z9 19
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 577
EP 584
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200073
DA 2019-06-15
ER

PT B
AU Och, FJ
   Gildea, D
   Khudanpur, S
   Sarkar, A
   Yamada, K
   Fraser, A
   Kumar, S
   Shen, LB
   Smith, D
   Eng, K
   Jain, V
   Jin, Z
   Radev, D
AF Och, FJ
   Gildea, D
   Khudanpur, S
   Sarkar, A
   Yamada, K
   Fraser, A
   Kumar, S
   Shen, LB
   Smith, D
   Eng, K
   Jain, V
   Jin, Z
   Radev, D
GP acl
TI A smorgasbord of features for statistical machine translation
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We describe a methodology for rapid experimentation in statistical machine translation which we use to add a large number of features to a baseline system exploiting features from a wide range of levels of syntactic representation. Feature values were combined in a log-linear model to select the highest scoring candidate translation from an n-best list. Feature weights were optimized directly against the BLEU evaluation metric on held-out data. We present results for a small selection of features at each level of syntactic representation.
RI Radev, Dragomir/E-9641-2012
CR Alshawi H, 2000, COMPUT LINGUIST, V26, P45, DOI 10.1162/089120100561629
   Brown P. F., 1993, Computational Linguistics, V19, P263
   GILDEA D, 2003, P 41 ANN M ASS COMP
   NEY H, 1995, P 4 EUR C SPEECH COM
   OCH F, 2003, P 41 ANN M ASS COMP
   OCH FJ, 2002, P 40 ANN M ASS COMP
   OCH FJ, 2004, IN PRESS COMPUTATION
   Och Franz Josef, 1999, P JOINT SIGDAT C EMP
   SCHAFER C, 2003, P 2003 C EMP METH NA
   Vogel S., 1996, COLING 96
   WU DK, 1998, COLING ACL 98
   YAMADA K, 2002, P 40 ANN M ASS COMP
   Yamada  K., 2001, P 39 ANN M ASS COMP
NR 13
TC 18
Z9 18
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 161
EP 168
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100021
DA 2019-06-15
ER

PT B
AU Shen, LB
   Sarkar, A
   Och, FJ
AF Shen, LB
   Sarkar, A
   Och, FJ
GP acl
TI Discriminative reranking for machine translation
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB This paper describes the application of discriminative reranking techniques to the problem of machine translation. For each sentence in the source language, we obtain from a baseline statistical machine translation system, a ranked n-best list of candidate translations in the target language. We introduce two novel perceptron-inspired reranking algorithms that improve on the quality of machine translation over the baseline system based on evaluation using the BLEU metric. We provide experimental results on the NIST 2003 Chinese-English large data track evaluation. We also provide theoretical analysis of our algorithms and experiments that verify that our algorithms provide state-of-the-art performance in machine translation.
C1 Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA.
RP Shen, LB (reprint author), Univ Penn, Dept Comp & Informat Sci, 200 S 33Rd St, Philadelphia, PA 19104 USA.
CR Brown P. F., 1990, Computational Linguistics, V16, P79
   COH FJ, 2003, ACL 2003
   Collins M., 2002, P ACL 2002
   COLLINS M, 2000, P 7 ICML
   CRAMMER K, 2001, NIPS 2001
   GILDEA D, 2003, ACL 2003
   Harrington E. F., 2003, ICML
   Herbrich R, 2000, ADV NEUR IN, P115
   KRAUTH W, 1987, J PHYSICS A, V20, P745
   LI Y, P ICML 2002
   OCH F, 2002, ACL 2002
   OCH FJ, 1999, EMNLP WVLC
   OCH FJ, 1998, COLING ACL 1998
   PAPINENI K, RC22176 IBM
   SCHAPIRE RE, 1997, P 14 ICML
   SHEN L, 2003, P CONLL
   SHEN L, 2004, P 1 IJCNLP
   *SMT TEAM, 2003, JHU SUMM WORKSH 2003
   Vapnik V. N., 1998, STAT LEARNING THEORY
   WANG Y, 1998, COLING ACL
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   YAMADA K, 2001, ACL 2001
   ZHANG T, 2000, KDD 2000 WORKSH TEXT
NR 23
TC 18
Z9 18
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 177
EP 184
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100023
DA 2019-06-15
ER

PT B
AU Schneider, KM
AF Schneider, KM
GP ACL
TI A comparison of event models for naive Bayes anti-spam e-mail filtering
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We describe experiments With a Naive Bayes text classifier in the context of anti-spam E-mail filtering, using two different statistical event models: a multi-variate Bernoulli model and a multinomial model. We introduce a family of feature ranking functions for feature selection in the multinomial event model that take account of the word frequency information. We present evaluation results on two publicly available corpora of legitimate and spam E-mails. We find that the multinomial model is less biased towards one class and achieves slightly higher accuracy than the multi-variate Bernoulli model.
C1 Univ Passau, Dept Gen Linguist, D-94032 Passau, Germany.
CR Androutsopoulos I., 2000, P WORKSH MACH LEARN, V97, P1
   Androutsopoulos I., 2000, P 23 ANN INT ACM SIG, P160
   CARRERAS X, 2001, P INT C REC ADV NAT
   Cohen W., 1996, AAAI SPRING S MACH L, P18
   COVER TM, 1991, ELEMENTS INFORMATION
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Harro J, 1999, EUR NEUROPSYCHOPHARM, V10, P5, DOI 10.1016/S0924-977X(99)00043-7
   LEWIS D. Naive, 1998, LECT NOTES COMPUTER, V1398, P4, DOI [DOI 10.1007/BFB0026666, 10.1007/BFb0026666]
   MCCALLUM A, 1998, P AAAI 98 WORKSH LEA, P41
   Mladenic D, 1999, P 16 INT C MACH LEAR, P258
   RENNIE J, 2000, P KDD 2000 WORKSH TE
   SAHAMI M, 1998, LEARNING TEXT CATEGO, P55
   Sakkis G, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P44
   YANG Y, 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026
NR 14
TC 18
Z9 18
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 307
EP 314
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200040
DA 2019-06-15
ER

PT B
AU Liao, SS
   Grishman, R
AF Liao, Shasha
   Grishman, Ralph
GP Assoc Computat Linguist
TI Using Document Level Cross-Event Inference to Improve Event Extraction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Event extraction is a particularly challenging type of information extraction (IE). Most current event extraction systems rely on local information at the phrase or sentence level. However, this local context may be insufficient to resolve ambiguities in identifying particular types of events; information from a wider scope can serve to resolve some of these ambiguities. In this paper, we use document level information to improve the performance of ACE event extraction. In contrast to previous work, we do not limit ourselves to information about events of the same type, but rather use information about other types of events to make predictions or resolve ambiguities regarding a given event. We learn such relationships from the training corpus and use them to help predict the occurrence of events and event arguments in a text. Experiments show that we can get 9.0% (absolute) gain in trigger (event) classification, and more than 8% gain for argument (role) classification in ACE event extraction.
C1 [Liao, Shasha; Grishman, Ralph] NYU, 715 Broadway,7th Floor, New York, NY 10003 USA.
RP Liao, SS (reprint author), NYU, 715 Broadway,7th Floor, New York, NY 10003 USA.
EM liaoss@cs.nyu.edu; grishman@cs.nyu.edu
CR Ahn D., 2006, P COLING ACL 2006 WO
   Finkel J. R., 2005, P 43 ANN M ASS COMP, P363, DOI DOI 10.3115/1219840.1219885
   Grishman R., 2005, P ACE 2005 EV WORKSH
   Gupta Prashant, 2009, P ACL IJCNLP 2009
   Hardy H., 2006, P AAAI06 WORKSH EV E
   Ji H., 2008, P 46 ANN M ASS COMP, P254
   Maslennikov M, 2007, P 45 ANN M ASS COMP, V45, P592
   Patwardhan S., 2009, P C EMP METH NAT LAN
   Patwardhan S., 2007, P 2007 JOINT C EMP M, V7, P717
   Yarowsky David, 1995, P ACL 1995 CAMBR MA
NR 10
TC 17
Z9 17
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 789
EP 797
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300081
DA 2019-06-15
ER

PT B
AU Brockett, C
   Dolan, WB
   Gamon, M
AF Brockett, Chris
   Dolan, William B.
   Gamon, Michael
GP COLING
TI Correcting ESL Errors Using Phrasal SMT Techniques
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents a pilot study of the use of phrasal Statistical Machine Translation (SMT) techniques to identify and correct writing errors made by learners of English as a Second Language (ESL). Using examples of mass noun errors found in the Chinese Learner Error Corpus (CLEC) to guide creation of an engineered training set, we show that application of the SMT paradigm can capture errors not well addressed by widely-used proofing tools designed for native speakers. Our system was able to correct 61.81% of mistakes in a set of naturally-occurring examples of mass noun errors found on the World Wide Web, suggesting that efforts to collect alignable corpora of pre- and post-editing ESL writing samples offer can enable the development of SMT-based writing assistance tools capable of repairing many of the complex syntactic and lexical problems found in the writing of ESL learners.
C1 [Brockett, Chris; Dolan, William B.; Gamon, Michael] Microsoft Res, Nat Language Proc Grp, Redmond, WA 98005 USA.
RP Brockett, C (reprint author), Microsoft Res, Nat Language Proc Grp, 1 Microsoft Way, Redmond, WA 98005 USA.
EM chrisbkt@microsoft.com; billdol@microsoft.com; mgamon@microsoft.com
CR BOND F, 1994, COUNTABILITY NUMBER
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHODOROW M, 2000, UNSUPERVISED METHOD
   COLLINS M, 2005, CLAUSE RESTRUCTURING, P531
   Dalgish G. M., 1984, CALICO Journal, V2, P32
   FALTIN AV, 2003, LINGUISTIK ONLINE, V17
   FOX HJ, 2002, PHRASAL COHESION STA
   Gui S., 2003, ZHONGGUO XUEXIZHE YI
   HUA DF, 2004, P 7 GEN APPR 2 LANG
   LIU T, 2000, PENS MACHINE AIDED E
   LONSDALE D, 2003, P HLT NAACL WORKSH B
   MENEZES A, 2005, P INT WORKSH SPOK LA
   Och FJ, 2003, MINIMUM ERROR RATE T
   OCH FJ, 2000, IMPROVED STAT ALIGNM
   QUIRK C, 2005, DEPENDENCY TREE TRAN
   Reuer V., 2003, CALICO Journal, V20, P497
   TOMOKIYO LM, 2001, YOU RE ROUND HERE AR
NR 17
TC 17
Z9 17
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 249
EP 256
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200032
DA 2019-06-15
ER

PT B
AU Demner-Fushman, D
   Lin, J
AF Demner-Fushman, Dina
   Lin, Jimmy
GP COLING
TI Answer Extraction, Semantic Clustering, and Extractive Summarization for
   Clinical Question Answering
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID INFORMATION NEEDS; CARE
AB This paper presents a hybrid approach to question answering in the clinical domain that combines techniques from summarization and information retrieval. We tackle a frequently-occurring class of questions that takes the form "What is the best drug treatment for X?" Starting from an initial set of MEDLINE citations, our system first identifies the drugs under study. Abstracts are then clustered using semantic classes from the UMLS ontology. Finally, a short extractive summary is generated for each abstract to populate the clusters. Two evaluations-a manual one focused on short answers and an automatic one focused on the supporting abstracts-demonstrate that our system compares favorably to PubMed, the search system most widely used by physicians today.
C1 [Demner-Fushman, Dina; Lin, Jimmy] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
RP Demner-Fushman, D (reprint author), Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
EM demner@cs.umd.edu; jimmylin@umd.edu
CR AMIGO E, 2004, ACL 2004
   ARONSON A, 2001, AMIA 2001
   Chambliss ML, 1996, J FAM PRACTICE, V43, P140
   Cogdill KW, 1997, B MED LIBR ASSOC, V85, P51
   COVELL DG, 1985, ANN INTERN MED, V103, P596, DOI 10.7326/0003-4819-103-4-596
   Dang H., 2005, DUC 2005 WORKSH HLT
   De Groote SL, 2003, J MED LIBR ASSOC, V91, P231
   DEMNERFUSHMAN D, 2006, COMP LING IN PRESS
   DEMNERFUSHMAN D, 2005, AAAI 2005 WORKSH QA
   DUMAIS S, 2001, CHI 2001
   Ely JW, 1999, BRIT MED J, V319, P358, DOI 10.1136/bmj.319.7206.358
   GORMAN PN, 1994, B MED LIBR ASSOC, V82, P140
   HAUSER S, 2004, MEDINFO 2004
   HEARST M, 1996, SIGIR 1996
   LAWRIE D, 2003, SIGIR 2003
   LIN J, 2005, SIGIR 2005
   LINDBERG DAB, 1993, METHOD INFORM MED, V32, P281
   MCKEOWN K, 2003, JCDL 2003
   MENDONCA E, 2001, MEDINFO 2001
   NIU Y, 2004, ACL 2004 WORKSH QA R
   Sackett D. L., 2000, EVIDENCE BASED MED P
   Voorhees E. M., 2005, HLT EMNLP 2005
   ZHAO Y, 2002, CIKM 2002
NR 23
TC 17
Z9 17
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 841
EP 848
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200106
DA 2019-06-15
ER

PT B
AU Jiao, F
   Wang, SJ
   Lee, CH
   Greiner, R
   Schuurmans, D
AF Jiao, Feng
   Wang, Shaojun
   Lee, Chi-Hoon
   Greiner, Russell
   Schuurmans, Dale
GP COLING
TI Semi-Supervised Conditional Random Fields for Improved Sequence
   Segmentation and Labeling
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a new semi-supervised training procedure for conditional random fields (CRFs) that can be used to train sequence segmentors and labelers from a combination of labeled and unlabeled training data. Our approach is based on extending the minimum entropy regularization framework to the structured prediction case, yielding a training objective that combines unlabeled conditional entropy with labeled conditional likelihood. Although the training objective is no longer concave, it can still be used to improve an initial model (e.g. obtained from supervised training) by iterative ascent. We apply our new training algorithm to the problem of identifying gene and protein mentions in biological texts, and show that incorporating unlabeled data improves the performance of the supervised CRF in this case.
C1 [Jiao, Feng] Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
RP Jiao, F (reprint author), Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
CR Abney S., 2004, Computational Linguistics, V30, P365, DOI 10.1162/0891201041850876
   Altun Y., 2005, ADV NEURAL INFORM PR, V18
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Boyd S., 2004, CONVEX OPTIMIZATION
   Castelli V, 1996, IEEE T INFORM THEORY, V42, P2102, DOI 10.1109/18.556600
   CELEUX G, 1992, COMPUT STAT DATA AN, V14, P315, DOI 10.1016/0167-9473(92)90042-E
   COHEN I, 2006, SEMISUPERVISED LEARN, P55
   CORDUNEANU A, 2006, SEMISUPERVISED LEARN, P163
   COVER T, 1991, ELENTENTS INFORM THE
   Duda RO, 1973, PATTERN CLASSIFICATI
   GRANDVALET Y, 2004, ADV NEURAL INFORM PR, V17, P529
   Lafferty J. D., 2001, P 18 INT C MACH LEAR, P282
   LI W, 2005, P 20 NAT C ART INT, P813
   McCallum Andrew Kachites, 2002, MALLET MACHINE LEARN
   McDonald R, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-S1-S6
   MCDONALD R, 2005, CONDITIONAL RANDOM F
   NIGAM K, 2000, MACH LEARN, V39, P135
   Nocedal Jorge, 2000, NUMERICAL OPTIMIZATI
   Roberts SJ, 2000, PATTERN RECOGN, V33, P833, DOI 10.1016/S0031-3203(99)00086-2
   VISWANATHAN S, 2006, P 23 INT C MACH LEAR
   Yarowsky D, 1995, P ACL, P189, DOI DOI 10.3115/981658.981684
   Zhou D., 2005, P 22 INT C MACH LEAR, P1041
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu X., 2003, P 20 INT C MACH LEAR, P912, DOI DOI 10.1109/18.850663
NR 24
TC 17
Z9 17
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 209
EP 216
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200027
DA 2019-06-15
ER

PT J
AU Klein, D
   Manning, CD
AF Klein, D
   Manning, CD
TI Natural language grammar induction with a generative constituent-context
   model
SO PATTERN RECOGNITION
LA English
DT Article; Proceedings Paper
CT 40th Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2002
CL Univ Penn, Philadelphia, PA
SP Assoc Computat Linguist, Assoc Computat Linguist, N Amer Chapter, Linguist Data Consortium, Microsoft Res, Sun, 240 Teragram, AT&T, BASIS Technol, BBN Technologies, LexisNexis, Cornell
HO Univ Penn
DE natural language; structure learning; grammar induction; distributional
   clustering; unsupervised learning
AB We present a generative probabilistic model for the unsupervised learning of hierarchical natural language syntactic Structure. Unlike most previous work, we do not learn a context-free grammar, but rather induce a distributional model of constituents which explicitly relates constituent yields and their linear contexts. Parameter search with EM produces higher quality analyses for human language data than those previously exhibited by unsupervised systems, giving the best published unsupervised parsing results on the ATIS corpus. Experiments on Penn treebank sentences of comparable length show an even higher constituent F-1 of 71% on non-trivial brackets. We compare distributionally induced and actual part-of-speech tags as input data, and examine extensions to the basic model. We discuss errors made by the system, compare the system to previous models, and discuss upper bounds, lower bounds, and stability for this task. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.
C1 Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Manning, CD (reprint author), Stanford Univ, Dept Comp Sci, 353 Serra Mall,Room 418, Stanford, CA 94305 USA.
EM manning@cs.stanford.edu
RI Manning, Christopher/A-1358-2007
CR Abe N., 1990, Proceedings of the Third Annual Workshop on Computational Learning Theory, P52
   Abney Stephen, 1987, THESIS MIT CAMBRIDGE
   ADRIAANS P, 1999, P 1 WORKSH LEARN LAN, P117
   Baker J., 1979, 97 M AC SOC AM, P547
   Black E., 1991, P DARPA SPEECH NAT L, P306
   BRILL E, 1993, ACL, V31, P259
   Carroll G, 1992, WORKSH STAT BAS NLP, P1
   Charniak E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1031
   Chater N., 1992, BACKGROUND EXPT MACH, P229
   CHEN SF, 1995, ACL, V33, P228
   CLARK A, 2001, 5 C NAT LANG LEARN
   CLARK A, 2000, 4 C NAT LANG LEARN
   COLLINS MJ, 1997, ACL 35 EACL, V8, P16
   DELAHIGUERA C, 1996, LECT NOTES ARTIF INT, V1147, P313
   Finch Steven P, 1993, THESIS U EDINBURGH
   Gazdar G., 1989, NATURAL LANGUAGE PRO
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Halliday M. A. K, 1994, INTRO FUNCTIONAL GRA
   Harris Zellig S., 1951, METHODS STRUCTURAL L
   Horning J.J., 1969, THESIS STANFORD
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Kearns M., 1994, Proceedings of the Twenty-Sixth Annual ACM Symposium on the Theory of Computing, P273, DOI 10.1145/195058.195155
   KLEIN D, 2001, P 5 C NAT LANG LEARN, P113
   KLEIN D, 2001, ADV NEURAL INFORMATI, V1, P35
   Lamb SM, 1961, 1961 C MACH TRANSL L, V2, P674
   LANG KJ, 1998, LECT NOTES ARTIF INT, V1433, P1, DOI DOI 10.1007/BFB0054059
   LANGLEY P, 1980, P 8 INT C COMP LING, P183
   LANGLEY P, 1982, P 20 ANN C SOC COMP, P145
   Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   OLIVIER DC, 1968, THESIS HARVARD U
   PEREIRA F, 1992, ACL, V30, P128
   Radford A, 1988, TRANSFORMATIONAL GRA
   SCHUTZE H, 1995, EACL, V7, P141
   SELFRIDGE M, 1981, P 7 INT JOINT C ART, P92
   Skut W, 1997, P 5 C APPL NAT LANG
   STOLCKE A, 1994, P 2 INT C GRAMM INF
   VANZAANEN M, 2000, COLING, V18, P961
   WOLFF JG, 1978, P AISB GI C ARTIFICI, P375
   WOLFF JG, 1988, CATEGORIES PROCESSES, P179
   XUE NW, 2002, P 19 INT C COMP LING
NR 41
TC 17
Z9 17
U1 0
U2 6
PU ELSEVIER SCI LTD
PI OXFORD
PA THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN 0031-3203
EI 1873-5142
J9 PATTERN RECOGN
JI Pattern Recognit.
PD SEP
PY 2005
VL 38
IS 9
BP 1407
EP 1419
DI 10.1016/j.patcog.2004.03.023
PG 13
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
SC Computer Science; Engineering
GA 939BT
UT WOS:000230047900007
DA 2019-06-15
ER

PT B
AU Gooi, CH
   Allan, J
AF Gooi, CH
   Allan, J
GP acl
TI Cross-document coreference on a large scale corpus
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB In this paper, we will compare and evaluate the effectiveness of different statistical methods in the task of cross-document coreference resolution. We created entity models for different test sets and compare the following disambiguation and clustering techniques to cluster the entity models in order to create coreference chains:
   Incremental Vector Space
   KL-Divergence
   Agglomerative Vector Space.
C1 Univ Massachusetts, Dept Comp Sci, Ctr Intelligent Informat Retrieval, Amherst, MA 01003 USA.
RP Gooi, CH (reprint author), Univ Massachusetts, Dept Comp Sci, Ctr Intelligent Informat Retrieval, Amherst, MA 01003 USA.
CR ALLAN J, 2002, ENTITY MODELS CONSTR
   Allan James, 2002, TOPIC DETECTION TRAC
   Bagga A, 2000, PROCEEDINGS OF THE FIFTH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1 AND 2, P207
   Bagga A., 1998, P 1 INT C LANG RES E, P563
   Bagga A., 1998, P 36 ANN M ASS COMP, P79
   BAGGA A, 1998, P COLING ACL 98 CONT, P19
   *BBN TECHN, 2001, ROUGH READ AUD IND M
   Kibble R, 2000, P 2 INT C LANG RES E, P1281
   LEE L, 2001, EFFECTIVENESS SKEW D
NR 9
TC 17
Z9 18
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 9
EP 16
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100002
DA 2019-06-15
ER

PT B
AU Zens, R
   Ney, H
AF Zens, R
   Ney, H
GP acl
TI Improvements in phrase-based statistical machine translation
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB In statistical machine translation, the currently best performing systems are based in some way on phrases or word groups. We describe the baseline phrase-based translation system and various refinements. We describe a highly efficient monotone search algorithm with a complexity linear in the input sentence length. We present translation results for three tasks: Verb-mobil, Xerox and the Canadian Hansards. For the Xerox task, it takes less than 7 seconds to translate the whole test set consisting of more than 10K words. The translation results for the Xerox and Canadian Hansards task are very promising. The system even outperforms the alignment template system.
C1 Rhein Westfal TH Aachen, Chair Comp Sci 6, Aachen, Germany.
RP Zens, R (reprint author), Rhein Westfal TH Aachen, Chair Comp Sci 6, Aachen, Germany.
EM zens@cs.rwth-aachen.de; ney@cs.rwth-aachen.de
CR Berger A.L., 1996, United States Patent, Patent No. 5510981
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Doddington George, 2002, P ARPA WORKSH HUM LA
   KOEHN P, 2003, P HLT NAACL, P127
   Marcu D, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P133
   Ney H, 1997, TEXT SPEECH LANG TEC, V2, P174
   Ney H., 1999, P JOINT SIGDAT C EMP, P20
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Och F. J., 2002, P 40 ANN M ASS COMP, P295
   PAPINENI KA, 2001, RC22176 TJ WATS RES
   Pearl J, 1988, PROBABILISTIC REASON
   Press W. H., 2002, NUMERICAL RECIPES C
   Tillmann C, 2003, COMPUT LINGUIST, V29, P97, DOI 10.1162/089120103321337458
   Tomas J, 2003, LECT NOTES COMPUT SC, V2652, P1020
   Wahlster W., 2000, VERBMOBIL FDN SPEECH
   ZENS R, 2002, 25 GERM C ART INT KI, P18
NR 16
TC 17
Z9 17
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 257
EP 264
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100033
DA 2019-06-15
ER

PT B
AU Jijkoun, V
   de Rijke, M
   Weerkamp, W
AF Jijkoun, Valentin
   de Rijke, Maarten
   Weerkamp, Wouter
GP Assoc Computat Linguist
TI Generating Focused Topic-specific Sentiment Lexicons
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a method for automatically generating focused and accurate topic-specific subjectivity lexicons from a general purpose polarity lexicon that allow users to pin-point subjective on-topic information in a set of relevant documents. We motivate the need for such lexicons in the field of media analysis, describe a bootstrapping method for generating a topic-specific lexicon from a general purpose polarity lexicon, and evaluate the quality of the generated lexicons both manually and using a TREC Blog track test set for opinionated blog post retrieval. Although the generated lexicons can be an order of magnitude more selective than the general purpose lexicon, they maintain, or even improve, the performance of an opinion retrieval system.
C1 [Jijkoun, Valentin; de Rijke, Maarten; Weerkamp, Wouter] Univ Amsterdam, ISLA, NL-1012 WX Amsterdam, Netherlands.
RP Jijkoun, V (reprint author), Univ Amsterdam, ISLA, NL-1012 WX Amsterdam, Netherlands.
EM jijkoun@uva.nl; derijke@uva.nl; w.weerkamp@uva.nl
CR Altheide D. L., 1996, QUALITATIVE MEDIA AN
   Choi Y., 2009, TSA 09 P 1 INT CIKM, P37
   Fahrni A, 2008, P S AFF LANG HUM MAC, P60
   Godbole  N, 2007, P INT C WEBL SOC MED
   Kanayama H., 2006, EMNLP, P355
   Kim S.M., 2004, P COLING 2004
   Lavrenko V., 2001, SIGIR 01
   Lee Y., 2008, P TREC 2008
   Liu  B., 2005, P 14 INT C WORLD WID
   MACDONALD C, 2006, TR2006224 U GLASG DE
   Metzler D., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P472
   Na S.-H., 2009, ECIR 09, P734
   Ounis I., 2007, 15 TEXT RETRIEVAL C
   Popescu A.-M., 2005, P HUM LANG TECHN C C
   Riloff E., 2003, P 2003 C EMP METH NA
   WEERKAMP W, 2009, JOINT C 47 ANN M ASS
   Weerkamp W., 2008, P ACL 08 HLT COL OH
   Wilson T., 2005, HLT 05, P347, DOI DOI 10.3115/1220575.1220619
   Wilson T, 2009, COMPUT LINGUIST, V35, P399, DOI 10.1162/coli.08-012-R1-06-90
NR 19
TC 16
Z9 16
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 585
EP 594
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300060
DA 2019-06-15
ER

PT B
AU Pennacchiotti, M
   Pantel, P
AF Pennacchiotti, Marco
   Pantel, Patrick
GP COLING
TI Ontologizing Semantic Relations
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Many algorithms have been developed to harvest lexical semantic resources, however few have linked the mined knowledge into formal knowledge repositories. In this paper, we propose two algorithms for automatically ontologizing (attaching) semantic relations into WordNet. We present an empirical evaluation on the task of attaching part-of and causation relations, showing an improvement on F-score over a baseline model.
C1 [Pennacchiotti, Marco] Univ Roma Tor Vergata, ART Grp, DISP, Rome, Italy.
RP Pennacchiotti, M (reprint author), Univ Roma Tor Vergata, ART Grp, DISP, Viale Politecn 1, Rome, Italy.
EM pennacchiotti@info.uniroma2.it; pantel@isi.edu
CR AGIRRE E, 1996, P 16 INT C COMP LING, P16
   AGIRRE E, 2001, P NAACL WORKSH WORLD
   BASILI R, 2000, P WORKSH MACH LEARN
   Corley C., 2005, P ACL WORKSH EMP MOD
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   GALE WA, 1992, COMPUT HUMANITIES, V26, P415, DOI 10.1007/BF00136984
   GIRJU R, 2003, P ACL WORKSH MULT SU
   GIRJU R, 2003, P HLT NAACL 03 EDM C, P80
   HARABAGIU S, 1999, P ACL SIGLEX99 STAND, P1
   HARRIS Z, 1985, PHILOS LINGUISTICS, P26
   Hindle D., 1990, P 28 ANN M ASS COMP, P268
   LIN D, 2002, P 19 INT C COMP LING, P577
   Pantel P., 2005, P 43 ANN M ASS COMP, P125
   RAVICHANDRAN D, 2002, P 40 ANN M ASS COMP, P41, DOI DOI 10.3115/1073083.1073092
   RILOFF E, 1997, P EMNLP 97
   Siegel S, 1988, NONPARAMETRIC STAT B
   SZPEKTOR I, 2004, P EMNLP 04 BARC SPAI
   WINSTON ME, 1987, COGNITIVE SCI, V11, P417, DOI 10.1016/S0364-0213(87)80015-0
NR 19
TC 16
Z9 16
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 793
EP 800
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200100
DA 2019-06-15
ER

PT B
AU Graehl, J
   Knight, K
AF Graehl, J
   Knight, K
GP acl
TI Training tree transducers
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB Many probabilistic models for natural language are now written in terms of hierarchical tree structure. Tree-based modeling still lacks many of the standard tools taken for granted in (finite-state) string-based modeling. The theory of tree transducer automata provides a possible framework to draw on, as it has been worked out in an extensive literature. We motivate the use of tree transducers for natural language and address the training problem for probabilistic tree-to-tree and tree-to-string transducers.
C1 Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Graehl, J (reprint author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way, Marina Del Rey, CA 90292 USA.
CR AHO AV, 1971, INFORM CONTROL, V19, P439, DOI 10.1016/S0019-9958(71)90706-6
   Alshawi H, 2000, COMPUT LINGUIST, V26, P45, DOI 10.1162/089120100561629
   Baker J., 1979, 97 M AC SOC AM, P547
   BANGALORE S, 2000, P COLING
   BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8
   CHARNIAK E, 2001, P ACL
   Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147
   COLLINS M, 1997, P ACL
   Comon H, 1997, TREE AUTOMATA TECHNI
   CORSTONOLIVER S, 2002, P IWNLG
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   EISNER J, 2003, P ACL
   ENGELFRIET J, 1975, MATH SYST THEORY, V9, P198, DOI 10.1007/BF01704020
   Gecseg F., 1984, TREE AUTOMATA
   GILDEA D, 2003, P ACL
   Joshi Aravind K., 1997, HDB FORMAL LANGUAGES, V3
   Klein D., 2003, P ACL
   Knight K., 1998, P AMTA
   KUMAR S, 2003, P HLT NAACL
   LANGKILDE I, 1998, P ACL
   LANGKILDE I, 2000, P NAACL
   Lari Karim, 1990, COMPUTER SPEECH LANG, V4
   Marcu Daniel, 2002, ARTIFICIAL INTELLIGE, V139
   NEDERHOF MJ, 2002, P ACL
   Pang Bo, 2003, P HLT NAACL
   Rounds W. C., 1970, MATH SYST THEORY, V4, P257, DOI DOI 10.1007/BF01695769
   Schabes Yves, 1990, THESIS U PENNSYLVANI
   Thatcher J. W., 1970, JCSS, V4, P339
   VITERBI AJ, 1967, IEEE T INFORMATION T, V13
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   Yamada K., 2001, P ACL
NR 31
TC 16
Z9 16
U1 0
U2 2
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 105
EP 112
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100014
DA 2019-06-15
ER

PT B
AU Bicknell, K
   Levy, R
AF Bicknell, Klinton
   Levy, Roger
GP Assoc Computat Linguist
TI A Rational Model of Eye Movement Control in Reading
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID IDEAL-OBSERVER MODEL; E-Z READER; WORD RECOGNITION; LANGUAGE;
   INFORMATION; DECISION; BEHAVIOR; CHIPS
AB A number of results in the study of real-time sentence comprehension have been explained by computational models as resulting from the rational use of probabilistic linguistic information. Many times, these hypotheses have been tested in reading by linking predictions about relative word difficulty to word-aggregated eye tracking measures such as go-past time. In this paper, we extend these results by asking to what extent reading is well-modeled as rational behavior at a finer level of analysis, predicting not aggregate measures, but the duration and location of each fixation. We present a new rational model of eye movement control in reading, the central assumption of which is that eye movement decisions are made to obtain noisy visual information as the reader performs Bayesian inference on the identities of the words in the sentence. As a case study, we present two simulations demonstrating that the model gives a rational explanation for between-word regressions.
C1 [Bicknell, Klinton; Levy, Roger] Univ Calif San Diego, Dept Linguist, 9500 Gilman Dr, La Jolla, CA 92093 USA.
RP Bicknell, K (reprint author), Univ Calif San Diego, Dept Linguist, 9500 Gilman Dr, La Jolla, CA 92093 USA.
EM kbicknell@ling.ucsd.edu; rlevy@ling.ucsd.edu
CR Allauzen C., 2007, P CIAA, V4783, P11
   Bicknell K., 2010, P 32 ANN C COGN SCI
   Boston MF, 2008, J EYE MOVEMENT RES, V2
   CONNINE CM, 1991, J MEM LANG, V30, P234, DOI 10.1016/0749-596X(91)90005-5
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008
   EHRLICH SF, 1981, J VERB LEARN VERB BE, V20, P641, DOI 10.1016/S0022-5371(81)90220-6
   Engbert R, 2005, PSYCHOL REV, V112, P777, DOI 10.1037/0033-295X.112.4.777
   Engbert R, 2002, VISION RES, V42, P621, DOI 10.1016/S0042-6989(01)00301-7
   Engbert R, 2010, PSYCHOL SCI, V21, P366, DOI 10.1177/0956797610362060
   ENGEL GR, 1973, CAN J PSYCHOL, V27, P317, DOI 10.1037/h0082482
   Genzel D, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P65
   Genzel D., 2002, P 40 ANN M ASS COMP, P199
   GEYER LH, 1977, PERCEPT PSYCHOPHYS, V22, P487, DOI 10.3758/BF03199515
   HALE J, 2001, P NAACL, V2, P159
   Jaeger TF, 2010, COGNITIVE PSYCHOL, V61, P23, DOI 10.1016/j.cogpsych.2010.02.002
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   Keller F, 2004, P C EMP METH NAT LAN, P317
   Legge GE, 2002, VISION RES, V42, P2219, DOI 10.1016/S0042-6989(02)00131-1
   Legge GE, 1997, PSYCHOL REV, V104, P524, DOI 10.1037/0033-295X.104.3.524
   Levy R., 2008, P 2008 C EMP METH NA, P234, DOI DOI 10.3115/1613715.1613749
   Levy R., 2007, ADV NEURAL INFORM PR, V19, P849
   Levy R, 2009, P NATL ACAD SCI USA, V106, P21086, DOI 10.1073/pnas.0907664106
   Levy Roger, 2009, ADV NEURAL INFORM PR, P937
   Mohri M, 1997, COMPUT LINGUIST, V23, P269
   Narayanan S., 2001, ADV NEURAL INFORM PR, V14, P59
   Ng A. Y., 2000, UNCERTAINTY ARTIFICI, P406
   Norris D, 2006, PSYCHOL REV, V113, P327, DOI 10.1037/0033-295X.113.2.327
   Norris D, 2009, PSYCHOL REV, V116, P207, DOI 10.1037/a0014259
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Reichle ED, 2006, PSYCHOL REV, V113, P390, DOI 10.1037/0033-295X.113.2.390
   Reichle ED, 2006, COGN SYST RES, V7, P4, DOI 10.1016/j.cogsys.2005.07.002
   Reichle ED, 1998, PSYCHOL REV, V105, P125, DOI 10.1037/0033-295X.105.1.125
   Reichle ED, 2009, PSYCHON B REV, V16, P1, DOI 10.3758/PBR.16.1.1
   Schilling HEH, 1998, MEM COGNITION, V26, P1270, DOI 10.3758/BF03201199
   Smith Nathaniel J., 2008, P 30 ANN C COGN SCI, P595
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
NR 36
TC 15
Z9 15
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1168
EP 1178
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300119
DA 2019-06-15
ER

PT B
AU Cathcart, N
   Carletta, J
   Klein, E
AF Cathcart, N
   Carletta, J
   Klein, E
GP ACL
TI A shallow model of backchannel continuers in spoken dialogue
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Spoken dialogue systems would be more acceptable if they were able to produce backchannel continuers such as mm-hmm in naturalistic locations during the user's utterances. Using the HCRC Map Task Corpus as our data source, we describe models for predicting these locations using only limited processing and features of the user's speech that are commonly available, and which therefore could be used as a low-cost improvement for current systems. The baseline model inserts continuers after a predetermined number of words. One further model correlates back-channel continuers with pause duration, while a second predicts their occurrence using trigram POS frequencies. Combining these two models gives the best results.
C1 Canon Res Ctr Europe, Bracknell, Berks, England.
EM nicolac@cre.canon.co.uk; jeanc@inf.ed.ac.uk; ewan@inf.ed.ac.uk
CR ANDERSON AH, 1991, LANG SPEECH, V34, P351, DOI 10.1177/002383099103400404
   Bull Matthew, 1998, P INT C SPOK LANG PR, V4, P1175
   Carletta J, 1997, COMPUT LINGUIST, V23, P13
   CLARK H, 1991, COGNITIVE SCI, V13, P259
   DENNY R, 1985, INTERACTION STRUCTUR, P135
   FORD C, 1996, INTERACTION GRAMMAR, pCH3
   HIRASAWA J, 1999, 6 EUR C SPEECH COMM, V3, P1391
   Jurafsky D., 1998, ACL COLING 98 WORKSH
   Knowles G, 1996, WORKING SPEECH PERSP
   KOISO H, 1998, LANG SPEECH, V23, P296
   Lauria S, 2001, IEEE INTELL SYST, V16, P38, DOI 10.1109/5254.956080
   LEMON L, 2002, TRAITEMENT AUTOMATIQ, V43, P131
   Levelt W. J. M., 1998, SPEAKING INTENTION A
   MCKELVIE D, 2001, PART SPEECH TAG SET
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Schuetze-Coburn S, 1993, TALKING DATA TRANSCR
   Theobalt C, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1338, DOI 10.1109/IRDS.2002.1043940
   Ward N, 2000, J PRAGMATICS, V32, P1177, DOI 10.1016/S0378-2166(99)00109-5
   YANKELOVICH N, 1995, CHI C HUM FACT COMP
   Yngve VH., 1970, 6 REG M CHIC LING SO, P567
NR 20
TC 15
Z9 15
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 51
EP 58
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200008
DA 2019-06-15
ER

PT B
AU Radev, DR
   Teufel, S
   Saggion, H
   Lam, W
   Blitzer, J
   Qi, H
AF Radev, DR
   Teufel, S
   Saggion, H
   Lam, W
   Blitzer, J
   Qi, H
GP ACL
TI Evaluation challenges in large-scale document summarization
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We present a large-scale meta evaluation of eight evaluation measures for both single-document and multi-document summarizers. To this end we built a corpus consisting of (a) 100 Million automatic summaries using six summarizers and baselines at ten summary lengths in both English and Chinese, (b) more than 10,000 manual abstracts and extracts, and (c) 200 Million automatic document and summary retrievals using 20 queries. We present both qualitative and quantitative results showing the strengths and drawbacks of all evaluation methods and how they rank the different summarizers.
C1 Univ Michigan, Ann Arbor, MI 48109 USA.
RI Saggion, Horacio/D-2029-2013; Radev, Dragomir/E-9641-2012
OI Saggion, Horacio/0000-0003-0016-7807; 
CR BRANDOW R, 1995, INFORM PROCESS MANAG, V31, P675, DOI 10.1016/0306-4573(95)00052-I
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Crochemore M., 1994, TEXT ALGORITHMS
   Gale W. A., 1993, Computational Linguistics, V19, P75
   HARMAN D, 2001, P 1 DOC UND C NEW OR
   Hovy E, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P81
   Krippendorff K., 1980, CONTENT ANAL INTRO I
   MANI I, 2000, INFORMATION RETRIEVA, V1
   MANI I, 2001, NATURAL LANGUAGE ENG
   Radev D. R., 2000, P WORKSH AUT SUMM 6
   SAGGION H, 2000, THESIS U MONTREAL
   Salton G., 1988, AUTOMATIC TEXT PROCE
   Siegel S, 1988, NONPARAMETRIC STAT B
   SPARCKJONES K, 2001, P 24 ANN INT ACM SIG, P190
   Teufel S, 1997, P WORKSH INT SCAL TE
   Tombros A., 1998, P AAAI S INT TEXT SU, P34
NR 16
TC 15
Z9 15
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 375
EP 382
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500048
DA 2019-06-15
ER

PT B
AU Han, XP
   Zhao, J
AF Han, Xianpei
   Zhao, Jun
GP Assoc Computat Linguist
TI Structural Semantic Relatedness: A Knowledge-Based Method to Named
   Entity Disambiguation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Name ambiguity problem has raised urgent demands for efficient, high-quality named entity disambiguation methods. In recent years, the increasing availability of large-scale, rich semantic knowledge sources (such as Wikipedia and WordNet) creates new opportunities to enhance the named entity disambiguation by developing algorithms which can exploit these knowledge sources at best. The problem is that these knowledge sources are heterogeneous and most of the semantic knowledge within them is embedded in complex structures, such as graphs and networks. This paper proposes a knowledge-based method, called Structural Semantic Relatedness (SSR), which can enhance the named entity disambiguation by capturing and leveraging the structural semantic knowledge in multiple knowledge sources. Empirical results show that, in comparison with the classical BOW based methods and social network based methods, our method can significantly improve the disambiguation performance by respectively 8.7% and 14.7%.
C1 [Han, Xianpei; Zhao, Jun] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
RP Zhao, J (reprint author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
EM xphan@nlpr.ia.ac.cn; jzhao@nlpr.ia.ac.cn
CR Amigo E, 2008, COMP EXTRINSIC CLUST
   Artiles J., 2009, WEPS2
   Artiles J., 2007, SEMEVAL
   Baeza-Yates R., 1999, MODERN INFORM RETRIE
   Bagga A, 1998, P 17 INT C COMP LING, P79, DOI DOI 10.3115/980451.980859
   Bekkerman  R., 2005, P 14 INT C WORLD WID, P463
   Bunescu R., 2006, P EACL, V6
   Chen Y, 2007, P 2007 JOINT C EMP M, P190
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Cucerzan S., 2007, P 2007 JOINT C EMP M, P708
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Fleischman M. B., 2004, P ACL REF RES WORKSH
   Han  X., 2009, P 18 ACM C INF KNOWL, P215, DOI DOI 10.1145/1645953.1645983
   Hassell J., 2006, P ISWC 06, P44
   Jeh G., 2002, P 8 ACM SIGKDD INT C, P543
   Kalashnikov D. V., 2008, P SIGIR
   Leicht EA, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevB.73.026120
   Lin D, 1998, P ICML
   Lu Y., 2007, P AAAI
   Malin B., 2005, Computational & Mathematical Organization Theory, V11, P119, DOI 10.1007/s10588-005-3940-3
   MALIN B, 2005, SIAM SDM WORKSH LINK
   Mann G. S., 2003, P 7 C NAT LANG LEARN, V4, P40
   McNamee P., 2009, P TEXT AN C TAC 2009
   Medelyan O, 2008, P AAAI WIKIAI WORKSH
   MILNE D, 2006, IEEE WIC ACM INT C W, P442
   Minkov E., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P27, DOI 10.1145/1148170.1148179
   Niu Cheng, 2005, P 42 ANN M ASS COMP, P598
   Pedersen T, 2005, LECT NOTES COMPUT SC, V3406, P226
   Strube M., 2006, P NAT C ART INT, V21, P1419
   Suchanek F. M., 2007, P 16 INT C WORLD WID, P706
   Wan X., 2005, P 14 ACM INT C INF K, P170
   Witten D. M., 2008, P AAAI WORKSH WIK AR, P25
   Yang K. H., 2006, P 2006 IEEE WIC ACM, P386
NR 33
TC 14
Z9 14
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 50
EP 59
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300006
DA 2019-06-15
ER

PT B
AU Toprak, C
   Jakob, N
   Gurevych, I
AF Toprak, Cigdem
   Jakob, Niklas
   Gurevych, Iryna
GP Assoc Computat Linguist
TI Sentence and Expression Level Annotation of Opinions in User-Generated
   Discourse
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In this paper, we introduce a corpus of consumer reviews from the rateitall and the eopinions websites annotated with opinion-related information. We present a two-level annotation scheme. In the first stage, the reviews are analyzed at the sentence level for (i) relevancy to a given topic, and (ii) expressing an evaluation about the topic. In the second stage, on-topic sentences containing evaluations about the topic are further investigated at the expression level for pinpointing the properties (semantic orientation, intensity), and the functional components of the evaluations (opinion terms, targets and holders). We discuss the annotation scheme, the inter-annotator agreement for different subtasks and our observations.
C1 [Toprak, Cigdem; Jakob, Niklas; Gurevych, Iryna] Tech Univ Darmstadt, Ubiquitous Knowledge Proc Lab, Dept Comp Sci, Hsch Str 10, D-64289 Darmstadt, Germany.
RP Toprak, C (reprint author), Tech Univ Darmstadt, Ubiquitous Knowledge Proc Lab, Dept Comp Sci, Hsch Str 10, D-64289 Darmstadt, Germany.
CR ASHER N, 2008, COLING, P7
   Breck E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2683
   Cheng XW, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P2710
   Choi Yejin, 2005, HUMAN LANGUAGE TECHN, P355
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Ding X., 2008, P 2008 INT C WEB SEA, P231, DOI DOI 10.1145/1341531.1341561
   Esuli A., 2006, P 5 INT C LANG RES E, V5, P417
   Fahrni A, 2008, P S AFF LANG HUM MAC, P60
   Hu M, 2004, P 10 ACM SIGKDD INT, V2004, P168, DOI DOI 10.1145/1014052.1014073
   Kim S.-M., 2006, P WORKSH SENT SUBJ T, P1, DOI DOI 10.3115/1654641.1654642
   Krippendorff K, 2004, CONTENT ANAL INTRO I
   PASSONNEAU R, 2004, P LREC, V4, P1503
   Quirk R., 1985, COMPREHENSIVE GRAMMA
   RILOFF E, 2003, EMNLP 03, P105
   Somasundaran S., 2008, P 9 SIGDIAL WORKSH D, P129
   STOYANOV V, 2008, P 22 INT C COMP LING, P817
   Wiebe J, 2005, LANG RESOUR EVAL, V39, P165, DOI 10.1007/s10579-005-7880-9
   WILSON T, 2005, P ACL WORKSH FRONT C, P53
   Wilson T., 2005, HLT 05, P347, DOI DOI 10.3115/1220575.1220619
   Wilson T.A., 2008, THESIS
   Wilson Theresa, 2008, P 6 INT LANG RES EV
   Zhuang L., 2006, C INF KNOWL MAN P 15, V6, P43, DOI DOI 10.1145/1183614.1183625
NR 22
TC 14
Z9 14
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 575
EP 584
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300059
DA 2019-06-15
ER

PT B
AU Wang, BX
   Wang, XL
   Sun, CJ
   Liu, BQ
   Sun, L
AF Wang, Baoxun
   Wang, Xiaolong
   Sun, Chengjie
   Liu, Bingquan
   Sun, Lin
GP Assoc Computat Linguist
TI Modeling Semantic Relevance for Question-Answer Pairs in Web Social
   Communities
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Quantifying the semantic relevance between questions and their candidate answers is essential to answer detection in social media corpora. In this paper, a deep belief network is proposed to model the semantic relevance for question-answer pairs. Observing the textual similarity between the community-driven question-answering (cQA) dataset and the forum dataset, we present a novel learning strategy to promote the performance of our method on the social community datasets without hand-annotating work. The experimental results show that our method outperforms the traditional approaches on both the cQA and the forum corpora.
C1 [Wang, Baoxun; Wang, Xiaolong; Sun, Chengjie; Liu, Bingquan; Sun, Lin] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
RP Wang, BX (reprint author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
EM bxwang@insun.hit.edu.cn; wangxl@insun.hit.edu.cn;
   cjsun@insun.hit.edu.cn; liubq@insun.hit.edu.cn; lsun@insun.hit.edu.cn
CR Berger A., 2000, P 23 ANN INT ACM SIG, P192
   Bernhard D, 2009, P ACL IJCNLP, P728, DOI DOI 10.1002/ASI.23153
   Cong G., 2008, SIGIR, P467, DOI DOI 10.1145/1390334.1390415
   Ding S., 2008, P 46 ANN M ASS COMP, P710
   Duan H., 2008, P 46 ANN M ASS COMP, P156
   Feng Donghui, 2006, IUI 2006, P171
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton Georey E., 2002, NEURAL COMPUT, P14
   Hong LJ, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P171, DOI 10.1145/1571941.1571973
   Huang JZ, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P423
   JEON J, 2006, SIGIR 06, P228
   JEON J, 2005, CIKM 05, P84
   JIJKOUN V, 2005, CIKM 05, P76
   Lee Jung-Tae, 2008, EMNLP, P410
   LI F, 2009, P JOINT C 47 ANN M A, P737
   RIEZLER S, 2007, P 45 ANN M ASS COMP, P464
   Salakhutdinov R, 2009, INT J APPROX REASON, V50, P969, DOI 10.1016/j.ijar.2008.11.006
   Shrestha L., 2004, P 20 INT C COMP LING, P889, DOI DOI 10.3115/1220355.1220483
   Surdeanu M., 2008, P 46 ANN M ASS COMP, P719
   Wang BX, 2009, IEEE SYS MAN CYBERN, P1159, DOI 10.1109/ICSMC.2009.5345956
NR 20
TC 14
Z9 14
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1230
EP 1238
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300125
DA 2019-06-15
ER

PT B
AU Yang, XF
   Su, J
   Tan, CL
AF Yang, Xiaofeng
   Su, Jian
   Tan, Chew Lim
GP COLING
TI Kernel-Based Pronoun Resolution with Structured Syntactic Knowledge
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Syntactic knowledge is important for pronoun resolution. Traditionally, the syntactic information for pronoun resolution is represented in terms of features that have to be selected and defined heuristically. In the paper, we propose a kernel-based method that can automatically mine the syntactic information from the parse trees for pronoun resolution. Specifically, we utilize the parse trees directly as a structured feature and apply kernel functions to this feature, as well as other normal features, to learn the resolution classifier. In this way, our approach avoids the efforts of decoding the parse trees into the set of flat syntactic features. The experimental results show that Our approach can bring significant performance improvement and is reliably effective for the pronoun resolution task.
C1 [Yang, Xiaofeng; Su, Jian] Inst Infocomm Res, Singapore 119613, Singapore.
RP Yang, XF (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.
EM xiaofengy@i2r.a-star.edu.sg; sujian@i2r.a-star.edu.sg;
   tancl@comp.nus.edu.sg
CR Aone C., 1995, P 33 ANN M ASS COMP, P122
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   COLLINS M, 2002, P 40 ANN M ASS COMP, P263
   Collins Michael, 1999, THESIS U PENNSYLVANI
   Hobbs J., 1978, LINGUA, V44, P339
   Joachims T, 1999, ADV KERNEL METHODS S
   Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604
   Kennedy C., 1996, P 16 INT C COMP LING, P113, DOI 10.3115/992628.992651
   LAPPIN S, 1994, COMPUTATIONAL LINGUI, V20, P525
   Luo Xiaoqiang, 2005, P HUM LANG TECHN C C, P660
   Mitkov R., 1998, P 18 INT C COMP LING, V2, P869
   MOSCHITTI A., 2004, P 42 ANN M ASS COMP, DOI [10.3115/1218955.1218998, DOI 10.3115/1218955.1218998]
   Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Vapnik VN, 1995, NATURE STAT LEARNING
   YANG X, 2004, P ACL 2004, P127
   Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205
   Zhao S. B, 2005, P 43 ANN M ASS COMP, P419
NR 18
TC 14
Z9 16
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 41
EP 48
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200006
DA 2019-06-15
ER

PT B
AU Collins-Thompson, K
   Callan, J
AF Collins-Thompson, K
   Callan, J
GP acl
TI A language modeling approach to predicting reading difficulty
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We demonstrate a new research approach to the problem of predicting the reading difficulty of a text passage, by recasting readability in terms of statistical language modeling. We derive a measure based on an extension of multinomial naive Bayes classification that combines multiple language models to estimate the most likely grade level for a given passage. The resulting classifier is not specific to any particular subject and can be trained with relatively little labeled data. We perform predictions for individual Web pages in English and compare our performance to widely-used semantic variables from traditional readability measures. We show that with minimal changes, the classifier may be retrained for use with French Web documents. For both English and French, the classifier maintains consistently good correlation with labeled grade level (0.63 to 0.79) across all test sets. Some traditional semantic variables such as type-token ratio gave the best performance on commercial calibrated test passages, while our language modeling approach gave better accuracy for Web documents and very short passages (less than 10 words).
C1 Carnegie Mellon Univ, Sch Comp Sci, Language Technol Inst, Pittsburgh, PA 15213 USA.
RP Collins-Thompson, K (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Language Technol Inst, 4502 Newell Simon Hall, Pittsburgh, PA 15213 USA.
CR Burnard L., 1995, USERS REFERENCE GUID
   Carroll J. B., 1971, WORD FREQUENCY BOOK
   Chall J. S., 1983, STAGES READING DEV
   Chall J. S., 1995, READABILITY REVISITE
   CHALL JS, 1958, BUREAU ED RES MONOGR, V34
   CRAMMER K, 2001, P C NEUR INF PROC SY, P641
   Dale E., 1981, LIVING WORD VOCABULA
   Duda R, 2001, PATTERN CLASSIFICATI
   FRY E, 1990, J READING, V33, P594
   Gale William A., 1995, J QUANT LINGUIST, V2, P217, DOI DOI 10.1080/09296179508590051
   GARTIN S, 1994, J AGR ED, V35
   Hastie T, 2001, ELEMENTS STAT LEARNI
   KINCAID J, 875 CHIEF NAV TRAIN
   Klare G. R., 1963, MEASUREMENT READABIL
   Kohavi R., 1995, P 14 INT JOINT C ART, P1137
   MACCULLAGH P, 1980, J ROYAL STAT SOC B, V42, P109
   MITCHELL JV, 1985, 9 MENTAL MEASUREMENT
   MLADENIC D, 1998, WORKING NOTES LEARNI
   *READ A Z COM, 2003, READ A Z LEV CORR CH
   SI L, 2001, P 10 INT C INF KNOWL, P574
   STENNER AJ, 1988, LEXILE FRAMEWORK
NR 21
TC 14
Z9 15
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 193
EP 200
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100025
DA 2019-06-15
ER

PT B
AU Kumar, S
   Byrne, W
AF Kumar, S
   Byrne, W
GP acl
TI Minimum Bayes-risk decoding for statistical machine translation
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We present Minimum Bayes-Risk (MBR) decoding for statistical machine translation. This statistical approach aims to minimize expected loss of translation errors under loss functions that measure translation performance. We describe a hierarchy of loss functions that incorporate different levels of linguistic information from word strings, word-to-word alignments from an MT system, and syntactic structure from parse-trees of source and target language sentences. We report the performance of the MBR decoders on a Chinese-to-English translation task. Our results show that MBR decoding can be used to tune statistical MT performance for specific loss functions.
C1 Johns Hopkins Univ, Ctr Language & Speech Proc, Baltimore, MD 21218 USA.
RP Kumar, S (reprint author), Johns Hopkins Univ, Ctr Language & Speech Proc, 3400 N Charles St, Baltimore, MD 21218 USA.
CR *AMTA, 2003, WORKSH MACH TRANSL E
   BANGALORE S, 2002, P COLING TAIP TAIW
   Bickel P. J., 1977, MATH STAT BASIC IDEA
   BIKEL DM, 2000, P 2 CHIN LANG PROC W, P1
   Brown P. F., 1990, Computational Linguistics, V16, P79
   COLLINS M, 2002, P EMNLP PHIL PA US
   Collins Michael, 1999, THESIS U PENNSYLVANI
   DODDINGTON G, 2002, P HLT 2002 SAN DIEG
   FOSTER G, 2002, P EMNLP PHIL PA US
   Goel V, 2000, COMPUT SPEECH LANG, V14, P115, DOI 10.1006/csla.2000.0138
   GOODMAN J, 1996, P 34 ANN M ASS COMP, P177
   *JHU, 2003, JHU SUMM WORKSH
   KUMAR S, 2002, P EMNLP PHIL PA US
   KUMAR S, 2003, P HLT NAACL EDM CAN
   MELAMED ID, 2003, P HLT NAACL EDM CAN
   *NIST, 2003, NIST MACH RANSL EV
   OCH F, 2003, P ACL SAPP JAP
   OCH FJ, 2002, THESIS RWTH AACHEN G
   PAPINENI KA, 2001, RC22176 IBM RES DIV
   Press W. H., 2002, NUMERICAL RECIPES C
   TAN M, 2002, P ACL 2002 PHIL PA U
   Ueffing N, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P156
NR 22
TC 14
Z9 14
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 169
EP 176
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100022
DA 2019-06-15
ER

PT B
AU Li, X
   Morie, P
   Roth, D
AF Li, X
   Morie, P
   Roth, D
GP acl
TI Robust reading: Identification and tracing of ambiguous names
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB A given entity, representing a person, a location or an organization, may be mentioned in text in multiple, ambiguous ways. Understanding natural language requires identifying whether different mentions of a name, within and across documents, represent the same entity.
   We develop an unsupervised learning approach that is shown to resolve accurately the name identification and tracing problem. At the heart of our approach is a generative model of how documents are generated and how names are "sprinkled" into them. In its most general form, our model assumes: (1) a joint distribution over entities, (2) an "author" model, that assumes that at least one mention of an entity in a document is easily identifiable, and then generates other mentions via (3) an appearance model, governing how mentions are transformed from the "representative" mention. We show how to estimate the model and do inference with it and how this resolves several aspects of the problem from the perspective of applications such as questions answering.
C1 Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
RP Li, X (reprint author), Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
CR BAGGA A, 1998, ACL
   BILENKO M, 2003, KDD
   Charniak Eugene, 2001, NAACL
   COHEN W, 2003, 2 WEB WORKSH 2003
   Cohen W. W., 2002, KDD
   HERNANDEZ M, 1995, SIGMOD
   Kehler Andrew, 2002, COHERENCE REFERENCE
   MANN G, 2003, CONLL
   NG V, 2003, ACL
   PASULA H, 2002, NIPS
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   VOORHEES E, 2002, P 11 TEXT RETRIEVAL, P115
NR 12
TC 14
Z9 14
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 17
EP 24
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100003
DA 2019-06-15
ER

PT B
AU Allauzen, C
   Mohri, M
   Roark, B
AF Allauzen, C
   Mohri, M
   Roark, B
GP ACL
TI Generalized algorithms for constructing statistical language models
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Recent text and speech processing applications such as speech mining raise new and more general problems related to the construction of language models. We present and describe in detail several new and efficient algorithms to address these more general problems and report experimental results demonstrating their usefulness. We give an algorithm for computing efficiently the expected counts of any sequence in a word lattice output by a speech recognizer or any arbitrary weighted automaton; describe a new technique for creating exact representations of n-gram language models by weighted automata whose size is practical for offline use even for a vocabulary size of about 500,000 words and an n-gram order n = 6; and present a simple and more general technique for constructing class-based language models that allows each class to represent an arbitrary weighted automaton. An efficient implementation of our algorithms and techniques has been incorporated in a general software library for language modeling, the GRM Library, that includes many other text and grammar processing functionalities.
C1 AT&T Labs Res, Florham Pk, NJ 07932 USA.
CR ALLAUZEN C, 2003, GRM LIB GRAMMER LIB
   Berstel J., 1988, RATIONAL SERIES THEI
   Brown P. F., 1992, Computational Linguistics, V18, P467
   CHEN SF, 1998, TR1098
   Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P381
   KAPLAN RM, 1994, COMPUTATIONAL LINGUS, V20
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KUICH W, 1986, EATCS MONOGRAPHS THE, V5
   Mohri M., 2002, Journal of Automata, Languages and Combinatorics, V7, P321
   MOHRI M, 1996, P 12 BIEN EUR C ART
   MOHRI M, 1996, 34 M ASS COMP LING A
   Mohri M., 1997, COMPUTATIONAL LINGUI, V23
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   SALOMAA A, 1978, AUTOMATA THEORETIC A
   SCHUTZENGBERGER MP, 1961, INFORMATION CONTROL, V4
   SEYMORE K, 1996, P INT C SPOK LANG PR
   STOKCKE A, 1998, P DAPRA BROADC NEWS, P270
NR 17
TC 14
Z9 14
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 40
EP 47
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500006
DA 2019-06-15
ER

PT B
AU Aker, A
   Gaizauskas, R
AF Aker, Ahmet
   Gaizauskas, Robert
GP Assoc Computat Linguist
TI Generating image descriptions using dependency relational patterns
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper presents a novel approach to automatic captioning of geo-tagged images by summarizing multiple web-documents that contain information related to an image's location. The summarizer is biased by dependency pattern models towards sentences which contain features typically provided for different scene types such as those of churches, bridges, etc. Our results show that summaries biased by dependency pattern models lead to significantly higher ROUGE scores than both n-gram language models reported in previous work and also Wikipedia baseline summaries. Summaries generated using dependency patterns also lead to more readable summaries than those generated without dependency patterns.
C1 [Aker, Ahmet; Gaizauskas, Robert] Univ Sheffield, Sheffield S10 2TN, S Yorkshire, England.
RP Aker, A (reprint author), Univ Sheffield, Sheffield S10 2TN, S Yorkshire, England.
EM a.aker@dcs.shef.ac.uk; r.gaizauskas@dcs.shef.ac.uk
CR Aker A., 2009, INT C REC ADV NAT LA
   Aker A., 2010, P LREC 2010 C
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   BARNARD K, 2001, INT C COMP VIS, V2, P408
   BERG TL, 2005, ADV NEURAL INFORM PR
   Bunescu R. C., 2005, P C HUM LANG TECHN E, P724, DOI DOI 10.3115/1220575.1220666
   Culotta A, 2004, P 42 ANN M ASS COMP, V432, DOI [10.3115/1218955.1219009, DOI 10.3115/1218955.1219009]
   Dang H. T., 2006, OVERVIEW OF DUC 2006
   Dang H. T., 2005, DUC 05 WORKSH HLT EM
   DESCHACHT K, 2007, P 45 ANN M ASS COMP
   DUYGULU P, 2002, P 7 EUR C COMP VIS, V4, P97
   Fan X., 2010, P 11 ACM SIGMM INT C
   Feng Y., 2008, P ASS COMP LING ACL
   Lin C. Y., 2004, P WORKSH TEXT SUMM B, P25
   Marsh EE, 2003, J DOC, V59, P647, DOI 10.1108/00220410310506303
   Mori Y., 2000, P RIAO 2000 CONT BAS
   NOBATA C, 2002, P 3 INT C LANG RES E, P1742
   Pan J. Y., 2004, MULT EXP 2004 ICME 0, V3
   Purves RS, 2008, 1 INT WORKSH MET MIN
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Song F, 1999, PROCEEDINGS OF THE EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION KNOWLEDGE MANAGEMENT, CIKM'99, P316, DOI 10.1145/319950.320022
   Stevenson M., 2005, P 43 ANN M ASS COMP, P379, DOI DOI 10.3115/1219840.1219887
   Stevenson Mark, 2009, RES LANG COMPUT, V7, P13
   Sudo K., 2001, P 1 INT C HUM LANG T, P7
   YANGARBER R, 2000, P 18 INT C COMP LING, P940, DOI DOI 10.3115/992730.992782
NR 25
TC 13
Z9 13
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1250
EP 1258
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300127
DA 2019-06-15
ER

PT B
AU Li, P
   Jiang, J
   Wang, YL
AF Li, Peng
   Jiang, Jing
   Wang, Yinglin
GP Assoc Computat Linguist
TI Generating Templates of Entity Summaries with an Entity-Aspect Model and
   Pattern Mining
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In this paper, we propose a novel approach to automatic generation of summary templates from given collections of summary articles. This kind of summary templates can be useful in various applications. We first develop an entity-aspect LDA model to simultaneously cluster both sentences and words into aspects. We then apply frequent subtree pattern mining on the dependency parse trees of the clustered and labeled sentences to discover sentence patterns that well represent the aspects. Key features of our method include automatic grouping of semantically related sentence patterns and automatic identification of template slots that need to be filled in. We apply our method on five Wikipedia entity categories and compare our method with two baseline methods. Both quantitative evaluation based on human judgment and qualitative comparison demonstrate the effectiveness and advantages of our method.
C1 [Li, Peng; Wang, Yinglin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Jiang, Jing] Singapore Management Univ, Sch Informat Syst, Singapore 178902, Singapore.
RP Li, P (reprint author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
EM lipeng@sjtu.edu.cn; jingjiang@smu.edu.sg; ylwang@sjtu.edu.cn
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   CHEMUDUGUNTA C, 2007, ADV NEURAL INFORM PR, P241
   Daume H, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P305
   Filatova E., 2006, P COLING ACL MAIN C, P207
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Haghighi A., 2009, P HUM LANG TECHN 200, P362, DOI DOI 10.3115/1620754.1620807
   Sauper C., 2009, P JOINT C 47 ANN M A, P208
   Sekine S, 2006, P COLING ACL MAIN C, P731
   SHINYAMA Y, 2006, P MAIN C HUM LANG TE, P304, DOI DOI 10.3115/1220835.1220874
   Sudo K., 2003, P 41 ANN M ASS COMP, V1, P224, DOI DOI 10.3115/1075096.1075125
   Titov I, 2008, P 17 INT C WORLD WID, P111, DOI DOI 10.1145/1367497.1367513
   Wu F., 2007, P 16 ACM C INF KNOWL, P41, DOI DOI 10.1145/1321440.1321449
   Yan Y., 2009, P JOINT C 47 ANN M A, V2, P1021
   Zaki M. J, 2002, P 8 ACM SIGKDD INT C, P71, DOI DOI 10.1145/775047.775058
NR 14
TC 13
Z9 13
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 640
EP 649
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300066
DA 2019-06-15
ER

PT B
AU Soricut, R
   Echihabi, A
AF Soricut, Radu
   Echihabi, Abdessamad
GP Assoc Computat Linguist
TI TrustRank: Inducing Trust in Automatic Translations via Ranking
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB The adoption of Machine Translation technology for commercial applications is hampered by the lack of trust associated with machine-translated output. In this paper, we describe TrustRank, an MT system enhanced with a capability to rank the quality of translation outputs from good to bad. This enables the user to set a quality threshold, granting the user control over the quality of the translations.
   We quantify the gains we obtain in translation quality, and show that our solution works on a wide variety of domains and language pairs.
C1 [Soricut, Radu; Echihabi, Abdessamad] Language Weaver Inc, 6060 Ctr Dr,Suite 150, Los Angeles, CA 90045 USA.
RP Soricut, R (reprint author), Language Weaver Inc, 6060 Ctr Dr,Suite 150, Los Angeles, CA 90045 USA.
EM rsoricut@languageweaver.com; echihabi@languageweaver.com
CR Albrecht Joshua, 2007, P ACL
   Albrecht Joshua, 2008, P ACL
   Amigo Enrique, 2009, P ACL
   Blatz John, 2004, P COLING
   Collins Michael, 2005, P ACL
   Demsar J., 2006, J MACHINE LEARNING R, V7
   Doddington George, 2002, P HLT
   Duh K., 2008, P ACL 3 WORKSH STAT
   Gamon Michael, 2005, P EAMT
   Gunawardana A, 2009, J MACH LEARN RES, V10, P2935
   Kauchak David, 2006, P HLT NAACL
   Koehn Philipp, 2009, P EACL WORKSH STAT M
   Lagarda A. - L., 2009, P HLT NAACL
   Lavie Alon, 2007, P ACL WORKSH STAT MA
   Liu Ding, 2005, P ACL WORKSH INTR EX
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Owczarzak K, 2007, MACH TRANSL, V21, P95, DOI 10.1007/s10590-008-9038-1
   Papineni  K., 2002, P ACL
   Ravi Sujith, 2008, P EMNLP
   Shieber Stuart M., 2004, P 10 INT C THEOR MET
   Specia Lucia, 2009, P EAMT
   Ueffing Nicola, 2005, P EAMT
   Xu Peng, 2009, P ACL
   Yang Muyun, 2008, P AMTA
   YE Y, 2007, P ACL 2 WORKSH STAT
   Zhou Liang, 2006, P EMNLP
NR 26
TC 13
Z9 14
U1 1
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 612
EP 621
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300063
DA 2019-06-15
ER

PT B
AU Vogel, A
   Jurafsky, D
AF Vogel, Adam
   Jurafsky, Dan
GP Assoc Computat Linguist
TI Learning to Follow Navigational Directions
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID TASK
AB We present a system that learns to follow navigational natural language directions. Where traditional models learn from linguistic annotation or word distributions, our approach is grounded in the world, learning by apprenticeship from routes through a map paired with English descriptions. Lacking an explicit alignment between the text and the reference path makes it difficult to determine what portions of the language describe which aspects of the route. We learn this correspondence with a reinforcement learning algorithm, using the deviation of the route we follow from the intended path as a reward signal. We demonstrate that our system successfully grounds the meaning of spatial terms like above and south into geometric properties of paths.
C1 [Vogel, Adam; Jurafsky, Dan] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Vogel, A (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM acvogel@stanford.edu; jurafsky@stanford.edu
CR Abbeel P., 2004, P 21 INT C MACH LEAR
   ANDERSON AH, 1991, LANG SPEECH, V34, P351, DOI 10.1177/002383099103400404
   Branavan S. R. K., 2009, ACL IJCNLP 09
   Curran J. R., 2003, THESIS
   Fillmore Charles, 1997, LECT DEIXIS
   Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5
   Levinson S. C., 2003, SPACE LANGUAGE COGNI
   Levit M, 2007, IEEE T SYST MAN CY B, V37, P667, DOI 10.1109/TSMCB.2006.889809
   Regier T., 1996, HUMAN SEMANTIC POTEN
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   Talmy L., 1983, SPATIAL ORIENTATION
   Tanz C., 1980, STUDIES ACQUISITION
   Wang Hongmei, 2004, GISCIENCE
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wei Y, 2009, IEEE INT CONF ROBOT, P3761, DOI 10.1109/ROBOT.2009.5152775
   Zettlemoyer L.S., 2009, ACL IJCNLP 09, P976
NR 16
TC 13
Z9 13
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 806
EP 814
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300083
DA 2019-06-15
ER

PT B
AU Bergsma, S
   Lin, DK
AF Bergsma, Shane
   Lin, Dekang
GP COLING
TI Bootstrapping Path-Based Pronoun Resolution
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present an approach to pronoun resolution based on syntactic paths. Through a simple bootstrapping procedure, we learn the likelihood of coreference between a pronoun and a candidate noun based on the path in the parse tree between the two entities. This path information enables us to handle previously challenging resolution instances, and also robustly addresses traditional syntactic coreference constraints. Highly coreferent paths also allow mining of precise probabilistic gender/number information. We combine statistical knowledge with well known features in a Support Vector Machine pronoun resolution classifier. Significant gains in performance are observed on several datasets.
C1 [Bergsma, Shane] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
RP Bergsma, S (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
EM bergsma@cs.ualberta.ca; lindek@google.com
CR Aone C., 1995, P 33 ANN M ASS COMP, P122
   BARBU C, 2001, P 39 ANN M 10 C EUR, P34
   Bean D, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P297
   BERGSMA S, 2005, P 18 CAN C ART INT C, P342
   Cherry Colin, 2005, P 9 C COMP NAT LANG, P88
   Church K. W., 1989, P ACL, V27, P76, DOI [DOI 10.3115/981623.981633, 10.3115/981623.981633]
   DAGAN I, 1990, P 13 INT C COMP LING, V3, P330
   Haegeman L., 1994, INTRO GOVT BINDING T
   Joachims T., 1999, ADV KERNEL METHODS
   KEHLER A, 2004, P HLT NAACL, P289
   Lappin S., 1994, Computational Linguistics, V20, P535
   Lin D., 1998, P WORKSH EV PARS SYS
   LIN D, 2001, NAT LANG ENG, V7, P343
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Mitkov R., 1997, P ACL 97 EACL 97 WOR, P14
   *MUC 7, 1997, P 7 MESS UND C MUC 7
   Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102
   Niyu G., 1998, P 6 WORKSH VER LARG, P161
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Yang X., 2005, P 43 ANN M ASS COMP, P165
NR 20
TC 13
Z9 13
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 33
EP 40
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200005
DA 2019-06-15
ER

PT B
AU Chen, JX
   Ji, DH
   Tan, CL
   Niu, ZY
AF Chen, Jinxiu
   Ji, Donghong
   Tan, Chew Lim
   Niu, Zhengyu
GP COLING
TI Relation Extraction Using Label Propagation Based Semi-supervised
   Learning
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Shortage of manually labeled data is an obstacle to supervised relation extraction methods. In this paper we investigate a graph based semi-supervised learning algorithm, a label propagation (LP) algorithm, for relation extraction. It represents labeled and unlabeled examples and their distances as the nodes and the weights of edges of a graph, and tries to obtain a labeling function to satisfy two constraints: 1) it should be fixed on the labeled nodes, 2) it should be smooth on the whole graph. Experiment results on the ACE corpus showed that this LP algorithm achieves better performance than SVM when only very few labeled examples are available, and it also performs better than bootstrapping for the relation extraction task.
C1 [Chen, Jinxiu; Ji, Donghong; Niu, Zhengyu] Inst Infocomm Res, Singapore 119613, Singapore.
RP Chen, JX (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.
EM jinxiu@i2r.a-star.edu.sg; dhji@i2r.a-star.edu.sg; tancl@comp.nus.edu.sg;
   zniu@i2r.a-star.edu.sg
CR AGICHTEIN E, 2000, P 5 ACM INT C DIG LI
   Belkin Mikhail, 2002, ADV NEURAL INFORM PR, V15
   Blum A., 2001, P 18 INT C MACH LEAR
   BLUM A, 2004, P 21 INT C MACH LEAR
   Brin Sergey, 1998, P WEBDB WORKSH 6 INT, P172
   Charniak E., 1999, CS9912 BROWN U COMP
   Culotta A, 2004, P 42 ANN M ASS COMP, DOI 10.3115/1218955.1219009
   Friedman Nir, 2002, P 25 ANN INT ACM SIG
   Hasegawa T., 2004, P C ACL2004 BARC SPA
   KAMBHATLA N., 2004, P 42 ANN M ASS COMP
   LIN J, 1991, IEEE T INFORM THEORY, V37, P1
   Miller S., 2000, P 6 APPL NAT LANG PR
   Yarowsky D, 1995, P ACL, P189, DOI DOI 10.3115/981658.981684
   Zelenko D., 2002, P C EMP METH NAT LAN
   Zhang Z., 2004, P ACM 13 C INF KNOWL
   Zhou GuoDong, 2005, P 43 ANN M ASS COMP
   Zhu X., 2003, P 20 INT C MACH LEAR
   Zhu  X., 2002, CMUCALD02107
NR 18
TC 13
Z9 13
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 129
EP 136
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200017
DA 2019-06-15
ER

PT B
AU Clarke, J
   Lapata, M
AF Clarke, James
   Lapata, Mirella
GP COLING
TI Models for Sentence Compression: A Comparison across Domains, Training
   Requirements and Evaluation Measures
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID EXTRACTION
AB Sentence compression is the task of producing a summary at the sentence level, This paper focuses on three aspects of this task which have not received detailed treatment in the literature: training requirements, scalability, and automatic evaluation. We provide a novel comparison between a supervised constituent-based and an weakly supervised word-based compression algorithm and examine how these models port to different domains (written vs. spoken text). To achieve this, a human-authored compression corpus has been created and our study highlights potential problems with the automatically gathered compression corpora currently used. Finally, we assess whether automatic evaluation measures can be used to determine compression quality.
C1 [Clarke, James; Lapata, Mirella] Univ Edinburgh, Sch Informat, Edinburgh EH8 9LW, Midlothian, Scotland.
RP Clarke, J (reprint author), Univ Edinburgh, Sch Informat, 2 Bucclecuch Pl, Edinburgh EH8 9LW, Midlothian, Scotland.
EM jclarke@ed.ac.uk; mlap@inf.ed.ac.uk
CR Bangalore Srinivas, 2000, P 1 INT C NAT LANG G, P1
   Carroll J. A., 2002, P 3 INT C LANG RES E, P1499
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   Charniak E., 2005, P 43 ANN M ASS COMP, P290
   Clarkson P., 1997, P EUR 97 RHOD GREEC, P2707
   Corston-Oliver S, 2001, P NAACL WORKSH AUT S, P89
   GREFENSTETTE G, 1998, P AAAI S INT TEXT SU, P111
   Hori C, 2004, IEICE T INF SYST, VE87D, P15
   JING H, 2000, P 6 C APPL NAT LANG, P310
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   LOU B, 2000, USERS REFERENCE GUID
   MCDONALD R., 2006, P 11 C EUR CHAPT ASS, P297
   Nguyen M. L., 2004, P 20 INT C COMP LING, P743
   NGUYEN ML, 2004, ACM TALIP, V3, P146
   Press W.H., 1992, NUMERICAL RECIPES C
   Quinlan J. R., 1993, M KAUFMANN SERIES MA
   Riezler S., 2003, P HUM LANG TECHN C 3, V1, P118
   van der Hoek W, 2004, ACTA TROP, V89, P95, DOI 10.1016/j.actatropica.2003.10.013
   Weiss SM, 1991, COMPUTER SYSTEMS LEA
NR 19
TC 13
Z9 13
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 377
EP 384
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200048
DA 2019-06-15
ER

PT B
AU Okanohara, D
   Miyao, Y
   Tsuruoka, Y
   Tsujii, J
AF Okanohara, Daisuke
   Miyao, Yusuke
   Tsuruoka, Yoshimasa
   Tsujii, Jun'ichi
GP COLING
TI Improving the Scalability of Semi-Markov Conditional Random Fields for
   Named Entity Recognition
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents techniques to apply semi-CRFs to Named Entity Recognition tasks with a tractable computational cost. Our framework can handle an NER task that has long named entities and many labels which increase the computational cost. To reduce the computational cost, we propose two techniques: the first is the use of feature forests, which enables us to pack feature-equivalent states, and the second is the introduction of a filtering process which significantly reduces the number of candidate states. This framework allows us to use a rich set of features extracted from the chunk-based representation that can capture informative characteristics of entities. We also introduce a simple trick to transfer information about distant entities by embedding label information into non-entity labels. Experimental results show that our model achieves an F-score of 71.48% on the JNLPBA 2004 shared task without using any external resources or post-processing techniques.
C1 [Okanohara, Daisuke; Miyao, Yusuke; Tsujii, Jun'ichi] Univ Tokyo, Dept Comp Sci, Bunkyo Ku, Tokyo, Japan.
RP Okanohara, D (reprint author), Univ Tokyo, Dept Comp Sci, Bunkyo Ku, Hongo 7-3-1, Tokyo, Japan.
EM hillbig@is.s.u-tokyo.ac.jp; yusuke@is.s.u-tokyo.ac.jp;
   tsuruoka@is.s.u-tokyo.ac.jp; tsujii@is.s.u-tokyo.ac.jp
RI Tsuruoka, Yoshimasa/O-6842-2018
OI Tsuruoka, Yoshimasa/0000-0002-0707-1077
CR BETH M, 1995, 6 MESS UND C MUC 6, P13
   FINKEL J, 2004, P JNLPBA 04
   Finkel J. R., 2005, P 43 ANN M ASS COMP, P363, DOI DOI 10.3115/1219840.1219885
   Kim J., 2004, P INT JOINT WORKSH N, P70
   Kim Su N., 2005, P 2 INT JOINT C NAT
   KOU ZZ, 2005, BIOINFORMATICS
   KRAUTHAMMER M, 2004, J BIOMEDICAL INFORM
   LAFFERTY J, 2001, P ICML 2001
   Miyao Y., 2002, P HLT 2002
   PESHKIN, 2003, IJCAI
   SARAWAGI S, 2004, NIPS 2004
   SETTLES B, 2004, P JNLPBA 04
   SUTTON C, 2004, ICML WORKSH STAT REL
   TSURUOKA Y, 2005, P 9 INT WORKSH PARS
   Weischedel R., 1997, P 5 C APPL NAT LANG
   ZHOU GD, 2004, P JNLPBA 04
NR 16
TC 13
Z9 13
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 465
EP 472
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200059
DA 2019-06-15
ER

PT B
AU Suzuki, J
   McDermott, E
   Isozaki, H
AF Suzuki, Jun
   McDermott, Erik
   Isozaki, Hideki
GP COLING
TI Training Conditional Random Fields with Multivariate Evaluation Measures
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper proposes a framework for training Conditional Random Fields (CRFs) to optimize multivariate evaluation measures, including non-linear measures such as F-score. Our proposed framework is derived from an error minimization approach that provides a simple solution for directly optimizing any evaluation measure. Specifically focusing on sequential segmentation tasks, i.e. text chunking and named entity recognition, we introduce a loss function that closely reflects the target evaluation measure for these tasks, namely, segmentation F-score. Our experiments show that our method performs better than standard CRF training.
C1 [Suzuki, Jun; McDermott, Erik; Isozaki, Hideki] NTT Corp, NTT Commun Sci Labs, Seika, Kyoto 6190237, Japan.
RP Suzuki, J (reprint author), NTT Corp, NTT Commun Sci Labs, 2-4 Hikaridai, Seika, Kyoto 6190237, Japan.
EM jun@cslab.kecl.ntt.co.jp; mcd@cslab.kecl.ntt.co.jp;
   isozaki@cslab.kecl.ntt.co.jp
CR Altun Y, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P145
   Fahlman S. E., 1988, CMUCS88162
   GAO W, 2003, P SIGIR 03, P174
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Jansche M., 2005, P C HUM LANG TECHN E, P692
   Joachims Thorsten, 2005, P 22 INT C MACH LEAR, P377
   JUANG BH, 1992, IEEE T SIGNAL PROCES, V40, P3043, DOI 10.1109/78.175747
   KAKADE S, 2002, P ICML 2002, P275
   KATAGIRI S, 1991, P IEEE WORKSH NEUR N, P299
   KUDO T, 2001, P 2 M N AM CHAPT ASS, P192
   LAFFERTY J, 2001, P 18 INT C MACH LEAR, P282
   LEROUX J, 2005, P EUR, P3341
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Mccallum A., 2003, P 7 C NAT LANG LEARN, P188, DOI DOI 10.3115/1119176.1119206
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   QI Y, 2005, P AI STAT 2005
   RAMSHAW A, 1995, P VLC 1995, P88
   SANG EFT, 2003, P 7 C NAT LANG LEARN, P142
   SARAWAGI S, 2004, P NIPS 2004
   SHA F, 2003, P HLT NAACL, P213
   TASKAR B, 2004, P NIPS 2004
   Tjong E. F., 2000, P CONLL 2000 LLL 200, P127
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
NR 23
TC 13
Z9 13
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 217
EP 224
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200028
DA 2019-06-15
ER

PT B
AU Turney, PD
AF Turney, Peter D.
GP COLING
TI Expressing Implicit Semantic Relations without Supervision
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present an unsupervised learning algorithm that mines large text corpora for patterns that express implicit semantic relations. For a given input word pair X:Y with some unspecified semantic relations, the corresponding output list of patterns (P-1, ... , P-m) is ranked according to how well each pattern Pi expresses the relations between X and Y. For example, given X = ostrich and Y = bird, the two highest ranking output patterns are "X is the largest Y" and "Y such as the X". The Output patterns are intended to be useful for finding further pairs with the same relations, to Support the construction of lexicons, ontologies, and semantic networks. The patterns are sorted by pertinence, where the pertinence of a pattern Pi for a word pair X: Y is the expected relational similarity between the given pair and typical pairs for Pi. The algorithm is empirically evaluated on two tasks, solving multiple-choice SAT word analogy questions and classifying semantic relations in noun-modifier pairs. On both tasks, the algorithm achieves state-of-the-art results, performing significantly better than several alternative pattern ranking algorithms, based on tf-idf.
C1 Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada.
RP Turney, PD (reprint author), Natl Res Council Canada, Inst Informat Technol, M-50 Montreal Rd, Ottawa, ON K1A 0R6, Canada.
EM peter.turney@nrc-cnrc.gc.ca
CR Agichtein E., 2000, P 5 ACM INT C DIG LI, P85, DOI DOI 10.1145/336597.336644
   Berland M., 1999, P 37 ANN M ASS COMP, V37, P57
   Brin S., 1998, WEBDB WORKSH 6 INT C, P172, DOI DOI 10.1007/I
   CLARKE CLA, 1998, ACM SIGIR FORUM, V32, P14
   Golub G. H., 1996, MATRIX COMPUTATIONS
   Hearst M.A., 1992, P 14 INT C COMP LING, P539, DOI DOI 10.3115/992133.992154
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   Lapata M, 2002, COMPUT LINGUIST, V28, P357, DOI 10.1162/089120102760276018
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Miller S, 2000, P 6 APPL NAT LANG PR, P226
   Nastase V., 2003, 5 INT WORKSH COMP SE, P285
   Riloff E, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P474
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   STEVENSON M, 2004, P 4 INT C LANG RES E
   Terra E., 2003, P HUM LANG TECHN N A, P244
   Turney PD, 2005, MACH LEARN, V60, P251, DOI 10.1007/s10994-005-0913-1
   TURNEY PD, 2005, P 19 INT JOINT C ART, P1136
   VEALE T, 2004, P 16 EUR C ART INT E, P606
   YANGARBER R, 2003, P 41 ANN M ASS COMP, P343
   YANGARBER R, 2000, P 6 APPL NAT LANG PR, P282
   Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205
NR 21
TC 13
Z9 13
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 313
EP 320
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200040
DA 2019-06-15
ER

PT B
AU Florian, R
   Hassan, H
   Ittycheriah, A
   Jing, H
   Kambhatla, N
   Luo, X
   Nicolov, N
   Roukos, S
AF Florian, R
   Hassan, H
   Ittycheriah, A
   Jing, H
   Kambhatla, N
   Luo, X
   Nicolov, N
   Roukos, S
GP acl
TI A statistical model for multilingual entity detection and tracking
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB Entity detection and tracking is a relatively new addition to the repertoire of natural language tasks. In this paper, we present a statistical language-independent framework for identifying and tracking named, nominal and pronominal references to entities within unrestricted text documents, and chaining them into clusters corresponding to each logical entity present in the text. Both the mention detection model and the novel entity tracking model can use arbitrary feature types, being able to integrate a wide array of lexical, syntactic and semantic features. In addition, the mention detection model crucially uses feature streams derived from different named entity classifiers. The proposed framework is evaluated with several experiments run in Arabic, Chinese and English texts; a system based on the approach described here and submitted to the latest Automatic Content Extraction (ACE) evaluation achieved top-tier results in all three evaluation languages.
C1 IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Florian, R (reprint author), IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM raduf@us.ibm.com; hanyh@eg.ibm.com; abei@us.ibm.com; hjing@us.ibm.com;
   nanda@us.ibm.com; xiaoluo@us.ibm.com; nicolas@us.ibm.com;
   roukos@us.ibm.com
CR ABERDEEN J, 1995, P MUC, V6, P141
   Bell E. T, 1934, AM MATH MONTHLY, V41, P411, DOI [10.2307/2300300, DOI 10.2307/2300300]
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BIKEL DM, 1997, P ANLP 97, P195
   BORTHWICK A, 1998, EXPLOITING DIVERSE K
   ITTYCHERIAH A, 2003, HLT NAACL 2003 SHORT
   Jing HY, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P200
   LEE YS, 2003, P ACL 03, P399
   MIKHEEV A, 1999, P EACL
   MILLER S, 1995, COMMUNICATIONS ACM, V38
   MILLER S, 1998, MUC, V7
   Ng V, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P104
   *NIST, 2003, P ACE 03
   *NIST, 2003, ACE EV PLAN
   Ramshaw L., 1995, P 3 WORKSH VER LARG, P82
   RAMSHAW L, 1994, P ACL WORKSH COMB SY, P128
   Sang E. F. Tjong Kim, 2002, P CONLL 2002 TAIP TA, V20, P1, DOI DOI 10.3115/1118853.1118877
   SANG EFT, 1999, P EACL 99
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Williams RJ, 1990, NEURAL COMPUT, V2, P490, DOI 10.1162/neco.1990.2.4.490
   Zhang T, 2002, J MACH LEARN RES, V2, P615, DOI 10.1162/153244302320884560
NR 21
TC 13
Z9 13
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 1
EP 8
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100001
DA 2019-06-15
ER

PT B
AU Levy, R
   Manning, C
AF Levy, R
   Manning, C
GP ACL
TI Is it harder to parse Chinese, or the Chinese treebank?
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We present a detailed investigation of the challenges posed when applying parsing models developed against English corpora to Chinese. We develop a factored-model statistical parser for the Penn Chinese Treebank, showing the implications of gross statistical differences between WSJ and Chinese Treebanks for the most general methods of parser adaptation. We then provide a detailed analysis of the major sources of statistical parse errors for this corpus, showing their causes and relative frequencies, and show that while some types of errors are due to difficult ambiguities inherent in Chinese grammar, others arise due to treebank annotation practices. We show how each type of error can be addressed with simple, targeted changes to the independence assumptions of the maximum likelihood-estimated PCFG factor of the parsing model, which raises our F1 from 80.7% to 82.6% on our development set, and achieves parse accuracy close to the best published figures for Chinese parsing.
C1 Stanford Univ, Dept Linguist, Stanford, CA 94305 USA.
CR BENDER E, 2001, J EAST ASIAN LINGUIS, V9, P105
   BIKEL DM, 2000, P 2 CHIN LANG PROC W, P1
   Charniak Eugene, 2000, P NAACL
   Chiang David, 2002, P COLING 2002, P183
   CHURCH K, 1982, AM J COMPUTATIONAL L, P8
   Collins M., 1999, THESIS U PENN
   COLLINS M, 2000, P 17 INT C MACH LEAR, P175
   HENDERSON JC, 1999, P EM NLP
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   KLEIN D, 2002, P NIPS
   Krotov Alexander, 1998, P COLING ACL 98 JOIN, P699
   SAG IA, 1999, SYNTACTIC THEORY FOR
   XUE N, 2002, P COLING
NR 13
TC 13
Z9 15
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 439
EP 446
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500056
DA 2019-06-15
ER

PT B
AU Nakano, YI
   Reinstein, G
   Stocky, T
   Cassell, J
AF Nakano, YI
   Reinstein, G
   Stocky, T
   Cassell, J
GP ACL
TI Towards a model of face-to-face grounding
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We investigate the verbal and nonverbal means for grounding, and propose a design for embodied conversational agents that relies on both kinds of signals to establish common ground in human-computer interaction. We analyzed eye gaze, head nods and attentional focus in the context of a direction-giving task. The distribution of nonverbal behaviors differed depending on the type of dialogue move being grounded, and the overall pattern reflected a monitoring of lack of negative feedback. Based on these results, we present an ECA that uses verbal and nonverbal grounding acts to update dialogue state.
C1 MIT, Media Lab, Cambridge, MA 02139 USA.
RI Cassell, Justine/B-7123-2009
CR ALLEN J, 1997, DRAFT DMSL DIALOGUE
   Argyle M, 1976, GAZE MUTUAL GAZE
   BOYLE EA, 1994, LANG SPEECH, V37, P1, DOI 10.1177/002383099403700101
   Cassell J, 1999, APPL ARTIF INTELL, V13, P519, DOI 10.1080/088395199117360
   CASSELL J, 2000, IUI 2000
   Clark Herbert H., 1996, USING LANGUAGE
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7
   CLARK HH, 1989, COGNITIVE SCI, V13, P259, DOI 10.1016/0364-0213(89)90008-6
   Duncan S, 1974, LANG SOC, V3, P161, DOI DOI 10.1017/S0047404500004322
   Goodwin C., 1981, CONVERSATIONAL ORG I, P55
   KAPOOR A, 2001, WORKSH PERCEPTIVE US
   MATHESON C, 2000, 1 ANN M N AM ASS COM
   MORENCY LP, 2003, IEEE C COMPUTER VISI
   NAKAJIMA S, 1992, ICSLP
   Nakatani C. H., 1999, CODING DISCOURSE STR
   NOVICK DG, 1996, COORDINATION TURN TA
   PAEK T, 1999, AAAI FALL S PSYCH MO, P85
   PIERREHUMBERT JB, 1980, PHONOLOGY PHONETIC
   TRAUM D, 2002, EMBODIED AGENTS MULT
   TRAUM D, 1996, ICSLP
   TRAUM DR, 1996, AAAI WORKSH DET REP
NR 21
TC 13
Z9 13
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 553
EP 561
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500070
DA 2019-06-15
ER

PT B
AU Ng, HT
   Wang, B
   Chan, YS
AF Ng, HT
   Wang, B
   Chan, YS
GP ACL
TI Exploiting parallel texts for word sense disambiguation: An empirical
   study
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB A central problem of word sense disambiguation (WSD) is the lack of manually sense-tagged data required for supervised learning. In this paper, we evaluate an approach to automatically acquire sense-tagged training data from English-Chinese parallel corpora, which are then used for disambiguating the nouns in the SENSEVAL-2 English lexical sample task. Our investigation reveals that this method of acquiring sense-tagged data is promising. On a subset of the most difficult SENSEVAL-2 nouns, the accuracy difference between the two approaches is only 14.0%, and the difference could narrow further to 6.5% if we disregard the advantage that manually sense-tagged data have in their sense coverage. Our analysis also highlights the importance of the issue of domain dependence in evaluating WSD programs.
C1 Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore.
CR [Anonymous], 1999, P 37 ANN M ASS COMP, P527, DOI DOI 10.3115/1034678.1034757
   Brown PF, 1991, P 29 ANN M ASS COMP, P264
   Chugur I., 2002, P SIGLEX SENSEVAL WO, P32
   Dan Melamed I., 2001, EMPIRICAL METHODS EX
   DIAB M, 2002, P 40 ANN M ASS COMP, P255
   Edmonds P., 2001, P 2 INT WORKSH EV WO, P1
   Escudero G, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P172
   Florian R, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P25
   Ide Nancy, 2002, P ACL 02 WORKSH WORD, P54
   Kilgarriff A., 2001, P SENS 2 2 INT WORKS, P17
   Lee YK, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P41
   LI C, 2002, P 40 ANN M ASS COMP, P343
   Mihalcea R.F., 2001, P 2 INT WORKSH EV WO, P127
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Resnik P., 2000, NAT LANG ENG, V5, P113, DOI DOI 10.1017/S1351324999002211
   Resnik P., 1997, P ACL SIGLEX WORKSH, P79
   Yarowsky D, 2001, P 2 INT WORKSH EV WO, P163
NR 18
TC 13
Z9 13
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 455
EP 462
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500058
DA 2019-06-15
ER

PT B
AU Hoffmann, R
   Zhang, CL
   Weld, DS
AF Hoffmann, Raphael
   Zhang, Congle
   Weld, Daniel S.
GP Assoc Computat Linguist
TI Learning 5000 Relational Extractors
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Many researchers are trying to use information extraction (IE) to create large-scale knowledge bases from natural language text on the Web. However, the primary approach (supervised learning of relation-specific extractors) requires manually-labeled training data for each relation and doesn't scale to the thousands of relations encoded in Web text.
   This paper presents LUCHS, a self-supervised, relation-specific IE system which learns 5025 relations - more than an order of magnitude greater than any previous approach-with an average F1 score of 61%. Crucial to LUCHS's performance is an automated system for dynamic lexicon learning, which allows it to learn accurately from heuristically-generated training data, which is often noisy and sparse.
C1 [Hoffmann, Raphael; Zhang, Congle; Weld, Daniel S.] Univ Washington, Comp Sci & Engn, Seattle, WA 98195 USA.
RP Hoffmann, R (reprint author), Univ Washington, Comp Sci & Engn, Seattle, WA 98195 USA.
EM raphaelh@cs.washington.edu; clzhang@cs.washington.edu;
   weld@cs.washington.edu
CR Agichtein E., 2004, P 10 ACM SIGKDD INT, P20
   Auer S., 2007, P 6 INT SEM WEB C 2, P722, DOI DOI 10.1007/978-3-540-76298-0_52
   Banko M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2670
   Bellare K., 2007, 6 INT WORKSH INF INT
   Bengio Y., 2006, SEMISUPERVISED LEARN, P193
   Cafarella MJ, 2008, PROC VLDB ENDOW, V1, P538, DOI 10.14778/1453856.1453916
   Carlson Andrew, 2009, NAACL HLT 2009 WORKS
   Carlson Andrew, 2009, AAAI SPRING S LEARN
   Cohen W. W., 2004, P 10 ACM SIGKDD INT, P89
   Collins Michael, 2002, P 2002 C EMP METH NA
   CRAVEN M, 1999, INTELLIGENT SYSTEMS, V1999, P77
   de Marneffe M. - C., 2006, P 5 INT C LANG RES E
   Etzioni O, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P391
   FEI W, 2007, P CIKM 07, P41
   Freitag D., 1998, P 36 ANN M ASS COMP, P404
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Ghahramani Zoubin, 2005, NEURAL INFORM PROCES
   Hirschman L, 2002, J BIOMED INFORM, V35, P247, DOI 10.1016/S1532-0464(03)00014-5
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Miller Scott, 2004, P HUM LANG TECHN C N
   Mintz Mike, 2009, ANN M ASS COMP LING
   Pasca Marius, 2009, P 12 C EUR CHAPT ASS, P639
   RILOFF E, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P811
   Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001
   Suchanek Fabian M., 2009, P 18 INT C WORLD WID
   Talukdar P. P., 2008, EMNLP, P582
   Talukdar Partha Pratim, 2006, 10 C NAT LANG LEARN
   Van Durme B., 2008, P 23 AAAI C ART INT, P1243
   Wang Gang, 2007, P 6 INT SEM WEB C 2, P580
   Wang RC, 2007, IEEE DATA MINING, P342, DOI 10.1109/ICDM.2007.104
   Wang Richard C., 2008, P 8 IEEE INT C DAT M
   Wang Y, 2009, IEEE INT CON AUTO SC, P37, DOI 10.1109/COASE.2009.5234118
   Wu Fei, 2010, ANN M ASS COMP LING
   Wu Fei, 2008, P 17 INT C WORLD WID, P635
   Wu Fei, 2008, P 14 ACM SIGKDD INT, P731
NR 35
TC 12
Z9 12
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 286
EP 295
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300030
DA 2019-06-15
ER

PT B
AU Huang, L
   Sagae, K
AF Huang, Liang
   Sagae, Kenji
GP Assoc Computat Linguist
TI Dynamic Programming for Linear-Time Incremental Parsing
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID ALGORITHM
AB Incremental parsing techniques such as shift-reduce have gained popularity thanks to their efficiency, but there remains a major problem: the search is greedy and only explores a tiny fraction of the whole space (even with beam search) as opposed to dynamic programming. We show that, surprisingly, dynamic programming is in fact possible for many shift-reduce parsers, by merging " equivalent" stacks based on feature values. Empirically, our algorithm yields up to a five-fold speedup over a state-of-the-art shift-reduce dependency parser with no loss in accuracy. Better search also leads to better learning, and our final parser outperforms all previously reported dependency parsers for English and Chinese, yet is much faster.
C1 [Huang, Liang] USC Informat Sci Inst, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
   [Sagae, Kenji] USC Inst Creat Technol, Marina Del Rey, CA 90292 USA.
RP Huang, L (reprint author), USC Informat Sci Inst, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
EM lhuang@isi.edu; sagae@ict.usc.edu
CR Aho Alfred V., 1972, PARSING SERIES AUTOM, VI
   Billot S., 1989, P 27 ANN M ASS COMP, P143
   Charniak Eugene, 2000, P NAACL
   Charniak Eugene, 2005, P 43 ACL ANN ARB MI
   Collins  M., 2002, P EMNLP
   Collins M., 2004, P ACL
   COLLINS M, 2000, P 17 INT C MACH LEAR, P175
   Duan Xiangyu, 2007, P ECML PKDD
   EARLEY J, 1970, COMMUN ACM, V13, P94, DOI 10.1145/362007.362035
   Eisner Jason, 1999, P ACL
   Eisner Jason M., 1996, P COLING
   FRAZIER L, 1982, COGNITIVE PSYCHOL, V14, P178, DOI 10.1016/0010-0285(82)90008-1
   HUANG L, 2005, P 9 INT WORKSH PARS
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Koo T., 2008, P ACL
   Lang Bernard, 1974, LECT NOTES COMPUTER, V14, P255, DOI DOI 10.1007/3-540-06841-4_65
   Lee L, 2002, J ACM, V49, P1, DOI 10.1145/505241.505242
   Liang Huang, 2009, P EMNLP
   Liang Huang, 2008, P ACL HLT COL OH JUN
   McDonald R., 2005, P HLT EMNLP
   McDonald Ryan, 2005, P 43 ACL
   Nederhof Mark- Jan, 2003, COMPUTATIONAL LINGUI, P135
   Nivre Joakim, 2004, INCREMENTAL PARSING
   Petrov Slav, 2007, P HLT NAACL
   Roark Brian, 2009, P HLT NAACL
   STOLCKE A, 1995, COMPUT LINGUIST, V21, P165
   TOMITA M, 1991, GEN LR PARSING
   Tomita Masaru, 1988, P 26 ANN M ASS COMP, P249
   YAMADA H, 2003, P IWPT
   Yue Zhang, 2008, P EMNLP
NR 30
TC 12
Z9 12
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1077
EP 1086
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300110
DA 2019-06-15
ER

PT B
AU Kelleher, JD
   Kruijff, GJM
AF Kelleher, John D.
   Kruijff, Geert-Jan M.
GP COLING
TI Incremental generation of spatial referring expressions in situated
   dialog
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID ATTENTION; SCENES
AB This paper presents an approach to incrementally generating locative expressions. It addresses the issue of combinatorial explosion inherent in the construction of relational context models by: (a) contextually defining the set of objects in the context that may function as a landmark, and (b) sequencing the order in which spatial relations are considered using a cognitively motivated hierarchy of relations, and visual and discourse salience.
C1 [Kelleher, John D.] Dublin Inst Technol, Dublin, Ireland.
RP Kelleher, JD (reprint author), Dublin Inst Technol, Dublin, Ireland.
EM john-kelleher@comp.dit.ie; gj@dfki.de
RI Kelleher, John/N-6963-2017
OI Kelleher, John/0000-0001-6462-3248
CR Beun R.- J., 1998, PRAGMAT COGN, V6, P121, DOI [DOI 10.1075/PC.6.1-2.08BEU, 10.1075/pc.6.1-2.08beu]
   BRYANT DJ, 1992, J MEM LANG, V31, P74, DOI 10.1016/0749-596X(92)90006-J
   CARLSONRADVANSKY LA, 1994, J MEM LANG, V33, P646, DOI 10.1006/jmla.1994.1031
   CarlsonRadvansky LA, 1997, J MEM LANG, V37, P411, DOI 10.1006/jmla.1997.2519
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7
   CONKLIN EJ, 1982, ACL P 20 ANN M, P129
   DALE R, 1995, COGNITIVE SCI, V19, P233
   Dale R., 1991, P 5 C EUR CHAPT ASS, P161
   Duwe I., 1997, 971 U BIEL
   Edwards G, 1998, REPRESENTATION AND PROCESSING OF SPATIAL EXPRESSIONS, P163
   Fillmore Charles, 1997, LECT DEIXIS
   GAPP KP, 1995, P 17 C COGN SCI SOC
   GARDENT C, 2002, P 40 ANN M ASS COMP, P96
   Garrod S, 1999, COGNITION, V72, P167, DOI 10.1016/S0010-0277(99)00038-4
   Gorniak P, 2004, J ARTIF INTELL RES, V21, P429, DOI 10.1613/jair.1327
   HAJICOVA E, 1993, THEORETICAL COMPUTAT, V6
   Herskovits A., 1986, LANGUAGE SPATIAL COG
   Horacek H., 1997, P 35 ANN M ASS COMP
   Jackendoff Ray, 1983, CURRENT STUDIES LING
   Kelleher J, 2004, ARTIF INTELL REV, V21, P253, DOI 10.1023/B:AIRE.0000036258.60851.83
   Kelleher JD, 2006, P ACL COLING 2006
   Krahmer E., 2002, INFORM SHARING REFER
   Kruijff G-.J.M., 2006, PERC INT TECHN PIT 2
   KRUIJFF GJM, 2006, P 1 ANN C HUM ROB IN
   Landesman B, 1996, SERIALS LIBR, V28, P317, DOI 10.1300/J123v28n03_17
   LOGAN GD, 1994, J EXP PSYCHOL HUMAN, V20, P1015, DOI 10.1037//0096-1523.20.5.1015
   LOGAN GD, 1980, COGNITIVE PSYCHOL, V12, P523, DOI 10.1016/0010-0285(80)90019-5
   MORATZ R, 2006, SPATIAL COGNITION CO
   Talmy Leonard, 1983, SPATIAL ORIENTATION, P225, DOI DOI 10.1007/978-1-4615-9325-6_11
   TREISMAN A, 1988, PSYCHOL REV, V95, P15, DOI 10.1037/0033-295X.95.1.15
   VANDEEMTER K, 2001, 4 INT C COMP SEM IWC
   Vandeloise Claude, 1991, SPATIAL PREPOSITIONS
   VANDERSLUIS I, 2004, P INT C SPOK LANG PR
   VARGES S, 2004, P 3 INT C NAT LANG G
NR 34
TC 12
Z9 12
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1041
EP 1048
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200131
DA 2019-06-15
ER

PT B
AU Liang, P
   Bouchard-Cote, A
   Klein, D
   Taskar, B
AF Liang, Percy
   Bouchard-Cote, Alexandre
   Klein, Dan
   Taskar, Ben
GP COLING
TI An End-to-End Discriminative Approach to Machine Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a perceptron-style discriminative approach to machine translation in which large feature sets can be exploited. Unlike discriminative reranking approaches, our system can take advantage of learned features in all stages of decoding. We first discuss several challenges to error-driven discriminative approaches. In particular, we explore different ways of updating parameters given a training example. We find that making frequent but smaller updates is preferable to making fewer but larger updates. Then, we discuss an array of features and show both how they quantitatively increase BLEU score and how they qualitatively interact on specific examples. One particular feature we investigate is a novel way to introduce learning into the initial phrase extraction process, which has previously been entirely heuristic.
C1 [Liang, Percy; Bouchard-Cote, Alexandre; Klein, Dan; Taskar, Ben] Univ Calif Berkeley, Dept EECS, Div Comp Sci, Berkeley, CA 94720 USA.
RP Liang, P (reprint author), Univ Calif Berkeley, Dept EECS, Div Comp Sci, Berkeley, CA 94720 USA.
EM pliang@cs.berkeley.edu; bouchard@cs.berkeley.edu; klein@cs.berkeley.edu;
   taskar@cs.berkeley.edu
CR Brown P. F., 1992, Computational Linguistics, V18, P467
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Chiang D., 2005, ACL 2005
   COLLINS M, 2004, ACL 2004
   Collins M., 2002, EMNLP 2002
   Koehn  P., 2002, EUROPARL MULTILINGUA
   KOEHN P, 2003, HLT NAACL 2003
   KOO T, 2005, EMNLP 2005
   OCH F, 2002, ACL 2002
   OCH F, 2003, ACL 2003
   Och F. J., 2004, HLT NAACL 2004
   QUATTONI A, 2004, NIPS 2004
   RIEZLER S, 2005, WORKSH INTR EXTR EV
   ROARK B, 2004, ACL 2004
   SCHMID H, 1994, INT C NEW METHODS LA
   SHEN L, 2004, HLT NAACL 2004
   STOLCKE A, 2002, ICSLP 2002
   TILLMANN C, 2005, ACL 2005
   ZENS R, 2004, HLT NAACL 2004
NR 19
TC 12
Z9 12
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 761
EP 768
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200096
DA 2019-06-15
ER

PT B
AU Forbes-Riley, K
   Litman, DJ
AF Forbes-Riley, K
   Litman, DJ
GP acl
TI Predicting emotion in spoken dialogue from multiple knowledge sources
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We examine the utility of multiple types of turn-level and contextual linguistic features for automatically predicting student emotions in human-human spoken tutoring dialogues. We first annotate student turns in our corpus for negative, neutral and positive emotions. We then automatically extract features representing acoustic-prosodic and other linguistic information from the speech signal and associated transcriptions. We compare the results of machine learning experiments using different feature sets to predict the annotated emotions. Our best performing feature set contains both acoustic-prosodic and other types of linguistic features, extracted from both the current turn and a context of previous student turns, and yields a prediction accuracy of 84.75%, which is a 44% relative improvement in error reduction over a baseline. Our results suggest that the intelligent tutoring spoken dialogue system we are developing can be enhanced to automatically predict and adapt to student emotions.
C1 Univ Pittsburgh, Ctr Learning Res & Dev, Pittsburgh, PA 15260 USA.
RP Forbes-Riley, K (reprint author), Univ Pittsburgh, Ctr Learning Res & Dev, Pittsburgh, PA 15260 USA.
CR AIST G, 2002, P INT TUT SYST 6 INT
   ALEVEN V, 2003, P AIED 2003 WORKS TU
   Ang J., 2002, P INT C SPOK LANG PR, P2037
   Batliner A, 2003, SPEECH COMMUN, V40, P117, DOI 10.1016/S0167-6393(02)00079-1
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   CORE MG, 2003, P 11 C EUR CHAPT ASS, P67
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Craggs R., 2004, P AAAI SPRING S EXPL
   DEVILLERS L, 2003, P IEEE INT C MULT EX
   EVENS M, 2002, 2002 S NAT LANG TUT
   Frank E., 1999, DATA MINING PRACTICA
   Freund Y., 1996, P 13 INT C MACH LEAR, P148, DOI DOI 10.4236/IIM.2010.26047
   LEE CM, 2001, P IEEE AUT SPEECH RE
   LEE CM, 2002, P INT C SPOK LANG PR
   Liscombe J., 2003, P EUR
   Litman D., 2004, P 5 SIGDIAL WORKSH D
   LITMAN D, 2001, P 39 ANN M 10 C EUR, P362
   LITMAN D, 2003, P IEEE AUT SPEECH RE
   Litman D. J., 2004, P HUM LANG TECHN C 4
   OUDEYER PY, 2002, INT J HUMAN COMPUTER, V59, P157
   POLZIN TS, 1998, P COOP MULT COMM
   QU Y, 2004, AAAI WORK NOT SPRING
   Shafran I., 2003, P IEEE AUT SPEECH RE
   VANLEHN K, 2002, P INT TUT SYST 6 INT
NR 24
TC 12
Z9 12
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 201
EP 208
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100026
DA 2019-06-15
ER

PT B
AU Echihabi, A
   Marcu, D
AF Echihabi, A
   Marcu, D
GP ACL
TI A noisy-channel approach to question answering
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We introduce a probabilistic noisy-channel model for question answering and we show how it can be exploited in the context of an end-to-end QA system. Our noisy-channel system outperforms a state-of-the-art rule-based QA system that uses similar resources. We also show that the model we propose is flexible enough to accommodate within one mathematical framework many QA-specific resources and techniques, which range from the exploitation of WordNet, structured, and semi-structured databases to reasoning, and paraphrasing.
C1 Univ So Calif, Inst Informat Sci, Dept Comp Sci, Marina Del Rey, CA 90292 USA.
CR ALONAIZAN Y, 1999, STAT MACHINE TRANSLA
   BERGER AL, 1999, P SIGIR 1999 BERK
   BRILL E, 2001, P TREC2001 C NIST GA
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHARLES LA, 2001, P TREC 2001 C NIST G
   Church K. W., 1988, P 2 C APPL NAT LANG
   HERMJAKOB U, 2002, P TREC2002 C NIST GA
   HOVY EH, 2001, P TREC 2001 C NIST G
   ITTYCHERIAH A, 2002, P TREC 2002 C NIST G
   Jelinek F., 1997, STAT METHODS SPEECH
   KATZ B, 2001, MIT ARTIFICIAL INTEL
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   LIN J, 2002, LREC 2002 LAS PALMAS
   MOLDOVAN D, 2002, P TREC 2002 C NIST
   MUSLEA I, 1999, P WORKSH MACH LEARN
   PASCA M, 2001, P NAACL 2001 WORKSH
   PRAGER JM, 2001, P TREC 2002 C NIST G
   XU J, 2002, P TREC 2002 C NIST G
NR 18
TC 12
Z9 14
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 16
EP 23
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500003
DA 2019-06-15
ER

PT B
AU Bloodgood, M
   Callison-Burch, C
AF Bloodgood, Michael
   Callison-Burch, Chris
GP Assoc Computat Linguist
TI Bucking the Trend: Large-Scale Cost-Focused Active Learning for
   Statistical Machine Translation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We explore how to improve machine translation systems by adding more translation data in situations where we already have substantial resources. The main challenge is how to buck the trend of diminishing returns that is commonly encountered. We present an active learning-style data solicitation algorithm to meet this challenge. We test it, gathering annotations via Amazon Mechanical Turk, and find that we get an order of magnitude increase in performance rates of improvement.
C1 [Bloodgood, Michael] Johns Hopkins Univ, Human Language Technol Ctr Excellence, Baltimore, MD 21211 USA.
   [Callison-Burch, Chris] Johns Hopkins Univ, Ctr Language & Speech Proc, Baltimore, MD 21211 USA.
RP Bloodgood, M (reprint author), Johns Hopkins Univ, Human Language Technol Ctr Excellence, Baltimore, MD 21211 USA.
EM bloodgood@jhu.edu; ccb@cs.jhu.edu
RI Ngai, Grace/A-1846-2014
OI Ngai, Grace/0000-0002-2027-168X
CR Ambati Vamshi, 2010, P 7 C INT LANG RES E
   Banko M., 2001, P 39 ANN M ASS COMP, P26
   Bloodgood M., 2009, P HUM LANG TECHN 200, P137
   Bloodgood M., 2009, P 13 C COMP NAT LANG, P39
   Bloodgood Michael, 2010, P WORKSH CREAT SPEEC
   Bloodgood Michael, 2008, P WORKSH CURR TRENDS, P104
   Callison-Burch Chris, 2006, 11 C EUR CHAPT ASS C
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Hachey B., 2005, P 9 C COMP NAT LANG, P144
   Haertel R., 2008, P 46 ANN M ASS COMP, P65
   Haffari Gholamreza, 2009, P N AM CHAPT ASS COM, P415
   Haffari Gholamreza, 2009, P 47 ANN M ACL 4 IJC, P181
   Hwa R, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P45
   Kapoor A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P877
   King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236
   Lewis D. D., 1994, P C RES DEV INF RETR, V17, P3, DOI DOI 10.1007/978-1-4471-2099-5_1
   Li ZY, 2009, PROCEEDINGS OF THE ASME SUMMER BIOENGINEERING CONFERENCE - 2009, PT A AND B, P135, DOI 10.3115/1626431.1626459
   Mairesse F., 2010, P 48 ANN M ASS COMP
   Ngai Grace, 2000, P 38 ANN M ASS COMP
   Osborne M, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P89
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Sassano M., 2002, ACL 02, P505
   Schohn G., 2000, P 17 INT C MACH LEAR, P839
   Snow R., 2008, P C EMP METH NAT LAN, P254, DOI DOI 10.3115/1613715.1613751
   Tomanek K., 2009, P JOINT C 47 ANN M A, V2, P1039
   Tong S, 2002, J MACH LEARN RES, V2, P45
   Venugopal A., 2006, P NAACL 2006 WORKSH
   Vickrey David, 2010, P 48 ANN M ASS COMP
   Vlachos A, 2008, COMPUT SPEECH LANG, V22, P295, DOI 10.1016/j.csl.2007.12.001
NR 29
TC 11
Z9 11
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 854
EP 864
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300088
DA 2019-06-15
ER

PT B
AU Feng, YS
   Lapata, M
AF Feng, Yansong
   Lapata, Mirella
GP Assoc Computat Linguist
TI How Many Words is a Picture Worth? Automatic Caption Generation for News
   Images
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID NATURAL-LANGUAGE; CLASSIFICATION; ANNOTATION
AB In this paper we tackle the problem of automatic caption generation for news images. Our approach leverages the vast resource of pictures available on the web and the fact that many of them are captioned. Inspired by recent work in summarization, we propose extractive and abstractive caption generation models. They both operate over the output of a probabilistic image annotation model that preprocesses the pictures and suggests keywords to describe their content. Experimental results show that an abstractive model defined over phrases is superior to extractive methods.
C1 [Feng, Yansong; Lapata, Mirella] Univ Edinburgh, Sch Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
RP Feng, YS (reprint author), Univ Edinburgh, Sch Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
EM Y.Feng-4@sms.ed.ac.uk; mlap@inf.ed.ac.uk
CR BANKO M, 2000, P 38 ANN M ASS COMP, P318
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei D.M., 2003, P 26 ANN INT ACM SIG, P127, DOI DOI 10.1145/860435.860460
   Chong W, 2009, PROC CVPR IEEE, P1903, DOI 10.1109/CVPRW.2009.5206800
   Corio M., 1999, P 7 EUR WORKSH NAT L, P49
   David B, 2003, J MACHINE LEARNING R, V3, P993
   Dorr Bonnie, 2006, P ASS MACH TRANSL AM, P223
   Duygulu P., 2002, P EUR C COMP VIS, P97, DOI DOI 10.1007/3-540-47979-1_7
   Elzer S, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1042
   Fasciano M., 2000, Knowledge and Information Systems, V2, P310, DOI 10.1007/PL00011645
   FEINER SK, 1990, PROCEEDINGS : EIGHTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P442
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Feng Y., 2008, P 46 ANN M ASS COMP, P272
   Feng Yansong, 2010, P 11 ANN C N AM CHAP
   Ferres L., 2006, P 10 INT C COMP HELP, P1122
   Hede Patrick, 2004, P COMP ASS INF RETR
   Jin R., 2002, P 19 INT C COMP LING, P1
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   KNESER R, 1997, P EUROSPEECH, P1971
   Kojima A, 2002, INT J COMPUT VISION, V50, P171, DOI 10.1023/A:1020346032608
   Kojima Atsuhiro, 2008, P 3 INT C INN COMP I, P53
   Lavrenko V., 2003, P 16 C ADV NEUR INF
   Lowe D. G., 1999, P INT C COMP VIS, V2, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mittal VO, 1998, COMPUT LINGUIST, V24, P431
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Salton  G., 1983, INTRO MODERN INFORM
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Steyvers M., 2007, HDB LATENT SEMANTIC
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   von Ahn L, 2004, ACM C HUM FACT COMP, P319, DOI DOI 10.1145/985692.985733
   Yao Benjamin, 2009, P IEEE INV INT VIS
   Zajic David, 2003, P HLT NAACL TEXT SUM, V5, P1, DOI DOI 10.3115/1119467.1119468
NR 32
TC 11
Z9 11
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1239
EP 1249
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300126
DA 2019-06-15
ER

PT B
AU He, YF
   Ma, YJ
   van Genabith, J
   Way, A
AF He, Yifan
   Ma, Yanjun
   van Genabith, Josef
   Way, Andy
GP Assoc Computat Linguist
TI Bridging SMT and TM with Translation Recommendation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We propose a translation recommendation framework to integrate Statistical Machine Translation (SMT) output with Translation Memory (TM) systems. The framework recommends SMT outputs to a TM user when it predicts that SMT outputs are more suitable for post-editing than the hits provided by the TM. We describe an implementation of this framework using an SVM binary classifier. We exploit methods to fine-tune the classifier and investigate a variety of features of different types. We rely on automatic MT evaluation metrics to approximate human judgements in our experiments. Experimental results show that our system can achieve 0.85 precision at 0.89 recall, excluding exact matches. Furthermore, it is possible for the end-user to achieve a desired balance between precision and recall by adjusting confidence levels.
C1 [He, Yifan; Ma, Yanjun; van Genabith, Josef; Way, Andy] Dublin City Univ, Sch Comp, Ctr Next Generat Localisat, Dublin 9, Ireland.
RP He, YF (reprint author), Dublin City Univ, Sch Comp, Ctr Next Generat Localisat, Dublin 9, Ireland.
EM yhe@computing.dcu.ie; yma@computing.dcu.ie; josef@computing.dcu.ie;
   away@computing.dcu.ie
OI Way, Andy/0000-0001-5736-5930
CR Blatz John, 2004, 20 COL GEN, P315
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Callison-Burch Chris, 2009, 2009 C EMP METH NAT, P286
   Chang C. C., 2001, LIB SVM LIB SUPPORT
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Koehn Philipp., 2003, 2003 C N AM CHAPT AS, P48
   Koehn Philipp, 2007, 45 ANN M ASS COMP LI, P177
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   Lin HT, 2007, MACH LEARN, V68, P267, DOI 10.1007/s10994-007-5018-6
   Och FJ, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P295
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Platt John C., 1999, ADV LARGE MARGIN CLA, P61
   Quirk Christopher B., 2004, 4 C LANG RES EV LISB, P825
   Sikes R., 2007, MULTILINGUAL, V18, P39
   Simard M., 2009, 12 MACHINE TRANSLATI, P120
   Snover Matthew, 2006, 2006 C ASS MACH TRAN, P223
   Specia Lucia, 2009, 13 C EUR ASS MACH TR, P28
   Specia Lucia, 2009, 12 MACHINE TRANSLATI, P136
   Stolcke A., 2002, P INT C SPOK LANG PR, P901
   Ueffing Nicola, 2005, 9 ANN C EUR ASS MACH, P262
   Ueffing Nicola, 2003, 9 MACHINE TRANSLATIO, P394
NR 22
TC 11
Z9 11
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 622
EP 630
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300064
DA 2019-06-15
ER

PT B
AU Li, X
AF Li, Xiao
GP Assoc Computat Linguist
TI Understanding the Semantic Structure of Noun Phrase Queries
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Determining the semantic intent of web queries not only involves identifying their semantic class, which is a primary focus of previous works, but also understanding their semantic structure. In this work, we formally define the semantic structure of noun phrase queries as comprised of intent heads and intent modifiers. We present methods that automatically identify these constituents as well as their semantic roles based on Markov and semi-Markov conditional random fields. We show that the use of semantic features and syntactic features significantly contribute to improving the understanding performance.
C1 [Li, Xiao] Microsoft Res, One Microsoft Way, Redmond, WA 98052 USA.
RP Li, X (reprint author), Microsoft Res, One Microsoft Way, Redmond, WA 98052 USA.
EM xiaol@microsoft.com
CR Arguello Jaime, 2009, SIGIR 09
   Barr C., 2008, P C EMP METH NAT LAN, P1021, DOI DOI 10.3115/1613715.1613848
   Borges C., 2005, P 22 INT C MACH LEAR, P89, DOI DOI 10.1145/1102351.1102363
   Collins M., 1999, THESIS
   Gao Jianfeng, 2001, SIGIR 01
   Kim J.Y., 2009, ECIR 2009, P228
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Li Fangtao, 2008, COLING, P481
   Li Xiao, 2009, SIGIR 09
   Li Xiao, 2008, SIGIR 08
   Manshadi Mehdi, 2009, P 47 ANN M ACL 4 IJC
   Mccallum A., 2003, P 7 C NAT LANG LEARN, P188, DOI DOI 10.3115/1119176.1119206
   Metzler Donald, 2005, J INFORM RETRIEVAL, V8
   Pantel P, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P113
   Paparizos Stelios, 2009, P 35 SIGMOD INT C MA
   Pasca M., 2007, IJCAI 07
   Pasca Marius, 2008, P ACL 08 HLT
   Pennacchiotti M., 2009, EMNLP, P238
   ROBERTSON S, 2004, CIKM 04, P42
   Sarawagi S., 2004, ADV NEURAL INFORM PR
   SHEN D, 2006, SIGIR 2006, P131
NR 21
TC 11
Z9 12
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1337
EP 1345
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300136
DA 2019-06-15
ER

PT B
AU Mairesse, F
   Gasic, M
   Jurcicek, F
   Keizer, S
   Thomson, B
   Yu, K
   Young, S
AF Mairesse, Francois
   Gasic, Milica
   Jurcicek, Filip
   Keizer, Simon
   Thomson, Blaise
   Yu, Kai
   Young, Steve
GP Assoc Computat Linguist
TI Phrase-based Statistical Language Generation using Graphical Models and
   Active Learning
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID STATE
AB Most previous work on trainable language generation has focused on two paradigms: (a) using a statistical model to rank a set of generated utterances, or (b) using statistics to inform the generation decision process. Both approaches rely on the existence of a handcrafted generator, which limits their scalability to new domains. This paper presents BAGEL, a statistical language generator which uses dynamic Bayesian networks to learn from semantically-aligned data produced by 42 untrained annotators. A human evaluation shows that BAGEL can generate natural and informative utterances from unseen inputs in the information presentation domain. Additionally, generation performance on sparse datasets is improved significantly by using certainty-based active learning, yielding ratings close to the human gold standard with a fraction of the data.
C1 [Mairesse, Francois; Gasic, Milica; Jurcicek, Filip; Keizer, Simon; Thomson, Blaise; Yu, Kai; Young, Steve] Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.
RP Mairesse, F (reprint author), Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 1PZ, England.
EM f.mairesse@eng.cam.ac.uk; mg436@eng.cam.ac.uk; fj228@eng.cam.ac.uk;
   sk561@eng.cam.ac.uk; brmt2@eng.cam.ac.uk; ky219@eng.cam.ac.uk;
   sjy@eng.cam.ac.uk
CR Bangalore S, 2000, P 18 INT C COMP LING, P42
   Belz Anja, 2008, Natural Language Engineering, P431, DOI 10.1017/S1351324907004664
   BILMES J, 2002, P ICASSP
   BILMES J, 2003, P HLT NAACL
   Bloodgood M., 2010, P 48 ANN M ASS COMP
   Espinosa D., 2008, P 46 ANN M ASS COMP
   Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534
   HAKKANITUR D, 2002, P ICASSP
   He Y, 2005, COMPUT SPEECH LANG, V19, P85, DOI 10.1016/j.csl.2004.03.001
   Isard  A., 2006, P 4 INT NAT LANG GEN, P22
   LANGKILDE I, 1998, P 36 ANN M ASS COMP, P704
   Lefevre F., 2006, P IEEE WORKSH SPOK L
   Lewis D. D., 1994, P ICML
   Mairesse F., 2008, P 46 ANN M ASS COMP
   Nakanishi H., 2005, P IWPT
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Paiva D. S., 2005, P 43 ANN M ASS COMP, P58
   Papineni  K., 2002, P 40 ANN M ASS COMP
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Reiter E., 2009, COMPUTATIONAL LINGUI, V25, P529
   Rieser V., 2009, P ANN M EUR CHAPT AC
   SASSANO M, 2002, P 40 ANN M ASS COMP
   Schatzmann Jost, 2007, HUMAN LANGUAGE TECHN, P149
   Stolcke A., 2002, P INT C SPOK LANG PR
   Tang M., 2002, P 40 ANN M ASS COMP
   Thompson C., 1999, P ICML
   Thomson B, 2010, COMPUT SPEECH LANG, V24, P562, DOI 10.1016/j.csl.2009.07.003
   Tokuda Y., 2000, P ICASSP
   Tur G., 2003, P ICASSP
   Varges S., 2001, P ANN M N AM CHAPT A
   Walker  M., 2002, COMPUTER SPEECH LANG, V16, P3
   White M., 2007, P WORKSH US CORP NLG
   Wong Y. W., 2007, P HLT NAACL
   Young S, 2010, COMPUT SPEECH LANG, V24, P150, DOI 10.1016/j.csl.2009.04.001
NR 34
TC 11
Z9 11
U1 4
U2 5
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1552
EP 1561
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300157
DA 2019-06-15
ER

PT B
AU Ritter, A
   Mausam
   Etzioni, O
AF Ritter, Alan
   Mausam
   Etzioni, Oren
GP Assoc Computat Linguist
TI A Latent Dirichlet Allocation method for Selectional Preferences
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB The computation of selectional preferences, the admissible argument values for a relation, is a well-known NLP task with broad applicability. We present LDA-SP, which utilizes LinkLDA (Erosheva et al., 2004) to model selectional preferences. By simultaneously inferring latent topics and topic distributions over relations, LDA-SP combines the benefits of previous approaches: like traditional class-based approaches, it produces human-interpretable classes describing each relation's preferences, but it is competitive with non-class-based methods in predictive power.
   We compare LDA-SP to several state-of-the- art methods achieving an 85% increase in recall at 0.9 precision over mutual information (Erk, 2007). We also evaluate LDA-SP's effectiveness at filtering improper applications of inference rules, where we show substantial improvement over Pantel et al.' s system (Pantel et al., 2007).
C1 [Ritter, Alan; Mausam; Etzioni, Oren] Univ Washington, Dept Comp Sci & Engn, Box 352350, Seattle, WA 98195 USA.
RP Ritter, A (reprint author), Univ Washington, Dept Comp Sci & Engn, Box 352350, Seattle, WA 98195 USA.
EM aritter@cs.washington.edu; mausam@cs.washington.edu;
   etzioni@cs.washington.edu
CR Banko Michele, 2008, ACL 08 HLT
   Bergsma Shane, 2008, EMNLP
   Blei D. M., 2003, J MACH LEARN RES
   Brody Samuel, 2009, EACL, P103
   Carlson A., 2010, WSDM 2010
   Chen Harr, 2009, NAACL
   Clark Stephen, 2002, COMPUT LINGUIST
   Dagan Ido, 1999, MACHINE LEARNING
   Daume III H., 2007, HBC HIERARCHICAL BAY
   Daume III Hal, 2006, P 21 INT C COMP LING
   Erk Katrin, 2007, P 45 ANN M ASS COMP
   Erosheva Elena, 2004, P NATL ACAD SCI US
   Etzioni O., 2005, ARTIFICIAL INTELLIGE
   Gildea Daniel, 2002, COMPUT LINGUIST
   Griffiths Thomas L., 2004, P NATL ACAD SCI US
   Keller Frank, 2003, COMPUT LINGUIST
   Kozareva Zornitsa, 2008, ACL 08 HLT
   Li Hang, 1998, COMPUT LINGUIST
   Lin  D., 2001, KDD
   Lin D., 1998, P WORKSH EV PARS SYS
   Mei Qiaozhu, 2007, KDD
   Mimno D., 2009, EMNLP
   Mimno D., 2009, KDD
   Newman D., 2010, NAACL HLT
   Newman D., 2009, JMLR
   Pantel P., 2007, HLT NAACL
   Pantel P. A., 2003, THESIS
   Reisinger Joseph, 2009, P JOINT C 47 ANN M A
   Resnik P., 1996, COGNITION
   Resnik Philip, 1997, P ACL SIGLEX WORKSH
   Rooth M., 1999, P 37 ANN M ASS COMP
   Schubert L., 2003, P HLT NAACL 2003 WOR, P7
   Seaghdha Diarmuid O, 2010, P 48 ANN M ASS COMP
   Van Durme Benjamin, 2009, TR946 U ROCH DEP COM
   Yano Tae, 2009, NAACL
NR 35
TC 11
Z9 11
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 424
EP 434
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300044
DA 2019-06-15
ER

PT B
AU Talukdar, PP
   Pereira, F
AF Talukdar, Partha Pratim
   Pereira, Fernando
GP Assoc Computat Linguist
TI Experiments in Graph-based Semi-Supervised Learning Methods for
   Class-Instance Acquisition
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Graph-based semi-supervised learning (SSL) algorithms have been successfully used to extract class-instance pairs from large unstructured and structured text collections. However, a careful comparison of different graph-based SSL algorithms on that task has been lacking. We compare three graph-based SSL algorithms for class-instance acquisition on a variety of graphs constructed from different domains. We find that the recently proposed MAD algorithm is the most effective. We also show that class-instance extraction can be significantly improved by adding semantic information in the form of instance-attribute edges derived from an independently developed knowledge base. All of our code and data will be made publicly available to encourage reproducible research in this area.
C1 [Talukdar, Partha Pratim] Microsoft Res, Search Labs, Mountain View, CA 94043 USA.
   [Pereira, Fernando] Google Inc, Mountain View, CA 94043 USA.
   [Talukdar, Partha Pratim] Univ Penn, Philadelphia, PA 19104 USA.
RP Talukdar, PP (reprint author), Microsoft Res, Search Labs, Mountain View, CA 94043 USA.
EM partha@talukdar.net; pereira@google.com
CR Baluja S., 2008, P WWW 2008
   Banko M., 2007, P IJCAI
   Bellare K., 2007, NIPS 2007 WORKSH MAC
   Carlson A., 2010, P 3 ACM INT C WEB SE, V2, P110
   Etzioni O., 2005, ARTIFICIAL INTELLIGE
   Hearst M. A., 1992, 14 INT C COMP LING N
   Metaweb Technologies, 2009, FREEB DAT DUMPS
   Pantel P., 2009, P EMNLP 09 SING
   Pasca M., 2007, IJCAI 07
   Pennacchiotti M., 2009, P EMNLP 09 SING
   Probst K., 2007, IJCAI 07
   Rao D., 2009, TEXTGRAPHS
   Reisinger J., 2009, P 18 INT C WORLD WID, P1235
   Riloff E, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P474
   Suchanek F. M., 2007, P 16 INT C WORLD WID, P706
   Talukdar P. P., 2009, ECML PKDD
   Talukdar P. P., 2006, 10 C COMP NAT LANG L, P141
   Talukdar P. P., 2008, P 2008 C EMP METH NA, P581
   Van Durme B., 2008, 23 AAAI C ART INT
   Wang RC, 2007, IEEE DATA MINING, P342, DOI 10.1109/ICDM.2007.104
   ZHU X, 2003, ICML 03 20 INT C MAC
NR 21
TC 11
Z9 11
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1473
EP 1481
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300149
DA 2019-06-15
ER

PT B
AU Zhang, D
   Mei, QZ
   Zhai, CX
AF Zhang, Duo
   Mei, Qiaozhu
   Zhai, ChengXiang
GP Assoc Computat Linguist
TI Cross-Lingual Latent Topic Extraction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Probabilistic latent topic models have recently enjoyed much success in extracting and analyzing latent topics in text in an unsupervised way. One common deficiency of existing topic models, though, is that they would not work well for extracting cross-lingual latent topics simply because words in different languages generally do not co-occur with each other. In this paper, we propose a way to incorporate a bilingual dictionary into a probabilistic topic model so that we can apply topic models to extract shared latent topics in text data of different languages. Specifically, we propose a new topic model called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) which extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary. Both qualitative and quantitative experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data.
C1 [Zhang, Duo; Zhai, ChengXiang] Univ Illinois, Champaign, IL 61801 USA.
   [Mei, Qiaozhu] Univ Michigan, Ann Arbor, MI 48109 USA.
RP Zhang, D (reprint author), Univ Illinois, Champaign, IL 61801 USA.
EM dzhang22@cs.uiuc.edu; qmei@umich.edu; czhai@cs.uiuc.edu
CR Blei D., 2003, NEURAL INFORM PROCES
   Blei D., 2006, ICML, V23, P113, DOI DOI 10.1145/1143844.1143859
   Blei David, 2005, NIPS 05 ADV NEURAL I, V18
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boyd-Graber J., 2009, UNCERTAINTY ARTIFICI
   Branavan S. R. K., 2008, P ACL 2008
   Franz M., 1998, TEXT RETRIEVAL C, P104
   FUNG P, 1995, P 33 ANN M ASS COMP, P236
   Gliozzo A, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P553
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   Hofmann T., 1999, IJCAI, V99, P682
   Jagaralamudi Jagadeesh, 2010, P EUR C INF RETR ECI
   Kim W., 2004, ACM T ASIAN LANGUAGE, P94
   Li W., 2006, ICML 06, P577
   Masuichi H., 2000, P 18 COLING, P1066
   Mei Q., 2006, P 12 ACM SIGKDD INT, P649
   Mei Q, 2008, SIGIR, P611
   Mei Q., 2008, WWW, P101, DOI DOI 10.1145/1367497.1367512
   MEI Q, 2007, P WWW 07
   Mimno D, 2009, P 2009 C EMP METH NA, P880
   Ni X., 2009, WWW 2009 APR, P1155
   Sadat F., 2003, ACL 03, P141
   Steyvers M., 2004, P 10 ACM SIGKDD INT, P306, DOI [10.1145/1014052.1014087, DOI 10.1145/1014052.1014087]
   Wang XH, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P784
   Zhao Bing, 2006, P 44 ANN M ASS COMP
NR 26
TC 11
Z9 11
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1128
EP 1137
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300115
DA 2019-06-15
ER

PT B
AU Blunsom, P
   Cohn, T
AF Blunsom, Phil
   Cohn, Trevor
GP COLING
TI Discriminative Word Alignment with Conditional Random Fields
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper we present a novel approach for inducing word alignments from sentence aligned data. We use a Conditional Random Field (CRF), a discriminative model, which is estimated on a small supervised training set. The CRF is conditioned on both the source and target texts, and thus allows for the use of arbitrary and overlapping features over these data. Moreover, the CRF has efficient training and decoding processes which both find globally optimal solutions.
   We apply this alignment model to both French-English and Romanian-English language pairs. We show how a large number of highly predictive features can be easily incorporated into the CRF, and demonstrate that even with only a few hundred word-aligned training sentences, our model improves over the current state-of-the-art with alignment error rates of 5.29 and 25.8 for the two tasks respectively.
C1 [Blunsom, Phil; Cohn, Trevor] Univ Melbourne, Dept Software Engn & Comp Sci, Melbourne, Vic 3010, Australia.
RP Blunsom, P (reprint author), Univ Melbourne, Dept Software Engn & Comp Sci, Melbourne, Vic 3010, Australia.
EM pcbl@csse.unimelb.edu.au; tacohn@csse.unimelb.edu.au
RI Cohn, Trevor/E-8053-2014
OI Cohn, Trevor/0000-0003-4363-1673
CR Brown P. F., 1993, Computational Linguistics, V19, P263
   CALLISONBURCH C, 2004, P 42 ANN M ASS COMP, P175
   Chen LS, 1999, J CHILD ADOLES SUBST, V8, P37, DOI 10.1300/J029v08n04_03
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   ITTYCHERIAH A, 2005, P HLT EMNLP, P89
   Koehn P., 2003, P HLT NAACL EDM ALB, P81
   Lafferty J. D., 2001, P 18 INT C MACH LEAR, P282
   Liu Y, 2005, P 43 ANN M ASS COMP, P459
   Malouf R., 2002, P 6 C NAT LANG LEARN, P49, DOI DOI 10.3115/1118853.1118871
   MARTIN J, 2005, P ACL WORKSH BUILD U, P65
   Mihalcea Rada, 2003, P HLT NAACL 2003 WOR, P1
   Moore R. C., 2005, P C HUM LANG TECHN E, P81, DOI DOI 10.3115/1220575.1220586
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   SHA F, 2003, P HLT NAACL, P213
   TASKAR B, 2005, P HUM LANG TECHN C C, P73
   Toutanova K, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P87
   Vogel S., 1996, P 16 INT C COMP LING, P836
NR 18
TC 11
Z9 11
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 65
EP 72
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200009
DA 2019-06-15
ER

PT B
AU Li, WJ
   Wu, ML
   Lu, Q
   Xu, W
   Yuan, CF
AF Li, Wenjie
   Wu, Mingli
   Lu, Qin
   Xu, Wei
   Yuan, Chunfa
GP COLING
TI Extractive Summarization using Inter- and Intra- Event Relevance
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Event-based summarization attempts to select and organize the sentences in a summary with respect to the events or the sub-events that the sentences describe. Each event has its own internal structure, and meanwhile often relates to other events semantically, temporally, spatially, causally or conditionally. In this paper, we define an event as one or more event terms along with the named entities associated, and present a novel approach to derive intra- and inter- event relevance using the information of internal association, semantic relatedness, distributional similarity and named entity clustering. We then apply PageRank ranking algorithm to estimate the significance of an event for inclusion in a summary from the event relevance derived. Experiments on the DUC 2001 test data shows that the relevance of the named entities involved in events achieves better result when their relevance is derived from the event terms they associate. It also reveals that the topic-specific relevance from documents themselves outperforms the semantic relevance from a general purpose knowledge base like Word-Net.
C1 [Li, Wenjie; Wu, Mingli; Lu, Qin] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
RP Li, WJ (reprint author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
EM cswjli@comp.polyu.edu.hk; csmlwu@comp.polyu.edu.hk;
   csluqin@comp.polyu.edu.hk; vivian00@mail.tsinghua.edu.cn;
   cfyuan@mail.tsinghua.edu.cn
OI Lu, Qin/0000-0002-9092-2476; Li, Wenjie/0000-0002-7360-8864
CR BARZILAY R, 2005, P 43 ANN M ASS COMP, P141
   DANIEL N, 2003, P HLT NAACL WORKSH T, P9
   Erkan G., 2004, J ARTIFICIAL INTELLI
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Filatova E., 2004, P ACL WORKSH SUMM, P104
   Lawrence P., 1998, PAGERANK CITATION RA
   LESKOVEC J, 2004, LINKKDD 2004
   LIN CY, 2003, P 2003 C N AM CHAPT, P71
   Mihalcea R., 2005, LANGUAGE INDEPENDENT
   PEDERSEN T, 2004, P AAAI, P25
   VANDERWENDE L, 2004, WORKING NOTES DUC 20
   XU W, 2006, P CICLING 06, P480
   YOSHIOKA M, 2004, WORKING NOTES NTCIR, V4
NR 13
TC 11
Z9 11
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 369
EP 376
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200047
DA 2019-06-15
ER

PT B
AU Paek, T
   Horvitz, E
AF Paek, T
   Horvitz, E
GP acl
TI Optimizing automated call routing by integrating spoken dialog models
   with queuing models
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB Organizations are increasingly turning to spoken dialog systems for automated call routing to reduce call center costs. To maintain quality service even in cases of failure, these systems often resort to ad-hoc rules for dispatching calls to a human operator. We present a principled procedure for determining when callers should be transferred to operators based on a cost-benefit analysis. The procedure integrates models that predict when a call is likely to fail using spoken dialog features with queuing models of call center volume and service time. We evaluate how the procedure would have performed on cases drawn from logs of interactions with a legacy spoken dialog system.
C1 Microsoft Corp, Redmond, WA 98052 USA.
RP Paek, T (reprint author), Microsoft Corp, 1 Microsoft Way, Redmond, WA 98052 USA.
CR ASHLEY D, 2002, INFORMS TRANSACTIONS, V2
   Chickering D.M., 2002, MSRTR2002103
   CHICKERING DM, 1997, UAI, P80
   Gross D., 1998, FUNDAMENTALS QUEUING
   HORVITZ E, 2003, 200377 MRS
   LANGKILDE I, 1999, P IEEE WORKSH AUT SP
   LITMAN D, 1999, ACL 99, P309
   Litman DJ, 2002, USER MODEL USER-ADAP, V12, P111, DOI 10.1023/A:1015036910358
   SUHM B, 2002, TOCHI
   TATCHELL G, 1996, CHI 96
   WALKER M, 2000, NAACL 2000, P210
   Walker M. A., 2002, J ARTIFICIAL INTELLI
NR 12
TC 11
Z9 11
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 41
EP 48
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100006
DA 2019-06-15
ER

PT B
AU Regneri, M
   Koller, A
   Pinkal, M
AF Regneri, Michaela
   Koller, Alexander
   Pinkal, Manfred
GP Assoc Computat Linguist
TI Learning Script Knowledge with Web Experiments
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We describe a novel approach to unsupervised learning of the events that make up a script, along with constraints on their temporal ordering. We collect natural-language descriptions of script-specific event sequences from volunteers over the Internet. Then we compute a graph representation of the script's temporal structure using a multiple sequence alignment algorithm. The evaluation of our system shows that we outperform two informed baselines.
C1 [Regneri, Michaela; Koller, Alexander; Pinkal, Manfred] Univ Saarland, Dept Computat Linguist & Cluster Excellence, Saarbrucken, Germany.
RP Regneri, M (reprint author), Univ Saarland, Dept Computat Linguist & Cluster Excellence, Saarbrucken, Germany.
EM regneri@coli.uni-saarland.de; koller@coli.uni-saarland.de;
   pinkal@coli.uni-saarland.de
CR Baker C., 1998, P 17 INT C COMP LING, V1, P86, DOI DOI 10.3115/980845.980860
   BARR A, 1981, HDB ARTIFICIAL INTEL, V1
   Barzilay Regina, 2003, P HLT NAACL 2003
   Chamberlain Jon, 2009, KDD WORKSH HUM COMP
   Chambers Nathanael, 2008, P EMNLP 2008
   Chambers Nathanael, 2009, P ACL IJCNLP 2009
   Chambers Nathanael, 2007, P ACL 07 INT DEM SES
   Chambers Nathanael, 2008, P ACL 08 HLT
   Cullingford Richard Edward, 1977, THESIS
   Durbin R., 1998, BIOL SEQUENCE ANAL
   EDGINGTON ES, 1986, RANDOMIZATION TESTS
   Flake G., 2004, INTERNET MATH, V1
   Gordon Andrew S., 2001, JASIST, V52
   HIGGINS DG, 1988, GENE, V73, P237, DOI 10.1016/0378-1119(88)90330-7
   Jones Dominic R., 2003, P CONNL 2003
   Mani Inderjeet, 2006, COLING ACL 2006
   Manshadi Mehdi, 2008, P 21 FLAIRS C
   Mctear M, 1987, ARTICULATE COMPUTER
   Miikkulainen Risto, 1995, APPL INTELL, V5
   MOONEY RJ, 1990, COGNITIVE SCI, V14, P483, DOI 10.1207/s15516709cog1404_1
   Mueller E.T., 1998, NATURAL LANGUAGE PRO
   Mueller Erik T., 2004, COGNITIVE SYSTEMS RE, V5
   Needleman Saul B., 1970, J MOL BIOL, V48
   RAU LF, 1989, INFORM PROCESS MANAG, V25, P419, DOI 10.1016/0306-4573(89)90069-1
   Schank R. C., 1977, SCRIPTS PLANS GOALS
   Singh P., 2002, MOVE MEANINGFUL INTE
   Smith Dustin, 2009, P COMM WORKSH IUI 09
   Snow R., 2008, P EMNLP 2008
   Swanson Reid, 2008, P ICIDS 2008
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
NR 30
TC 10
Z9 10
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 979
EP 988
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300100
DA 2019-06-15
ER

PT B
AU Shutova, E
AF Shutova, Ekaterina
GP Assoc Computat Linguist
TI Models of Metaphor in NLP
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID LANGUAGE
AB Automatic processing of metaphor can be clearly divided into two subtasks: metaphor recognition (distinguishing between literal and metaphorical language in a text) and metaphor interpretation (identifying the intended literal meaning of a metaphorical expression). Both of them have been repeatedly addressed in NLP. This paper is the first comprehensive and systematic review of the existing computational models of metaphor, the issues of metaphor annotation in corpora and the available resources.
C1 [Shutova, Ekaterina] Univ Cambridge, Comp Lab, 15 JJ Thomson Ave, Cambridge CB3 0FD, England.
RP Shutova, E (reprint author), Univ Cambridge, Comp Lab, 15 JJ Thomson Ave, Cambridge CB3 0FD, England.
EM Ekaterina.Shutova@cl.cam.ac.uk
CR Alonge Antonietta, 2003, P ACL 2003 WORKSH LE, P10
   Barnden J., 2002, THEORIA HIST SCI, V6, P399, DOI 10.12775/ths.2002.017
   Barnden John, 2007, P RANLP 2007 BOR, P17
   Birke J., 2006, P 11 C EUR CHAPT ASS, V6, P329
   Black Max, 1962, MODELS METAPHORS
   Burnard Lou., 2007, REFERENCE GUIDE BRIT
   Copestake A., 1995, J SEMANT, V12, P15, DOI DOI 10.1093/J0S/12.1.15
   Deignan A, 2006, TRENDS LINGUIST-STUD, V171, P106
   Eilts Carina, 2004, P 2 INT WORDN C GWC, P157
   Espenson Jane, 1991, TECHNICAL REPORT
   Fass D., 1991, Computational Linguistics, V17, P49
   Feldman J, 2004, BRAIN LANG, V89, P385, DOI 10.1016/S0093-934X(03)00355-9
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Fillmore CJ, 2003, INT J LEXICOGR, V16, P235, DOI 10.1093/ijl/16.3.235
   Gedigian Matt, 2006, P 3 WORKSH SCAL NAT, P41, DOI DOI 10.3115/1621459.1621467
   GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1016/S0364-0213(83)80009-3
   GIBBS RW, 1984, COGNITIVE SCI, V8, P275, DOI 10.1207/s15516709cog0803_4
   Goatly Andrew, 1997, LANGUAGE METAPHORS
   Group Pragglejaz, 2007, METAPHOR SYMBOL, V22, P1
   Hesse Mary, 1966, MODELS ANALOGIES SCI
   Hofstadter D. R., 1995, FLUID CONCEPTS CREAT
   Hofstadter Douglas, 1994, ADV CONNECTIONIST NE
   Karov Y, 1998, COMPUT LINGUIST, V24, P41
   Kingsbury P., 2002, P LREC 2002 GRAN CAN
   Koivisto-Alanko P, 2006, TRENDS LINGUIST-STUD, V171, P191
   Krishnakumaran Saisuresh, 2007, P WORKSH COMP APPR F, P13
   Lakoff G., 1980, METAPHORS WE LIVE BY
   Lonneker-Rodman B, 2008, LANG RESOUR EVAL, V42, P293, DOI 10.1007/s10579-008-9073-9
   Lonneker Birte, 2004, P LREC 2004 WORKSH L, P9
   Martin J., 1990, COMPUTATIONAL MODEL
   Martin J. H., 1994, Computational Intelligence, V10, P134, DOI 10.1111/j.1467-8640.1994.tb00161.x
   Martin James, 1988, P 12 C COMP LING, P396
   Martin JH, 2006, TRENDS LINGUIST-STUD, V171, P214
   Mason ZJ, 2004, COMPUT LINGUIST, V30, P23, DOI 10.1162/089120104773633376
   Narayanan S, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P121
   Narayanan S., 1997, THESIS
   Nunberg Geoffrey, 1987, P 1987 WORKSH THEOR, P198
   Orwell G, 1946, HORIZON
   Peters Wim, 2000, P LREC 2000 ATH
   Reining Astrid, 2007, P HLT NAACL 07 WORKS, P5
   Resnik P., 1993, THESIS
   Shutova E., 2010, P NAACL 2010 LOS ANG
   Shutova E., 2010, P LREC 2010 MALT
   Steen Gerard, 2007, LANGUAGE CULTURE REP, V5, P9
   Stefanowitsch A, 2006, TRENDS LINGUIST-STUD, V171, P1, DOI 10.1515/9783110199895
   SUN L, 2009, P 2009 C EMP METH NA, P638
   TOURANGEAU R, 1982, COGNITION, V11, P203, DOI 10.1016/0010-0277(82)90016-6
   Veale T., 2008, P COLING 2008 MANCH, V1, P945
   Wallington A. M., 2003, TECHNICAL REPORT
   WILKS Y, 1978, ARTIF INTELL, V11, P197, DOI 10.1016/0004-3702(78)90001-2
   WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8
NR 51
TC 10
Z9 10
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 688
EP 697
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300071
DA 2019-06-15
ER

PT B
AU Wan, XJ
   Li, HY
   Xiao, JG
AF Wan, Xiaojun
   Li, Huiying
   Xiao, Jianguo
GP Assoc Computat Linguist
TI Cross-Language Document Summarization Based on Machine Translation
   Quality Prediction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Cross-language document summarization is a task of producing a summary in one language for a document set in a different language. Existing methods simply use machine translation for document translation or summary translation. However, current machine translation services are far from satisfactory, which results in that the quality of the cross-language summary is usually very poor, both in readability and content. In this paper, we propose to consider the translation quality of each sentence in the English-to-Chinese cross-language summarization process. First, the translation quality of each English sentence in the document set is predicted with the SVM regression method, and then the quality score of each sentence is incorporated into the summarization process. Finally, the English sentences with high translation quality and high informativeness are selected and translated to form the Chinese summary. Experimental results demonstrate the effectiveness and usefulness of the proposed approach.
C1 [Wan, Xiaojun] Peking Univ, Inst Compute Sci & Technol, Beijing 100871, Peoples R China.
   Peking Univ, MOE, Key Lab Computat Linguist, Beijing, Peoples R China.
RP Wan, XJ (reprint author), Peking Univ, Inst Compute Sci & Technol, Beijing 100871, Peoples R China.
EM wanxiaojun@icst.pku.edu.cn; lihuiying@icst.pku.edu.cn;
   xiaojianguo@icst.pku.edu.cn
CR Albrecht J., 2007, P ACL2007
   Amini M. R., 2002, P SIGIR2002
   Blatz J, 2003, CONFIDENCE ESTIMATIO
   Chae J., 2009, P EACL2009
   Chang Chih-Chung, 2001, LIBSVM LIB SUPPORT V
   de Chalendar G., 2005, WORKSH CROSS BARR TE
   ErKan G., 2004, P EMNLP2004
   Gamon M., 2005, P EAMT2005
   Klein D., 2002, P NIPS2002
   Kupiec J., 1995, P SIGIR1995
   Leuski Anton, 2003, ACM T ASIAN LANGUAGE, V2, P245
   Lim J.-M., 2004, P NTCIR 4
   Lin C.-Y., 2002, P ACL 02
   Lin C.-Y., 2003, P HLT NAACL 03
   Lin C.-Y., 2005, P MSE ACL 2005 WORKS
   LIN CY, 2000, P 17 C COMP LING
   Luhn H. P., 1969, IBM J RES DEV, V2
   Mihalcea R., 2005, P IJCNLP 05
   Mihalcea R., 2004, P EMNLP2004
   Nenkova A., 2008, P ACL 08 HLT
   Nenkova A, 2007, ACM T SPEECH LANGUAG, V4, P4, DOI [DOI 10.1145/1233912.1233913, 10.1145/1233912.1233913]
   Orasan C., 2008, P 6 LANG RES EV C LR
   Pingali P, 2007, WORKSH CROSS LING IN
   Quirk C., 2004, P LREC2004
   Radev DR, 2004, INFORM PROCESS MANAG, V40, P919, DOI 10.1016/j.ipm.2003.10.006
   Siddharthan A., 2005, P HLT EMNLP 2005
   Specia L., 2009, MT SUMMIT 2009 MACHI
   Vapnik VN, 1995, NATURE STAT LEARNING
   Wan X., 2008, P SIGIR 08
   Wan X., 2007, P ACL2007
   Wan X., 2006, P WI2006
   Wan X., 2010, P SIGIR2010
   Wong K.-F., 2008, P COLING 08
   Zha H. Y., 2002, P SIGIR2002
NR 34
TC 10
Z9 10
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 917
EP 926
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300094
DA 2019-06-15
ER

PT B
AU Wu, S
   Bachrach, A
   Cardenas, C
   Schuler, W
AF Wu, Stephen
   Bachrach, Asaf
   Cardenas, Carlos
   Schuler, William
GP Assoc Computat Linguist
TI Complexity Metrics in an Incremental Right-corner Parser
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID COMPREHENSION; MODEL; MEMORY; COSTS
AB Hierarchical HMM (HHMM) parsers make promising cognitive models: while they use a bounded model of working memory and pursue incremental hypotheses in parallel, they still achieve parsing accuracies competitive with chart-based techniques. This paper aims to validate that a right-corner HHMM parser is also able to produce complexity metrics, which quantify a reader's incremental difficulty in understanding a sentence. Besides defining standard metrics in the HHMM framework, a new metric, embedding difference, is also proposed, which tests the hypothesis that HHMM store elements represents syntactic working memory. Results show that HHMM surprisal outperforms all other evaluated metrics in predicting reading times, and that embedding difference makes a significant, independent contribution.
C1 [Wu, Stephen] Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.
   [Bachrach, Asaf] CEA, INSERM, Unit Neuroimagerie Cognit, Rome, Italy.
   [Cardenas, Carlos] MIT, Dept Brain & Cognit Sci, Cambridge, MA 02139 USA.
   [Schuler, William] Univ Minnesota, Minneapolis, MN 55455 USA.
   [Schuler, William] Ohio State Univ, Columbus, OH 43210 USA.
RP Wu, S (reprint author), Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.
EM swu@cs.umn.edu; asaf@mit.edu; cardenas@mit.edu;
   schuler@ling.ohio-state.edu
CR ABNEY SP, 1991, J PSYCHOLINGUIST RES, V20, P233, DOI 10.1007/BF01067217
   Bachrach Asaf, 2009, INCREMENTAL PREDICTI
   Bates D, 2008, LME4 LINEAR MIXED EF
   Boston M. F., 2008, P 46 ANN M ASS COMP, P5
   Boston MF, 2008, J EYE MOVEMENT RES, V2
   Brants T., 2000, P 18 INT C COMP LING, P111
   Chen E, 2005, J MEM LANG, V52, P144, DOI 10.1016/j.jml.2004.10.001
   Chomsky Noam, 1963, HDB MATH PSYCHOL, V2, P269, DOI DOI 10.1016/S0010-0277(98)00034-1
   Cowan N, 2001, BEHAV BRAIN SCI, V24, P87, DOI 10.1017/S0140525X01003922
   Crocker MW, 2000, J PSYCHOLINGUIST RES, V29, P647, DOI 10.1023/A:1026560822390
   Dahan D, 2007, J MEM LANG, V57, P483, DOI 10.1016/j.jm1.2007.01.001
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008
   Engbert R, 2005, PSYCHOL REV, V112, P777, DOI 10.1037/0033-295X.112.4.777
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   Frank S., 2009, P 31 ANN C COGN SCI, P1139
   Gibson E, 2000, IMAGE, LANGUAGE, BRAIN, P95
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159
   Hale J., 2003, THESIS
   Hale J, 2006, COGNITIVE SCI, V30, P643, DOI 10.1207/s15516709cog0000_64
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   McDonald SA, 2003, VISION RES, V43, P1735, DOI 10.1016/S0042-6989(03)00237-2
   Miller George A., 1963, HDB MATH PSYCHOL, P419
   Murphy KP, 2001, P NIPS, V14, P833
   Nivre Joakim, 2007, COMPUTATIONAL LINGUI, V33
   Pollatsek A, 2006, COGNITIVE PSYCHOL, V52, P1, DOI 10.1016/j.cogpsych.2005.06.001
   Rabiner L. R., 1990, READINGS SPEECH RECO, P267, DOI DOI 10.1109/5.18626
   Roark B, 2001, COMPUT LINGUIST, V27, P249, DOI 10.1162/089120101750300526
   Roark B., 2009, P 2009 C EMP METH NA, P324, DOI DOI 10.3115/1699510.1699553
   Schuler William, 2010, COMPUTATIONAL LINGUI, V36
   Schuler William, 2008, P COLING MANCH UK, P785
   Schuler William, 2009, P N AM ASS COMP LING, P344
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
NR 33
TC 10
Z9 10
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1189
EP 1198
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300121
DA 2019-06-15
ER

PT B
AU Chan, YS
   Ng, HT
AF Chan, Yee Seng
   Ng, Hwee Tou
GP COLING
TI Estimating Class Priors in Domain Adaptation for Word Sense
   Disambiguation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Instances of a word drawn from different domains may have different sense priors (the proportions of the different senses of a word). This in turn affects the accuracy of word sense disambiguation (WSD) systems trained and applied on different domains. This paper presents a method to estimate the sense priors of words drawn from a new domain, and highlights the importance of using well calibrated probabilities when performing these estimations. By using well calibrated probabilities, we are able to estimate the sense priors effectively to achieve significant improvements in WSD accuracy.
C1 [Chan, Yee Seng; Ng, Hwee Tou] Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore.
RP Chan, YS (reprint author), Natl Univ Singapore, Dept Comp Sci, 3 Sci Dr 2, Singapore 117543, Singapore.
EM chanys@comp.nus.edu.sg; nght@comp.nus.edu.sg
CR AGIRRE E, 2004, P EMNLP04
   Ayer M., 1955, ANN MATH STAT, V26
   CHAN YS, 2005, P IJCA105
   CHAN YS, 2005, P AAA105
   DOMINGOS P, 1996, P ICML 1996
   ESCUDERO G, 2000, P EMNLP VLC00
   KILGARRIFF A, 2001, P SENSEVAL 2
   LEE YK, 2002, P EMNLP02
   MCCARTHY D, 2004, P ACL04
   Mihalcea Rada, 2004, P SENSEVAL 3
   Miller G.A., 1994, P ARPA HUM LANG TECH
   NG AY, 2001, P NIPS14
   NG HT, 1996, P ACL96
   NG HT, 2003, P ACL03
   NICULESCUMIZIL A, 2005, P ICML05
   Robertson T, 1988, ORDER RESTRICTED STA
   SAERENS M, 2002, NEURAL COMPUTATION, V14
   VUCETIC S, 2001, P ECML01
   ZADROZNY B, 2002, P KDD02
   ZHANG J, 2004, P ICML04
NR 20
TC 10
Z9 10
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 89
EP 96
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200012
DA 2019-06-15
ER

PT B
AU Ishioka, T
   Kameda, M
AF Ishioka, Tsunenori
   Kameda, Masayuki
GP COLING
TI Automated Japanese Essay Scoring System based on Articles Written by
   Experts
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We have developed an automated Japanese essay scoring system called Jess. The system needs expert writings rather than expert raters to build the evaluation model. By detecting statistical outliers of predetermined aimed essay features compared with many professional writings for each prompt, our system can evaluate essays. The following three features are examined: (1) rhetoric - syntactic variety, or the use of various structures in the arrangement of phases, clauses, and sentences, (2) organization - characteristics associated with the orderly presentation of ideas, such as rhetorical features and linguistic cues, and (3) content - vocabulary related to the topic, such as relevant information and precise or specialized vocabulary. The final evaluation score is calculated by deducting from a perfect score assigned by a learning process using editorials and columns from the Mainichi Daily News newspaper. A diagnosis for the essay is also given.
C1 [Ishioka, Tsunenori] Natl Ctr Univ Entrance Examinat, Div Res, Tokyo 1538501, Japan.
RP Ishioka, T (reprint author), Natl Ctr Univ Entrance Examinat, Div Res, Tokyo 1538501, Japan.
EM tunenori@rd.dnc.ac.jp; masayuki.kameda@nts.ricoh.co.jp
CR Bennett R., 1997, ED MEASUREMENT ISSUE, V1997, P1, DOI [10.1111/j.1745-3992.1998.tb00631.x, DOI 10.1111/J.1745-3992.1998.TB00631.X]
   Bereiter C., 2003, AUTOMATED ESSAY SCOR
   BERRY MW, 1992, INT J SUPERCOMPUT AP, V6, P13, DOI 10.1177/109434209200600103
   Burstein J., 1998, ANN M ASS COMP LING
   Chase C. I., 1979, J EDUC MEAS, V16, P293
   CHASE CI, 1986, J EDUC MEAS, V23, P33, DOI 10.1111/j.1745-3984.1986.tb00232.x
   Cooper P. L., 1984, 8215R GREB
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DUFF IS, 1989, ACM T MATH SOFTWARE, V15, P1, DOI 10.1145/62038.62043
   Elliot S, 2003, AUTOMATED ESSAY SCORING: A CROSS-DISCIPLINARY PERSPECTIVE, P71
   Foltz P. W., 1999, AUTOMATED ESSAY SCOR
   HUGHES DC, 1983, EDUC PSYCHOL MEAS, V43, P1047, DOI 10.1177/001316448304300413
   ISHIOKA T, 1999, JAPANESE J APPL STAT, V28, P107
   Jelinek F., 1991, EUROSPEECH 91. 2nd European Conference on Speech Communication and Technology Proceedings, P1037
   KNUTH DE, 1988, STANCS881193 STANF U
   MAEKAWA M, 1995, SCI ANAL WRITING
   MARSHALL JC, 1969, J EDUC MEAS, V6, P97, DOI 10.1111/j.1745-3984.1969.tb00665.x
   Meyer G, 1939, J EDUC PSYCHOL, V30, P161, DOI 10.1037/h0063367
   NAGAO M, 1996, IWANAMI SOFTWARE SCI, V15
   Noya S., 1997, LOGICAL TRAINING
   PAGE EB, 1997, AERA NCME S GRAD ESS
   POWERS DE, 2000, 9808A GRE ED TEST SE
   Quirk R., 1985, COMPREHENSIVE GRAMMA
   RUDNER LM, 2002, NATL COUNC MEASUREME
   Tweedie FJ, 1998, COMPUT HUMANITIES, V32, P323, DOI 10.1023/A:1001749303137
   WATANABE H, 1988, RES B U TOKYO FACULT, V28, P143
   Yule G. I, 1944, STAT STUDY LIT VOCAB
NR 27
TC 10
Z9 10
U1 1
U2 3
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 233
EP 240
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200030
DA 2019-06-15
ER

PT B
AU Seretan, V
   Wehrli, E
AF Seretan, Violeta
   Wehrli, Eric
GP COLING
TI Accurate Collocation Extraction Using a Multilingual Parser
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper focuses on the use of advanced techniques of text analysis as support for collocation extraction. A hybrid system is presented that combines statistical methods and multilingual parsing for detecting accurate collocational information from English, French, Spanish and Italian corpora. The advantage of relying on full parsing over using a traditional window method (which ignores the syntactic information) is first theoretically motivated, then empirically validated by a comparative evaluation experiment.
C1 [Seretan, Violeta; Wehrli, Eric] Univ Geneva, Language Technol Lab, CH-1211 Geneva, Switzerland.
RP Seretan, V (reprint author), Univ Geneva, Language Technol Lab, 2 Rue Candolle, CH-1211 Geneva, Switzerland.
EM Violeta.Seretan@latl.unige.ch; Eric.Wehrli@latl.unige.ch
RI Seretan, Violeta/C-1272-2016
OI Seretan, Violeta/0000-0002-9199-9467
CR Benson M., 1990, INT J LEXICOGR, V3.1, P23, DOI DOI 10.1093/IJL/3.1.23
   BREIDT E, 1993, P WORKSH VER LARG CO
   CHOUEKA Y, 1988, P INT C US OR CONT B, P609
   COWIE AP, 1978, HONOUR AS HORNBY, P127
   Cruse D. Alan, 1986, LEXICAL SEMANTICS
   Dias G, 2003, P ACL WORKSH MULT EX, P41, DOI [10.3115/1119282.1119288, DOI 10.3115/1119282.1119288]
   Dunning T., 1993, Computational Linguistics, V19, P61
   Evert S., 2003, P 10 C EUR CHAPT ASS, P83
   Evert Stefan, 2004, THESIS U STUTTGART
   Firth John Rupert, 1957, PAPERS LINGUISTICS 1
   FRANK AL, 1993, J ENDODONT, V19, P177, DOI 10.1016/S0099-2399(06)80683-7
   Jackendoff Ray, 1997, ARCHITECTURE LANGUAG
   Justeson J. S., 1995, NAT LANG ENG, V1, P9, DOI DOI 10.1017/S1351324900000048
   Krenn Brigitte, 2001, P ACL WORKSH COLL TO, P39
   LIN D, 1998, 1 WORKSH COMP TERM, P57
   Manning C.D., 1999, FDN STAT NATURAL LAN
   McKeown Kathleen R., 2000, HDB NATURAL LANGUAGE, P507
   Melcuk I, 1998, PHRASEOLOGY THEORY A, P23
   Orliac B., 2003, P MACH TRANSL SUMM 9, P292
   PEARCE D, 2001, WORDNET OTHER LEXICA, P41
   Pecina P, 2005, P ACL STUD RES WORKS, P13
   SAG IA, 2002, P 3 INT C INT TEXT P, P1
   SERETAN V, 2006, P COLING AC IN PRESS
   Seretan  V., 2003, P 4 INT C REC ADV NL, P424
   Wehrli Eric, 2004, STRUCTURES DISCOURS, P311
NR 25
TC 10
Z9 10
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 953
EP 960
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200120
DA 2019-06-15
ER

PT B
AU Shinzato, K
   Torisawa, K
AF Shinzato, K
   Torisawa, K
GP acl
TI Acquiring hyponymy relations from web documents
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB This paper describes an automatic method for acquiring hyponymy relations from HTML documents on the WWW. Hyponymy relations can play a crucial role in various natural language processing systems. Most existing acquisition methods for hyponymy relations rely on particular linguistic patterns, such as "NP such as NP". Our method, however, does not use such linguistic patterns, and we expect that our procedure can be applied to a wide range of expressions for which existing methods cannot be used. Our acquisition algorithm uses clues such as itemization or listing in HTML documents and statistical measures such as document frequencies and verb-noun co-occurrences.
C1 Japan Adv Inst Sci & Technol, Sch Informat Sci, Ishikawa 9231292, Japan.
RP Shinzato, K (reprint author), Japan Adv Inst Sci & Technol, Sch Informat Sci, 1-1 Asahidai, Ishikawa 9231292, Japan.
CR ANDO M, 2003, 2003NL157 IPSJ SIG, P77
   Caraballo S, 1999, P 37 ANN M ASS COMP, P120
   Fleischman Michael, 2003, P 41 ANN M ASS COMP, P1
   Hearst M.A., 1992, P 14 INT C COMP LING, P539, DOI DOI 10.3115/992133.992154
   IMASUMI K, 2001, THESIS KYUSHU I TECH
   Kanayama H., 2000, P COLING 2000, P411
   MATSUMOTO Y, 1993, JAPANESE MORPHOLOGIC
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   MORIN E, 2003, IN PRESS COMPUTER HU
NR 9
TC 10
Z9 10
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 73
EP 80
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100010
DA 2019-06-15
ER

PT B
AU Kudo, T
   Matsumoto, Y
AF Kudo, T
   Matsumoto, Y
GP ACL
TI Fast methods for Kernel-based text analysis
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Kernel-based learning (e.g., Support Vector Machines) has been successfully applied to many hard problems in Natural Language Processing (NLP). In NLP, although feature combinations are crucial to improving performance, they are heuristically selected. Kernel methods change this situation. The merit of the kernel methods is that effective feature combination is implicitly expanded without loss of generality and increasing the computational costs. Kernel-based text analysis shows an excellent performance in terms in accuracy; however, these methods are usually too slow to apply to large-scale text analysis. In this paper, we extend a Basket Mining algorithm to convert a kernel-based classifier into a simple and fast linear classifier. Experimental results on English BaseNP Chunking, Japanese Word Segmentation and Japanese Dependency Parsing show that our new classifiers are about 30 to 300 times faster than the standard kernel-based classifiers.
C1 Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Japan.
CR AOE J, 1989, IEEE T SOFTWARE ENG, V15
   COLLINS M, 2001, ADV NEURAL INFORMATI, V1, P625
   HUMA L, 2002, J MACHINE LEARNING R, P2
   ISOZAKI H, 2002, P COLING 2002, P390
   Jian Pei, 2001, Proceedings 17th International Conference on Data Engineering, P215, DOI 10.1109/ICDE.2001.914830
   KASHIMA H, 2002, P 19 INT C MACH LEAR, P291
   Kudo T, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P18
   KUDO T, 2001, P 2 M N AM CHAPT ASS, P192
   Kudo T., 2002, P 6 C NAT LANG LEARN, V2002, P63
   Kurohashi S., 1997, P 3 ANN M ASS NAT LA, P115
   LANCE A, 1995, P VLC, P88
   MOHAMMED Z, 2002, P 8 INT C KNOWL DISC, P71
   SADAO K, 1997, P ANLP 1997, P115
   TAKU K, 2002, P CONLL 2002, P63
   Taku K, 2001, P N AM CHAPT ASS COM, P192
   TETSUJI N, 2002, P ACL 2002, P497
   Vapnik VN, 1995, NATURE STAT LEARNING
NR 17
TC 10
Z9 10
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 24
EP 31
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500004
DA 2019-06-15
ER

PT B
AU Lapata, M
AF Lapata, M
GP ACL
TI Probabilistic text structuring: Experiments with sentence ordering
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Ordering information is a critical task for natural language generation applications. In this paper we propose an approach to information ordering that is particularly suited for text-to-text generation. We describe a model that learns constraints on sentence order from a corpus of domain-specific texts and an algorithm that yields the most likely order among several alternatives. We evaluate the automatically generated orderings against authored texts from our corpus and against human subjects that are asked to mimic the model's task. We also assess the appropriateness of such a model for multidocument summarization.
C1 Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England.
EM mlap@dcs.shef.ac.uk
CR Asher Nicholas, 2003, LOGICS CONVERSATION
   Barzilay R, 2002, J ARTIF INTELL RES, V17, P35, DOI 10.1613/jair.991
   BARZILAY R, 2003, THESIS COLUMBIA U
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   Cohen WW, 1999, J ARTIF INTELL RES, V10, P243, DOI 10.1613/jair.587
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   KIBBLE R, 2000, P 1 INT C NAT LANG G, P77
   Lafferty J., 2002, P 19 INT C MACH LEAR
   LIN DK, 1998, P LREC WORKSH EV PAR, P48
   MARCU D., 1997, P 14 NAT C ART INT P, P629
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   McKeown KR, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P453
   Mellish C., 1998, P 9 INT WORKSH NAT L, P98
   Reiter E., 2000, BUILDING NATURAL LAN
   SAMPSON G, 1996, ENGLISH COMPUTER
NR 16
TC 10
Z9 10
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 545
EP 552
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500069
DA 2019-06-15
ER

PT B
AU Chiang, D
AF Chiang, David
GP Assoc Computat Linguist
TI Learning to Translate with Source and Target Syntax
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Statistical translation models that try to capture the recursive structure of language have been widely adopted over the last few years. These models make use of varying amounts of information from linguistic theory: some use none at all, some use information about the grammar of the target language, some use information about the grammar of the source language. But progress has been slower on translation models that are able to learn the relationship between the grammars of both the source and target language. We discuss the reasons why this has been a challenge, review existing attempts to meet this challenge, and show how some old and new ideas can be combined into a simple approach that uses both source and target syntax for significant improvements in translation accuracy.
C1 [Chiang, David] USC Informat Sci Inst, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
RP Chiang, D (reprint author), USC Informat Sci Inst, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
EM chiang@isi.edu
CR Ambati Vamshi, 2008, P 8 C ASS MACH TRANS, P235
   Bar-Hillel Y, 1953, LANGUAGE, V29, P47, DOI 10.2307/410452
   CHEN SF, 1998, TR1098 HARV U CTR RE
   Chiang D, 2009, P HUM LANG TECHN 200, P218
   Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Collins M., 1997, P 35 ANN M ASS COMP, P16
   Crammer K, 2003, J MACH LEARN RES, V3, P951, DOI 10.1162/jmlr.2003.3.4-5.951
   EISNER J, 2003, P 41 ANN M ASS COMP, P205
   Fossum Victoria, 2008, P 3 WORKSH STAT MACH, P44
   FRASER A, 2007, P JOINT C EMP METH N, P51
   GALLEY M, 2004, P HUM LANG TECHN C N, P273
   Galley M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P961
   Hearne Mary, 2003, P MT SUMM 9, P165
   Huang Liang, 2006, P AMTA 2006, P65
   Lavie Alon, 2008, P 2 WORKSH SYNT STRU, P87
   Liu Y., 2009, P JOINT C 47 ANN M A, V2, P558
   Liu Y, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P609
   Melamed D, 2004, P 42 ANN M ASS COMP, P661
   Petrov S, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P433
   Poutsma A, 2000, P 18 INT C COMP LING, P635
   Talbot D., 2008, P ACL 08 HLT, P505
   Venugopal A, 2009, P HUM LANG TECHN 200, P236
   Weir D., 1988, THESIS
   Wellington B, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P977
   Zhang M, 2008, ACLHLT, V08, P559
   Zollmann A, 2006, P WORKSH STAT MACH T, P138
NR 27
TC 9
Z9 9
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1443
EP 1452
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300146
DA 2019-06-15
ER

PT B
AU Pitler, E
   Louis, A
   Nenkova, A
AF Pitler, Emily
   Louis, Annie
   Nenkova, Ani
GP Assoc Computat Linguist
TI Automatic Evaluation of Linguistic Quality in Multi-Document
   Summarization
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID LOCAL COHERENCE; TEXT
AB To date, few attempts have been made to develop and validate methods for automatic evaluation of linguistic quality in text summarization. We present the first systematic assessment of several diverse classes of metrics designed to capture various aspects of well-written text. We train and test linguistic quality models on consecutive years of NIST evaluation data in order to show the generality of results. For grammaticality, the best results come from a set of syntactic features. Focus, coherence and referential clarity are best evaluated by a class of features measuring local coherence on the basis of cosine similarity between sentences, coreference information, and summarization specific features. Our best results are 90% accuracy for pair-wise comparisons of competing systems over a test set of several inputs and 70% for ranking summaries of a specific input.
C1 [Pitler, Emily; Louis, Annie; Nenkova, Ani] Univ Penn, Comp & Informat Sci, Philadelphia, PA 19104 USA.
RP Pitler, E (reprint author), Univ Penn, Comp & Informat Sci, Philadelphia, PA 19104 USA.
EM epitler@seas.upenn.edu; lannie@seas.upenn.edu; nenkova@seas.upenn.edu
CR Barzilay R, 2008, COMPUT LINGUIST, V34, P1, DOI 10.1162/coli.2008.34.1.1
   Chae Jieun, 2009, P 12 C EUR CHAPT ASS, P139
   Charniak E, 2009, P 12 C EUR CHAPT ASS, P148
   Conroy J. M., 2008, P 22 INT C COMP LING, P145
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Elsner M., 2007, P NAACL HLT
   Elsner M., 2008, P ACL 2008 HLT SHORT, P41
   Finkel J. R., 2005, P 43 ANN M ASS COMP, P363, DOI DOI 10.3115/1219840.1219885
   Fordyce C., 2008, P 3 WORKSH STAT MACH, P70
   Fraurud K., 1990, Journal of Semantics, V7, P395, DOI 10.1093/jos/7.4.395
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P193, DOI 10.3758/BF03195564
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   HABERLANDT KF, 1985, J EXP PSYCHOL GEN, V114, P357, DOI 10.1037//0096-3445.114.3.357
   Halliday M. A. K., 1976, COHESION ENGLISH
   Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI DOI 10.1145/775047.775067
   Just M. A., 1987, PSYCHOL READING LANG
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   Lapata M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P545
   Lapata M, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P1085
   Lin C. Y., 2003, P NAACL HLT, P78
   Lin C. Y., 2004, P WORKSH TEXT SUMM B, P25
   Nenkova A., 2003, P HLT NAACL 2003
   Otterbacher J., 2002, P WORKSH AUT SUMM AC
   Over P, 2007, INFORM PROCESS MANAG, V43, P1506, DOI 10.1016/j.ipm.2007.01.019
   Paice C. D., 1980, P 3 ANN ACM C RES DE, P172
   PAICE CD, 1990, INFORM PROCESS MANAG, V26, P171, DOI 10.1016/0306-4573(90)90014-S
   Prince E. F., 1981, RADICAL PRAGMATICS, V223, P255
   Saggion H. A, 2009, P 2009 WORKSH LANG G, P31
   Soricut R., 2006, P ACL
   Steinberger J, 2007, INFORM PROCESS MANAG, V43, P1663, DOI 10.1016/j.ipm.2007.01.010
   Stolcke A., 2002, 7 INT C SPOK LANG PR, V3
NR 32
TC 9
Z9 9
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 544
EP 554
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300056
DA 2019-06-15
ER

PT B
AU Bangalore, S
   Di Fabbrizio, G
   Stent, A
AF Bangalore, Srinivas
   Di Fabbrizio, Giuseppe
   Stent, Amanda
GP COLING
TI Learning the Structure of Task-driven Human-Human Dialogs
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Data-driven techniques have been used for many computational linguistics tasks. Models derived from data are generally more robust than hand-crafted systems since they better reflect the distribution of the phenomena being modeled. With the availability of large corpora of spoken dialog, dialog management is now reaping the benefits of data-driven techniques. In this paper, we compare two approaches to modeling subtask structure in dialog: a chunk-based model of subdialog sequences, and a parse-based, or hierarchical, model. We evaluate these models using customer agent dialogs from a catalog service domain.
C1 [Bangalore, Srinivas; Di Fabbrizio, Giuseppe] AT&T Labs Res, Florham Pk, NJ 07932 USA.
RP Bangalore, S (reprint author), AT&T Labs Res, 180 Pk Ave, Florham Pk, NJ 07932 USA.
EM srini@research.att.com; pino@research.att.com; stent@cs.sunysb.edu
CR ALEXANDERSSON, 1997, P EUR 97
   BANGALORE, 2004, J TRAITEMENT AUTOMAT, V45
   BANGALORE, 1999, COMPUTATIONAL LINGUI, V25
   BEAR J, 1992, P ACL 92
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BOHUS D, 2003, P EUR 03
   BOS J, 2003, P SIGDIAL
   BUI HH, 2003, P IJCAI 03
   CARBERRY S, 2001, USER MODELING USER A, V11
   CARLETTA J, 1997, COMPUTATIONAL LINGUI, V23
   CHARNIAK E, 2001, P NAACL 01
   CORE M, 1998, P AAAI SPRING S APPL
   DIFABBRIZIO G, 2004, ICSLP 2004
   FRAMPTON M, 2005, P 4 IJCAI WORKSH KNO
   GILBERT M, 2005, IEEE SIGNAL PROC SEP, V22
   Grosz B., 1986, COMPUTATIONAL LINGUI, V12
   HAFFNER P, 2006, SPEECH COMMUNICATION, V48
   HARDY H, 2004, P ACL 04
   HASTIE HW, 2002, SPEECH COMMUNICATION, V36
   HENDERSON J, 2005, P 4 IJCAI WORKSH KNO
   JOSHI AK, 1987, MATH LANGUAGE
   JURAFSKY D, 1998, 30 J HOPK U CTR SPEE
   LARSSON, 1999, D22 TRINDI
   LEMON O, 1999, ACM T COMPUTER HUMAN, V11
   LEVIN E, 1997, P EUR 97
   LITMNA D, 1987, COGNITIVE SCI, V11
   Lochbaum K., 1998, COMPUTATIONAL LINGUI, V24
   METEER M, 1995, DYSFLUENCY ANNOTATIO
   POESIO M, 1998, P ICSLP 98
   PYNADATH DV, 2000, P 16 C UNC ART INT U
   RICH C, 1997, P 1 INT C AUT AG AG
   ROARK B, 2001, COMPUTATIONAL LINGUI, V27
   SAMUEL K, 1998, P AAAI SPRING S APPL
   SCHEFFLER K, 2002, P HLT 02
   SENEFF S, 1992, P SPEECH NAT LANG WO
   SHRIBERG E, 2000, SPEECH COMMUNICATION, V32
   Sidner C. L., 1985, COMPUTATIONAL INTELL, V1
   SINGH S, 2002, J ARTIFICIAL INTELLI, V16
   Stolcke A., 2000, COMPUTATIONAL LINGUI, V26
   TAYLOR P, 1998, LANGUAGE SPEECH, V41
   WILLIAMS J, 2005, P SIGDIAL
NR 41
TC 9
Z9 9
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 201
EP 208
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200026
DA 2019-06-15
ER

PT B
AU Bod, R
AF Bod, Rens
GP COLING
TI An All-Subtrees Approach to Unsupervised Parsing
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We investigate generalizations of the all-subtrees "DOP" approach to unsupervised parsing. Unsupervised DOP models assign all possible binary trees to a set of sentences and next use (a large random subset of) all subtrees from these binary trees to compute the most probable parse trees. We will test both a relative frequency estimator for unsupervised DOP and a maximum likelihood estimator which is known to be statistically consistent. We report state-of-the-art results on English (WSJ), German (NEGRA) and Chinese (CTB) data. To the best of our knowledge this is the first paper which tests a maximum likelihood estimator for DOP on the Wall Street Journal, leading to the surprising result that an unsupervised parsing model beats a widely used supervised model (a treebank PCFG).
C1 Univ St Andrews, Sch Comp Sci, St Andrews KY16 9SX, Fife, Scotland.
RP Bod, R (reprint author), Univ St Andrews, Sch Comp Sci, St Andrews KY16 9SX, Fife, Scotland.
EM rb@dcs.st-and.ac.uk
CR Bod R, 1998, GRAMMAR EXPERIENCE B
   BOD R, 2003, P EACL 2003 BUD
   BOD R, 2000, P ICSLP 2000 BEIJ
   Bod Rens, 2006, P CONLL 2006 NEW YOR
   BONNEMA R, 1997, P ACL EACL 1997 MADR
   Chi ZY, 1998, COMPUT LINGUIST, V24, P299
   CLARK A, 2001, P CONLL 2001
   COLLINS M, 2002, P ACL 2002 PHIL
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Goodman J., 2003, DATA ORIENTED PARSIN
   HUANG L, 2005, P IWPT 2005 VANC
   Johnson M, 2002, COMPUT LINGUIST, V28, P71, DOI 10.1162/089120102317341783
   Klein D, 2005, PATTERN RECOGN, V38, P1407, DOI 10.1016/j.patcog.2004.03.023
   KLEIN D, 2005, THESIS STANFORD U
   KLEIN D, 2004, P ACL 2004 BARC
   KLEIN D, 2002, P ACL 2002 PHIL
   MAGERMAN D, 1993, EXPECTATION MAXIMIZA
   Manning C.D., 1999, FDN STAT NATURAL LAN
   MCCLOSKY D, 2006, P HLTNAACL 2006 NEW
   PRESCHER D, 2004, P CLIN 2004 LEID
   SCHUTZE H, 1995, P ACL 1995 DUBL
   Shao J., 1999, MATH STAT
   SIMAAN K, 1996, P COLING 1996 COP
   SKUT W, 1997, P ANLP 1997
   VANZAANEN M, 2000, P COLING 2000 SAARBR
   XUE N, 2002, P COLING 2002 TAIP
   ZOLLMANN A, 2005, J AUTOMATA IN PRESS
   ZUIDEMA W, 2006, P CONLL 2006 NEW YOR
NR 28
TC 9
Z9 9
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 865
EP 872
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200109
DA 2019-06-15
ER

PT B
AU Davidov, D
   Rappoort, A
AF Davidov, Dmitry
   Rappoort, Ari
GP COLING
TI Efficient Unsupervised Discovery of Word Categories Using Symmetric
   Patterns and High Frequency Words
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a novel approach for discovering word categories, sets of words sharing a significant aspect of their meaning. We utilize meta-patterns of high-frequency words and content words in order to discover pattern candidates. Symmetric patterns are then identified using graph-based measures, and word categories are created based on graph clique sets. Our method is the first pattern-based method that requires no corpus annotation or manually provided seed patterns or words. We evaluate our algorithm on very large corpora in two languages, using both human judgments and WordNet-based evaluation. Our fully unsupervised results are superior to previous work that used a POS tagged corpus, and computation time for huge corpora are orders of magnitude faster than previously reported.
C1 [Davidov, Dmitry] Hebrew Univ Jerusalem, ICNC, IL-91904 Jerusalem, Israel.
RP Davidov, D (reprint author), Hebrew Univ Jerusalem, ICNC, IL-91904 Jerusalem, Israel.
EM dmitry@alice.nc.huji.ac.il
CR BERLAND M, 1999, FINDING PARTS VERY L
   BROWN PF, 1992, COMPUTATIONAL LINGUI, V18, P468
   CARABALLO SA, 1999, AUTOMATIC CONSTRUCTI
   CHKLOVSKI T, 2004, VERBOCEAN MINING WEB
   Cimiano P, 2005, J ARTIF INTELL RES, V24, P305, DOI 10.1613/jair.1648
   CURRAN J, 2002, ACL WORKSH UNS LEX A
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   DOROW B, 2005, USING CURVATURE MARK
   FREITAG D, 2004, TRAINED NAMED ENTITY
   GABRILOVICH E, 2005, FEATURE GENERATION T
   Hearst MA, 1992, AUTOMATIC ACQUISITIO
   LI H, 1996, CLUSTERING WORDS MDL
   LIN D, 1998, AUTOMATIC RETRIEVAL
   Matlin M. W, 2005, COGNITION
   PANTEL P, 2004, TERASCALE KNOWLEDGE
   PANTEL P, 2002, DISCOVERING WORD SEN
   PEREIRA F, 1993, DISTRIBUTIONAL CLUST
   RILOFF E, 1999, LEARNING DICT INFORM
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Widdows D., 2002, GRAPH MODEL UNSUPERV
NR 20
TC 9
Z9 9
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 297
EP 304
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200038
DA 2019-06-15
ER

PT B
AU Ellison, TM
   Kirby, S
AF Ellison, T. Mark
   Kirby, Simon
GP COLING
TI Measuring Language Divergence by Intra-Lexical Comparison
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents a method for building genetic language taxonomies based on a new approach to comparing lexical forms. Instead of comparing forms cross-linguistically, a matrix of language-internal similarities between forms is calculated. These matrices are then compared to give distances between languages. We argue that this coheres better with current thinking in linguistics and psycholinguistics. An implementation of this approach, called PHILOLOGICON, is described, along with its application to Dyen et al.'s (1992) ninety-five wordlists from Indo-European languages.
C1 [Ellison, T. Mark] Univ Edinburgh, Edinburgh EH8 9YL, Midlothian, Scotland.
RP Ellison, TM (reprint author), Univ Edinburgh, Edinburgh EH8 9YL, Midlothian, Scotland.
EM mark@markellison.net; simon@ling.ed.ac.uk
CR Atkinson C., 1981, SANKHYA A, V43, P345
   Bailey TM, 2001, J MEM LANG, V44, P568, DOI 10.1006/jmla.2000.2756
   BENEDETTO D, 2002, PHYS REV LETT, V88
   DYEN I, 1992, T AM PHILOS SOC, V82
   Fisher RA, 1959, STAT METHODS SCI INF
   Gray RD, 2003, NATURE, V426, P435, DOI 10.1038/nature02029
   Grimes B, 2000, ETHNOLOGUE LANGUAGES
   HEGGARTY P, 2005, PERSPECTIVES VARIATI
   JEFFREYS H, 1946, PROC R SOC LON SER-A, V186, P453, DOI 10.1098/rspa.1946.0056
   KAPATSINSKI V, 2006, 27 U SPEECH RES LAB
   Kessler B, 2005, T PHILOL SOC, V103, P243, DOI 10.1111/j.1467-968X.2005.00153.x
   KIDD GR, 1992, J ACOUST SOC AM, V92, P3109, DOI 10.1121/1.404207
   Kondrak G., 2002, THESIS U TORONTO
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Luce PA, 1998, EAR HEARING, V19, P1, DOI 10.1097/00003446-199802000-00001
   LUCE PA, 1990, ACL MIT NAT, P122
   McMahon A, 2005, T PHILOL SOC, V103, P147, DOI 10.1111/j.1467-968X.2005.00148.x
   McMahon A, 2003, T PHILOL SOC, V101, P7, DOI 10.1111/1467-968X.00108
   Micchelli CA, 2005, J MULTIVARIATE ANAL, V92, P97, DOI 10.1016/S0047-259X(03)00132-5
   MICHIELS N K, 1989, Odonatologica, V18, P349
   NAKLEH L, 2005, T PHILOS SOC, V103, P171
   Nerbonne John, 1997, P SIGPHON 97 3 M ACL
   Port RF, 2005, LANGUAGE, V81, P927, DOI 10.1353/lan.2005.0195
   Rao CR, 1949, SANKHYA, V9, P246
   Ringe D, 2002, T PHILOL SOC, V100, P59, DOI 10.1111/1467-968X.00091
   Shawe-Taylor John, 2004, KERNEL METHODS PATTE
   SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243
   Shillcock R., 2001, P 2001 C DISFL SPONT, P53
   Swadesh M., 1952, P AM PHILOS SOC, V96
   TAMARIZ M, 2005, THESIS U EDINBURGH
NR 30
TC 9
Z9 9
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 273
EP 280
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200035
DA 2019-06-15
ER

PT B
AU Klementiev, A
   Roth, D
AF Klementiev, Alexandre
   Roth, Dan
GP COLING
TI Weakly Supervised Named Entity Transliteration and Discovery from
   Multilingual Comparable Corpora
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Named Entity recognition (NER) is an important pan of many natural language processing tasks. Current approaches often employ machine learning techniques and require supervised data. However, many languages lack such resources. This paper presents an (almost) unsupervised learning algorithm for automatic discovery of Named Entities (NEs) in a resource free language, given a bilingual corpora in which it is weakly temporally aligned with a resource rich language. NEs have similar time distributions across such corpora, and often some of the tokens in a multi-word NE are transliterated. We develop an algorithm that exploits both observations iteratively. The algorithm makes use of a new, frequency based, metric for time distributions and a resource free discriminative approach to transliteration. Seeded with a small number of transliteration pairs, our algorithm discovers multi-word NEs, and takes advantage of a dictionary (if one exists) to account for translated or partially translated NEs. We evaluate the algorithm on an English-Russian corpus, and show high level of NEs discovery in Russian.
C1 [Klementiev, Alexandre; Roth, Dan] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
RP Klementiev, A (reprint author), Univ Illinois, Dept Comp Sci, 1304 W Springfield Ave, Urbana, IL 61801 USA.
EM klementi@uiuc.edu; danr@uiuc.edu
CR ABDULJALEEL N, 2003, P 12 INT C INF KNOWL, P139
   Arfken G., 1985, MATH METHODS PHYS
   BENTASKAR, 2005, C ADV NEUR INF PROC
   BLUM A, 1992, MACH LEARN, V9, P373, DOI 10.1023/A:1022653502461
   COLLINS M, 1999, P C EMP METH NAT LAN
   CUCERZAN S, 1999, P C EMP METH NAT LAN
   HETLAND ML, 2004, DATA MINING TIME SER
   JUNG SY, 2000, P 18 C COMP LING, P383
   KLEMENTIEV A, 2006, P ANN M N AM ASS COM
   KNIGHT K, 1997, P M EUR ASS COMP LIN, P129
   Li X, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P419
   Moore R. C., 2005, P C HUM LANG TECHN E, P81, DOI DOI 10.3115/1220575.1220586
   Rosenblatt F, 1958, PSYCHOL REV, P65
   Roth D, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P806
   ROTH D, 1999, P INT JOINT C ART IN, P898
   Salton G., 1986, INTRO MODERN INFORM
   Shinyama  Y., 2004, P 20 INT C COMP LING, P848
NR 17
TC 9
Z9 9
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 817
EP 824
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200103
DA 2019-06-15
ER

PT B
AU Lee, YS
   Papineni, K
   Roukos, S
   Emam, O
   Hassan, H
AF Lee, YS
   Papineni, K
   Roukos, S
   Emam, O
   Hassan, H
GP ACL
TI Language model based arabic word segmentation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We approximate Arabic's rich morphology by a model that a word consists of a sequence of morphemes in the pattern prefix*-stem-suffix* (* denotes zero or more occurrences of a morpheme). Our method is seeded by a small manually segmented Arabic corpus and uses it to bootstrap an unsupervised algorithm to build the Arabic word segmenter from a large unsegmented Arabic corpus. The algorithm uses a trigram language model to determine the most probable morpheme sequence for a given input. The language model is initially estimated from a small manually segmented corpus of about 110,000 words. To improve the segmentation accuracy, we use an unsupervised algorithm for automatically acquiring new stems from a 155 million word unsegmented corpus, and re-estimate the model parameters with the expanded vocabulary and training corpus. The resulting Arabic word segmentation system achieves around 97% exact match accuracy on a test corpus containing 28,449 word tokens. We believe this is a state-of-the-art performance and the algorithm can be used for many highly inflected languages provided that one can create a small manually segmented corpus of the language of interest.
C1 IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
CR Beesley Kenneth R., 1996, P COLING 96, P89
   Brown P. F., 1993, Computational Linguistics, V19, P263
   DARWISH K, 2002, P WORKSH COMP APPR S, P47
   FRANZ M, 2002, P TREC 2002, P402
   GOLDSMITH J, 2000, COMPUTATIONAL LINGUI, V27
   Jelinek F., 1997, STAT METHODS SPEECH
   LUO XQ, 1996, P 34 ANN M ASS COMP, P139
   Schone P., 2001, P N AM CHAPT ASS COM
   Wicentowski Richard, 2001, P 1 INT C HUM LANG T, P161
   YAROWSKY D, 2000, P ACL 2000, P207
NR 10
TC 9
Z9 11
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 399
EP 406
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500051
DA 2019-06-15
ER

PT B
AU Yangarber, R
AF Yangarber, R
GP ACL
TI Counter-training in discovery of semantic patterns
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper presents a method for unsupervised discovery of semantic patterns. Semantic patterns are useful for a variety of text understanding tasks, in particular for locating events in text for information extraction. The method builds upon previously described approaches to iterative unsupervised pattern acquisition. One common characteristic of prior approaches is that the output of the algorithm is a continuous stream of patterns, with gradually degrading precision.
   Our method differs from the previous pattern acquisition algorithms in that it introduces competition among several scenarios simultaneously. This provides natural stopping criteria for the unsupervised learners, while maintaining good precision levels at termination. We discuss the results of experiments with several scenarios, and examine different aspects of the new procedure.
C1 NYU, Courant Inst Math Sci, New York, NY USA.
RI Yangarber, Roman/H-4762-2016
CR Blum Avrim, 1998, P 11 ANN C COMP LEAR
   Collins Michael, 1999, P JOINT SIGDAT C EMN
   RILOFF E, 1999, P 16 NAT C AI AAAI 9
   RILOFF E, 1996, P 13 NAT C AI AAAI 9
   STRZALKOWSKI T, 1996, P 16 INT C COMP LING
   Tapanainen P, 1997, P 5 C APPL NAT LANG
   THELEN M, 2002, P 2002 C EMP METH NL
   YANGARBER R, 2000, P 18 INT C COMP LING
   Yangarber R., 2002, P 19 INT C COMP LING
   YAROWSKY D, 1995, P 33 ANN M ACL CAMBR
NR 10
TC 9
Z9 9
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 343
EP 350
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500044
DA 2019-06-15
ER

PT S
AU Ek, T
   Kirkegaard, C
   Jonsson, H
   Nugues, P
AF Ek, Tobias
   Kirkegaard, Camilla
   Jonsson, Hakan
   Nugues, Pierre
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Named Entity Recognition for Short Text Messages
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Named entity recognition; Short text messages; SMS; Information
   extraction; Ensemble systems
AB This paper describes a named entity recognition (NER) system for short text messages (SMS) running on a mobile platform. Most NER systems deal with text that is structured, formal, well written, with a good grammatical structure, and few spelling errors. SMS text messages lack these qualities and have instead a short-handed and mixed language studded with emoticons, which makes NER a challenge on this kind of material.
   We implemented a system that recognizes named entities from SMSes written in Swedish and that runs on an Android cellular telephone. The entities extracted are locations, names, dates, times, and telephone numbers with the idea that extraction of these entities could be utilized by other applications running on the telephone. We started from a regular expression implementation that we complemented with classifiers using logistic regression. We optimized the recognition so that the incoming text messages could be processed on the telephone with a fast response time. We reached an F-score of 86 for strict matches and 89 for partial matches. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Ek, Tobias; Kirkegaard, Camilla; Nugues, Pierre] Lund Univ, Dept Comp Sci, Box 118, S-22100 Lund, Sweden.
   [Jonsson, Hakan] Sony Ericsson, S-22188 Lund, Sweden.
RP Ek, T (reprint author), Lund Univ, Dept Comp Sci, Box 118, S-22100 Lund, Sweden.
EM tobias.ek@telia.com
OI Nugues, Pierre/0000-0002-9563-4000
CR BIKEL DM, 1997, P 5 C APPL NAT LANG, P194
   Carlberger J, 1999, SOFTWARE PRACT EXPER, V29, P815, DOI 10.1002/(SICI)1097-024X(19990725)29:9<815::AID-SPE256>3.0.CO;2-F
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Florian R., 2003, P CONLL 2003, P168
   Hai Leong Chieu, 2003, P CONLL 2003, V4, P160
   Jiangtao Huang, 2010, Proceedings of the 2010 WASE International Conference on Information Engineering (ICIE 2010), P149, DOI 10.1109/ICIE.2010.43
   Kudoh Taku, 2000, P CONLL 2000 LLL 200, P142
   Mikheev A., 1999, P EACL 99
   OpenNLP, 2004, PACK JAV BAS NLP TOO
   Polifroni J., 2010, P LREC
   Sang E. F. Tjong Kim, 2002, P CONLL 2002 TAIP TA, V20, P1, DOI DOI 10.3115/1118853.1118877
   SANG EFT, 2003, P 7 C NAT LANG LEARN, P142
   Segerstad Y.H., 2002, THESIS GOTEBORG U
NR 13
TC 8
Z9 9
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 178
EP 187
DI 10.1016/j.sbspro.2011.10.596
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700020
OA Green Published, Other Gold
DA 2019-06-15
ER

PT S
AU Belz, A
   Kow, E
   Viethen, J
   Gatt, A
AF Belz, Anja
   Kow, Eric
   Viethen, Jette
   Gatt, Albert
BE Krahmer, E
   Theune, M
TI Generating Referring Expressions in Context: The GREC Task Evaluation
   Challenges
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
AB Until recently, referring expression generation (REG) research focused on the task of selecting the semantic content of definite mentions of listener-familiar discourse entities. In the GREC research programme we have been interested in a version of the REG problem definition that is (i) grounded within discourse context, (ii) embedded within an application context, and (iii) informed by naturally occurring data. This paper provides an overview of our aims and motivations in this research programme, the data resources we have built, and the first three shared-task challenges, GREC-MSR'08, GREC-MSR'09 and GREC-NEG'09, we have run based on the data.
C1 [Belz, Anja; Kow, Eric] Univ Brighton, NLTG, Sch Comp Math & Informat Sci, Brighton BN2 4GJ, E Sussex, England.
   [Viethen, Jette] Macquarie Univ, Sydney, NSW 2109, Australia.
   [Gatt, Albert] Univ Malta, Inst Linguist, Ctr Commun Technol, Msida, Malta.
   [Gatt, Albert] Tilburg Univ, Fac Arts, Commun & Cognit, NL-5000 LE Tilburg, Netherlands.
RP Belz, A (reprint author), Univ Brighton, NLTG, Sch Comp Math & Informat Sci, Brighton BN2 4GJ, E Sussex, England.
EM a.s.belz@brighton.ac.uk; e.y.kow@brighton.ac.uk; jviethen@ics.mq.edu.au;
   albert.gatt@um.edu.mt
OI Gatt, Albert/0000-0001-6388-8244
FU Epsrc (UK) [EP/E029116/1, EP/F059760/1, EP/G03995X/1]
FX The research reported in this paper was supported under Epsrc (UK)
   grants EP/E029116/1 (the Prodigy Project), EP/F059760/1 (REG Challenges
   2008), and EP/G03995X/1 (Generation Challenges 2009).
CR Bagga A., 1998, P 1 INT C LANG RES E, P563
   BELZ A, 2007, P 11 EUR WORKSH NAT, P9
   Belz A., 2006, P 11 C EUR CHAPT ASS, P313
   Belz A, 2009, COMPUT LINGUIST, V35, P111, DOI 10.1162/coli.2009.35.1.111
   BOHNET B, 2005, P 19 INT JOINT C ART, P1004
   CHARNIAK E, 2003, P MT SUMMIT 9
   CHENG H, 2001, P 2 M N AM CHAPT ASS
   Copestake A., 2004, P 42 ANN M ASS COMP
   DALE R, 1995, COGNITIVE SCI, V19, P233
   DALE R, 1989, P 27 ANN M ASS COMP
   DANG HT, 2006, P COLING ACL 06 WORK, P48
   DENEEFE S, 2009, P 2009 C EMP METH NA
   Forster KI, 2003, BEHAV RES METH INS C, V35, P116, DOI 10.3758/BF03195503
   Gatt A, 2010, LECT NOTES ARTIF INT, V5790, P264, DOI 10.1007/978-3-642-15573-4_14
   GUPTA S, 2005, P 1 WORKSH US CORP N, P1
   Huddleston R. D., 2002, CAMBRIDGE GRAMMAR EN
   JORDAN PW, 2000, P 38 ANN M ASS COMP
   JORDAN PW, 2002, INFORM SHARING REFER
   KOLLER A, 2010, LNCS LNAI, V5790, P329
   KRAHMER E, 2002, INFORM SHARING REFER, P223
   Lin CY, 2004, P 20 INT C COMP LING, P501, DOI DOI 10.3115/1220355.1220427
   Luo X., 2005, P C HUM LANG TECHN E, P25, DOI DOI 10.3115/1220575.1220579
   MORTON T, 2005, THESIS U PENSYLVANIA
   NENKOVA A, 2008, P 3 INT JOINT C NAT
   NENKOVA A, 2006, THESIS COLUMBIA U
   Otterbacher J. C., 2002, P ACL 02 WORKSH AUT, V4, P27
   Pak A., 2005, PREVENTING CHRONIC D, V2
   POESIO M, 2000, P 2 INT C LANG RES E
   POESIO M, 2004, P ACL 2004 DISC ANN
   Qiu L., 2004, P 4 INT C LANG RES E, P291
   REITER E, 1992, P 14 INT C COMP LING, P232
   SIEGEL S, 1957, AM STAT, V11, P13, DOI 10.2307/2685679
   Steinberger J, 2007, INFORM PROCESS MANAG, V43, P1663, DOI 10.1016/j.ipm.2007.01.010
   Turian J. P., 2003, P MT SUMM 9 NEW ORL, P386
   van Deemter K, 2002, COMPUT LINGUIST, V28, P37, DOI 10.1162/089120102317341765
   van Deemter K., 2006, P 4 INT C NAT LANG G, P130
   VIETHEN J, 2006, P 4 AUSTR LANG TECHN, P115
   Vilain M., 1995, P 6 MESS UND C MUC 6, P45, DOI DOI 10.3115/1072399.1072405
NR 38
TC 8
Z9 8
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 294
EP +
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600015
DA 2019-06-15
ER

PT B
AU Branavan, SRK
   Zettlemoyer, LS
   Barzilay, R
AF Branavan, S. R. K.
   Zettlemoyer, Luke S.
   Barzilay, Regina
GP Assoc Computat Linguist
TI Reading Between the Lines: Learning to Map High-level Instructions to
   Commands
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In this paper, we address the task of mapping high-level instructions to sequences of commands in an external environment. Processing these instructions is challenging-they posit goals to be achieved without specifying the steps required to complete them. We describe a method that fills in missing information using an automatically derived environment model that encodes states, transitions, and commands that cause these transitions to happen. We present an efficient approximate approach for learning this environment model as part of a policygradient reinforcement learning algorithm for text interpretation. This design enables learning for mapping high-level instructions, which previous statistical methods cannot handle.(1)
C1 [Branavan, S. R. K.; Zettlemoyer, Luke S.; Barzilay, Regina] MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
RP Branavan, SRK (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
EM branavan@csail.mit.edu; lsz@csail.mit.edu; regina@csail.mit.edu
CR Agre Philip E., 1988, TECHNICAL REPORT
   Boyan J. A., 1995, Advances in Neural Information Processing Systems 7, P369
   Branavan S, 2009, P JOINT C 47 ANN M A, P82
   Darken C., 1990, ADV NIPS, P832
   Di Eugenio Barbara, 1992, P ANN M ASS COMPUTAT, P120
   Di Eugenio Barbara, 1992, P 14 INT C COMP LING, P1147
   Eisenstein J., 2009, P EMNLP, P958
   Fleischman Michael, 2005, P CONLL, P104
   Jong Nicholas K., 2007, P 6 INT JOINT C AUT, P670
   Kushman Nate, 2009, P HOTNETS
   Lascarides Alex, 2004, SEMANTICS PRAGMATICS
   Lemon Oliver, 2009, P EACL, P505
   Liang P., 2009, P JOINT C 47 ANN M A, P91
   MacMahon M., 2006, P NAT C ART INT AAAI, P1475
   Matuszek C, 2010, ACMIEEE INT CONF HUM, P251, DOI 10.1109/HRI.2010.5453189
   Mooney R.J., 2008, P 23 AAAI C ART INT, V3, P1598
   Oates James Timothy, 2001, THESIS
   Powell W. B., 2007, APPROXIMATE DYNAMIC
   Schatzmann J, 2009, IEEE T AUDIO SPEECH, V17, P733, DOI 10.1109/TASL.2008.2012071
   Singh S, 2002, J ARTIF INTELL RES, V16, P105, DOI 10.1613/jair.859
   Siskind JM, 2001, J ARTIF INTELL RES, V15, P31, DOI 10.1613/jair.790
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Webber Bonnie, 1995, ARTIFICIAL INTELLIGE, V73
   Winograd T., 1972, UNDERSTANDING NATURA
   Yu C, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P488
NR 26
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1268
EP 1277
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300129
DA 2019-06-15
ER

PT B
AU Heinz, J
AF Heinz, Jeffrey
GP Assoc Computat Linguist
TI String Extension Learning
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID POSITIVE DATA; LANGUAGES; IDENTIFICATION; INFERENCE; PATTERNS; FAMILIES;
   KERNELS; WORD
AB This paper provides a unified, learning-theoretic analysis of several learnable classes of languages discussed previously in the literature. The analysis shows that for these classes an incremental, globally consistent, locally conservative, set-driven learner always exists. Additionally, the analysis provides a recipe for constructing new learnable classes. Potential applications include learnable models for aspects of natural language and cognition.
C1 [Heinz, Jeffrey] Univ Delaware, Newark, DE 19716 USA.
RP Heinz, J (reprint author), Univ Delaware, Newark, DE 19716 USA.
EM heinz@udel.edu
CR ANGLUIN D, 1980, J COMPUT SYST SCI, V21, P46, DOI 10.1016/0022-0000(80)90041-0
   ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5
   Angluin D., 1988, 614 YAL U
   BEAUQUIER D, 1991, THEOR COMPUT SCI, V84, P3, DOI 10.1016/0304-3975(91)90258-4
   BLUMER A, 1989, J ACM, V36, P929, DOI 10.1145/76359.76371
   Brzozowski J., 1962, MATH THEORY AUTOMATA, P529
   Brzozowski J. A., 1973, Discrete Mathematics, V4, P243, DOI 10.1016/S0012-365X(73)80005-6
   Cancedda N, 2003, J MACH LEARN RES, V3, P1059, DOI 10.1162/153244303322533197
   Caron P, 2000, THEOR COMPUT SCI, V242, P361, DOI 10.1016/S0304-3975(98)00332-6
   Case J, 1999, INFORM COMPUT, V152, P74, DOI 10.1006/inco.1998.2784
   Case J, 2007, LECT NOTES ARTIF INT, V4754, P49
   Chambers KE, 2003, COGNITION, V87, pB69, DOI 10.1016/S0010-0277(02)00233-0
   CLARK A, 2006, P 8 INT C GRAMM INF, P148
   Clark A, 2006, LECT NOTES COMPUT SC, V4212, P90
   Cristia A, 2008, LANG LEARN DEV, V4, P203, DOI 10.1080/15475440802143109
   DelaHiguera C, 1997, MACH LEARN, V27, P125, DOI 10.1023/A:1007353007695
   Edlefsen Matt, 2008, P MIDST C UND RES CO, P66
   Fernau H, 2003, THEOR COMPUT SCI, V290, P1679, DOI 10.1016/S0304-3975(02)00075-0
   Gallistel C. R., 2009, MEMORY COMPUTATIONAL
   Garcia P., 2004, GRAMMARS, V7, P125
   GARCIA P, 1990, P WORKSH ALG LEARN T, P325
   Garcia Pedro, 1996, LECT NOTES COMPUTER, V1147, P203
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Grainger J, 2004, TRENDS COGN SCI, V8, P58, DOI 10.1016/j.tics.2003.11.006
   Heinz J., 2007, THESIS
   Heinz J, 2009, PHONOLOGY, V26, P303, DOI 10.1017/S0952675709990145
   Heinz Jeffrey, 2010, P ACL
   Heinz Jeffrey, LINGUISTIC IN PRESS
   Horning J. J., 1969, THESIS
   Jain S., 1999, SYSTEMS LEARN INTRO
   Jain S, 2007, INFORM COMPUT, V205, P1671, DOI 10.1016/j.ic.2007.06.002
   Jurafsky D, 2008, SPEECH LANGUAGE PROC
   Kasprzik Anna, 2010, P 4 INT C L IN PRESS
   KIM SM, 1991, IEEE T COMPUT, V40, P1087, DOI 10.1109/12.93741
   Kontorovich L, 2008, THEOR COMPUT SCI, V405, P223, DOI 10.1016/j.tcs.2008.06.037
   Lange S, 2008, THEOR COMPUT SCI, V397, P194, DOI 10.1016/j.tcs.2008.02.030
   Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687
   Lothaire M, 2005, APPL COMBINATORICS W
   McNaughton R., 1974, Mathematical Systems Theory, V8, P60, DOI 10.1007/BF01761708
   McNaughton  Robert, 1971, COUNTER FREE AUTOMAT
   Onishi KH, 2002, COGNITION, V83, pB13, DOI 10.1016/S0010-0277(01)00165-2
   PARIKH RJ, 1966, J ACM, V13, P570, DOI 10.1145/321356.321364
   Rogers James, J LOGIC LANGUAGE INF
   Rogers James, 2009, P 11 M ASS MATH LANG
   Shawe-Taylor J., 2005, KERNEL METHODS PATTE
   Simon I., 1975, Automata Theory and Formal Language 2nd GI Conference, P214
   Simon Imre, 1993, ICALP 93, P430
   Whitney C, 2001, PSYCHON B REV, V8, P221, DOI 10.3758/BF03196158
   Whitney C, 2008, LANG COGNITIVE PROC, V23, P143, DOI 10.1080/01690960701579771
NR 49
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 897
EP 906
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300092
DA 2019-06-15
ER

PT B
AU Li, BY
   Zhou, LJ
   Feng, S
   Wong, KF
AF Li, Binyang
   Zhou, Lanjun
   Feng, Shi
   Wong, Kam-Fai
GP Assoc Computat Linguist
TI A Unified Graph Model for Sentence-based Opinion Retrieval
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB There is a growing research interest in opinion retrieval as on-line users' opinions are becoming more and more popular in business, social networks, etc. Practically speaking, the goal of opinion retrieval is to retrieve documents, which entail opinions or comments, relevant to a target subject specified by the user's query. A fundamental challenge in opinion retrieval is information representation. Existing research focuses on document-based approaches and documents are represented by bag-of-word. However, due to loss of contextual information, this representation fails to capture the associative information between an opinion and its corresponding target. It cannot distinguish different degrees of a sentiment word when associated with different targets. This in turn seriously affects opinion retrieval performance. In this paper, we propose a sentence-based approach based on a new information representation, namely topic-sentiment word pair, to capture intra-sentence contextual information between an opinion and its target. Additionally, we consider inter-sentence information to capture the relationships among the opinions on the same topic. Finally, the two types of information are combined in a unified graph-based model, which can effectively rank the documents. Compared with existing approaches, experimental results on the COAE08 dataset showed that our graph-based model achieved significant improvement.
C1 [Li, Binyang; Zhou, Lanjun; Feng, Shi; Wong, Kam-Fai] Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
RP Li, BY (reprint author), Chinese Univ Hong Kong, Dept Syst Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
EM byli@se.cuhk.edu.hk; ljzhou@se.cuhk.edu.hk; sfeng@se.cuhk.edu.hk;
   kfwong@se.cuhk.edu.hk
CR Allan J., 2003, P 26 ANN INT ACM SIG, P314, DOI DOI 10.1145/860435.860493
   Amati Giambattista, 2007, P 15 TEXT RETR C
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Eguchi K., 2006, P 2006 C EMP METH NA, P345
   Erkan Gunes, 2004, EMNLP 04
   Hannah David, 2007, P 15 TEXT RETR C
   Huang Xuanjing, 2009, P CIKM
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Lee Yeha, 2008, P 15 TEXT RETR C
   Li Fangtao, 2009, ACL 09
   Liu Bing, 2005, WWW 05
   Macdonald Craig, 2007, P 15 TEXT RETR C
   Macdonald Craig, 2006, P 14 TEXT RETR C
   Mei Q., 2007, WWW 07
   Na SH, 2009, LECT NOTES COMPUT SC, V5478, P734
   Oard Douglas, 2006, P 15 TEXT RETR C
   Otterbacher Jahna, 2005, EMNLP 05
   Page L, 1998, TECHNICAL REPORT
   Popescu A-M., 2005, EMNLP 05
   Wan X., 2008, P 31 ANN INT ACM SIG, P299, DOI [10.1145/1390334.1390386, DOI 10.1145/1390334.1390386]
   Wilson Theresa, 2005, EMNLP 05
   Xu Ruifeng, 2007, P NTCIR 6
   Zhang M., 2008, P 31 ANN INT ACM SIG, P411, DOI DOI 10.1145/1390334.1390405
   Zhang Wei, 2007, P 15 TEXT RETR C
   Zhao Jun, 2008, P 1 CHIN OP AN EV
NR 25
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1367
EP 1375
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300139
DA 2019-06-15
ER

PT B
AU Li, LL
   Roth, B
   Sporleder, C
AF Li, Linlin
   Roth, Benjamin
   Sporleder, Caroline
GP Assoc Computat Linguist
TI Topic Models for Word Sense Disambiguation and Token-based Idiom
   Detection
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper presents a probabilistic model for sense disambiguation which chooses the best sense based on the conditional probability of sense paraphrases given a context. We use a topic model to decompose this conditional probability into two conditional probabilities with latent variables. We propose three different instantiations of the model for solving sense disambiguation problems with different degrees of resource availability. The proposed models are tested on three different tasks: coarse-grained word sense disambiguation, fine-grained word sense disambiguation, and detection of literal vs. non-literal usages of potentially idiomatic expressions. In all three cases, we outperform state-of-the-art systems either quantitatively or statistically significantly.
C1 [Li, Linlin; Roth, Benjamin; Sporleder, Caroline] Univ Saarland, Postfach 15 11 50, D-66041 Saarbrucken, Germany.
RP Li, LL (reprint author), Univ Saarland, Postfach 15 11 50, D-66041 Saarbrucken, Germany.
EM linlin@coli.uni-saarland.de; beroth@coli.uni-saarland.de;
   csporled@coli.uni-saarland.de
CR Anaya-Sanchez H., 2007, SEMEVAL 07, P322
   Bethard S., 2009, CALC 09, P9
   Birke J., 2006, P EACL 06
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boyd-Graber J., 2007, P 4 INT WORKSH SEM E, P277
   Boyd-Graber J., 2008, COMPUTATIONAL LINGUI
   Boyd-Graber J., 2007, P 2007 JOINT C EMP M, P1024
   Briscoe T., 2006, P COLING ACL 2006 MA, P41
   Brody S, 2009, P 12 C EUR CHAPT ASS, P103
   Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13
   Buscaldi D., 2007, SEMEVAL 07, P434
   Cai J. F., 2007, P 2007 JOINT C EMP M, P1015
   Chan Y. S., 2007, SEMEVAL 07, P253
   Geman S, 1987, READINGS COMPUTER VI, P564
   Griffiths T. L., 2005, ADV NEURAL INFORM PR, V17, P537
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Ion R., 2007, SEMEVAL 07, P282
   Katz G., 2006, P ACL COLING 06 WORK
   Klebanov B. B., 2009, CALC 09, P1
   Li L., 2009, P EMNLP 09
   McCarthy D., 2004, P 42 M ASS COMP LING, V279-286
   McCarthy D, 2009, LANG LINGUIST COMPAS, V3, P537, DOI 10.1111/j.1749-818x.2009.00131.x
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Navigli R., 2006, P 44 ANN M ASS COMP
   Navigli R., 2009, P 4 INT WORKSH SEM E
   Porter M. F., 2001, SNOWBALL LANGUAGE ST
   Pradhan S. S., 2009, P 4 INT WORKSH SEM E
   Song F., 1999, RES DEV INFORMATION, P279
   Sorg Philipp, 2008, CLEF 2008 WORKSH
   Sporleder C., 2009, P EACL 09
   Wang Y., 2009, P 5 INT C ALG ASP IN
NR 32
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1138
EP 1147
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300116
DA 2019-06-15
ER

PT B
AU Wang, WT
   Su, J
   Tan, CL
AF Wang, WenTing
   Su, Jian
   Tan, Chew Lim
GP Assoc Computat Linguist
TI Kernel Based Discourse Relation Recognition with Temporal Ordering
   Information
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Syntactic knowledge is important for discourse relation recognition. Yet only heuristically selected flat paths and 2-level production rules have been used to incorporate such information so far. In this paper we propose using tree kernel based approach to automatically mine the syntactic information from the parse trees for discourse analysis, applying kernel function to the tree structures directly. These structural syntactic features, together with other normal flat features are incorporated into our composite kernel to capture diverse knowledge for simultaneous discourse identification and classification for both explicit and implicit relations. The experiment shows tree kernel approach is able to give statistical significant improvements over flat syntactic path feature. We also illustrate that tree kernel approach covers more structure information than the production rules, which allows tree kernel to further incorporate information from a higher dimension space for possible better discrimination. Besides, we further propose to leverage on temporal ordering information to constrain the interpretation of discourse relation, which also demonstrate statistical significant improvements for discourse relation recognition on PDTB 2.0 for both explicit and implicit as well.
C1 [Wang, WenTing; Su, Jian] Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis, Singapore 138632, Singapore.
   [Tan, Chew Lim] Natl Univ Singapore, Dept Comp Sci, Singapore 117417, Singapore.
RP Wang, WT (reprint author), Inst Infocomm Res, 1 Fusionopolis Way,21-01 Connexis, Singapore 138632, Singapore.
EM wwang@i2r.a-star.edu.sg; sujian@i2r.a-star.edu.sg; tacl@comp.nus.edu.sg
CR Collins M., 2002, NIPS 2001
   Collins Michael, 2001, P 40 ANN M ASS COMP, P263
   Culotta A, 2004, P 42 ANN M ASS COMP, V432, DOI [10.3115/1218955.1219009, DOI 10.3115/1218955.1219009]
   HAUSSLER D, 1999, UCSCRL9910 U CAL
   Joachims T, 1999, ADV KERNEL METHODS S
   Knott A., 2001, TEXT REPRESENTATION, P181
   LEE A, 2006, P 5 INT WORKSH TREEB
   Lin Z., 2009, P 2009 C EMP METH NA
   Marcu D, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P368
   Moschitti A., 2004, ACL, P335
   Pettibone J., 2003, WORKING PAPER
   Pitler E., 2009, P JOINT C 47 ANN M A
   Prasad  R., 2008, P 6 INT C LANG RES E
   Saito M., 2006, P HUM LANG TECHN C N, P133
   Vapnik VN, 1995, NATURE STAT LEARNING
   Webber B. L., 1988, Computational Linguistics, V14, P61
   Wellner B., 2007, P 2007 JOINT C EMP M, P92
   Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205
   Zhang M., 2006, P HUM LANG TECHN C N
NR 19
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 710
EP 719
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300073
DA 2019-06-15
ER

PT B
AU Wuebker, J
   Mauser, A
   Ney, H
AF Wuebker, Joern
   Mauser, Arne
   Ney, Hermann
GP Assoc Computat Linguist
TI Training Phrase Translation Models with Leaving-One-Out
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Several attempts have been made to learn phrase translation probabilities for phrase-based statistical machine translation that go beyond pure counting of phrases in word-aligned training data. Most approaches report problems with over-fitting. We describe a novel leaving-one- out approach to prevent over-fitting that allows us to train phrase models that show improved translation performance on the WMT08 Europarl German-English task. In contrast to most previous work where phrase models were trained separately from other models used in translation, we include all components such as single word lexica and reordering models in training. Using this consistent training of phrase models we are able to achieve improvements of up to 1.4 points in BLEU. As a side effect, the phrase table size is reduced by more than 80%.
C1 [Wuebker, Joern; Mauser, Arne; Ney, Hermann] Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit Grp, Aachen, Germany.
RP Wuebker, J (reprint author), Rhein Westfal TH Aachen, Human Language Technol & Pattern Recognit Grp, Aachen, Germany.
EM wuebker@cs.rwth-aachen.de; mauser@cs.rwth-aachen.de;
   ney@cs.rwth-aachen.de
CR Birch Alexandra, 2006, SMT2006, P154
   Blunsom Phil, 2008, P ACL HLT COL OH, P200
   Brown P. F., 1993, Computational Linguistics, V19, P263
   DeNero J, 2008, P 46 ANN M ASS COMP, P25
   DeNero J., 2006, P WORKSH STAT MACH T, P31
   DeNero J., 2008, P 2008 C EMP METH NA, P314
   Dorr Bonnie, 2006, P ASS MACH TRANSL AM, P223
   Ehling Nicola, 2007, ACL 07, P101
   Ferrer Jesus-Andres, 2009, P EUR ASS MACH TRANS
   KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394
   Koehn Philipp, 2003, P 2003 C N AM CHAPT, V1, P48, DOI DOI 10.3115/1073445.1073462
   Liang P, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P761
   MARCU D, 2002, P C EMP METH NAT LAN
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Ney H., 1999, P JOINT SIGDAT C EMP, P20
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Shen Wade, 2008, P INT WORKSH SPOK LA, P69
   Tromble Roy, 2008, P 2008 C EMP METH NA, P620
   Ueffing N, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P156
NR 21
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 475
EP 484
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300049
DA 2019-06-15
ER

PT J
AU Hardy, H
   Biermann, A
   Inouye, RB
   McKenzie, A
   Strzalkowski, T
   Ursu, C
   Webb, N
   Wu, M
AF Hardy, H
   Biermann, A
   Inouye, RB
   McKenzie, A
   Strzalkowski, T
   Ursu, C
   Webb, N
   Wu, M
TI The AMITIES system: Data-driven techniques for automated dialogue
SO SPEECH COMMUNICATION
LA English
DT Article; Proceedings Paper
CT 42nd Annual Meeting of the Association-for-Computational-Linguistics
CY 2004
CL Barcelona, SPAIN
SP Assoc Computat Linguist
DE human-computer dialogue; spoken dialogue systems; language
   understanding; language generation
ID RECOGNITION; SPEECH
AB We present a natural-language customer service application for a telephone banking call center, developed as part of the Amities dialogue project (Automated Multilingual Interaction with Information and Services). Our dialogue system, based on empirical data gathered from real call-center conversations, features data-driven techniques that allow for spoken language understanding despite speech recognition errors, as well as mixed system/customer initiative and spontaneous conversation. These techniques include robust named-entity extraction, slot-filling Frame Agents, vector-based task identification and dialogue act classification, a Bayesian database record selection algorithm, and a natural language generator designed with templates created from real agents' expressions. Preliminary evaluation results indicate efficient dialogues and high user satisfaction, with performance comparable to or better than that of current conversational information systems. (c) 2005 Elsevier B.V. All rights reserved.
C1 SUNY Albany, ILS Inst, Albany, NY 12222 USA.
   Duke Univ, Levine Sci Res Ctr, Dept Comp Sci, Durham, NC 27708 USA.
   Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England.
RP Hardy, H (reprint author), SUNY Albany, ILS Inst, 1400 Washington Ave,SS262, Albany, NY 12222 USA.
EM hhardy@cs.albany.edu; awb@cs.duke.edu; rbi@cs.duke.edu;
   armckenz@cs.duke.edu; tomek@cs.albany.edu; c.ursu@dcs.shef.ac.uk;
   n.webb@dcs.shef.ac.uk; minwu@cs.albany.edu
CR Allen J., 1997, DRAFT DAMSL DIALOG A
   Allen J., 2001, AI MAGAZINE
   Allen J.F., 1996, P 34 ANN M ASS COMP
   ALLEN JF, 1995, J EXP THEOR ARTIF IN, V7, P7, DOI 10.1080/09528139508953799
   AUSTIN JL, 1962, HOW DO THINGS WORDS
   BIERMANN A, UNPUB CALLER IDENTIF
   Brill E, 1992, P 3 C APPL NAT LANG
   Chu-Carroll J, 1999, COMPUT LINGUIST, V25, P361
   COLE R, 1991, P IEEE INT C AC SPEE
   CORTES C, 2003, P ICASSP 03 HONG KON
   Cunningham H., 2002, P 40 ANN M ASS COMP
   Cunningham H, 2000, CS0010 U SHEFF DEP C
   DAHLBACK N, 1992, P 14 ANN C COGN SCI
   EFABBRIZIO G, 2002, P 7 INT C SPOK LANG
   FERNANDEZ R, 2004, P 20 INT C COMP LING
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   HARDY H, 2003, RES DIRECTIONS DIALO
   Hardy H., 2004, P 42 ANN M ASS COMP
   HARDY H, 2003, EUROSPEECH 2003
   Hardy Hilda, 2002, P ISLE WORKSH DIAL T
   HILD H, 1995, P EUR, V2, P1977
   Johnston M., 2002, P 40 ANN M ASS COMP
   Jurafsky D., 1998, 30 J HOPK U CTR LANG
   KARIS D, 1991, IEEE J SEL AREA COMM, V9, P574, DOI 10.1109/49.81951
   Lamel L, 2002, SPEECH COMMUN, V38, P131, DOI 10.1016/S0167-6393(01)00048-6
   Lamel L., 1999, P IEEE INT C AC SPEE, P501
   LEVIN E, ICSLP 2000
   MAYNARD D, 2003, EXPERT UPDATE
   MAYNARD S, 2003, RECENT ADV NATURAL L
   MEYER M, 1997, P EUR, P1579
   Peckham J., 1993, P 3 EUR C SPEECH COM, P33
   Reithinger N., 1997, P 5 EUR C SPEECH COM, P2235
   ROBERTSON SE, 1995, NATL I STANDARDS TEC, P219
   SAIC, 1998, P 7 MESS UND C MUC 7
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   SENEFF S, 1998, ICSLP 1998
   SENEFF S, 2000, SAT DIAL WORKSH ANLP
   Singhal A., 1996, SIGIR Forum, P21
   Stolcke A, 2000, COMPUT LINGUIST, V26, P339, DOI 10.1162/089120100561737
   Vijay-Shanker K., 1998, P 36 ANN M ASS COMP
   WALKER M, 2001, EUROSPEECH 2001
   WALKER M, 2002, ICSLP 2002
   Walker MA, 2000, J ARTIF INTELL RES, V12, P387, DOI 10.1613/jair.713
   WARD W, 1999, IEEE ASRU, P341
   XU W, 2000, ANLP NAACL WORKSH CO, P42
   YOUNG SJ, 2002, INT C SPOK LANG PROC
   ZUE V, 1994, SPEECH COMMUN, V15, P331, DOI 10.1016/0167-6393(94)90083-3
   Zue V., 2000, IEEE T SPEECH AUDIO, V8
NR 48
TC 8
Z9 8
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0167-6393
EI 1872-7182
J9 SPEECH COMMUN
JI Speech Commun.
PD MAR-APR
PY 2006
VL 48
IS 3-4
BP 354
EP 373
DI 10.1016/j.specom.2005.07.006
PG 20
WC Acoustics; Computer Science, Interdisciplinary Applications
SC Acoustics; Computer Science
GA 016ZS
UT WOS:000235664500009
DA 2019-06-15
ER

PT B
AU Chen, Y
   Zhou, M
   Wang, SL
AF Chen, Yi
   Zhou, Ming
   Wang, Shilong
GP COLING
TI Reranking Answers for Definitional QA Using Language Modeling
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Statistical ranking methods based on centroid vector (profile) extracted from external knowledge have become widely adopted in the top definitional QA systems in TREC 2003 and 2004. In these approaches, terms in the centroid vector are treated as a bag of words based on the independent assumption. To relax this assumption, this paper proposes a novel language model-based answer reranking method to improve the existing bag-of-words model approach by considering the dependence of the words in the centroid vector. Experiments have been conducted to evaluate the different dependence models. The results on the TREC 2003 test set show that the reranking approach with biterm language model, significantly outperforms the one with the bag-of-words model and unigram language model by 14.9% and 12.5% respectively in F-Measure(5).
C1 [Chen, Yi] Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
RP Chen, Y (reprint author), Chongqing Univ, Sch Software Engn, Chongqing 400044, Peoples R China.
EM 126cy@126.com; mingzhou@microsoft.com; slwang@cqu.edu.cn
CR BLAIRGOLDENSOHN S, 2003, P 12 TEXT RETR C TRE, P336
   Brill E, 2001, P TREC 10 C NIST GAI, P183
   Cao XL, 2005, J LIQ CHROMATOGR R T, V28, P2005, DOI 10.1081/JLC-200063655
   Chen S. F., 1996, P 34 ANN M ASS COMP, P310, DOI DOI 10.3115/981863.981904
   Cui H., 2004, P 13 WORLD WID WEB C, P90
   ELLEN M, 2002, P 11 TEXT RETRIEVAL
   GAO JF, 2004, P 27 ANN INT ACM SIG
   Lafferty John, 2001, P 24 ANN INT ACM SIG, P111, DOI DOI 10.1145/383952.383970
   LIN CY, 2002, P 19 INT C COMP LING
   MAGNINI B, 2002, P 40 ANN M ASS COMP
   Miller DRH, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P214, DOI 10.1145/312624.312680
   PAPINENI K, 2001, RC22176W0109022 IBM
   Ponte J. M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P275, DOI 10.1145/290941.291008
   PRAGER J, 2001, P HUM LANG TECHN C H
   RAVICHANDRAN D, 2002, P 40 ANN M ASS COMP, P41, DOI DOI 10.3115/1073083.1073092
   SONG F, 1999, P 22 ANN INT ACM SIG, P279, DOI DOI 10.1145/312624.312698
   Srikanth M., 2002, P 2002 ACM SIGIR C R
   VOORHEES EM, 2003, P 12 TEXT RETRIEVAL
   VOORHEES EM, 2004, P 12 TEXT TETRIEVAL
   WU L, 2004, P 13 TEXT RETRIEVAL
   XU J, 2003, P 12 TEXT RETRIEVAL
   XU J, 2005, P 14 INT C WORLD WID, P811
   Zhai C., 2001, P 24 ANN INT ACM SIG, P334, DOI [10.1145/383952, DOI 10.1145/383952.384019]
   Zhang XW, 2003, DIAM RELAT MATER, V12, P1, DOI 10.1016/S0925-9635(02)00246-7
NR 24
TC 8
Z9 8
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1081
EP 1088
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200136
DA 2019-06-15
ER

PT B
AU Hagiwara, M
   Ogawa, Y
   Toyama, K
AF Hagiwara, Masato
   Ogawa, Yasuhiro
   Toyama, Katsuhiko
GP COLING
TI Selection of Effective Contextual Information for Automatic Synonym
   Acquisition
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Various methods have been proposed for automatic synonym acquisition, as synonyms are one of the most fundamental lexical knowledge. Whereas many methods are based on contextual clues of words, little attention has been paid to what kind of categories of contextual information are useful for the purpose. This study has experimentally investigated the impact of contextual information selection, by extracting three kinds of word relationships from corpora: dependency, sentence co-occurrence, and proximity. The evaluation result shows that while dependency and proximity perform relatively well by themselves, combination of two or more kinds of contextual information gives more stable performance. We've further investigated useful selection of dependency relations and modification categories, and it is found that modification has the greatest contribution, even greater than the widely adopted subject-object combination.
C1 [Hagiwara, Masato; Ogawa, Yasuhiro; Toyama, Katsuhiko] Nagoya Univ, Grad Sch Informat Sci, Chikusa Ku, Nagoya, Aichi 4648603, Japan.
RP Hagiwara, M (reprint author), Nagoya Univ, Grad Sch Informat Sci, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648603, Japan.
EM hagiwara@kl.i.is.nagoya-u.ac.jp; yasuhiro@kl.i.is.nagoya-u.ac.jp;
   toyama@kl.i.is.nagoya-u.ac.jp
CR Baroni M., 2004, P 4 INT C LANG RES E
   Briscoe EJ, 2002, P PARSEVAL WORKSH 3, P4
   BRISCOE T, 2002, P 3 INT C LANG RES E, P1499
   COLLINS, 2002, COLLINS COBUILD MLD
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   HAGIWARA M, 2005, P 2 INT JOINT C NAT, P334
   HARRIS Z, 1985, PHILOS LINGUISTICS, P26
   Hindle D., 1990, P 28 ANN M ASS COMP, P268
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   KOJIMA K, 2004, P FOR INF TECHN FIT2
   Lin Dekang, 1998, P 36 ANN M ASS COMP, P786
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   NAGAO M, 1996, IWANAMI SOFTWARE SCI, V15
NR 14
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 353
EP 360
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200045
DA 2019-06-15
ER

PT B
AU Sproat, R
   Tao, T
   Zhai, CX
AF Sproat, Richard
   Tao, Tao
   Zhai, ChengXiang
GP COLING
TI Named Entity Transliteration with Comparable Corpora
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper we investigate Chinese-English name transliteration using comparable corpora, corpora where texts in the two languages deal in some of the same topics - and therefore share references to named entities - but are not translations of each other. We present two distinct methods for transliteration, one approach using phonetic transliteration, and the second using the temporal distribution of candidate pairs. Each of these approaches works quite well, but by combining the approaches one can achieve even better results. We then propose a novel score propagation method that utilizes the co-occurrence of transliteration pairs within document pairs. This propagation method achieves further improvement over the best results from the previous step.
C1 [Sproat, Richard; Tao, Tao; Zhai, ChengXiang] Univ Illinois, Urbana, IL 61801 USA.
RP Sproat, R (reprint author), Univ Illinois, Urbana, IL 61801 USA.
EM rws@uiuc.edu; taotao@cs.uiuc.edu; czhai@cs.uiuc.edu
CR BALLESTEROS L, 1998, RES DEV INFORM RETRI, P64
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Carlson A, 1999, UIUCDCSR992101
   Franz M., 1998, TEXT RETRIEVAL C, P104
   FUNG P, 1995, P 33 ANN M ASS COMP, P236
   GAO W, 2004, IJCNLP, P374
   Kantor P. B., 2000, Information Retrieval, V2, P165, DOI 10.1023/A:1009902609570
   KAY M, 1993, COMPUTATIONAL LINGUI, V19, P75
   KNIGHT K, 1998, CL, V24
   Kruskal J, 1999, TIME WARPS STRING ED, P1
   LI X, 2004, NAACL 2004
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   MASUICHI H, 2000, BOOTSTRAPPING METHOD
   MENG H, 2001, P AUT SPEECH REC UND
   Rapp R., 1995, P 33 ANN M ASS COMP, P320, DOI DOI 10.3115/981658.981709
   Sadat F., 2003, ACL 03, P141
   Salton  G., 1983, INTRO MODERN INFORM
   SPROAT R, 1996, CL, V22
   TANAKA K, 1996, P COLING 1996
   TAO T, 2006, EMNLP 2006
   TAO T, 2005, KDD, P691
   TAYLOR P, 1998, P 3 ESCA WORKSH SPEE, P147
   Zhang Y., 2004, SIGIR 2004, P162
NR 23
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 73
EP 80
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200010
DA 2019-06-15
ER

PT B
AU Wermter, J
   Hahn, U
AF Wermter, Joachim
   Hahn, Udo
GP COLING
TI You Can't Beat Frequency (Unless You Use Linguistic Knowledge) - A
   Qualitative Evaluation of Association Measures for Collocation and Term
   Extraction
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In the past years, a number of lexical association measures have been studied to help extract new scientific terminology or general-language collocations. The implicit assumption of this research was that newly designed term measures involving more sophisticated statistical criteria would outperform simple counts of co-occurrence frequencies. We here explicitly test this assumption. By way of four qualitative criteria, we show that purely statistics-based measures reveal virtually no difference compared with frequency of occurrence counts, while linguistically more informed metrics do reveal such a marked difference.
C1 [Wermter, Joachim; Hahn, Udo] Univ Jena, Language & Informat Engn Lab, D-07743 Jena, Germany.
RP Wermter, J (reprint author), Univ Jena, Language & Informat Engn Lab, D-07743 Jena, Germany.
EM wermter@coling-uni-jena.de; hahn@coling-uni-jena.de
CR Daille B., 1996, BALANCING ACT COMBIN, V1, P49
   Evert S., 2001, ACL 01, P188
   Frantzi K., 2000, International Journal on Digital Libraries, V3, P115, DOI 10.1007/s007999900023
   Jacquemin C., 1999, P 37 ANN M ASS COMP, P341, DOI DOI 10.3115/1034678.1034733
   Jacquemin Christian, 2001, SPOTTING DISCOVERING
   KRENN B, 2001, P ACL WORKSH COLL TO
   Lin D., 1998, COLING ACL 98, V2, P768
   LIN D, 1999, P 37 ANN M ASS COMP, P317
   Manning C.D., 1999, FDN STAT NATURAL LAN
   *NAT LIB MED, 2004, UN MED LANG SYST
   NENADIC G, 2004, COLING 2004, P604
   Sachs L., 1984, APPL STAT HDB TECHNI
   WERMTER J, 2004, COLING GENEVA 2004, V2, P980
   WERMTER J, 2005, HLT 05, P843
NR 14
TC 8
Z9 8
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 785
EP 792
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200099
DA 2019-06-15
ER

PT B
AU Chen, F
   Farahat, A
   Brants, T
AF Chen, F
   Farahat, A
   Brants, T
GP acl
TI Multiple similarity measures and source-pair information in story link
   detection
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB State-of-the-art story link detection systems, that is, systems that determine whether two stories are about the same event or linked, are usually based on the cosine-similarity measured between two stories. This paper presents a method for improving the performance of a link detection system by using a variety of similarity measures and using source-pair specific statistical information. The utility of a number of different similarity measures, including cosine, Hellinger, Tanimoto, and clarity, both alone and in combination, was investigated. We also compared several machine learning techniques for combining the different types of information. The techniques investigated were SVMs, voting, and decision trees, each of which makes use of similarity and statistical information differently. Our experimental results indicate that the combination of similarity measures and source-pair specific statistical information using an SVM provides the largest improvement in estimating whether two stories are linked; the resulting system was the best-performing link detection system at TDT-2002.
C1 Palo Alto Res Ctr, Palo Alto, CA 94304 USA.
RP Chen, F (reprint author), Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.
CR ALLAN J, 2002, P TOP DET TRACK WORK
   Allan James, 2000, P TOP DET TRACK WORK
   BELKIN NJ, 1995, INFORM PROCESS MANAG, V31, P431, DOI 10.1016/0306-4573(94)00057-A
   Brants T., 2002, INT C INF KNOWL MAN, P211
   Breiman L., 1984, CLASSIFICATION REGRE
   Brill E., 1998, P COLING ACL 98, V1, P191
   CARBONELL J, 2001, CMU TDT REPORT SLIDE
   CHEN F, 2003, P HLT NAACL 2003 COM, P13
   CIERI C, 2003, P TOP DET TRACK WORS
   Cristianini N, 2000, SUPPORT VECTOR MACHI
   Croft W. B., 2001, DELOS WORKSH PERS RE, P49
   Dietterich T. G., 2000, MULTIPLE CLASSIER SY
   Duda RO, 1973, PATTERN CLASSIFICATI
   Frank E., 1999, DATA MINING PRACTICA
   Joachims T, 1999, ADV KERNEL METHODS S
   Joachims T., 1998, P 10 EUR C MACH LEAR, P137
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Lavrenko V., 2002, P HLT 2002 SAN DIEG
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   VANGESTEL T, 2000, 0037 ESATSISTA KU LE
   2002, 2002 TOPIC DETECTION
NR 21
TC 8
Z9 11
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 313
EP 320
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100040
DA 2019-06-15
ER

PT B
AU Munteanu, DS
   Fraser, A
   Marcu, D
AF Munteanu, DS
   Fraser, A
   Marcu, D
GP acl
TI Improved machine translation performance via parallel sentence
   extraction from comparable corpora
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We present a novel method for discovering parallel sentences in comparable corpora. We train a maximum entropy classifier that, given a pair of sentences, can reliably determine whether or not they are translations of each other. Using this approach we extract parallel data from large, Gigaword, Arabic and English newspaper corpora. We evaluate the quality of the extracted data by showing it improves the performance of a baseline statistical machine translation system.
C1 Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Munteanu, DS (reprint author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
EM dragos@isi.edu; fraser@isi.edu; marcu@isi.edu
CR BARZILAY R, 2003, P C EMP METH NAT LAN
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Brown P. F., 1990, Computational Linguistics, V16, P79
   CALLAN JP, 1995, INFORM PROCESS MANAG, V31, P327, DOI 10.1016/0306-4573(94)00050-D
   DARROCH JN, 1974, ANN MATH STAT, V43, P95
   Diab M, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P255
   Diab M., 2000, P C CONT BAS MULT IN
   ECHIHABI A, 2003, P 41 ANN M ASS COMP, P16
   Fung P., 1998, P 17 INT C COMP LING, V1, P414
   Koehn P, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P711
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   OCH FJ, 2003, COMPUTATIONAL LINGUI, V29
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Rapp R, 1999, P 37 ANN M ASS COMP, P519, DOI DOI 10.3115/1034678.1034756
   UTIYAMA M, 2003, P 41 ANN M ASS COMP, P72
   VOGEL S, 2003, P 10 C EUR CHAPT ASS, P175
   Zhao B, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P745, DOI 10.1109/ICDM.2002.1184044
NR 18
TC 8
Z9 8
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 265
EP 272
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100034
DA 2019-06-15
ER

PT B
AU Soricut, R
   Brill, E
AF Soricut, R
   Brill, E
GP acl
TI Automatic question answering: Beyond the factoid
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB In this paper we describe and evaluate a Question Answering system that goes beyond answering factoid questions. We focus on FAQ-like questions and answers, and build our system around a noisy-channel architecture which exploits both a language model for answers and a transformation model for answer/question terms, trained on a corpus of 1 million question/answer pairs collected from the Web.
C1 Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Soricut, R (reprint author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way, Marina Del Rey, CA 90292 USA.
CR AGICHTEN E, 2002, LEARNING FIND ANSWER
   Berger Adam, 2000, BRIDGING LEXICAL CHA, P192
   BERGER AL, 1999, INFORMATION RETRIEVA
   Brill E., 2001, DATA INTENSIVE QUEST
   Brown P. F., 1993, Computational Linguistics, V19, P263
   BURKE R, 1997, TR970I U CHICAGO DEP
   DUNNING T, 1993, ACCURATE METHODS STA, V19
   ECHIHABI A, 2003, NOISY CHANNEL APPROA
   GARJU R, 2003, P ACL 2003 WORKSH MU
   HERMJAKOB U, 2002, NATURAL LANGUAGE BAS
   ITTYCHERIAH A, 2002, P TREC 2002 C NIST G
   KWOK CCT, 2001, SCALING QUESTION ANS
   LIN C, 2003, P HLT NAACL
   MOLDOVAN D, 2002, P TREC 2002 C NIST G
   Och F. J., 2003, P ACL 2003 SAPP JAP
   PAPINENI K, 2002, BLEU METHOD AUT EV M
   PASCA M, 2001, P NAACL 2001 WORKSH
   PRAGER JM, 2001, P TREC 2002 C NIST G
   RADEV D, 2001, 10 INT C INF KNOW MA
   XU J, 2002, P TREC 2002 C NIST G
NR 20
TC 8
Z9 9
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 57
EP 64
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100008
DA 2019-06-15
ER

PT B
AU Dickinson, M
   Meurers, WD
AF Dickinson, M
   Meurers, WD
GP ACL
TI Detecting errors in part-of-speech annotation
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We propose a new method for detecting errors in "gold-standard" part-of-speech annotation. The approach locates errors with high precision based on n-grams occurring in the corpus with multiple taggings. Two further techniques, closed-class analysis and finite-state tagging guide patterns, are discussed. The success of the three approaches is illustrated for the Wall Street Journal corpus as part of the Penn Treebank.
C1 Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
CR AGRAWAL R, 1994, VLDB, P487
   BAKER JP, 1997, CONSISTENCY ACCURACY, P243
   Brants Thorsten, 2000, P LREC ATH GREEC
   BRYANT Michael, 1994, P 15 INT C COMP LING, P622
   ESKIN E, 2000, P NAACL SEATTL WASH
   GARSIDE R, 1997, CORPUS ANNOTATION LI
   HIRAKAWA H, 2000, P COLING SAARBR GERM
   Kveton P., 2002, Text, Speech and Dialogue. 5th International Conference, TSD 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2448), P19
   Leech Geoffrey, 1997, BRIEF USERS GUIDE GR
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   MULLER FH, 2002, P COLING TAIP TAIW
   Oliva K., 2001, Text, Speech and Dialogue. 4th International Conference, TSD 2001. Proceedings (Lecture Notes in Computer Science Vol.2166), P39
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   SANTORINI B, 1990, THESIS UPENN PHILADE
   Schapire Robert E., 1999, P 1999 JOINT SIGDAT, P38
   SINCLAIR JM, 1999, DIRECTIONS CORPUS LI, P379
   SKUT W, 1997, P ANLP WASH DC
   van Halteren H., 2000, P 2 WORKSH LING INT
   VOUTILAINEN A, 1995, P 7 C EACL DUBL IR
NR 19
TC 8
Z9 8
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 107
EP 114
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200015
DA 2019-06-15
ER

PT B
AU Bejan, CA
   Harabagiu, S
AF Bejan, Cosmin Adrian
   Harabagiu, Sanda
GP Assoc Computat Linguist
TI Unsupervised Event Coreference Resolution with Rich Linguistic Features
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper examines how a new class of nonparametric Bayesian models can be effectively applied to an open-domain event coreference task. Designed with the purpose of clustering complex linguistic objects, these models consider a potentially infinite number of features and categorical outcomes. The evaluation performed for solving both within-and cross-document event coreference shows significant improvements of the models when compared against two baselines for this task.
C1 [Bejan, Cosmin Adrian] Univ Southern Calif, Inst Creat Technol, Marina Del Rey, CA 90292 USA.
   [Harabagiu, Sanda] Univ Texas Dallas, Human Language Technol Inst, Richardson, TX 75083 USA.
RP Bejan, CA (reprint author), Univ Southern Calif, Inst Creat Technol, Marina Del Rey, CA 90292 USA.
CR ACE- Event, 2005, ACE AUT CONT EXTR EN
   Ahn D, 2006, P WORKSH ANN REAS TI, P1
   Allan J., 1998, P DARPA BROADC NEWS, P194
   Bagga A, 1998, INT C LANG RES EV W, V1, P1, DOI DOI 10.3115/980845.980859
   Bagga A., 1999, P ACL 99 WORKSH COR, P1
   Baker C.F., 1998, P 36 ANN M ASS COMP
   Beal M, 2002, ADV NEURAL INFORM PR, V14
   Bejan C. A., 2007, P 20 FLOR ART INT RE
   Bejan Cosmin Adrian, 2008, P 6 INT C LANG RES E
   Bejan Cosmin Adrian, 2009, ADV NEURAL INFORM PR, V23
   Bejan Cosmin Adrian, 2007, P 4 INT WORKSH SEM E, P460
   Chen Z., 2009, P 2009 WORKSH GRAPH, P54
   Davidson D., 1985, ACTIONS EVENTS PERSP, P172
   Davidson Donald, 1969, ESSAYS ACTIONS EVENT
   DEMARNEFFE MC, 2008, P 46 ANN M ASS COMP, P1039
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360
   Fillmore Charles J., 1982, LINGUISTICS MORNING
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Ghahramani Z., 2007, BAYESIAN STAT, V8, P201
   GRIFFITHS T, 2006, ADV NEURAL INFORM PR, V18, P475
   Haghighi A.D., 2005, P HUM LANG TECHN C C, P387, DOI DOI 10.3115/1220575.1220624
   Haghighi Aria, 2007, ANN M ASS COMP LING, P848
   Hasler Laura, 2009, P 7 DISC AN AN RES C
   Humphreys Kevin, 1997, P WORKSH OP FACT PRA, P75
   Lowe J. B., 1997, P SIGLEX WORKSH TAGG, P18
   Luo X., 2005, P C HUM LANG TECHN E, P25, DOI DOI 10.3115/1220575.1220579
   Malpas J., 2009, STANFORD ENCY PHILOS
   Narayanan S., 2004, P 20 INT C COMP LING, DOI 10.3115/1220355.1220455
   Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Poon Hoifung, 2008, P 2008 C EMP METH NA, P650
   Pustejovsky J, 2003, P 5 INT WORKSH COMP
   Pustejovsky J, 2003, CORPUS LINGUISTICS, P647
   Quine W. V. O., 1985, EVENTS, P162
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Van Gael J., 2008, P 25 INT C MACH LEAR, V25, P1088
   Van Gael Jurgen, 2008, ADV NEURAL INFORM PR, V21
   Vincent Ng, 2008, P EMNLP 08, P640
NR 40
TC 7
Z9 8
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1412
EP 1422
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300143
DA 2019-06-15
ER

PT S
AU Dale, R
   Viethen, J
AF Dale, Robert
   Viethen, Jette
BE Krahmer, E
   Theune, M
TI Attribute-Centric Referring Expression Generation
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
AB In this chapter, we take the view that much of the existing work on the generation of referring expressions has focused on aspects of the problem that appear to be somewhat artificial when we look more closely at human-produced referring expressions. In particular, we argue that an over-emphasis on the extent to which each property in a description performs a discriminatory function has blinded us to alternative approaches to referring expression generation that might be better-placed to provide an explanation of the variety we find in human-produced referring expressions. On the basis of an analysis of a collection of such data, we propose an alternative view of the process of referring expression generation which we believe is more intuitively plausible, is a better match for the observed data, and opens the door to more sophisticated algorithms that are freed of the constraints adopted in the literature so far.
C1 [Dale, Robert; Viethen, Jette] Macquarie Univ, Ctr Language Technol, Sydney, NSW 2109, Australia.
RP Dale, R (reprint author), Macquarie Univ, Ctr Language Technol, Sydney, NSW 2109, Australia.
EM rdale@science.mq.edu.au; jviethen@science.mq.edu.au
OI Dale, Robert/0000-0001-7864-6942
CR Belz A., 2008, P 5 INT NAT LANG GEN, P183
   CARLETTA JC, 1992, THESIS U EDINBURGH
   Dale R., 1991, Computational Intelligence, V7, P252, DOI 10.1111/j.1467-8640.1991.tb00399.x
   DALE R, 1995, COGNITIVE SCI, V19, P233
   DALE R, 1989, P 27 ANN M ASS COMP
   Gardent C., 2002, P 40 ANN M ASS COMP
   GATT A, 2008, P 5 INT NAT LANG GEN, P198
   GATT A, 2006, P 21 COLING 44 ACL C
   HORACEK H, 2004, P 3 INT C NAT LANG G, P70
   JAMESON A, 1982, P 5 EUR C ART INT OR, P222
   JORDAN PW, 2002, INFORM SHARING REFER
   KELLEHER J, 2006, P 21 COLING 44 ACL C
   Krahmer E, 2003, COMPUT LINGUIST, V29, P53, DOI 10.1162/089120103321337430
   KRAHMER E, 2002, INFORM SHARING REFER, P223
   Quinlan J. R, 1993, C4 5 PROGRAMS MACHIN
   van Deemter K, 2002, COMPUT LINGUIST, V28, P37, DOI 10.1162/089120102317341765
   van Deemter K, 2006, COMPUT LINGUIST, V32, P195, DOI 10.1162/coli.2006.32.2.195
   VANDERSLUIS I, 2005, THESIS TILBURG U NET
   Viethen J., 2006, P 4 INT C NAT LANG G, P63, DOI [10.3115/1706269.1706283, DOI 10.3115/1706269.1706283]
   Viethen J., 2008, P 5 INT C NAT LANG G
   VIETHEN J, 2008, AUSTR LANG TECHN ASS, P160
   Witten IH, 2005, DATA MINING PRACTICA
NR 22
TC 7
Z9 7
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 163
EP 179
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600009
DA 2019-06-15
ER

PT B
AU Kazama, J
   De Saeger, S
   Kuroda, K
   Murata, M
   Torisawa, K
AF Kazama, Jun'ichi
   De Saeger, Stijn
   Kuroda, Kow
   Murata, Masaki
   Torisawa, Kentaro
GP Assoc Computat Linguist
TI A Bayesian Method for Robust Estimation of Distributional Similarities
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID MODELS
AB Existing word similarity measures are not robust to data sparseness since they rely only on the point estimation of words' context profiles obtained from a limited amount of data. This paper proposes a Bayesian method for robust distributional word similarities. The method uses a distribution of context profiles obtained by Bayesian estimation and takes the expectation of a base similarity measure under that distribution. When the context profiles are multinomial distributions, the priors are Dirichlet, and the base measure is the Bhattacharyya coefficient, we can derive an analytical form that allows efficient calculation. For the task of word similarity estimation using a large amount of Web data in Japanese, we show that the proposed measure gives better accuracies than other well-known similarity measures.
C1 [Kazama, Jun'ichi; De Saeger, Stijn; Kuroda, Kow; Torisawa, Kentaro] Natl Inst Informat & Commun Technol NICT, MASTAR Project, Language Infrastruct Grp, 3-5 Hikaridai,Seika Cho, Kyoto 6190289, Japan.
   [Murata, Masaki] Tottori Univ, Dept Informat, Tottori 6808550, Japan.
   [Murata, Masaki] Tottori Univ, Knowledge Engn Fac, Grad Sch Engn, Tottori 6808550, Japan.
RP Kazama, J (reprint author), Natl Inst Informat & Commun Technol NICT, MASTAR Project, Language Infrastruct Grp, 3-5 Hikaridai,Seika Cho, Kyoto 6190289, Japan.
EM kazama@nict.go.jp; stijn@nict.go.jp; kuroda@nict.go.jp;
   murata@ike.tottori-u.ac.jp; torisawa@nict.go.jp
CR BHATTACHARYYA A, 1943, B CALCUTTA MATH SOC, V49, P214
   Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452
   Chen SF, 1998, TR1098 HARV U COMP S
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CRL, 2002, EDR EL DICT VERS 2 0
   DAGAN I, 1995, COMPUT SPEECH LANG, V9, P123, DOI 10.1006/csla.1995.0008
   Dagan I, 1999, MACH LEARN, V34, P43, DOI 10.1023/A:1007537716579
   Dagan Ido, 1997, P ACL 97
   Dagan Ido, 1994, P ACL 94
   Grefenstette G., 1994, EXPLORATIONS AUTOMAT
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hindle D., 1990, P 28 ANN M ASS COMP, P268
   Kazama Jun'ichi, 2008, P ACL 08 HLT
   Kazama Jun'ichi, 2009, P 15 ANN M ASS NAT L
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   Mochihashi Daichi, 2009, P JOINT C 47 ANN M A, P100
   Murata Masaki, 2004, P LREC 2004 WORKSH C, P6
   Pantel P., 2009, P 2009 C EMP METH NA, P938
   Pantel P., 2002, P 8 ACM SIGKDD INT C, P613
   Rauber TW, 2008, PATTERN RECOGN, V41, P637, DOI 10.1016/j.patcog.2007.06.023
   Shinzato Keiji, 2008, P IJCNLP 2008
   Teh YW, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P985
   Terada Akira, 2004, IPSJ SIG TECHNICAL R, P87
NR 23
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 247
EP 256
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300026
DA 2019-06-15
ER

PT S
AU Rieser, V
   Lemon, O
AF Rieser, Verena
   Lemon, Oliver
BE Krahmer, E
   Theune, M
TI Natural Language Generation as Planning under Uncertainty for Spoken
   Dialogue Systems
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
DE Reinforcement Learning; Adaptivity; Spoken Dialogue Systems; Information
   Presentation; Incremental NLG; Optimisation; data-driven methods
AB We present and evaluate a new model for Natural Language Generation (NLG) in Spoken Dialogue Systems, based on statistical planning, given noisy feedback from the current generation context (e.g. a user and a surface realiser). The model is adaptive and incremental at the turn level, and optimises NLG actions with respect to a data-driven objective function. We study its use in a standard NLG problem: how to present information (in this case a set of search results) to users, given the complex trade-offs between utterance length, amount of information conveyed, and cognitive load. We set these trade-offs in an objective function by analysing existing MATCH data. We then train a NLG policy using Reinforcement Learning (RL), which adapts its behaviour to noisy feedback from the current generation context. This policy is compared to several baselines derived from previous work in this area. The learned policy significantly outperforms all the prior approaches.
C1 [Rieser, Verena] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
   [Lemon, Oliver] Heriot Watt Univ, Sch Math & Comp Sci, Edinburgh EH14 4AS, Midlothian, Scotland.
RP Rieser, V (reprint author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
EM vrieser@inf.ed.ac.uk; o.lemon@hw.ac.uk
OI Lemon, Oliver/0000-0001-9497-4743; Rieser, Verena/0000-0001-6117-4395
FU European Community's Seventh Framework Programme (FP7) [216594]; EPSRC
   [EP/E019501/1.]
FX The research leading to these results has received funding from the
   European Communitys Seventh Framework Programme (FP7/2007-2013) un-der
   grant agreement no. 216594 (CLASSiC project project:
   www.classic-project.org) and from the EPSRC project no. EP/E019501/1.
CR BADDELEY A, 2001, J COMMUN DISORD, V36, P189
   BOIDIN C, 2009, P INT SPEC SESS MACH
   Branavan S, 2009, P JOINT C 47 ANN M A, P82
   DEMBERG V, 2006, P 11 C EUR CHAPT ASS, P65
   Gasic M., 2008, P SIGDIAL WORKSH DIS, P112
   Henderson J., 2008, P 46 ANN M ASS COMP, P73
   Henderson J, 2008, COMPUT LINGUIST, V34, P487, DOI 10.1162/coli.2008.07-028-R2-05-82
   JANARTHANAM S, 2008, P SEMDIAL, P133
   Janarthanam S, 2010, LECT NOTES ARTIF INT, V5790, P67, DOI 10.1007/978-3-642-15573-4_4
   KOLLER A, 2008, ICAPS
   KOLLER A, 2007, P 45 ANN M ASS COMP, P336
   LEMON O, 2008, P SEMDIAL
   LEMON O, COMPUTER SP IN PRESS
   Liu X., 2009, P 1 INT WORKSH SPOK
   Moore J., 2004, P FLAIRS
   NAKATSU C, 2006, P ACL
   Oh AH, 2002, COMPUT SPEECH LANG, V16, P387, DOI 10.1016/S0885-2308(02)00012-8
   Paek T, 2000, P 16 C UNC ART INT S, P455
   POLIFRONI J, 2008, P ACL, P479
   Rieser V., 2008, P ACL, P638
   RIESER V, COMPUTATIONAL UNPUB
   RIESER V, 2008, J NATURAL LANGUAGE E, V15, P55
   Singh S, 2002, J ARTIF INTELL RES, V16, P105, DOI 10.1613/jair.859
   Stent A., 2004, P 42 ANN M ASS COMP, P79
   STENT A, 2002, P ICSLP
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   VANDEEMTER K, 2009, 12 EUR WORKSH NAT LA, P154
   WAHLSTER W, 1993, ARTIF INTELL, V16, P387
   Walker MA, 2004, COGNITIVE SCI, V28, P811, DOI [10.1016/j.cogsci.2004.06.002, 10.1016/j.cogsci.2004.06,002]
   WALKER MA, 2000, NATURAL LANGUAGE ENG, V6
   Walker M, 2007, J ARTIF INTELL RES, V30, P413, DOI 10.1613/jair.2329
   WHITTAKER S, 2003, P EUROSPEECH
   WHITTAKER S, 2002, P LREC
   WINTERBOER A, 2007, P INT ICSLP
   YOUNG S, 2007, ICASSP
NR 35
TC 7
Z9 7
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 105
EP +
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600006
DA 2019-06-15
ER

PT B
AU Selfridge, EO
   Heeman, PA
AF Selfridge, Ethan O.
   Heeman, Peter A.
GP Assoc Computat Linguist
TI Importance-Driven Turn-Bidding for Spoken Dialogue Systems
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID CONVERSATION; ORGANIZATION
AB Current turn-taking approaches for spoken dialogue systems rely on the speaker releasing the turn before the other can take it. This reliance results in restricted interactions that can lead to inefficient dialogues. In this paper we present a model we refer to as Importance-Driven Turn-Bidding that treats turn-taking as a negotiative process. Each conversant bids for the turn based on the importance of the intended utterance, and Reinforcement Learning is used to indirectly learn this parameter. We find that Importance-Driven Turn-Bidding performs better than two current turntaking approaches in an artificial collaborative slot-filling domain. The negotiative nature of this model creates efficient dialogues, and supports the improvement of mixed-initiative interaction.
C1 [Selfridge, Ethan O.; Heeman, Peter A.] Oregon Hlth & Sci Univ, Ctr Spoken Language Understanding, 20000 NW Walker Rd, Beaverton, OR 97006 USA.
RP Selfridge, EO (reprint author), Oregon Hlth & Sci Univ, Ctr Spoken Language Understanding, 20000 NW Walker Rd, Beaverton, OR 97006 USA.
EM selfridg@ohsu.edu; heemanp@ohsu.edu
CR Chu-Carroll Jennifer, 1995, P 33 ANN M ASS COMP, P136
   DeVault D, 2009, P SIGDIAL LOND UK, P11
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   DUNCAN S, 1974, J EXP SOC PSYCHOL, V10, P234, DOI 10.1016/0022-1031(74)90070-5
   English M., 2005, P C HUM LANG TECHN E, P1011
   Ferguson G., 1996, Proceedings. Third International Conference on Artificial Intelligence Planning Systems, P70
   Gravano A., 2009, P SIGDIAL, P253
   GUINN CI, 1996, P 34 ANN M ASS COMP, P278
   Hearst M, 1999, IEEE INTELL SYST APP, V14, P14, DOI 10.1109/5254.796083
   HEEMAN P, 2007, P 8 ANN C N AM CHAPT, P268
   Jonsdottir GR, 2008, LECT NOTES COMPUT SC, V5208, P162
   Larsson S., 2000, Natural Language Engineering, P323, DOI 10.1017/S1351324900002539
   Levin E, 2000, IEEE T SPEECH AUDI P, V8, P11, DOI 10.1109/89.817450
   Raux A., 2009, P HUM LANG TECHN 200, P629
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   SATO R, 2002, ICSLP 02, P861
   Schegloff EA, 2000, LANG SOC, V29, P1, DOI 10.1017/S0047404500001019
   Selfridge EO, 2009, 1 INT WORKSH SPOK DI
   Skantze G., 2009, P 12 C EUR CHAPT ASS, P745
   Strom N., 2000, 6 INT C SPOK LANG PR
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   Sutton S., 1996, ICSLP
   WALKER M, 1990, P 28 ANN M ASS COMP, P70
   Walker M., 1997, 5 EUR C SPEECH COMM
   Yang F, 2010, COMPUT SPEECH LANG, V24, P175, DOI 10.1016/j.csl.2009.04.003
NR 25
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 177
EP 185
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300019
DA 2019-06-15
ER

PT B
AU Tratz, S
   Hovy, E
AF Tratz, Stephen
   Hovy, Eduard
GP Assoc Computat Linguist
TI A Taxonomy, Dataset, and Classifier for Automatic Noun Compound
   Interpretation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB The automatic interpretation of noun-noun compounds is an important subproblem within many natural language processing applications and is an area of increasing interest. The problem is difficult, with disagreement regarding the number and nature of the relations, low inter-annotator agreement, and limited annotated data. In this paper, we present a novel taxonomy of relations that integrates previous relations, the largest publicly-available annotated dataset, and a supervised classification method for automatic noun compound interpretation.
C1 [Tratz, Stephen; Hovy, Eduard] Univ Southern Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Tratz, S (reprint author), Univ Southern Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
EM stratz@isi.edu; hovy@isi.edu
CR Ahn K., 2005, P TREC 2005
   Baldwin T., 2004, P ACL 2004 WORKSH MU
   Barker K., 1998, P 17 INT C COMP LING
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Brants T., 2006, WEB 1T 5 GRAM CORPUS
   Butnariu C., 2009, P NAACL HLT WORKSH S
   Butnariu C., 2008, P 22 INT C COMP LING
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Crammer K., J MACHINE LEARNING R
   DOWNING P, 1977, LANGUAGE, V53, P810, DOI 10.2307/412913
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Finin T. W., 1980, THESIS
   Girju R., 2005, COMPUTER SPEECH LANG, V19
   Girju R., 2007, P 45 ANN M ASS COMP
   Girju R., 2009, COMPUTATIONAL LINGUI, V35
   Jespersen O., 1949, MODERN ENGLISH GRAMM
   Kim SN., 2007, P 10 C PAC ASS COMP
   Kim Su N., 2005, P 2 INT JOINT C NAT
   Lauer M., 1995, P 33 M ASS COMP LING
   Lees R., 1960, GRAMMAR ENGLISH NOMI
   Levi J. N., 1978, SYNTAX SEMANTICS COM
   McCallum Andrew Kachites, 2002, MALLET MACHINE LEARN
   Moldovan D., 2004, P COMP LEX SEM WORKS
   Nakov P., 2005, P 9 C COMP NAT LANG
   Nakov P., 2008, P 13 INT C ART INT M
   Nastase V., 2006, P 21 NAT C ART INT A
   Nastase V., 2003, P 5 INT WORKSH COMP
   O Seaghdha D., 2007, P ACL 2007 STUD RES
   O Seaghdha D., 2009, P 12 C EUR ASS COMP
   Rosario Barbara, 2001, P 2001 C EMP METH NA
   Sandhaus E., 2008, NEW YORK TIMES ANNOT
   Sparck Jones K., 1983, COMPOUND NOUN INTERP
   Turney PD, 2006, COMPUT LINGUIST, V32, P379, DOI 10.1162/coli.2006.32.3.379
   Vanderwende L., 1994, P COLING 94
   Warren Beatrice, 1978, SEMANTIC PATTERNS NO
   Ye P., 2007, P 4 INT WORKSH SEM E
NR 36
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 678
EP 687
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300070
DA 2019-06-15
ER

PT B
AU Xiong, DY
   Zhang, M
   Li, HZ
AF Xiong, Deyi
   Zhang, Min
   Li, Haizhou
GP Assoc Computat Linguist
TI Error Detection for Statistical Machine Translation Using Linguistic
   Features
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Automatic error detection is desired in the post-processing to improve machine translation quality. The previous work is largely based on confidence estimation using system-based features, such as word posterior probabilities calculated from Nbest lists or word lattices. We propose to incorporate two groups of linguistic features, which convey information from outside machine translation systems, into error detection: lexical and syntactic features. We use a maximum entropy classifier to predict translation errors by integrating word posterior probability feature and linguistic features. The experimental results show that 1) linguistic features alone outperform word posterior probability based confidence estimation in error detection; and 2) linguistic features can further provide complementary information when combined with word confidence scores, which collectively reduce the classification error rate by 18.52% and improve the F measure by 16.37%.
C1 [Xiong, Deyi; Zhang, Min; Li, Haizhou] Inst Infocomm Res, Human Language Technol, 1 Fusionopolis Way,21-01 Connexis, Singapore 138632, Singapore.
RP Xiong, DY (reprint author), Inst Infocomm Res, Human Language Technol, 1 Fusionopolis Way,21-01 Connexis, Singapore 138632, Singapore.
EM dyxiong@i2r.a-star.edu.sg; mzhang@i2r.a-star.edu.sg;
   hli@i2r.a-star.edu.sg
RI Li, Haizhou/Q-6438-2019
OI Li, Haizhou/0000-0001-9158-9401
CR Akibay Yasuhiro, 2004, P COLING
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Blatz J, 2003, JHU CLSP SUMM WORKSH
   Elliott Debra, 2006, THESIS
   Gandrabur Simona, 2003, P HLT NAACL
   Jayaraman S., 2005, P EAMT
   Koehn P., 2003, P HLT NAACL
   Koehn P., 2007, P ACL DEM SESS
   Le Z, 2004, MAXIMUM ENTROPY MODE
   Levenshtein VI, 1966, SOVIET PHYS DOKLADY
   Och F. J, 2003, P ACL 2003
   Papineni Kishore, 2002, P ACL 2002
   Raybaud Sylvain, 2009, P EAMT 2009
   Sanchis Alberto, 2007, P MACH TRANSL SUMM
   Shi Yongmei, 2005, P HLT EMNLP 2005
   SLEATOR DD, 1993, P 3 INT WORKSH PARS
   Stolcke A., 2002, P INT C SPOK LANG PR, P901
   Ueffing N, 2007, COMPUT LINGUIST, V33, P9, DOI 10.1162/coli.2007.33.1.9
   Ueffing Nicola, 2003, P MT SUMM
   Zens Richard, 2006, HLT NAACL
NR 20
TC 7
Z9 7
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 604
EP 611
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300062
DA 2019-06-15
ER

PT B
AU Al-Onaizan, Y
   Papineni, K
AF Al-Onaizan, Yaser
   Papineni, Kishore
GP COLING
TI Distortion Models For Statistical Machine Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper, we argue that n-gram language models are not sufficient to address word reordering required for Machine Translation. We propose a new distortion model that can be used with existing phrase-based SMT decoders to address those n-gram language model limitations. We present empirical results in Arabic to English Machine Translation that show statistically significant improvements when our proposed model is used. We also propose a novel metric to measure word order similarity (or difference) between any pair of languages based on word alignments.
C1 [Al-Onaizan, Yaser; Papineni, Kishore] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Al-Onaizan, Y (reprint author), IBM Corp, TJ Watson Res Ctr, 1101 Kitchawan Rd, Yorktown Hts, NY 10598 USA.
EM onaizan@us.ibm.com; papineni@us.ibm.com
CR ALONAIZAN Y, 1999, STAT MACHINE TRANSLA
   ALONAIZAN Y, 2005, DARPA TIDES NIST MT
   BAHL LR, 1983, IEEE T PATTERN ANAL, V5, P179, DOI 10.1109/TPAMI.1983.4767370
   Berger A.L., 1996, United States Patent, Patent No. 5510981
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Brown P. F., 1990, Computational Linguistics, V16, P79
   GE N, 2004, DARPA TIDES NIST MT
   Knight K, 1999, COMPUT LINGUIST, V25, P607
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   Koehn P., 2004, P 6 C ASS MACH TRANS, P115
   Och FJ, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P161
   OCH FJ, 1999, JOINT C EMP METH NAT, P20
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311
   TILLMAN C, 2004, HLT NAACL 2004 SHORT, P101
   Tillmann C, 2003, COMPUT LINGUIST, V29, P97, DOI 10.1162/089120103321337458
   Tillmann C, 1997, P 35 ANN C ASS COMP, P289
   Vogel S., 1996, P 16 INT C COMP LING
   Wu D, 1996, P 34 ANN C ASS COMP, P152
   Xia F., 2004, P 20 INT C COMP LING
   YAMADA K, 2002, P 40 ANN M ASS COMP, P303
   ZENS R, 2003, P ACL 2003, P144
NR 21
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 529
EP 536
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200067
DA 2019-06-15
ER

PT B
AU Blake, C
AF Blake, Catherine
GP COLING
TI A Comparison of Document, Sentence, and Term Event Spaces
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID MATHEMATICAL-THEORY; COMMUNICATION; RETRIEVAL
AB The trend in Information retrieval systems is from document to sub-document retrieval, such as sentences in a summarization system and words or phrases in question-answering system. Despite this trend, systems continue to model language at a document level using the inverse document frequency (IDF). In this paper, we compare and contrast IDF with inverse sentence frequency (ISF) and inverse term frequency (ITF). A direct comparison reveals that all language models are highly correlated; however, the average ISF and ITF values are 5.5 and 10.4 higher than IDF. All language models appeared to follow a power law distribution with a slope coefficient of 1.6 for documents and 1.7 for sentences and terms. We conclude with an analysis of IDF stability with respect to random, journal, and section partitions of the 100,830 full-text scientific articles in our experimental corpus.
C1 Univ N Carolina, Sch Informat & Lib Sci, Chapel Hill, NC 27599 USA.
RP Blake, C (reprint author), Univ N Carolina, Sch Informat & Lib Sci, Chapel Hill, NC 27599 USA.
EM cablake@email.unc.edu
CR Baeza-Yates R., 1999, MODERN INFORM RETRIE
   Cancho RFI, 2005, EUR PHYS J B, V44, P249, DOI 10.1140/epjb/e2005-00121-8
   Church K. W., 1995, NAT LANG ENG, V1, P163, DOI DOI 10.1017/S1351324900000139
   CHURCH KW, 1999, NLP USING VERY LARGE
   GUITER H, 1982, STUDIES ZIPFS LAW
   HALEQUAN, 2002, 19 INT C COMP LING
   JONES KS, 2000, INFORM PROCESSING MA, V36, P799
   Kamps J, 2005, INFORM RETRIEVAL, V8, P631, DOI 10.1007/s10791-005-0750-7
   LADA A, 2000, ZIPF POWER LAWS PARE
   LUHN HP, 1958, IBM J RES DEV, V2, P159, DOI 10.1147/rd.22.0159
   Pickett Joseph P, 2000, AM HERITAGE DICT ENG
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Robertson S, 2004, J DOC, V60, P503, DOI [10.1108/00220410410560582, 10.1108/00220410560582]
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526
   ZIPF GK, 1999, HUMAN BEHAV PRINCIPL
NR 17
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 601
EP 608
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200076
DA 2019-06-15
ER

PT B
AU Cahill, A
   van Genabith, J
AF Cahill, Aoife
   van Genabith, Josef
GP COLING
TI Robust PCFG-Based Generation using Automatically Acquired LFG
   Approximations
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al., 2004) automatically extracted from treebanks, maximising the probability of a tree given an f-structure. We evaluate our approach using string-based evaluation. We currently achieve coverage of 95.26%, a BLEU score of 0.7227 and string accuracy of 0.7476 on the Perm-H WSJ Section 23 sentences of length <= 20.
C1 [Cahill, Aoife; van Genabith, Josef] Dublin City Univ, Sch Comp, NCLT, Dublin 9, Ireland.
RP Cahill, A (reprint author), Dublin City Univ, Sch Comp, NCLT, Dublin 9, Ireland.
EM acahill@computing.dcu.ie; josef@computing.dcu.ie
OI Cahill, Aoife/0000-0002-3519-7726
CR Abney SP, 1997, COMPUT LINGUIST, V23, P597
   Baayen H, 1996, COMPUT LINGUIST, V22, P155
   Bangalore S, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P159
   Bangalore S, 2000, P 18 INT C COMP LING, P42
   BELZ A, 2005, P 10 EUR WORKSH NAT, P15
   Burke M, 2004, PACLIC 18: Proceedings of the 18th Pacific Asia Conference on Language, Information and Computation, P161
   CAHILL A, 2005, J RES LANGUAGE COMPU, P247
   CAHILL A, 2004, P 42 ANN M ASS COMP, P320
   CALLAWAY C, 2003, P 18 INT JOINT C ART, P811
   Carrol J., 2005, P 2 INT JOINT C NAT, P165
   KAPLAN R, 2000, P COLING 2000 SAARBR, P141
   Kaplan Ronald, 1982, MENTAL REPRESENTATIO, P173
   Kay M., 1996, P 34 ANN M ASS COMP, P200
   Langkilde I, 2000, P 6 APPL NAT LANG PR, P170
   LANGKILDEGEARY I, 2002, 2 INT NAT LANG GEN C, P17
   Marcus Mitchell, 1994, P ARPA WORKSH HUM LA, P110
   NAKANISHI H, 2005, P INT WORKSH PARS TE
   ODONOVAN R, 2005, P LFG 05 BERG NORW, P334
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Ratnaparkhi A., 2000, P 1 ANN N AM ASS COM, P194
   VALLDAL E, 2005, P 10 MACH TRANSL SUM, P109
NR 21
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1033
EP 1040
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200130
DA 2019-06-15
ER

PT B
AU Ferret, O
   Zock, M
AF Ferret, Olivier
   Zock, Michael
GP COLING
TI Enhancing electronic dictionaries with an index based on associations
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID TIP
AB A good dictionary contains not only many entries and a lot of information concerning each one of them, but also adequate means to reveal the stored information. Information access depends crucially on the quality of the index. We will present here some ideas of how a dictionary could be enhanced to support a speaker/writer to find the word s/he is looking for. To this end we suggest to add to an existing electronic resource an index based on the notion of association. We will also present preliminary work of how a subset of such associations, for example, topical associations, can be acquired by filtering a network of lexical co-occurrences extracted from a corpus.
C1 [Ferret, Olivier] CEA, LIST, LIC2M, F-92265 Fontenay Aux Roses, France.
RP Ferret, O (reprint author), CEA, LIST, LIC2M, 18 Route Panorama, F-92265 Fontenay Aux Roses, France.
EM ferreto@zoe.cea.fr; michael.zock@lif.univ-mrs.fr
CR Agirre E., 2001, NAACL 01 WORKSH WORD
   Avancini H., 2003, 18 ACM S APPL COMP S
   Beeferman D, 1999, MACH LEARN, V34, P177, DOI 10.1023/A:1007506220214
   BILAC S, 2004, 10 ANN M ASS NAT LAN, P556
   BROWN R, 1966, J VERB LEARN VERB BE, V5, P325, DOI 10.1016/S0022-5371(66)80040-3
   Church Kenneth, 1990, COMPUTATIONAL LINGUI, V16, P177
   DUTOIT D, 2002, 15 EUR C ART INT ECA, P450
   El-Kahlout I. D., 2004, 2 GLOB WORDNET C BRN
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Ferret O., 2006, LREC 2006
   Ferret  O., 2002, COLING 2002, P260
   HARABAGIU SM, 1999, ACL SIGLEX99 STANDAR, P1
   Humble P, 2001, DICT LANGUAGE LEARNE
   Levelt WJM, 1999, BEHAV BRAIN SCI, V22, P1
   MAGNINI B, 2000, LREC 2000
   MANDALA R, 1999, EACL 99
   Melcuk I., 1995, INTRO LEXICOLOGIE EX
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Richardson S. W., 1998, ACL COLING MONTR CAN, P1098
   SANDA M, 1998, WORDNET ELECT LEXICA, P379
   Vigliocco G, 1997, PSYCHOL SCI, V8, P314, DOI 10.1111/j.1467-9280.1997.tb00444.x
   Vossen P., 1998, EUROWORDNET MULTILIN
   ZOCK M, 2004, COLING 2004 WORKSH E
   ZOCK M, 2002, SEMANET WORKSH COLIN
NR 24
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 281
EP 288
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200036
DA 2019-06-15
ER

PT B
AU Giuglea, AM
   Moschitti, A
AF Giuglea, Ana-Maria
   Moschitti, Alessandro
GP COLING
TI Semantic Role Labeling via FrameNet, VerbNet and PropBank
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This article describes a robust semantic parser that uses a broad knowledge base created by interconnecting three major resources: FrameNet, VerbNet and PropBank. The FrameNet corpus contains the examples annotated with semantic roles whereas the VerbNet lexicon provides the knowledge about the syntactic behavior of the verbs. We connect VerbNet and FrameNet by mapping the FrameNet frames to the VerbNet Intersective Levin classes. The PropBank corpus, which is tightly connected to the VerbNet lexicon, is used to increase the verb coverage and also to test the effectiveness of our approach. The results indicate that our model is an interesting step towards the design of more robust semantic parsers.
C1 [Giuglea, Ana-Maria; Moschitti, Alessandro] Univ Roma Tor Vergata, Dept Comp Sci, Rome, Italy.
RP Giuglea, AM (reprint author), Univ Roma Tor Vergata, Dept Comp Sci, Rome, Italy.
EM agiuglea@gmail.com; moschitti@info.uniroma2.it
OI Moschitti, Alessandro/0000-0003-2216-8034
CR Baker C. F., 2002, 28 ANN M BERK LING S
   CHARNIAK E, 2000, P NACL00 SEATTL WASH
   DANG HT, 1998, COLING ACL98
   Fillmore CH., 1968, UNIVERSALS LINGUISTI
   Gildea D., 2002, COMPUTATIONAL LINGUI
   Giuglea A. M., 2004, P WORKSH ONT KNOWL D
   GIUGLEA AM, 2006, P 17 EUR C ART INT R
   Joachims T, 1999, ADV KERNEL METHODS S
   JOHNSON C, 2003, FRAMENET THEORY PRAC
   KINGSBURY P, 2002, LREC02
   KIPPER K, 2000, AAAI00
   Levin B., 1993, ENGLISH VERB CLASSES
   LITKOWSKI K, 2004, SENSEVAL 3
   Marquez Lluis, 2005, P CONLL 2005
   MERLO P, 2001, CL J
   MOSCHITTI A, 2004, ACL04
   Pradhan S., 2005, MACHINE LEARNING J
   SHI L, 2005, P CICL 2005 MEX
   THOMPSON CA, 2003, 14 EUR C MACH LEARN
   Vapnik VN, 1995, NATURE STAT LEARNING
   XUE NW, 2004, P EMNLP 2004 BARC SP
NR 21
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 929
EP 936
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200117
DA 2019-06-15
ER

PT B
AU Gliozzo, A
   Strapparava, C
AF Gliozzo, Alfio
   Strapparava, Carlo
GP COLING
TI Exploiting Comparable Corpora and Bilingual Dictionaries for
   Cross-Language Text Categorization
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Cross-language Text Categorization is the task of assigning semantic classes to documents written in a target language (e.g. English) while the system is trained using labeled documents in a source language (e.g. Italian).
   In this work we present many solutions according to the availability of bilingual resources, and we show that it is possible to deal with the problem even when no such resources are accessible. The core technique relies on the automatic acquisition of Multilingual Domain Models from comparable corpora.
   Experiments show the effectiveness of our approach, providing a low cost solution for the Cross Language Text Categorization task. In particular, when bilingual dictionaries are available the performance of the categorization gets close to that of monolingual text categorization.
C1 [Gliozzo, Alfio; Strapparava, Carlo] ITC Irst, I-38050 Trento, Italy.
RP Gliozzo, A (reprint author), ITC Irst, Via Sommarive, I-38050 Trento, Italy.
EM gliozzo@itc.it; strappa@itc.it
CR BEL N, 2003, P EUR C DIG LIB ECDL
   CALLISONBURCH C, 2004, P ACL 04 BARC SPAIN
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   GAUSSIER E, 2004, P ACL 04 BARC SPAIN
   Gliozzo A, 2004, COMPUT SPEECH LANG, V18, P275, DOI 10.1016/j.csl.2004.05.006
   Gliozzo A., 2005, P ACL WORKSH BUILD U
   Joachims T., 2002, LEARNING CLASSIFY TE
   Koehn Philipp, 2002, P ACL WORKSH UNS LEX
   LITTMAN M, 1998, CROSS LANGUAGE INFOR, P51
   Melamed DI, 2001, EMPIRICAL METHODS EX
   RIGUTINI L, 2005, P WEB INT C WI 2005
   STRAPPARAVA C, 2004, P SENSEVAL 3 BARC SP
   WONG SKM, 1985, P 8 ACM SIGIR C
NR 13
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 553
EP 560
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200070
DA 2019-06-15
ER

PT B
AU Judge, J
   Cahill, A
   van Genabith, J
AF Judge, John
   Cahill, Aoife
   van Genabith, Josef
GP COLING
TI QuestionBank: Creating a Corpus of Parse-Annotated Questions
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper describes the development of QuestionBank, a corpus of 4000 parse-annotated questions for (i) use in training parsers employed in QA, and (ii) evaluation of question parsing. We present a series of experiments to investigate the effectiveness of QuestionBank as both an exclusive and supplementary training resource for a state-of-the-art parser in parsing both question and non-question test sets. We introduce a new method for recovering empty nodes and their antecedents (capturing long distance dependencies) from parser Output in CFG trees using LFG f-structure reentrancies. Our main findings are (i) using QuestionBank training data improves parser performance to 89.75% labelled bracketing f-score, an increase of almost 11% over the baseline; (ii) back-testing experiments on non-question data (Penn-II WSJ Section 23) shows that the retrained parser does not suffer a performance drop on non-question material; (iii) ablation experiments show that the size of training material provided by QuestionBank is sufficient to achieve optimal results; (iv) our method for recovering empty nodes captures long distance dependencies in questions from the ATIS corpus with high precision (96.82%) and low recall (39.38%). In summary, QuestionBank provides a useful new resource in parser-based QA research.
C1 [Judge, John; Cahill, Aoife; van Genabith, Josef] Dublin City Univ, Natl Ctr Language Technol, Dublin 9, Ireland.
RP Judge, J (reprint author), Dublin City Univ, Natl Ctr Language Technol, Dublin 9, Ireland.
EM jjudge@computing.dcu.ie; acahill@computing.dcu.ie;
   josef@computing.dcu.ie
OI Cahill, Aoife/0000-0002-3519-7726
CR BIKEL D., 2002, P HLT 2002 SAN DIEG, P24
   CAHILL A, 2004, P 42 ANN M ASS COMP, P320
   Clark Stephen, 2004, P 2004 C EMP METH NA, P111
   Collins Michael, 1999, THESIS U PENNSYLVANI
   Gildea D, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P167
   Hemphill CT, 1990, P DARPA SPEECH NAT L
   JOHNSON M, 2002, P ACL 02 U PENNS PHI
   JUDGE J, 2005, P LFG 05 BERG NORW J, P186
   Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P556, DOI 10.1109/ICPST.2002.1053604
   MITCHELL P, 1993, COMPUTATIONAL LINGUI, V19, P313
NR 10
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 497
EP 504
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200063
DA 2019-06-15
ER

PT B
AU Shi, L
   Niu, C
   Zhou, M
   Gao, JF
AF Shi, Lei
   Niu, Cheng
   Zhou, Ming
   Gao, Jianfeng
GP COLING
TI A DOM Tree Alignment Model for Mining Parallel Data from the Web
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents a new web mining scheme for parallel data acquisition. Based on the Document Object Model (DOM), a web page is represented as a DOM tree. Then a DOM tree alignment model is proposed to identify the translationally equivalent texts and hyperlinks between two parallel DOM trees. By tracing the identified parallel hyperlinks, parallel web documents are recursively mined. Compared with previous mining schemes, the benchmarks show that this new mining scheme improves the mining coverage, reduces mining bandwidth, and enhances the quality of mined parallel sentences.
C1 [Shi, Lei; Niu, Cheng; Zhou, Ming] Microsoft Res Asia, Sigma Ctr 5F, Beijing 10080, Peoples R China.
RP Shi, L (reprint author), Microsoft Res Asia, Sigma Ctr 5F, 49 Zhichun Rd, Beijing 10080, Peoples R China.
EM leishi@microsoft.com; chengniu@microsoft.com; mingzhou@microsoft.com;
   jfgao@microsoft.com
CR ASHAWI H, 2000, COMPUTATIONAL LINGUI, V26
   Brown P. F., 1993, COMPUTATIONAL LINGUI, V19
   Brown PF, 1991, P 29 ANN M ASS COMP
   CALLISONBURCH C, 2005, P 43 ANN M ASS COMP
   CHEN J, 1991, P 2 WORKSH AUSTR INF
   Chen SF, 1993, P 31 ANN M ASS COMP
   CHURCH KW, 1993, P 31 ANN M ASS COMP
   FUNG P, 1994, P 1 C ASS MACH TRANS
   GALE W, 1991, P 29 ANN M ASS COMP
   HAJIC J, 2004, FINAL REPORT NATURAL
   KAY M, 1993, COMPUTATIONAL LINGUI, V19
   Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X
   Liberman Mark, 1999, P MACH TRANSL SUMM 7
   Moore R. C., 2002, P 5 C ASS MACH TRANS
   MUNTEANU DS, 2002, P HUM LANG TECHN C N
   Ng H. T., 2003, P 41 ANN M ASS COMP
   Nie JY, 1999, P 22 ANN INT ACM SIG
   PIETRA SD, 1995, IEEE T PATTERN ANAL
   RESNIK P, 2003, COMPUTATIONAL LINGUI, V29
   SHIEBER S, 1990, P 13 INT C COMP LING
   Utiyama M., 2003, P 41 ANN M ASS COMP, P7
   Wu Dekai, 1994, P 32 ANN M ASS COMP
   Wu Dekai, 1997, COMPUTATIONAL LINGUI, V23
   Yamada  K., 2001, P 39 ANN M ASS COMP
   Zhang Y., 2006, P 28 EUR C INF RETR
   ZHAO B, 2002, 2002 IEEE INT C DAT
NR 26
TC 7
Z9 7
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 489
EP 496
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200062
DA 2019-06-15
ER

PT B
AU Wang, MQ
   Sagae, K
   Mitamura, T
AF Wang, Mengqiu
   Sagae, Kenji
   Mitamura, Teruko
GP COLING
TI A Fast, Accurate Deterministic Parser for Chinese
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a novel classifier-based deterministic parser for Chinese constituency parsing. Our parser computes parse trees from bottom up in one pass, and uses classifiers to make shift-reduce decisions. Trained and evaluated on the standard training and test sets, our best model (using stacked classifiers) runs in linear time and has labeled precision and recall above 88% using gold-standard part-of-speech tags, surpassing the best published results. Our SVM parser is 2-13 times faster than state-of-the-art parsers, while producing more accurate results. Our Maxent and DTree parsers run at speeds 40-270 times faster than state-of-the-art parsers, but with 5-6% losses in accuracy.
C1 [Wang, Mengqiu; Sagae, Kenji; Mitamura, Teruko] Carnegie Mellon Univ, Sch Comp Sci, Language Technol Inst, Pittsburgh, PA 15213 USA.
RP Wang, MQ (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Language Technol Inst, Pittsburgh, PA 15213 USA.
EM mengqiu@cs.cmu.edu; sagae@cs.cmu.edu; teruko@cs.cmu.edu
CR Bikel Daniel, 2004, THESIS U PENNSYLVANI
   Bikel Daniel M., 2000, P 2 CHIN LANG PROC W
   CHENG YC, 2005, P ICCC 05
   CHENG YC, 2004, P IJCNLP 04
   CHIANG D, 2002, P COLING 02
   Collins Michael, 1999, THESIS U PENNSYLVANI
   DAELEMANS W, 2004, TIMBL VERSION 5 1 RE
   FREUND Y, 1996, P ICML 96
   FUNG P, 2004, ACM T ASIAN LANGUAGE, V3, P159
   HEARNE M, 2004, P IJCNLP 04
   HENDERSON J, 1999, P EMNLP 99
   JIANG ZP, 2004, THESIS NATL U SINGAP
   KUDO T, 2000, P CONLL LLL 00
   Levy R., 2003, P ACL 03
   LUO XQ, 2003, P EMNLP 03
   Magerman D. M, 1994, THESIS STANFORD U
   NG HT, 2004, P EMNLP 04
   NIVRE J, 2004, P COLING 04
   Ratnaparkhi A, 1999, MACH LEARN, V34, P151, DOI 10.1023/A:1007502103375
   SAGAE K, 2005, P IWPT 05
   SUN H, 2004, P HLT NAACL 04
   SUN HL, 2003, P SIGHAN WORKSH 03
   VANDENBOSCH A, 2000, P ICML 00
   XIONG D, 2005, P IJCNLP 05
   XUE N, 2005, NAT LANG ENG, V11, P207, DOI DOI 10.1017/S135132490400364X
   YAMADA H, 2003, P IWPT 03
   Zhang L., 2004, MAXIMUM ENTROPY MODE
NR 27
TC 7
Z9 7
U1 0
U2 3
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 425
EP 432
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200054
DA 2019-06-15
ER

PT B
AU Goodman, J
AF Goodman, J
GP acl
TI Exponential priors for maximum entropy models
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
ID SMOOTHING TECHNIQUES
AB Maximum entropy models are a common modeling technique, but prone to overfitting. We show that using an exponential distribution as a prior leads to bounded absolute discounting by a constant. We show that this prior is better motivated by the data than previous techniques such as a Gaussian prior, and often produces lower error rates. Exponential priors also lead to a simpler teaming algorithm and to easier to understand behavior. Furthermore, exponential priors help explain the success of some previous smoothing techniques, and suggest simple variations that work better.
RP Goodman, J (reprint author), 1 Microsoft Way, Redmond, WA 98052 USA.
CR BANKO M, 2001, HLT
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452
   Chen SF, 1999, COMPUT SPEECH LANG, V13, P359, DOI 10.1006/csla.1999.0128
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   DELLAPIETRA S, 1993, UNPUB STAT MODELING
   FIGUEIREDO MAT, 2003, SUPERVISED SEMISUPER
   GOOD IJ, 1953, BIOMETRIKA, V40, P237, DOI 10.2307/2333344
   GOODMAN J, 2001, ICASSP 2001
   GOODMAN J, 2002, ACL 02
   KADI CM, 2002, P UAI, P242
   KHUDANPUR S, 1995, 1995 J HOPKS U LANG
   Kneser R., 1995, P IEEE INT C AC SPEE, V1, P181, DOI DOI 10.1109/ICASSP.1995.479394
   LAU R, 1994, ADAPTIVE STAT LANGUA
   NEWMAN W, 1997, IEEE T INFORMATION T, V23, P89
   NEY H, 1994, COMPUT SPEECH LANG, V8, P1, DOI 10.1006/csla.1994.1001
   PERKINS S, 2003, ONLINE FEATURE SELEC
   Ratnaparkhi Adwait, 1998, THESIS U PENNSYLVANI
   REYNAR J, 1909, ANLP
   ROSENFELD R, 1994, THESIS CARNEGIE MELL
   Tibshirani R., 1994, REGRESSION SHRINKAGE
   WILLIAMS PM, 1995, NEURAL COMPUT, V7, P117, DOI 10.1162/neco.1995.7.1.117
NR 23
TC 7
Z9 7
U1 0
U2 4
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 305
EP 312
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100039
DA 2019-06-15
ER

PT B
AU Baldridge, J
   Kruijff, GJM
AF Baldridge, J
   Kruijff, GJM
GP ACL
TI Multi-modal combinatory categorial grammar
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB The paper shows how Combinatory Categorial Grammar (CCG) can be adapted to take advantage of the extra resource-sensitivity provided by the Categorial Type Logic framework. The resulting reformulation, Multi-Modal CCG, supports lexically specified control over the applicability of combinatory rules, permitting a universal rule component and shedding the need for language-specific restrictions on rules. We discuss some of the linguistic motivation for these changes, define the Multi-Modal CCG system and demonstrate how it works on some basic examples. We furthermore outline some possible extensions and address computational aspects of Multi-Modal CCG.
C1 Univ Edinburgh, Sch Informat, ICCS, Edinburgh EH8 9LW, Midlothian, Scotland.
CR Baldridge J., 2002, THESIS U EDINBURGH
   BALDRIDGE J, 2002, P 40 ANN M ASS COMP, P319
   HEPPLE M, 1995, P EACL 7 DUBL IR
   KORNAGATA N, 1999, THESIS U PENNSYLVANI
   KRUIJFF GM, 2001, THESIS CHARLES U PRA
   MOORTAT M, 1997, HDB LOGIC LANGUAGE
   MOORTGAT M, 1991, UNPUB HEADS PHRASES
   Morrill Glyn V., 1994, TYPE LOGICAL GRAMMAR
   OEHRLE RT, IN PRESS NONTRANSFOR
   Steedman M., 2000, SYNTACTIC PROCESS
   Trechsel FR, 2000, NAT LANG LINGUIST TH, V18, P611, DOI 10.1023/A:1006409422158
   VIJAYSHANKER K, 1990, P 28 ANN M ASS COMP, P1
   Villavicencio Aline, 2002, THESIS U CAMBRIDGE
NR 13
TC 7
Z9 7
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 211
EP 218
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200028
DA 2019-06-15
ER

PT B
AU Core, MG
   Moore, JD
   Zinn, C
AF Core, MG
   Moore, JD
   Zinn, C
GP ACL
TI The role of initiative in tutorial dialogue
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB This work is the first systematic investigation of initiative in human-human tutorial dialogue. We studied initiative management in two dialogue strategies: didactic tutoring and Socratic tutoring. We hypothesized that didactic tutoring would be mostly tutor-initiative while Socratic tutoring would be mixed-initiative, and that more student initiative would lead to more learning (i.e., task success for the tutor). Surprisingly, students had initiative more of the time in the didactic dialogues (21% of the turns) than in the Socratic dialogues (10% of the turns), and there was no direct relationship between student initiative and learning. However, Socratic dialogues were more interactive than didactic dialogues as measured by percentage of tutor utterances that were questions and percentage of words in the dialogue uttered by the student, and interactivity had a positive correlation with learning.
C1 Univ Edinburgh, Sch Informat, Edinburgh EH8 9LW, Midlothian, Scotland.
CR Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Chi Michelene T.H., 1994, COGNITIVE SCI, V18, P439
   Chu-Carroll J, 1998, USER MODEL USER-ADAP, V8, P215, DOI 10.1023/A:1008205526147
   CHUCARROLL J, 2000, P 1 C N AM CHAPT ASS, P202
   CORE MG, 2002, P ITS 02 WORKSH EMP
   Doran C., 2001, 2 SIGDIAL WORKSH DIS
   FOX BA, 1993, HUMAN TURORIAL DIALO
   GRAESSER AC, 1995, APPL COGNITIVE PSYCH, V9, P495, DOI 10.1002/acp.2350090604
   GRAESSER AC, 1994, AM EDUC RES J, V31, P104, DOI 10.2307/1163269
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   GUINN CI, 1996, P 34 ANN M ASS COMP, P278
   JORDAN PW, 2002, P ITS 02 WORKSH EMP
   JORDAN PW, 1997, AAAI 1997 SPRING S C
   Krippendorff K., 1980, CONTENT ANAL INTRO I
   LINELL P, 1988, LINGUISTICS, V26, P415, DOI 10.1515/ling.1988.26.3.415
   Merrill D. C., 1992, ANN M AM ED RES ASS
   Merrill D. C., 1992, J LEARN SCI, V2, P277, DOI DOI 10.1207/S15327809JLS0203_2
   MICHELENE TH, 2001, COGNITIVE SCI, V25, P471
   MICHELENE TH, 1989, COGNITIVE SCI, V13, P145
   MUNRO A, 1994, USE COMPUTER MODELS
   ROSE CP, 2000, LRDCBEE1 U PITTSB
   Shah F, 1997, THESIS ILLINOIS I TE
   Sinclair J., 1975, ANAL DISCOURSE ENGLI
   STRAYER SE, 2001, I SIGDIAL WORKSH DIS
   VANLEHN K, 1998, P 20 ANN C COGN SCI
   WALKER M, 1990, P 28 ANN M ASS COMP, P70
   WHITTAKER S, 1988, P 26 ANN M ASS COMP, P123
NR 27
TC 7
Z9 7
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 67
EP 74
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200010
DA 2019-06-15
ER

PT B
AU Creutz, M
AF Creutz, M
GP ACL
TI Unsupervised segmentation of words using prior distributions of morph
   length and frequency
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We present a language-independent and unsupervised algorithm for the segmentation of words into morphs. The algorithm is based on a new generative probabilistic model, which makes use of relevant prior information on the length and frequency distributions of morphs in a language. Our algorithm is shown to outperform two competing algorithms, when evaluated on data from a language with agglutinative morphology (Finnish), and to perform well also on English data.
C1 Helsinki Univ Technol, Neural Networks Res Ctr, FIN-02015 Helsinki, Finland.
CR Baayen R. Harald, 2001, WORD FREQUENCY DISTR
   BARONI M, 2002, P ACL WORKSH MORPH P, P48
   Brent MR, 1999, MACH LEARN, V34, P71, DOI 10.1023/A:1007541817488
   Creutz M., 2002, P WORKSH MORPH PHON, P21
   DEJEAN H, 1998, WORKSH PAR GROUND NA, P295
   Deligne S, 1997, SPEECH COMMUN, V23, P223, DOI 10.1016/S0167-6393(97)00048-4
   DELIGNE S, 1995, P ICASSP
   Fulop Sean A., 2002, P ACL WORKSH MORPH P, P31
   Goldsmith J, 2001, COMPUT LINGUIST, V27, P153, DOI 10.1162/089120101750300490
   KARLSSON F, 1987, FINNISH GRAMMAR
   KIT C, 1999, P CONLL99 ACL WORKSH
   KOSKENNIEMEI K, 1983, THESIS U HELSINKI
   LI W, 1992, IEEE T INFORMATION T, V38, P1840
   Rissanen J., 1989, WORLD SCI SERIES COM
   SCHONE P., 2000, P 4 C COMP NAT LANG, P67, DOI [10.3115/1117601.1117615, DOI 10.3115/1117601.1117615]
   Snover M., 2002, P ACL 02 WORKSH MORP, V6, P11
   Snover M. G., 2001, P 39 ANN M ACL, P482
   YU H, 2000, P ISCSL BEIJ
NR 18
TC 7
Z9 7
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 280
EP 287
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500036
DA 2019-06-15
ER

PT B
AU Koehn, P
   Knight, K
AF Koehn, P
   Knight, K
GP ACL
TI Empirical methods for compound splitting
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Compounded words are a challenge for NLP applications such as machine translation (MT). We introduce methods to learn splitting rules from monolingual and parallel corpora. We evaluate them against a gold standard and measure their impact on performance of statistical MT systems. Results show accuracy of 99.1% and performance gains for MT of 0.039 BLEU on a German-English noun phrase translation task.
C1 Univ So Calif, Dept Comp Sci, Inst Sci Informat, Los Angeles, CA 90089 USA.
CR ALONAIZAN Y, 1999, STAT MACHINE TRANSLA
   Brants T., 2000, P 6 APPL NAT LANG PR
   Brown Peter, 1990, COMPUTATIONAL LINGUI, V16, P76
   Brown R. D., 2002, P 9 INT C THEOR METH
   FINKLER W, 1998, 4 OST ART INT TAG WI
   GERMANN U, 2001, P ACL 39
   Hedlund T., 2001, 2 WORKSH CROSS LANG
   Koehn  P., 2002, EUROPARL MULTILINGUA
   KOEHN P, 2001, P C EMP METH NAT LAN
   LANGER S, 1998, TAG 4 K VER NAT SPAR
   LARSON M, 2000, 6 INT C SPOK LANG PR
   MARCU D, 2002, P C EMP METH NAT LAN
   MONZ C, 2001, 2 WORKSH CROSS LANG
   Papineni  K., 2002, P 40 ANN M ASS COMP
NR 14
TC 7
Z9 8
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 187
EP 193
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200025
DA 2019-06-15
ER

PT B
AU Utiyama, M
   Isahara, H
AF Utiyama, M
   Isahara, H
GP ACL
TI Reliable measures for aligning Japanese-English news articles and
   sentences
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We have aligned Japanese and English news articles and sentences to make a large parallel corpus. We first used a method based on cross-language information retrieval (CLIR) to align the Japanese and English articles and then used a method based on dynamic programming (DP) matching to align the Japanese and English sentences in these articles. However, the results included many incorrect alignments. To remove these, we propose two measures (scores) that evaluate the validity of alignments. The measure for article alignment uses similarities in sentences aligned by DP matching and that for sentence alignment uses similarities in articles aligned by CLIR. They enhance each other to improve the accuracy of alignment. Using these measures, we have successfully constructed a largescale article and sentence alignment corpus available to the public.
C1 Commun Res Labs, Seika, Kyoto 6190289, Japan.
CR BRILL E, 1992, ANLP 92 P 3 C APPL N, P152
   COLLIER N, 1998, COLING ACL 98, P263
   Gale W. A., 1993, Computational Linguistics, V19, P75
   *JAP EL IND DEV AS, 2000, SIZ GENG SY KANS TYO
   JEFFREY C, 1997, ANLP 97
   KENJI M, 2002, LREC 2002, P480
   Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232
   UTSURO T, 1994, COLING94, P1076
NR 8
TC 7
Z9 7
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 72
EP 79
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500010
DA 2019-06-15
ER

PT B
AU Abney, S
   Bird, S
AF Abney, Steven
   Bird, Steven
GP Assoc Computat Linguist
TI The Human Language Project: Building a Universal Corpus of the World's
   Languages
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a grand challenge to build a corpus that will include all of the world's languages, in a consistent structure that permits large-scale cross-linguistic processing, enabling the study of universal linguistics. The focal data types, bilingual texts and lexicons, relate each language to one of a set of reference languages. We propose that the ability to train systems to translate into and out of a given language be the yardstick for determining when we have successfully captured a language. We call on the computational linguistics community to begin work on this Universal Corpus, pursuing the many strands of activity described here, as their contribution to the global effort to document the world's linguistic heritage before more languages fall silent.
C1 [Abney, Steven] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Bird, Steven] Univ Melbourne, Melbourne, Vic 3010, Australia.
   [Bird, Steven] Univ Penn, Philadelphia, PA 19104 USA.
RP Abney, S (reprint author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM abney@umich.edu; sbird@unimelb.edu.au
CR Abney S, 2008, CH CRC COMP SCI DATA, P1
   Bird S., 2009, NATURAL LANGUAGE PRO
   Bird Steven, 2010, P 12 INT C AS PAC DI, P5
   Broeder D., 2006, International Journal of Metadata, Semantics and Ontologies, V1, P119, DOI 10.1504/IJMSO.2006.011008
   Cieri Christopher, 2010, P 7 INT C LANG RES E
   Crane Gregory R., 2010, PERSEUS DIGITAL LIB
   CUNNINGHAM H, 2002, P 40 ANN M ASS COMP, P168, DOI DOI 10.3115/1073083.1073112
   DiPersio Denise, 2010, FLARENET FORUM 2010
   HALE K, 1992, LANGUAGE, V68, P1, DOI 10.2307/416368
   Himmelmann NP, 2006, TRENDS LINGUIST-STUD, V178, P1
   Human Genome Project, 2007, SCI HUM GEN PROJ
   Hutchins W. John, 1992, INTRO MACHINE TRANSL
   Koehn P., 2010, STAT MACHINE TRANSLA
   Kumar Shankar, 2007, P JOINT C EMP METH N, P42
   MAXWELL M, 2006, P WORKSH FRONT LING, P29
   Resnik P, 1999, COMPUT HUMANITIES, V33, P129, DOI 10.1023/A:1001798929185
   Scannell Kevin, 2008, CAHIERS CENTAL, V5
   Simons G., 2003, Literary & Linguistic Computing, V18, P117, DOI 10.1093/llc/18.2.117
   Swadesh M, 1955, INT J AM LINGUIST, V21, P121, DOI 10.1086/464321
   Varadi T., 2008, P 6 INT LANG RES EV
   Wagner D. A., 1993, LITERACY CULTURE DEV
   Waters G., 1998, LOCAL LITERACIES THE
   Whalen Douglas H., 2009, P 1 INT C LANG DOC C
   Woodbury Anthony, 2010, CAMBRIDGE HDB ENDANG
   Xia Fei, 2007, P M N AM CHAPT ASS C
NR 25
TC 6
Z9 6
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 88
EP 97
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300010
DA 2019-06-15
ER

PT B
AU Gomez-Rodriguez, C
   Nivre, J
AF Gomez-Rodriguez, Carlos
   Nivre, Joakim
GP Assoc Computat Linguist
TI A Transition-Based Parser for 2-Planar Dependency Structures
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Finding a class of structures that is rich enough for adequate linguistic representation yet restricted enough for efficient computational processing is an important problem for dependency parsing. In this paper, we present a transition system for 2-planar dependency trees -trees that can be decomposed into at most two planar graphs -and show that it can be used to implement a classifier-based parser that runs in linear time and outperforms a stateof- the-art transition-based parser on four data sets from the CoNLL-X shared task. In addition, we present an efficient method for determining whether an arbitrary tree is 2-planar and show that 99% or more of the trees in existing treebanks are 2-planar.
C1 [Gomez-Rodriguez, Carlos] Univ A Coruna, Dept Comp, La Coruna, Spain.
   [Nivre, Joakim] Uppsala Univ, Dept Linguist & Philol, S-75105 Uppsala, Sweden.
RP Gomez-Rodriguez, C (reprint author), Univ A Coruna, Dept Comp, La Coruna, Spain.
EM carlos.gomez@udc.es; joakim.nivre@lingfil.uu.se
RI Gomez-Rodriguez, Carlos/A-5935-2011
OI Gomez-Rodriguez, Carlos/0000-0003-0752-8812
CR Afonso S., 2002, P 3 INT C LANG RES E, P1968
   Atalay Nart B., 2003, P EACL WORKSH LING I, P243
   Bodirsky Manuel, 2005, 10 C FORM GRAMM 9 M
   Brants Sabine, 2002, P WORKSH TREEB LING
   Buch-Kromann M., 2006, THESIS
   Buchholz S, 2006, P 10 C COMP NAT LANG, P149
   Chang Chih-Chung, 2001, LIBSVM LIB SUPPORT V
   Eisner J., 1996, P 16 INT C COMP LING, P340
   GAIFMAN H, 1965, INFORM CONTROL, V8, P304, DOI 10.1016/S0019-9958(65)90232-9
   Gomez-Rodriguez C, 2009, P 12 C EUR CHAPT ASS, P291
   Gomez-Rodriguez Carlos, 2008, P 46 ANN M ASS COMP, P968
   Hajic J, 2006, PRAGUE DEPENDENCY TR
   Hajic Jan, 2004, P NEMLAR INT C AR LA, P110
   Havelka Jiri, 2007, P 45 ANN M ASS COMP, P608
   Karp R. M., 1972, COMPLEXITY COMPUTER, P85, DOI [DOI 10.1007/978-1-4684-2001-2_9, 10.1007/978-1-4684-2001-29]
   KROMANN MT, 2003, P 2 WORKSH TREEB LIN, P217
   Kuhlmann M., 2009, P 12 C EUR CHAPT ASS, P478, DOI DOI 10.3115/1609067.1609120
   Kuhlmann M, 2007, P 45 ANN M ASS COMP, P160
   Kuhlmann Marco, 2007, THESIS
   Kuhlmann Marco, 2006, P COLING ACL 2006 MA, P507
   Marinov Svetoslav, 2006, P 10 C COMP NAT LANG, P221
   Martins A., 2009, P JOINT C 47 ANN M A, P342
   McDonald R., 2005, P 43 ANN M ASS COMP, P91, DOI DOI 10.3115/1219840.1219852
   McDonald R., 2005, HLT 05 P C HUM LANG, P523
   McDonald R., 2007, P 2007 JOINT C EMP M, P122
   Neuhaus Peter, 1997, P 35 ACL ANN M 8 C E, P337
   Nilsson Jens, 2005, P NODALIDA 2005 SPEC, P119
   Nivre J., 2004, HLT NAACL 2004 WORKS, P49
   Nivre J., 2006, P 5 INT C LANG RES E, V6, P2216
   Nivre J., 2005, P 43 ANN M ASS COMP, P99
   NIVRE J, 2003, P 8 INT WORKSH PARS, P149
   NIVRE J, 2006, P 11 C EUR CHAPT ASS, P73
   Nivre J, 2008, COMPUT LINGUIST, V34, P513, DOI 10.1162/coli.07-056-R1-07-027
   Oflazer Kemal, 2003, BUILDING EXPLOITING, P261
   Sagae Kenji, 2008, COLING 08, P753
   Sleator D., 1993, P 3 INT WORKSH PARS, P277
   TITOV I, 2007, P 10 INT C PARS TECH, P144
   van der Beek L, 2002, LANG COMPUT, P8
   Yamada H., 2003, P 8 INT WORKSH PARS, V3, P195
   Yli-Jyra Anssi Mikael, 2003, MATH MODELLING PHYS, V9, P189
NR 40
TC 6
Z9 6
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1492
EP 1501
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300151
DA 2019-06-15
ER

PT B
AU Park, KC
   Jeong, Y
   Myaeng, SH
AF Park, Keun Chan
   Jeong, Yoonjae
   Myaeng, Sung Hyon
GP Assoc Computat Linguist
TI Detecting Experiences from Weblogs
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Weblogs are a source of human activity knowledge comprising valuable information such as facts, opinions and personal experiences. In this paper, we propose a method for mining personal experiences from a large set of weblogs. We define experience as knowledge embedded in a collection of activities or events which an individual or group has actually undergone. Based on an observation that experience-revealing sentences have a certain linguistic style, we formulate the problem of detecting experience as a classification task using various features including tense, mood, aspect, modality, experiencer, and verb classes. We also present an activity verb lexicon construction method based on theories of lexical semantics. Our results demonstrate that the activity verb lexicon plays a pivotal role among selected features in the classification performance and shows that our proposed method outperforms the baseline significantly.
C1 [Park, Keun Chan; Jeong, Yoonjae; Myaeng, Sung Hyon] Korea Adv Inst Sci & Technol, Dept Comp Sci, Daejeon, South Korea.
RP Park, KC (reprint author), Korea Adv Inst Sci & Technol, Dept Comp Sci, Daejeon, South Korea.
EM keunchan@kaist.ac.kr; hybris@kaist.ac.kr; myaeng@kaist.ac.kr
CR Aramaki Eiji, 2009, P WORKSH BIONLP
   Baker Collin F., 2003, INT J LEXICOGRAPHY
   Berger A. L., 1996, COMPUTATIONAL LINGUI
   Chang Chih-Chung, 2001, LIBSVM LIB SUPPORT V
   Dowty David, 1979, WORD MEANING MONTAGU
   Fellbaum C., 1998, WORDNET ELECT LEXICA
NR 6
TC 6
Z9 6
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1464
EP 1472
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300148
DA 2019-06-15
ER

PT B
AU Recasens, M
   Hovy, E
AF Recasens, Marta
   Hovy, Eduard
GP Assoc Computat Linguist
TI Coreference Resolution across Corpora: Languages, Coding Schemes, and
   Preprocessing Information
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper explores the effect that different corpus configurations have on the performance of a coreference resolution system, as measured by MUC, B-3, and CEAF. By varying separately three parameters (language, annotation scheme, and preprocessing information) and applying the same coreference resolution system, the strong bonds between system and corpus are demonstrated. The experiments reveal problems in coreference resolution evaluation relating to task definition, coding schemes, and features. They also expose systematic biases in the coreference evaluation metrics. We show that system comparison is only possible when corpus parameters are in exact agreement.
C1 [Recasens, Marta] Univ Barcelona, CLiC, Gran Via 585, Barcelona, Spain.
   [Hovy, Eduard] USC Informat Sci Inst, Marina Del Rey, CA USA.
RP Recasens, M (reprint author), Univ Barcelona, CLiC, Gran Via 585, Barcelona, Spain.
EM mrecasens@ub.edu; hovy@isi.edu
CR Bagga A., 1998, P 1 INT C LANG RES E, P563
   Bengtson Eric, 2008, P C EMP METH NAT LAN, P294
   Brants Thorsten, 2000, P ANLP 2000 SEATTL W
   Chinchor Nancy, 1997, P MUC 7
   Culotta Aron, 2007, P HLT NAACL ROCH NY, P81
   Daelemans W., 2005, MEMORY BASED LANGUAG
   Denis P., 2009, PROCESAMIENTO LENGUA, V42, P87
   ERIK F, 2003, P CONLL 2003 EDM CAN, P142
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Finkel J. R., 2008, P ACL 08 HLT COL OH, P45
   Haghighi Aria, 2009, P 2009 C EMP METH NA, P1152
   Hovy E., 2006, P HUM LANG TECHN C N, P57
   Kudoh Taku, 2000, P CONLL 2000 LLL 200, P142
   Luo X., 2004, P ACL, P21
   Luo X., 2005, P C HUM LANG TECHN E, P25, DOI DOI 10.3115/1220575.1220579
   Luo Xiaoqiang, 2005, P HUM LANG TECHN C C, P660
   Ng V., 2009, P NAACL HLT 2009 BOU, P575
   Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102
   Poon Hoifung, 2008, P 2008 C EMP METH NA, P650
   Pradhan Sameer S., 2007, P INT C SEM COMP ICS, P517
   Recasens M, 2010, LANG RESOUR EVAL, V44, P315, DOI 10.1007/s10579-009-9108-x
   Recasens M, 2009, LECT NOTES ARTIF INT, V5847, P29, DOI 10.1007/978-3-642-04975-0_3
   Recasens Marta, 2010, P 5 INT WORKSH SEM E
   Saers Markus, 2007, P CONLL SHAR TASK EM, P933
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Stoyanov V., 2009, P ACL INT JOINT C NA, P656
   Strassel, 2004, P 4 INT C LANG RES E, P837
   Uryupina O., 2006, P LREC 2006
   van Deemter K, 2000, COMPUT LINGUIST, V26, P629, DOI 10.1162/089120100750105966
   Vilain M., 1995, P 6 MESS UND C MUC 6, P45, DOI DOI 10.3115/1072399.1072405
NR 30
TC 6
Z9 6
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1423
EP 1432
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300144
DA 2019-06-15
ER

PT B
AU Shezaf, D
   Rappoport, A
AF Shezaf, Daphna
   Rappoport, Ari
GP Assoc Computat Linguist
TI Bilingual Lexicon Generation Using Non-Aligned Signatures
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Bilingual lexicons are fundamental resources. Modern automated lexicon generation methods usually require parallel corpora, which are not available for most language pairs. Lexicons can be generated using non-parallel corpora or a pivot language, but such lexicons are noisy. We present an algorithm for generating a high quality lexicon from a noisy one, which only requires an independent corpus for each language. Our algorithm introduces non-aligned signatures (NAS), a cross-lingual word context similarity score that avoids the over-constrained and inefficient nature of alignment-based methods. We use NAS to eliminate incorrect translations from the generated lexicon. We evaluate our method by improving the quality of noisy Spanish-Hebrew lexicons generated from two pivot English lexicons. Our algorithm substantially outperforms other lexicon generation methods.
C1 [Shezaf, Daphna; Rappoport, Ari] Hebrew Univ Jerusalem, Inst Comp Sci, IL-91905 Jerusalem, Israel.
RP Shezaf, D (reprint author), Hebrew Univ Jerusalem, Inst Comp Sci, IL-91905 Jerusalem, Israel.
EM daphna.shezaf@mail.huji.ac.il; arir@cs.huji.ac.il
CR Ahn Kisuh, 2006, EACL 2006 WORKSH CRO
   Bond Francis, 2001, MT SUMM 8 SANT DE CO, P53
   Church K. W., 1990, Computational Linguistics, V16, P22
   Dinur Elad, 2009, EACL 2009 WORKSH COM
   Fung Pascale, 1998, 3 C ASS MACH TRANSL
   Garera Nikesh, 2009, CONLL
   Kaji Hiroyuki, 2008, LREC
   Kaji Hiroyuki, 1996, COLING
   Koehn Philipp, 2002, P ACL WORKSH UNS LEX
   Lopez A, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1380584.1380586
   Mausam Stephen Soderland, 2009, P 47 ANN M ASS COMP
   Paik Kyonghee, 2004, COLING MULT LING RES
   Pekar V, 2006, MACH TRANSL, V20, P247, DOI 10.1007/s10590-007-9029-7
   Prolog, 2003, PRACT BIL DICT SPAN
   Rapp Reinhard, 1999, ACL
   Schafer Charles, 2002, CONLL
   Skoumalova Hana, 2001, INT J CORPUS LINGUIS, V6, P95
   Tanaka Kumiko, 1996, C COMP LING
   Tanaka Kumiko, 1994, C COMP LING
   Tomaszczyk Jerzy, 1998, ZURILEX 86
NR 20
TC 6
Z9 6
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 98
EP 107
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300011
DA 2019-06-15
ER

PT B
AU Brody, S
   Navigli, R
   Lapata, M
AF Brody, Samuel
   Navigli, Roberto
   Lapata, Mirella
GP COLING
TI Ensemble Methods for Unsupervised WSD
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Combination methods are an effective way of improving system performance. This paper examines the benefits of system combination for unsupervised WSD. We investigate several voting- and arbiter-based combination strategies over a diverse pool of unsupervised WSD systems. Our combination methods rely on predominant senses which are derived automatically from raw text. Experiments using the SemCor and Senseval-3 data sets demonstrate that our ensembles yield significantly better results when compared with state-of-the-art.
C1 [Brody, Samuel; Lapata, Mirella] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
RP Brody, S (reprint author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
EM s.brody@sms.ed.ac.uk; navigli@di.uniroma1.it; mlap@inf.ed.ac.uk
CR Banerjee S., 2003, P 18 INT JOINT C ART, P805
   BRISCOE T, 2002, P 3 INT C LANG RES E, P1499
   Dietterich TG, 1997, AI MAG, V18, P97
   Edmonds Phil, 2000, DESIGNING TASK SENSE
   FLORIAN R, 2002, NAT LANG ENG, V1, P1
   GALLEY M, 2003, P 18 INT JOINT C ART, P1486
   HOSTE V, 2002, LANGUAGE ENG, V8, P311
   Lesk M. E., 1986, P 5 ANN INT C SYST D, P24, DOI [DOI 10.1145/318723.318728, 10.1145/318723]
   Lin Dekang, 1998, P 15 INT C MACH LEAR, P296
   McCarthy D, 2004, P 42 ANN M ASS COMP, P280
   MIHALCEA R, 2004, P SENSEVAL 3 BARC SP
   Mihalcea R., 2005, P C HUM LANG TECHN E, P411, DOI DOI 10.3115/1220575.1220627
   Miller G. A., 1993, P WORKSH HUM LANG TE, P303, DOI DOI 10.3115/1075671.1075742
   Mohammad S., 2006, P 11 C EUR CHAPT ASS, P121
   Morris J., 1991, Computational Linguistics, V17, P21
   Navigli R, 2005, IEEE T PATTERN ANAL, V27, P1075, DOI 10.1109/TPAMI.2005.149
   NAVIGLI R, 2005, P 18 FLAIRS FLOR
   NG TH, 1997, P ACL SIGLEX WORKSH, P1
   STOKOE C, 2005, P C HUM LANG TECHN E, P403
   Strapparava C., 2004, P SENSEVAL 3 3 INT W, P229
   TAN PN, 2004, P 10 KDD SEATTL WA, P22
   van Halteren H, 2001, COMPUT LINGUIST, V27, P199, DOI 10.1162/089120101750300508
   Vickrey D, 2005, P C HUM LANG TECHN E, P771
   Yarowsky D., 2002, Natural Language Engineering, P293, DOI 10.1017/S135132490200298X
NR 24
TC 6
Z9 6
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 97
EP 104
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200013
DA 2019-06-15
ER

PT B
AU Frampton, M
   Lemon, O
AF Frampton, Matthew
   Lemon, Oliver
GP COLING
TI Learning More Effective Dialogue Strategies Using Limited Dialogue Move
   Features
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We explore the use of restricted dialogue contexts in reinforcement learning (RL) of effective dialogue strategies for information seeking spoken dialogue systems (e.g. COMMUNICATOR (Walker et al., 2001)). The contexts we use are richer than previous research in this area, e.g. (Levin and Pieraccini, 1997; Scheffler and Young, 2001; Singh et al., 2002; Pietquin, 2004), which use only slot-based information, but are much less complex than the full dialogue "Information States" explored in (Henderson et al., 2005), for which tractabe learning is an issue. We explore how incrementally adding richer features allows learning of more effective dialogue strategies. We use 2 user simulations learned from COMMUNICATOR data (Walker et al., 2001; Georgila et al., 2005b) to explore the effects of different features on learned dialogue strategies. Our results show that adding the dialogue moves of the last system and user turns increases the average reward of the automatically learned strategies by 65.9% over the original (hand-coded) COMMUNICATOR systems, and by 7.8% over a baseline RL policy that uses only slot-status features. We show that the learned strategies exhibit an emergent "focus switching" strategy and effective use of the 'give help' action.
C1 [Frampton, Matthew; Lemon, Oliver] Univ Edinburgh, Sch Informat, HCRC, Edinburgh EH8 9LW, Midlothian, Scotland.
RP Frampton, M (reprint author), Univ Edinburgh, Sch Informat, HCRC, Edinburgh EH8 9LW, Midlothian, Scotland.
EM M.J.E.Frampton@sms.ed.ac.uk; olemon@inf.ed.ac.uk
OI Lemon, Oliver/0000-0001-9497-4743
CR Austin J. L, 1962, DO THINGS WORDS
   BOS J, 2003, 4 SIGDIAL WORKSH DIS
   Clark Herbert H., 1996, USING LANGUAGE
   ECKERT W, 1997, IEEE WORKSH AUT SPEE
   FRAMPTON M, 2005, IJCAI WORKSH KNOWL R
   GEORGILA K, 2005, 9 WORKSH SEM PRAGM D
   GEORGILA K, 2005, INTERSPEECH LEUROSPE
   Henderson J, 2005, IJCAI WORKSH KNOWL R
   Larsson S., 2000, Natural Language Engineering, P323, DOI 10.1017/S1351324900002539
   LEVIN E, 1997, EUROSPEECH
   PIETQUIN O, 2004, FRAMEWORK UNSUPERVIS
   RIESER V, 2006, P ACL
   SCHEFFLER K, 2001, NAACL 2001 WORKSH AD
   Searle J., 1969, SPEECH ACTS
   SINGH S, 2002, J ARTIFICIAL INTELLI
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   Walker M. A., 2001, M ASS COMP LING, P515
   WALKER MA, 2000, NATURAL LANGUAGE ENG, V6
NR 18
TC 6
Z9 6
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 185
EP 192
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200024
DA 2019-06-15
ER

PT B
AU Montalvo, S
   Martinez, R
   Casillas, A
   Fresno, V
AF Montalvo, Soto
   Martinez, Raquel
   Casillas, Arantza
   Fresno, Victor
GP COLING
TI Multilingual Document Clustering: an Heuristic Approach Based on Cognate
   Named Entities
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents an approach for Multilingual Document Clustering in comparable corpora. The algorithm is of heuristic nature and it uses as unique evidence for clustering the identification of cognate named entities between both sides of the comparable corpora. One of the main advantages of this approach is that it does not depend on bilingual or multilingual resources. However, it depends on the possibility of identifying cognate named entities between the languages used in the corpus. An additional advantage of the approach is that it does not need any information about the right number of clusters; the algorithm calculates it. We have tested this approach with a comparable corpus of news written in English and Spanish. In addition, we have compared the results with a system which translates selected document features. The obtained results are encouraging.
EM soto.montalvo@urjc.es; raquel@lsi.uned.es; arantza.casillas@ehu.es;
   victor.fresno@urjc.es
RI CASILLAS RUBIO, ARANTZA/B-8954-2018
OI CASILLAS RUBIO, ARANTZA/0000-0003-4248-8182; , Soto/0000-0001-8158-7939
CR Carreras X, 2004, P 4 INT C LANG RES E
   CASILLAS A, 2004, LECT NOTES COMPUTER, P601
   CHE HH, 2000, P 18 INT C COMP LING, P159
   Evans D. K., 2004, P HUM LANG TECHN C N
   Karypis George, 2002, 02017 U MINN DEP COM
   LEFTIN LJ, 2003, NEWSBLASTER RUSSIAN
   MATHIEU B, 2004, MULTILINGUAL DOCUMEN
   POULIQUEN B., 2004, P 20 INT C COMP LING, P23
   Rauber A., 2001, 3 ALL RUSS C DIG LIB
   Silva J., 2004, PLISKA STUDIA MATH B, V16, P207
   STEINBERGER R, 2002, LECT NOTES COMPUTER, P415
   STEINBERGER R, 2004, SLOV LANG TECHN C IN
   VANRIJSBERGEN CJ, 1974, J DOC, V30, P365, DOI 10.1108/eb026584
   VOSSEN P, 1998, INTRO EUROWORDNET CO
NR 14
TC 6
Z9 6
U1 0
U2 4
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1145
EP 1152
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200144
DA 2019-06-15
ER

PT B
AU Nagata, R
   Kawai, A
   Morihiro, K
   Isu, N
AF Nagata, Ryo
   Kawai, Atsuo
   Morihiro, Koichiro
   Isu, Naoki
GP COLING
TI A Feedback-Augmented Method for Detecting Errors in the Writing of
   Learners of English
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper proposes a method for detecting errors in article usage and singular plural usage based on the mass count distinction. First, it learns decision lists from training data generated automatically to distinguish mass and count nouns. Then, in order to improve its performance, it is augmented by feedback that is obtained from the writing of learners. Finally, it detects errors by applying rules to the mass count distinction. Experiments show that it achieves a recall of 0.71 and a precision of 0.72 and outperforms other methods used for comparison when augmented by feedback.
C1 [Nagata, Ryo; Morihiro, Koichiro] Hyogo Univ Teachers Educ, Kobe, Hyogo 6731494, Japan.
RP Nagata, R (reprint author), Hyogo Univ Teachers Educ, Kobe, Hyogo 6731494, Japan.
EM rnagata@hyogo-u.ac.jp; kawai@ai.info.mie-u.ac.jp; mori@hyogo-u.ac.jp;
   isu@ai.info.mie-u.ac.jp
CR ALLAN K, 1980, LANGUAGE, V56, P541, DOI 10.2307/414449
   [Anonymous], 1993, EDR EL DICT SPEC GUI
   Bond F., 2005, TRANSLATING UNTRANSL
   Burnard L., 1995, USERS REFERENCE GUID
   Chodorow M., 2000, P 1 M N AM CHAPT ASS, P140
   Granger S., 1998, PHRASEOLOGY THEORY A, P145
   Huddleston R. D., 2002, CAMBRIDGE GRAMMAR EN
   Izumi E., 2003, P 41 ANN M ASS COMP, V2, P145
   KAWAI A, 1984, IPSJ J, V25, P1072
   Keller F., 2005, ACM T SPEECH LANGUAG, V2, P1
   LEE J, 2004, P IEEE INT C AUT FAC, P31
   McCoy K. F., 1996, P 5 INT C US MOD, P69
   Minnen G., 2000, P 4 C COMP NAT LANG, V7, P43
   OSTLER N, 1991, P 1 SIGLEX WORKSH LE, P87
   Schneider D., 1998, P 17 INT C COMP LING, V2, P1198
   TANAKA Y, 1977, PSYCHOL METHODS
   Tschichold C., 1997, P RES COMM APPL WORK, P7
   YAROWSKY D, 1995, P 33 ANN M ASS COMP, P189, DOI DOI 10.3115/981658.981684
   YAROWSKY D, 1996, HOMOGRAPH DISAMBIGUA
NR 19
TC 6
Z9 6
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 241
EP 248
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200031
DA 2019-06-15
ER

PT B
AU Nilsson, J
   Nivre, J
   Hall, J
AF Nilsson, Jens
   Nivre, Joakim
   Hall, Johan
GP COLING
TI Graph Transformations in Data-Driven Dependency Parsing
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Transforming syntactic representations in order to improve parsing accuracy has been exploited successfully in statistical parsing systems using constituency-based representations. In this paper, we show that similar transformations can give substantial improvements also in data-driven dependency parsing. Experiments on the Prague Dependency Treebank show that systematic transformations of coordinate structures and verb groups result in a 10% error reduction for a deterministic data-driven dependency parser. Combining these transformations with previously proposed techniques for recovering non-projective dependencies leads to state-of-the-art accuracy for the given data set.
C1 [Nilsson, Jens; Nivre, Joakim; Hall, Johan] Vaxjo Univ, Vaxjo, Sweden.
RP Nilsson, J (reprint author), Vaxjo Univ, Vaxjo, Sweden.
EM jni@msi.vxu.se; nivre@msi.vxu.se; jha@msi.vxu.se
CR Abeille Anne, 2003, TREEBANKS BUILDING U
   Bikel DM, 2004, COMPUT LINGUIST, V30, P479, DOI 10.1162/0891201042544929
   CHANG CC, 2005, LIB SVM LIB SUPPORT
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   COLLINS M, 1999, P 37 ANN M ASS COMP, P505
   Collins M., 1997, P 35 ANN M ASS COMP, P16
   Collins Michael, 1999, THESIS U PENNSYLVANI
   Daelemans W., 2005, MEMORY BASED LANGUAG
   EISNER J, 2005, P 9 INT WORKSH PARS
   Hajic J, 2001, PRAGUE DEPENDENCY TR
   Hajicova Eva, 1998, ISSUES VALENCY MEANI, P12
   HALL K, 2005, P 9 INT WORKSH PARS
   HUDSON Richard A., 1990, ENGLISH WORD GRAMMAR
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   LOMBARDO V, 1998, P WORKSH PROC DEP BA, P11
   McDonald R. T., 2006, P 11 C EUR CHAPT ASS, P81
   MEL'CUK I., 1988, DEPENDENCY SYNTAX TH
   Nilsson Jens, 2006, P 5 INT C LANG RES E
   NIVRE J, 2005, P 43 ANN M ASS COMP, P99
   NIVRE J, 2003, P 8 INT WORKSH PARS, P149
   NIVRE J, 2005, P 4 WORKSH TREEB LIN, P137
   PARK JC, 2000, P INT C COMP LING CO, P593
   Sagae K, 2005, P 9 INT WORKSH PARS, P125
   Sgall P, 1986, MEANING SENTENCE ITS
   Tesniere Lucien., 1959, ELEMENTS SYNTAXE STR
   ZEMAN D, 2004, THESIS CHARLES U
   Zeman D., 2005, P 9 INT WORKSH PARS
NR 28
TC 6
Z9 6
U1 2
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 257
EP 264
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200033
DA 2019-06-15
ER

PT B
AU Schmid, H
AF Schmid, Helmut
GP COLING
TI Trace Prediction and Recovery With Unlexicalized PCFGs and Slash
   Features
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper describes a parser which generates parse trees with empty elements in which traces and fillers are co-indexed. The parser is an unlexicalized PCFG parser which is guaranteed to return the most probable parse. The grammar is extracted from a version of the PENN treebank which was automatically annotated with features in the style of Klein and Manning (2003). The annotation includes GPSG-style slash features which link traces and fillers, and other features which improve the general parsing accuracy. In an evaluation on the PENN treebank (Marcus et al., 1993), the parser outperformed other unlexicalized PCFG parsers in terms of labeled bracketing f-score. Its results for the empty cateory prediction task and the trace -filler coindexation task exceed all previously reported results with 84.1% and 77.4% f-score, respectively.
C1 Univ Stuttgart, IMS, D-7000 Stuttgart, Germany.
RP Schmid, H (reprint author), Univ Stuttgart, IMS, D-7000 Stuttgart, Germany.
EM schmid@ims.uni-stuttgart.de
CR Campbell R., 2004, P 42 M ASS COMP LING, P645
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   COLLINS M, 1997, P 35 ANN M ACL MADR
   Dienes P., 2003, P 41 ANN M ASS COMP, P431
   DIENES P, 2003, P 2003 C EMP METH NA
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Johnson M., 2001, P 39 ANN M ACL TOUL, P136
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   LEVY R, 2004, P 42 ANN M ASS COMP, P327
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   SCHMID H, 2004, P 20 INT C COMP LING, V1, P162
NR 11
TC 6
Z9 6
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 177
EP 184
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200023
DA 2019-06-15
ER

PT B
AU Zhou, GD
   Su, J
   Zhang, M
AF Zhou GuoDong
   Su Jian
   Zhang Min
GP COLING
TI Modeling Commonality among Related Classes in Relation Extraction
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper proposes a novel hierarchical learning strategy to deal with the data sparseness problem in relation extraction by modeling the commonality among related classes. For each class in the hierarchy either manually predefined or automatically clustered, a linear discriminative function is determined in a top-down way using a perceptron algorithm with the lower-level weight vector derived from the upper-level weight vector. As the upper-level class normally has much more positive training examples than the lower-level class, the corresponding linear discriminative function can be determined more reliably. The upper-level discriminative function then can effectively guide the discriminative function learning in the lower-level, which otherwise might suffer from limited training data. Evaluation on the ACE RDC 2003 corpus shows that the hierarchical strategy much improves the performance by 5.6 and 5.1 in F-measure on least- and medium- frequent relations respectively. It also shows that our system outperforms the previous best-reported system by 2.7 in F-measure on the 24 subtypes using the same feature set.
C1 [Zhou GuoDong; Su Jian; Zhang Min] Inst Infocomm Res, Singapore 119613, Singapore.
RP Zhou, GD (reprint author), Inst Infocomm Res, 21 Heng Mui Keng Terrace, Singapore 119613, Singapore.
EM zhougd@i2r.a-star.edu.sg; sujian@i2r.a-star.edu.sg;
   mzhang@i2r.a-star.edu.sg
CR Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Bunescu R. C., 2005, SHORTEST PATH DEPEND, P724
   BUNESCU RC, 2005, SUBSEQUENCE KERNELS
   Collins Michael, 1999, THESIS U PENNSYLVANI
   CULOTTA A, 2004, DEPENDENCY TREE KERN, P423
   Kambhatla N., 2004, COMP VOL P 42 ANN M, P178
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   MILLER S, 2000, NOVEL USE STAT PARSI, P226
   *MUC 7, 1998, P 7 MESS UND C MUC 7
   PLATT J. C., 1999, ADV LARGE MARGIN CLA
   ROTH D, 2002, P 20 INT C COMP LING, P835
   Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205
   Zhang M, 2005, LECT NOTES ARTIF INT, V3651, P378
   Zhao S., 2005, EXTRACTING RELATIONS, P419
   Zhou G., 2005, EXPLORING VARIOUS KN, P427
   ZHOU GD, 2002, NAMED ENTITY RECOGNI, P473
NR 16
TC 6
Z9 6
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 121
EP 128
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200016
DA 2019-06-15
ER

PT B
AU Bean, D
   Riloff, E
AF Bean, D
   Riloff, E
GP acl
TI Unsupervised learning of contextual role knowledge for coreference
   resolution
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB We present a coreference resolver called BABAR that uses contextual role knowledge to evaluate possible antecedents for an anaphor. BABAR uses information extraction patterns to identify contextual roles and creates four contextual role knowledge sources using unsupervised learning. These knowledge sources determine whether the contexts surrounding an anaphor and antecedent are compatible. BABAR applies a Dempster-Shafer probabilistic model to make resolutions based on evidence from the contextual role knowledge sources as well as general knowledge sources. Experiments in two domains showed that the contextual role knowledge improved coreference performance, especially on pronouns.
C1 Attens Corp, Salt Lake City, UT 84101 USA.
RP Bean, D (reprint author), Attens Corp, Suite 600,Gateway 1 90 S 400 W, Salt Lake City, UT 84101 USA.
EM dbean@attensity.com; riloff@cs.utah.edu
CR Allen J., 1995, NATURAL LANGUAGE UND
   [Anonymous], 1992, P 4 MESS UND C MUC 4
   AONE C, 1995, IJCAI 95 WORKSH NEW
   BEAN D, 1999, P 37 ANN M ASS COMP
   Cardie C., 2002, P 40 ANN M ASS COMP
   Dagan I., 1990, P 13 INT C COMP LING, P330
   Dunning T., 1993, Computational Linguistics, V19, P61
   GROSZ B, 1998, CENTERING THEORY DIS, P89
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   HOBBS JR, 1978, LINGUA, V44, P311, DOI 10.1016/0024-3841(78)90006-2
   KEHLER A, 1997, P 2 C EMP METH NAT L
   Lappin S., 1994, Computational Linguistics, V20, P535
   McCarthy J.F., 1995, P 14 INT JOINT C ART
   MILLER G, 1990, INT J LEXICOGRAPHY, V3
   NIYU G, 1998, P 6 WORKSH VER LARG
   Riloff E, 1996, ARTIF INTELL, V85, P101, DOI 10.1016/0004-3702(95)00123-9
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Stefik M., 1995, INTRO KNOWLEDGE SYST
   1998, P 7 MESS UND C MUC 7
   1995, P 6 MESS UND C MUC 6
NR 20
TC 6
Z9 6
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 297
EP 304
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100038
DA 2019-06-15
ER

PT B
AU Higgins, D
   Burstein, J
   Marcu, D
   Gentile, C
AF Higgins, D
   Burstein, J
   Marcu, D
   Gentile, C
GP acl
TI Evaluating multiple aspects of coherence in student essays
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
ID LATENT SEMANTIC ANALYSIS
AB Criterion(SM) Online Essay Evaluation Service includes a capability that labels sentences in student writing with essay-based discourse elements (e.g., thesis statements). We describe a new system that enhances Criterion's capability, by evaluating multiple aspects of coherence in essays. This system identifies features of sentences based on semantic similarity measures and discourse structure. A support vector machine uses these features to capture breakdowns in coherence due to relatedness to the essay question and relatedness between discourse elements. Intra-sentential quality is evaluated with rule-based heuristics. Results indicate that the system yields higher performance than a baseline on all three aspects.
CR BURSTEIN J, 2003, IEEE T INTELLIGENT S, V181, P32
   Burstein J., 2003, P 15 ANN C INN APPL
   Christianini N, 2000, SUPPORT VECTOR MACHI
   Foltz PW, 1998, DISCOURSE PROCESS, V25, P285, DOI 10.1080/01638539809545029
   Hearst MA, 1997, COMPUT LINGUIST, V23, P33
   HEARST MA, 1993, P 16 ANN INT ACM SIG, P59
   Kanerva P., 2000, P 22 ANN C COGN SCI
   KRIPPENDORFF K, 1980, CONTENT ANAL INTRO M
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   LEACOCK C, 2000, P NAACL 2000, P140
   MANN WC, 1986, DISCOURSE PROCESS, V9, P57, DOI 10.1080/01638538609544632
   MILTSAKAKI E, 2000, P LREC 2000 ATH GREE
   SAHLGREN M, 2001, P ESSLLI 2001 WORKSH
   Vapnik VN, 1995, NATURE STAT LEARNING
   Wiemer-Hastings P., 2000, Interactive Learning Environments, V8, P149
NR 15
TC 6
Z9 6
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 185
EP 192
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100024
DA 2019-06-15
ER

PT B
AU Lapata, M
   Keller, F
AF Lapata, M
   Keller, F
GP acl
TI The web as a baseline: Evaluating the performance of unsupervised
   web-based models for a range of NLP tasks
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB Previous work demonstrated that web counts can be used to approximate bigram frequencies, and thus should be useful for a wide variety of NLP tasks. So far, only two generation tasks (candidate selection for machine translation and confusion-set disambiguation) have been tested using web-scale data sets. The present paper investigates if these results generalize to tasks covering both syntax and semantics, both generation and analysis, and a larger range of n-grams. For the majority of tasks, we find that simple, unsupervised models perform better when n-gram frequencies are obtained from the web rather than from a large corpus. However, in most cases, web-based models fail to outperform more sophisticated state-of-the-art models trained on small corpora. We argue that web-based models should therefore be used as a baseline for, rather than an alternative to, standard models.
C1 Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England.
RP Lapata, M (reprint author), Univ Sheffield, Dept Comp Sci, 211 Portobello St, Sheffield S1 4DP, S Yorkshire, England.
CR BALDWIN T, 2003, P 41 ANN M ASS COMP, P463
   Banko M., 2001, P 1 INT C HUM LANG T
   Brill Eric, 2001, P 39 ANN M ASS COMP
   Burnard L., 1995, USERS REFERENCE GUID
   Corley S, 2001, COMPUT HUMANITIES, V35, P81, DOI 10.1023/A:1002497503122
   Cucerzan S, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P33
   Dagan I., 1994, Computational Linguistics, V20, P563
   Golding A.R, 1995, P 3 WORKSH VER LARG, P39
   Golding A. R., 1996, P 34 ANN M ASS COMP, P71
   GOLDING AR, 1999, MACH LEARN, V34, P1
   Grefenstette G, 1998, P ASLIB C TRANSL COM
   Grishman R., 1994, P 15 INT C COMP LING, P268
   IKEHARA S, 1991, P 3 MACH TRANSL SUMM, P101
   Jones M.P., 1997, P 5 C APPL NAT LANG, P166
   Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604
   Lauer M., 1995, P 33 ANN M ASS COMP, P47
   MALOUF R, 2000, P 38 ANN M ASS COMP, P85
   MANGU L, 1997, P 14 INT C MACH LEAR, P187
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Prescher D., 2000, P 18 INT C COMP LING, P649
   Pustejovsky J., 1993, Computational Linguistics, V19, P331
   Resnik Philip, 1993, THESIS U PENNSYLVANI
   Shaw J., 1999, P 37 ANN M ASS COMP, P135
NR 23
TC 6
Z9 6
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 121
EP 128
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100016
DA 2019-06-15
ER

PT B
AU Cherry, C
   Lin, D
AF Cherry, C
   Lin, D
GP ACL
TI A probability model to improve word alignment
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Word alignment plays a crucial role in statistical machine translation. Word-aligned corpora have been found to be an excellent source of translation-related knowledge. We present a statistical model for computing the probability of an alignment given a sentence pair. This model allows easy integration of context-specific features. Our experiments show that this model can be an effective tool for improving an existing word alignment.
C1 Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
CR ADAM LB, 1996, COMPUTATIONAL LINGUI, V22, P39
   Alshawi H, 2000, COMPUT LINGUIST, V26, P45, DOI 10.1162/089120100561629
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CARBONELL J, 2002, P AMTA 02, P1
   Dan Melamed I., 1996, P 2 C ASS MACH T AM, P125
   DANMELAMED I, 2000, COMPUTATIONAL LINGUI, V26, P221
   Dunning T., 1993, Computational Linguistics, V19, P61
   Gale W. A., 1991, P 4 DARPA WORKSH SPE, P152
   HEIDI JF, 2002, P EMNLP02, P304
   IGOR A, 1987, DEPENDENCY SYNTAX TH
   KER SJ, 1997, COMPUTATIONAL LINGUI, V2, P63
   Lopez A., 2002, P WORKSH LING KNOWL
   Menezes A., 2001, P WORKSH DAT DRIV MA
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Resnik Philip, 2002, P 40 ANN M ASS COMP, P392
   Vogel S., 1996, P 16 INT C COMP LING, P836
   WU D, 1997, COMPUTATIONAL LINGUI, V23, P374
   YAMADA K, 2001, M ASS COMPUTATIONAL, P523
NR 18
TC 6
Z9 6
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 88
EP 95
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500012
DA 2019-06-15
ER

PT B
AU Gildea, D
AF Gildea, D
GP ACL
TI Loosely tree-based alignment for machine translation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We augment a model of translation based on re-ordering nodes in syntactic trees in order to allow alignments not conforming to the original tree structure, while keeping computational complexity polynomial in the sentence length. This is done by adding a new subtree cloning operation to either tree-to-string or tree-to-tree alignment algorithms.
C1 Univ Penn, Philadelphia, PA 19104 USA.
CR Barton G. E.  Jr., 1985, Computational Linguistics, V11, P205
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Carroll G, 1992, WORKSH STAT BAS NLP, P1
   Collins Michael, 1999, THESIS U PENNSYLVANI
   Dorr B. J., 1994, Computational Linguistics, V20, P597
   HAJIC J, 2002, NATURAL LANG GENERAT
   HAN CH, 2001, IRCS01010 IRCS
   HIYAN A, 2000, COMPUTATIONAL LINGUI, V26, P45
   MARIALDO B, 1994, COMPUTATIONAL LINGUI, V20, P155
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   OCH FJ, 2002, P ACL 02 PHIL PA
   WU D, 1997, COMPUTATIONAL LINGUI, V23, P3
   YAMADA K, 2001, P ACL01
   YAMADA K, 2002, P ACL 02 PHIL PA
NR 15
TC 6
Z9 6
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 80
EP 87
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500011
DA 2019-06-15
ER

PT B
AU Zens, R
   Ney, H
AF Zens, R
   Ney, H
GP ACL
TI A comparative study on reordering constraints in statistical machine
   translation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
ID SCHRODER NUMBERS
AB In statistical machine translation, the generation of a translation hypothesis is computationally expensive. If arbitrary wordreorderings are permitted, the search problem is NP-hard. On the other hand, if we restrict the possible word-reorderings in an appropriate way, we obtain a polynomial-time search algorithm.
   In this paper, we compare two different reordering constraints, namely the ITG constraints and the IBM constraints. This comparison includes a theoretical discussion on the permitted number of re-orderings for each of these constraints. We show a connection between the ITG constraints and the since 1870 known Schroder numbers.
   We evaluate these constraints on two tasks: the Verbmobil task and the Canadian Hansards task. The evaluation consists of two parts: First, we check how many of the Viterbi alignments of the training corpus satisfy each of these constraints. Second, we restrict the search to each of these constraints and compare the resulting translation hypotheses.
   The experiments will show that the baseline ITG constraints are not sufficient on the Canadian Hansards task. Therefore, we present an extension to the ITG constraints. These extended ITG constraints increase the alignment coverage from about 87% to 96%.
C1 Rhein Westfal TH Aachen, Rhein Westfal TH Aachen, Chair Comp Sci 6, Aachen, Germany.
CR Berger A.L., 1996, United States Patent, Patent No. 5510981
   Brown P. F., 1990, Computational Linguistics, V16, P79
   Knight K, 1999, COMPUT LINGUIST, V25, P607
   Knuth D. E., 1973, ART COMPUTER PROGRAM, V1
   Niessen S, 2000, P 2 INT C LANG RES E, P39
   Och F. J., 2002, P 40 ANN M ASS COMP, P295
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   PAPINENI KA, 2001, RC22176 IBM RES DIV
   Schroeder E., 1870, Z MATH PHYS, V15, P361
   SHAPIRO L, 1991, SIAM J DISCRETE MATH, V4, P275, DOI 10.1137/0404025
   Ueffing N, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P156
   VILAR JM, 1998, THESIS U POLITECNICA
   Wahlster W., 2000, VERBMOBIL FDN SPEECH
   WEST J, 1995, DISCRETE MATH, V146, P247, DOI 10.1016/0012-365X(94)00067-1
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   WU D, 1995, P 14 INT JOINT C ART, P1328
   Wu D, 1996, P 34 ANN C ASS COMP, P152
NR 17
TC 6
Z9 6
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 144
EP 151
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500019
DA 2019-06-15
ER

PT S
AU Shimada, K
   Tadano, R
   Endo, T
AF Shimada, Kazutaka
   Tadano, Ryosuke
   Endo, Tsutomu
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Multi-aspects review summarization with objective information
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE sentiment analysis; multi-aspects review summarization; objective
   information; opinion integration
AB In this paper, we propose a method for multi-aspects review summarization based on evaluative sentence extraction. We handle three features; ratings of aspects, the tfidf value, and the number of mentions with a similar topic. For estimating the number of mentions, we apply a clustering algorithm. By using these features, we generate a more appropriate summary. In this paper, we also focus on objective information of the target product. We integrate the summary from sentiment information in reviews and the objective information extracted from Wikipedia. The experiment results show the effectiveness of our method. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Shimada, Kazutaka; Tadano, Ryosuke; Endo, Tsutomu] Kyushu Inst Technol, Dept Artificial Intelligence, Iizuka, Fukuoka 8208502, Japan.
EM shimada@pluto.ai.kyutech.ac.jp
CR Blair-Goldensohn Sasha, 2008, P WWW 2008 NLPIX WOR
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   BRANDOW R, 1995, INFORM PROCESS MANAG, V31, P675, DOI 10.1016/0306-4573(95)00052-I
   Hadano M., 2011, P PACLING 2011
   Ishii H., 2001, INFORM PROCESSING SO, V2001, P83
   LIN C, 2004, P NTCIR WORKSH, V4
   Lu Y., 2008, P 17 INT C WORLD WID, P121, DOI DOI 10.1145/1367497.1367514
   Meng X., 2009, P ACL IJCNLP 2009 C, P177
   Nishikawa H., 2010, P 23 INT C COMP LING
   Pang B., 2004, P 42 ANN M ASS COMP, V42, P271, DOI DOI 10.3115/1218955.1218990
   Seki Tsunehito, 2007, Systems and Computers in Japan, V38, P25, DOI 10.1002/scj.20827
   Shimada K., 2008, P PAKDD 2008
   Tadano R, 2010, PROCEEDINGS OF THE 24TH PACIFIC ASIA CONFERENCE ON LANGUAGE, INFORMATION AND COMPUTATION, P685
   Takamura H., 2009, P 18 ACM INT C INF K, P1589
NR 14
TC 5
Z9 6
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 140
EP 149
DI 10.1016/j.sbspro.2011.10.592
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700016
OA Other Gold
DA 2019-06-15
ER

PT B
AU Bergsma, S
   Pitler, E
   Lin, D
AF Bergsma, Shane
   Pitler, Emily
   Lin, Dekang
GP Assoc Computat Linguist
TI Creating Robust Supervised Classifiers via Web-Scale N-gram Data
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In this paper, we systematically assess the value of using web-scale N-gram data in state-of-the-art supervised NLP classifiers. We compare classifiers that include or exclude features for the counts of various N-grams, where the counts are obtained from a web-scale auxiliary corpus. We show that including N-gram count features can advance the state-of-the-art accuracy on standard data sets for adjective ordering, spelling correction, noun compound bracketing, and verb part-of-speech dis-ambiguation. More importantly, when operating on new domains, or when labeled training data is not plentiful, we show that using web-scale N-gram features is essential for achieving robust performance.
C1 [Bergsma, Shane] Univ Alberta, Edmonton, AB T6G 2M7, Canada.
   [Pitler, Emily] Univ Penn, Philadelphia, PA 19104 USA.
   [Lin, Dekang] Google Inc, Mountain View, CA USA.
RP Bergsma, S (reprint author), Univ Alberta, Edmonton, AB T6G 2M7, Canada.
EM sbergsma@ualberta.ca; epitler@seas.upenn.edu; lindek@google.com
CR Ailon Nir, 2008, COLT
   BANKO M, 2001, ACL
   Barr C., 2008, EMNLP
   Bergsma Shane, 2009, IJCAI
   Blitzer  John, 2007, ACL
   Brants T., 2007, EMNLP
   Brants T., 2006, GOOGLE WEB 1T 5 GRAM
   Brants T., 2000, ANLP
   CARLSON A, 2008, CMUML08107
   Church Kenneth, 2007, EMNLP CONLL
   DaumeIII H., 2007, ACL
   Fan R.-E., 2008, J MACHINE LEARNING R, V9
   Gildea D., 2001, EMNLP
   Golding AR, 1999, MACH LEARN, V34, P107, DOI 10.1023/A:1007545901558
   Joachims  T., 2002, KDD
   Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604
   Keller F., 2005, ACM T SPEECH LANGUAG, V2, P1
   Kilgarriff A, 2003, COMPUT LINGUIST, V29, P333, DOI 10.1162/089120103322711569
   Kulick Seth, 2004, BIOLINK 2004 LINKING
   Lauer M., 1995, THESIS
   Lauer Mark, 1995, ACL
   Lin Dekang, 2010, LREC
   Malouf Robert, 2000, ACL
   Marcus M. P., 1980, THEORY SYNTACTIC REC
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   McClosky David, 2006, COLING ACL
   Mitchell Margaret, 2009, 12 EUR WORKSH NAT LA
   Modjeska Natalia N., 2003, EMNLP
   Nakov Preslav, 2005, CONLL
   Nakov Preslav Ivanov, 2007, THESIS
   Phan X.-H., 2006, CRFTAGGER CRF ENGLIS
   Rimell Laura, 2008, EMNLP
   Shaw James, 1999, ACL
   Tsuruoka Y, 2005, ADV INFORM
   Turney PD, 2006, COMPUT LINGUIST, V32, P379, DOI 10.1162/coli.2006.32.3.379
   Vadas D., 2007, ACL
   Vadas David, 2007, PACLING
   YANG X, 2005, ACL
NR 38
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 865
EP 874
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300089
DA 2019-06-15
ER

PT B
AU Chen, YF
   Zong, CQ
   Su, KY
AF Chen, Yufeng
   Zong, Chengqing
   Su, Keh-Yih
GP Assoc Computat Linguist
TI On Jointly Recognizing and Aligning Bilingual Named Entities
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We observe that (1) how a given named entity (NE) is translated (i. e., either semantically or phonetically) depends greatly on its associated entity type, and (2) entities within an aligned pair should share the same type. Also, (3) those initially detected NEs are anchors, whose information should be used to give certainty scores when selecting candidates. From this basis, an integrated model is thus proposed in this paper to jointly identify and align bilingual named entities between Chinese and English. It adopts a new mapping type ratio feature (which is the proportion of NE internal tokens that are semantically translated), enforces an entity type consistency constraint, and utilizes additional monolingual candidate certainty factors (based on those NE anchors). The experiments show that this novel approach has substantially raised the type-sensitive F-score of identified NE-pairs from 68.4% to 81.7% (42.1% F-score imperfection reduction) in our Chinese-English NE alignment task.
C1 [Chen, Yufeng; Zong, Chengqing] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
   [Su, Keh-Yih] Behav Design Corp, Hsinchu, Taiwan.
RP Chen, YF (reprint author), Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
EM chenyf@nlpr.ia.ac.cn; cqzong@nlpr.ia.ac.cn; bdc.kysu@gmail.com
CR Al-Onaizan Y., 2002, P 40 ANN M ASS COMP, P400, DOI DOI 10.3115/1073083.1073150
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Chen H.-J., 2003, P ACL 2003 WORKSH MU, P1
   Feng D., 2004, P C EMP METH NAT LAN, V2004, P372
   Huang Fei, 2003, P ACL 03 WORKSH MULT
   Ji Heng, 2006, P COLING ACL 06 SYDN
   Lee Chun-Jen, 2006, ACM T ASIAN LANGUAGE, V5, P121
   Moore R. C., 2003, P 10 C EUR ACL BUD H
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Stolcke A., 2002, P INT C SPOK LANG PR, P901
   Wu Youzheng, 2005, P HUM LANG TECHN C C, P427
   Zhang Y., 2004, P 4 INT C LANG RES E, P2051
NR 12
TC 5
Z9 5
U1 1
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 631
EP 639
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300065
DA 2019-06-15
ER

PT B
AU Croce, D
   Giannone, C
   Annesi, P
   Basili, R
AF Croce, Danilo
   Giannone, Cristina
   Annesi, Paolo
   Basili, Roberto
GP Assoc Computat Linguist
TI Towards Open-Domain Semantic Role Labeling
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Current Semantic Role Labeling technologies are based on inductive algorithms trained over large scale repositories of annotated examples. Frame-based systems currently make use of the FrameNet database but fail to show suitable generalization capabilities in out-of-domain scenarios. In this paper, a state-of-art system for frame-based SRL is extended through the encapsulation of a distributional model of semantic similarity. The resulting argument classification model promotes a simpler feature space that limits the potential overfitting effects. The large scale empirical study here discussed confirms that state-of-art accuracy can be obtained for out-of-domain evaluations.
C1 [Croce, Danilo; Giannone, Cristina; Annesi, Paolo; Basili, Roberto] Univ Roma, Dept Comp Sci Syst & Prod, Tor Vergata, Italy.
RP Croce, D (reprint author), Univ Roma, Dept Comp Sci Syst & Prod, Tor Vergata, Italy.
EM croce@info.uniroma2.it; giannone@info.uniroma2.it;
   annesi@info.uniroma2.it; basili@info.uniroma2.it
OI CROCE, DANILO/0000-0001-9111-1950; BASILI, ROBERTO/0000-0001-5140-0694
CR BAKER C, 2007, P 4 INT WORKSH SEM E, P99
   BAKER Collin F., 1998, P COLING ACL MONTR C
   Carreras X., 2005, P 9 C COMP NAT LANG, P152
   Collobert R., 2008, P 25 INT C MACH LEAR, P160
   Coppola B., 2009, P HUM LANG TECHN 200, P85
   Deschacht K., 2009, EMNLP, P21
   ERK K, 2006, P LREC 2006 GEN IT
   Erk Katrin, 2009, P 13 C COMP NAT LANG, P57
   Fillmore Charles J., 1985, QUADERNI SEMANTICA, V6, P222, DOI DOI 10.4236/CE.2011.24050
   Furstenau H., 2009, P 2009 C EMP METH NA, P11
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Goldberg Yoav, 2009, P EMNLP 09 SING AUG, P1142
   Heyer LJ, 1999, GENOME RES, V9, P1106, DOI 10.1101/gr.9.11.1106
   Johansson R., 2008, P CONLL 2008 MANCH U
   Johansson R., 2008, P COLING MANCH UK AU
   Johnson R, 2008, IEEE T INFORM THEORY, V54, P275, DOI 10.1109/TIT.2007.911294
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   Lapata Mirella, 2007, COMPUTATIONAL LINGUI, V33
   Martha P., 2005, COMPUT LINGUIST, V31, P1, DOI DOI 10.1162/0891201053630264
   Moschitti A., 2008, COMPUTATIONAL LINGUI, V34
   Pado Sebastian, 2007, THESIS
   Pradhan SS, 2008, COMPUT LINGUIST, V34, P289, DOI 10.1162/coli.2008.34.2.289
   Tjong E. F., 2000, P CONLL 2000 LLL 200, P127
   Toutanova K, 2008, COMPUT LINGUIST, V34, P161, DOI 10.1162/coli.2008.34.2.161
NR 24
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 237
EP 246
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300025
DA 2019-06-15
ER

PT B
AU Finkel, JR
   Manning, CD
AF Finkel, Jenny Rose
   Manning, Christopher D.
GP Assoc Computat Linguist
TI Hierarchical Joint Learning: Improving Joint Parsing and Named Entity
   Recognition with Non-Jointly Labeled Data
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB One of the main obstacles to producing high quality joint models is the lack of jointly annotated data. Joint modeling of multiple natural language processing tasks outperforms single-task models learned from the same data, but still under-performs compared to single-task models learned on the more abundant quantities of available single-task annotated data. In this paper we present a novel model which makes use of additional single-task annotated data to improve the performance of a joint model. Our model utilizes a hierarchical prior to link the feature weights for shared features in several single-task models and the joint model. Experiments on joint parsing and named entity recognition, using the OntoNotes corpus, show that our hierarchical joint model can produce substantial gains over a joint model trained on only the jointly annotated data.
C1 [Finkel, Jenny Rose; Manning, Christopher D.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Finkel, JR (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM jrfinkel@cs.stanford.edu; manning@cs.stanford.edu
CR Adler M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P665
   Ando Rie Kubota, 2005, ACL 05 P 43 ANN M AS, P1
   Andrew Galen, 2006, P C EMP METH NAT LAN
   Baxter J., 1997, MACHINE LEARNING, V28
   Caruana R., 1997, MACHINE LEARNING, V28
   COLLINS M, 1997, ACL 1997
   Daume III H, 2007, C ASS COMP LING ACL
   Elidan Gal, 2008, UAI 2008
   Evgeniou T., 2005, J MACHINE LEARNING R
   Finkel Jenny Rose, 2009, P N AM ASS COMP LING
   Finkel Jenny Rose, P N AM ASS COMP LING
   Finkel Jenny Rose, 2008, ACL HLT 2008
   Finkel Jenny Rose, 2009, P EMNLP 2009
   Gelman A., 2003, BAYESIAN DATA ANAL
   Gelman A., 2006, DATA ANAL USING REGR
   Hovy Eduard, 2006, HLT NAACL 2006
   Johansson Richard, 2008, CONLL 2008, P183
   Miller Scott, 2000, 6 APPL NAT LANG PROC, P226
   Sarawagi S, 2004, ADV NEURAL INFORM PR, P1185
   Surdeanu M., 2008, P 12 C COMP NAT LANG
   Sutton Charles, 2005, C NAT LANG LEARN CON
   Toutanova K, 2009, P JOINT C 47 ANN M A, V1, P486
   Tsarfaty Reut, 2008, P ACL 08 HLT COL OH, P371
   Xue Y, 2007, J MACH LEARN RES, V8, P35
   Yu Kai, 2005, ICML 05
   Zhang Yue, 2008, ACL 2008
NR 26
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 720
EP 728
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300074
DA 2019-06-15
ER

PT B
AU Kozareva, Z
   Hovy, E
AF Kozareva, Zornitsa
   Hovy, Eduard
GP Assoc Computat Linguist
TI Learning Arguments and Supertypes of Semantic Relations using Recursive
   Patterns
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB A challenging problem in open information extraction and text mining is the learning of the selectional restrictions of semantic relations. We propose a minimally supervised bootstrapping algorithm that uses a single seed and a recursive lexico-syntactic pattern to learn the arguments and the supertypes of a diverse set of semantic relations from the Web. We evaluate the performance of our algorithm on multiple semantic relations expressed using "verb", "noun", and "verb prep" lexico-syntactic patterns. Human-based evaluation shows that the accuracy of the harvested information is about 90%. We also compare our results with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge.
C1 [Kozareva, Zornitsa; Hovy, Eduard] USC Informat Sci Inst, 4676 Admiralty Way, Marina Del Rey, CA 90292 USA.
RP Kozareva, Z (reprint author), USC Informat Sci Inst, 4676 Admiralty Way, Marina Del Rey, CA 90292 USA.
EM kozareva@isi.edu; hovy@isi.edu
CR Banko M., 2008, P 46 ANN M ASS COMP, V8, P28
   DAVIDOV D, 2007, P 45 ANN M ASS COMP, P232
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   Fleischman M, 2002, P 19 INT C COMP LING, P1, DOI DOI 10.3115/1072228.1072358
   Girju Roxana, 2003, P C N AM CHAPT ASS C, V1, P1
   Hearst M. A., 1992, P 14 C COMP LING, V2, P539, DOI DOI 10.3115/992133.992154
   Hovy E., 2009, P 2009 C EMP METH NA, V2, P948
   Igo Sean, 2009, P WORKSH UNS MIN SUP
   Katz B., 2003, P WORKSH NAT LANG PR, P43
   Katz Boris, 2003, TREC 2003, P426
   Kozareva Z., 2008, P 46 ANN M ASS COMP, V8, P1048
   Lehrberger John, 1988, MACHINE TRANSLATION
   Lin D., 2002, P 19 INT C COMP LING
   Pantel P, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P321
   Pantel P, 2009, P 2009 C EMP METH NA, P938
   Pasca M., 2004, P 13 ACM C INF KNOWL, P137
   Pennacchiotti M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P793
   Riloff E., 1999, AAAI 99 IAAI 99, P474
   Riloff E, 1997, P 2 C EMP METH NAT L, P117
   Roark B., 1998, P 36 ANN M ASS COMP, P1110, DOI DOI 10.3115/980691.980751
   Snow R., 2005, ADV NEURAL INFORM PR, V17, P1297
   Suchanek Fabian M, 2007, P 16 INT C WORLD WID, P697, DOI [10.1145/1242572.1242667, DOI 10.1145/1242572.1242667]
   Talukdar P. P., 2008, EMNLP, P582
   Thelen M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P214
   WILKS Y, 1975, ARTIF INTELL, V6, P53, DOI 10.1016/0004-3702(75)90016-8
   Yates A., 2007, P HUM LANG TECHN ANN, P25
   Zanzotto FM, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P849
NR 27
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1482
EP 1491
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300150
DA 2019-06-15
ER

PT B
AU May, J
   Knight, K
   Vogler, H
AF May, Jonathan
   Knight, Kevin
   Vogler, Heiko
GP Assoc Computat Linguist
TI Efficient Inference Through Cascades of Weighted Tree Transducers
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID TOP-DOWN; AUTOMATA
AB Weighted tree transducers have been proposed as useful formal models for representing syntactic natural language processing applications, but there has been little description of inference algorithms for these automata beyond formal foundations. We give a detailed description of algorithms for application of cascades of weighted tree transducers to weighted tree acceptors, connecting formal theory with actual practice. Additionally, we present novel on-the-fly variants of these algorithms, and compare their performance on a syntax machine translation cascade based on (Yamada and Knight, 2001).
C1 [May, Jonathan; Knight, Kevin] Univ Southern Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
   [Vogler, Heiko] Tech Univ Dresden, Inst Theoret Informat, D-01062 Dresden, Germany.
RP May, J (reprint author), Univ Southern Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
EM jonmay@isi.edu; knight@isi.edu; heiko.vogler@tu-dresden.de
CR ALEXANDRAKIS A, 1987, INFORM PROCESS LETT, V24, P1, DOI 10.1016/0020-0190(87)90190-6
   BAKER BS, 1979, INFORM CONTROL, V41, P186, DOI 10.1016/S0019-9958(79)90561-8
   Esik Z., 2003, Journal of Automata, Languages and Combinatorics, V8, P219
   Fulop Z, 2009, MONOGR THEOR COMPUT, P313, DOI 10.1007/978-3-642-01492-5_9
   Fulop Zoltan, 2010, BACKWARD FORWA UNPUB
   Gecseg F., 1984, TREE AUTOMATA
   Kuich W., 1999, Acta Cybernetica, V14, P135
   Kuich Werner, 1998, P 3 INT C DEV LANG T, P61
   Liang Huang, 2005, P 9 INT WORKSH PARS, P53
   Maletti A, 2008, INFORM COMPUT, V206, P1187, DOI 10.1016/j.ic.2008.03.019
   Maletti A, 2006, THEOR COMPUT SCI, V366, P248, DOI 10.1016/j.tcs.2006.08.026
   Maletti A, 2009, SIAM J COMPUT, V39, P410, DOI 10.1137/070699160
   Maletti Andreas, 2009, COMMUNICATION
   Mohri M, 1997, COMPUT LINGUIST, V23, P269
   Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6
   Mohri M, 2009, MONOGR THEOR COMPUT, P213, DOI 10.1007/978-3-642-01492-5_6
   Pauls Adam, 2009, P JOINT C 47 ANN M A, P958
   Pereira FCN, 1997, LANG SPEECH & COMMUN, P431
   Woods W. A., 1980, AM J COMPUTATIONAL L, V6, P1
   YAMADA K, 2001, P 39 ANN M ASS COMP, P523
NR 20
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1058
EP 1066
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300108
DA 2019-06-15
ER

PT B
AU Mitchell, J
   Lapata, M
   Demberg, V
   Keller, F
AF Mitchell, Jeff
   Lapata, Mirella
   Demberg, Vera
   Keller, Frank
GP Assoc Computat Linguist
TI Syntactic and Semantic Factors in Processing Difficulty: An Integrated
   Measure
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID LANGUAGE COMPREHENSION; SENTENCE; REPRESENTATION; INFORMATION; CONTEXT;
   MODEL
AB The analysis of reading times can provide insights into the processes that underlie language comprehension, with longer reading times indicating greater cognitive load. There is evidence that the language processor is highly predictive, such that prior context allows upcoming linguistic material to be anticipated. Previous work has investigated the contributions of semantic and syntactic contexts in isolation, essentially treating them as independent factors. In this paper we analyze reading times in terms of a single predictive measure which integrates a model of semantic composition with an incremental parser and a language model.
C1 [Mitchell, Jeff; Lapata, Mirella; Demberg, Vera; Keller, Frank] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
RP Mitchell, J (reprint author), Univ Edinburgh, Edinburgh, Midlothian, Scotland.
EM jeff.mitchell@ed.ac.uk; mlap@inf.ed.ac.uk; v.demberg@ed.ac.uk;
   keller@inf.ed.ac.uk
CR ACL, 2010, P 48 ANN M ASS COMP
   ALTMANN G, 1988, COGNITION, V30, P191, DOI 10.1016/0010-0277(88)90020-0
   Altmann GTM, 1999, COGNITION, V73, P247, DOI 10.1016/S0010-0277(99)00059-1
   [Anonymous], 1999, P EUROSPEECH, P2167
   Bellegarda JR, 2000, P IEEE, V88, P1279, DOI 10.1109/5.880084
   Berry MW, 1995, SIAM REV, V37, P573, DOI 10.1137/1037127
   Bever T. G., 1970, COGNITION DEV LANGUA, P279, DOI DOI 10.1093/ACPROF:OSO/9780199677139.003.0001
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boston MF, 2008, J EYE MOVEMENT RES, V2
   Brian R., 2001, COMPUTATIONAL LINGUI, V27, P249
   Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020
   Clifton Charles Jr., 2007, P341, DOI 10.1016/B978-008044980-7/50017-3
   COCCARO N, 1998, P INT C SPOK LANG PR, P2403
   Demberg V, 2008, COGNITION, V109, P193, DOI 10.1016/j.cognition.2008.07.008
   Dubey Amit, 2010, ACL
   Frank Stefan L., 2009, P 31 ANN C COGN SCI, P139
   Gibson E, 2000, IMAGE, LANGUAGE, BRAIN, P95
   Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211
   HALE J, 2001, P NAACL, V2, P159
   Keith Rayner, 1998, PSYCHOL BULL, V124, P372
   Keller Frank, 2010, ACL
   Kennedy A, 2005, VISION RES, V45, P153, DOI 10.1016/j.visres.2004.07.037
   Konieczny L, 2000, J PSYCHOLINGUIST RES, V29, P627, DOI 10.1023/A:1026528912821
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   Lapata M., 2008, P 46 ANN M ASS COMP, P236
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   MCDONALD S, 2004, P 42 ANN M ASS COMP, P17
   McDonald S, 2000, THESIS
   McDonald SA, 2003, VISION RES, V43, P1735, DOI 10.1016/S0042-6989(03)00237-2
   Mitchell Jeff, 2009, P 2009 C EMP METH NA, P430
   Narayanan S, 2002, ADV NEUR IN, V14, P59
   Pado S, 2007, COMPUT LINGUIST, V33, P161, DOI 10.1162/coli.2007.33.2.161
   Pado U, 2009, COGNITIVE SCI, V33, P794, DOI 10.1111/j.1551-6709.2009.01033.x
   Pinheiro J. C., 2000, MIXED EFFECTS MODELS
   Pinker S., 1994, LANGUAGE INSTINCT MI
   PLATE TA, 1995, IEEE T NEURAL NETWOR, V6, P623, DOI 10.1109/72.377968
   Pynte J, 2008, VISION RES, V48, P2172, DOI 10.1016/j.visres.2008.02.004
   Roark B., 2009, P 2009 C EMP METH NA, P324, DOI DOI 10.3115/1699510.1699553
   SMOLENSKY P, 1990, ARTIF INTELL, V46, P159, DOI 10.1016/0004-3702(90)90007-M
   STANOVICH KE, 1981, J EXP PSYCHOL HUMAN, V7, P658
   Staub A, 2006, J EXP PSYCHOL LEARN, V32, P425, DOI 10.1037/0278-7393.32.2.425
   Steyvers M., 2007, HDB LATENT SEMANTIC
   Stolcke A., 2002, P INT C SPOK LANG PR
   Sturt P, 2005, COGNITIVE SCI, V29, P291, DOI 10.1207/s15516709cog0000_8
   TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863
   van Berkum JJA, 1999, J MEM LANG, V41, P147, DOI 10.1006/jmla.1999.2641
   WILSON WM, 1973, NATURE, V244, P522, DOI 10.1038/244522a0
   WRIGHT B, 1984, MEM COGNITION, V12, P31, DOI 10.3758/BF03196995
NR 48
TC 5
Z9 5
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 196
EP 206
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300021
DA 2019-06-15
ER

PT S
AU Nenkova, A
   Chae, J
   Louis, A
   Pitler, E
AF Nenkova, Ani
   Chae, Jieun
   Louis, Annie
   Pitler, Emily
BE Krahmer, E
   Theune, M
TI Structural Features for Predicting the Linguistic Quality of Text
   Applications to Machine Translation, Automatic Summarization and
   Human-Authored Text
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
ID SENTENCE COMPRESSION; LOCAL COHERENCE; LANGUAGE
AB Sentence structure is considered to be an important component of the overall linguistic quality of text. Yet few empirical studies have sought to characterize how and to what extent structural features determine fluency and linguistic quality. We report the results of experiments on the predictive power of syntactic phrasing statistics and other structural features for these aspects of text. Manual assessments of sentence fluency for machine translation evaluation and text quality for summarization evaluation are used as gold-standard. We find that many structural features related to phrase length are weakly but significantly correlated with fluency and classifiers based on the entire suite of structural features can achieve high accuracy in pairwise comparison of sentence fluency and in distinguishing machine translations from human translations. We also test the hypothesis that the learned models capture general fluency properties applicable to human-authored text. The results from our experiments do not support the hypothesis. At the same time structural features and models based on them prove to be robust for automatic evaluation of the linguistic quality of multi-document summaries.
C1 [Nenkova, Ani; Chae, Jieun; Louis, Annie; Pitler, Emily] Univ Penn, Philadelphia, PA 19104 USA.
RP Nenkova, A (reprint author), Univ Penn, Philadelphia, PA 19104 USA.
EM nenkova@seas.upenn.edu; chaeji@seas.upenn.edu; lannie@seas.upenn.edu;
   epitler@seas.upenn.edu
CR Bailin A, 2001, LANG COMMUN, V21, P285, DOI 10.1016/S0271-5309(01)00005-2
   Bangalore S, 2000, P 18 INT C COMP LING, P42
   Bangalore Srinivas, 2000, P 1 INT C NAT LANG G, P1
   BANKO M, 2000, P 38 ANN M ASS COMP, P318
   Barzilay R, 2005, COMPUT LINGUIST, V31, P297, DOI 10.1162/089120105774321091
   Barzilay R, 2008, COMPUT LINGUIST, V34, P1, DOI 10.1162/coli.2008.34.1.1
   Cahill A., 2007, P 11 EUR WORKSH NAT, P17
   Cahill A, 2010, LECT NOTES ARTIF INT, V5790, P201, DOI 10.1007/978-3-642-15573-4_11
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   Charniak E, 2005, P 43 ANN M ASS COMP, P173, DOI DOI 10.3115/1219840.1219862
   Charniak E., 2005, P 43 ANN M ASS COMP, P290
   CLARKE J, 2006, P 21 INT C COMP LING, P377
   Collins M, 2005, COMPUT LINGUIST, V31, P25, DOI 10.1162/0891201053630273
   Collins-Thompson K., 2004, P HUM LANG TECHN C N, P193
   Conroy J. M., 2008, P 22 INT C COMP LING, P145
   CORSTONOLIVER S, 2001, P 39 ANN M ASS COMP, P148
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Elsner M., 2007, HUMAN LANGUAGE TECHN, P436
   Galley M., 2007, HUMAN LANGUAGE TECHN, P180
   Graesser AC, 2004, BEHAV RES METH INS C, V36, P193, DOI 10.3758/BF03195564
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   HABERLANDT KF, 1985, J EXP PSYCHOL GEN, V114, P357, DOI 10.1037//0096-3445.114.3.357
   Holmes G., 1994, 2 AUSTR NZ C INT INF, P357
   Huang Liang, 2008, P 46 ANN M ASS COMP, P586
   JING H, 2000, P 6 C APPL NAT LANG, P310
   Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI DOI 10.1145/775047.775067
   Just M. A., 1987, PSYCHOL READING LANG
   Karamanis N, 2009, COMPUT LINGUIST, V35, P29, DOI 10.1162/coli.07-036-R2-06-22
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   LANGKILDE I, 1998, P 36 ANN M ASS COMP, P704
   LAPATA M, 2005, P 19 INT JOINT C ART, P1085
   LAPATA M, 2003, P 41 M ASS COMP LING, P545
   Lin C. Y., 2004, P WORKSH TEXT SUMM B, P25
   LIN CY, 2003, P 2003 C N AM CHAPT, P71
   MCDONALD R., 2006, P 11 C EUR CHAPT ASS, P297
   Mutton Andrew, 2007, P 45 ANN M ASS COMP, P344
   Over P, 2007, INFORM PROCESS MANAG, V43, P1506, DOI 10.1016/j.ipm.2007.01.019
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Petersen SE, 2009, COMPUT SPEECH LANG, V23, P89, DOI 10.1016/j.csl.2008.04.003
   Pitler Emily, 2008, P C EMP METH NAT LAN, P186, DOI DOI 10.3115/1613715.1613742
   Rieser V, 2010, LECT NOTES ARTIF INT, V5790, P105, DOI 10.1007/978-3-642-15573-4_6
   Schwarm SE, 2005, P 43 ANN M ASS COMP, P523
   SIDDHARTHAN A, 2003, THESIS U CAMBRIDGE U
   Soricut R, 2007, INFORM PROCESS MANAG, V43, P1536, DOI 10.1016/j.ipm.2007.01.017
   Soricut R., 2006, P COLING ACL MAIN C, P803
   Stolcke A., 2002, 7 INT C SPOK LANG PR, V3
   Velldal Erik, 2005, P 10 MACH TRANSL SUM, P109
   WAN S, 2005, P 10 EUR WORKSH NAT, P211
   Zajic D, 2007, INFORM PROCESS MANAG, V43, P1549, DOI 10.1016/j.ipm.2007.01.016
   Zwarts S., 2008, P 22 INT C COMP LING, P1153
NR 50
TC 5
Z9 5
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 222
EP 241
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600012
DA 2019-06-15
ER

PT B
AU Schmitz, S
AF Schmitz, Sylvain
GP Assoc Computat Linguist
TI On the Computational Complexity of Dominance Links in Grammatical
   Formalisms
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID PETRI NETS; LANGUAGES; GRAMMARS; TREES
AB Dominance links were introduced in grammars to model long distance scrambling phenomena, motivating the definition of multiset-valued linear indexed grammars (MLIGs) by Rambow (1994b), and inspiring quite a few recent formalisms. It turns out that MLIGs have since been rediscovered and reused in a variety of contexts, and that the complexity of their emptiness problem has become the key to several open questions in computer science. We survey complexity results and open issues on MLIGs and related formalisms, and provide new complexity bounds for some linguistically motivated restrictions.
C1 [Schmitz, Sylvain] ENS Cachan, LSV, Cachan, France.
   [Schmitz, Sylvain] CNRS, F-75700 Paris, France.
RP Schmitz, S (reprint author), ENS Cachan, LSV, Cachan, France.
EM sylvain.schmitz@lsv.ens-cachan.fr
CR Althaus E, 2003, J ALGORITHMS, V48, P194, DOI 10.1016/S0196-6774(03)00050-6
   Anthony Kroch, 1991, PRINCIPLES PARAMETER, P269
   Bar-Hillel Y, 1961, Z PHONETIK SPRACHWIS, V14, P143
   Becker Tilman, 1991, EACL 91, P21
   Bojanczyk M, 2009, J ACM, V56, DOI 10.1145/1516512.1516515
   Candito Marie-Helene, 1998, TAG 4, P25
   Cardoza E., 1976, STOC, P50, DOI DOI 10.1145/800113.803630
   Champollion Lucas, 2007, MOL 10
   CHANDRA AK, 1981, J ACM, V28, P114, DOI 10.1145/322234.322243
   Chiang David, 2008, TAG 9
   CREMERS AB, 1974, J COMPUT SYST SCI, V8, P158, DOI 10.1016/S0022-0000(74)80053-X
   de Groote P, 2004, IEEE S LOG, P64, DOI 10.1109/LICS.2004.1319601
   DEMRI S, 2009, LEIBNIZ INT P INFORM, V4, P181
   Dufourd C, 1999, THEOR COMPUT SCI, V222, P187, DOI 10.1016/S0304-3975(98)00351-X
   Edward Barton G., 1985, ACL 85, P76
   ESPARZA J, 1995, LNCS, V965, P221
   Guillaume Bruno, 2010, RES LANGUAG IN PRESS
   Haddad S, 2007, ACTA INFORM, V44, P463, DOI 10.1007/s00236-007-0055-y
   Hopcroft J., 1979, Theoretical Computer Science, V8, P135, DOI 10.1016/0304-3975(79)90041-0
   HUYNH DT, 1983, INFORM CONTROL, V57, P21, DOI 10.1016/S0019-9958(83)80022-9
   JANTZEN M, 1979, RAIRO-INF THEOR-TH C, V13, P19
   Jones N. D., 1977, Theoretical Computer Science, V4, P277, DOI 10.1016/0304-3975(77)90014-7
   Jones N. D., 1976, Theoretical Computer Science, V3, P105, DOI 10.1016/0304-3975(76)90068-2
   Joshi A. K., 1985, NATURAL LANGUAGE PAR, P206, DOI DOI 10.1017/CBO9780511597855
   Joshi A. K., 2000, TREE ADJOINING GRAMM, P167
   Kallmeyer L., 2001, Grammars, V4, P85, DOI 10.1023/A:1011431526022
   Kallmeyer L, 2008, LECT NOTES COMPUT SC, V5196, P263, DOI 10.1007/978-3-540-88282-4_25
   Karp R. M., 1969, J COMPUT SYST SCI, V3, P147, DOI DOI 10.1016/S0022-0000(69)80011-5
   Koller Alexander, 2007, FG 07
   KOSARAJU SR, 1982, STOC, P267
   LAMBERT JL, 1992, THEOR COMPUT SCI, V99, P79, DOI 10.1016/0304-3975(92)90173-D
   Lang B., 1994, Computational Intelligence, V10, P486, DOI 10.1111/j.1467-8640.1994.tb00011.x
   Lazic Ranko, 2010, REACHABILITY P UNPUB
   Lichte Timm, 2007, FG 07
   LIPTON R, 1976, 62 YAL U
   Maclachlan Anna, 2002, TAG 6, P100
   Marcus Mitchell P., 1983, ACL 83, P129
   MAYR EW, 1981, STOC, P238
   Mayr R, 2000, INFORM COMPUT, V156, P264, DOI 10.1006/inco.1999.2826
   Papadimitriou C. M., 1994, COMPUTATIONAL COMPLE
   PARIKH RJ, 1966, J ACM, V13, P570, DOI 10.1145/321356.321364
   Peterson J.L., 1981, PETRI NET THEORY MOD
   Petri CA., 1962, THESIS
   Rackoff C., 1978, Theoretical Computer Science, V6, P223, DOI 10.1016/0304-3975(78)90036-1
   Rambow O, 2001, COMPUT LINGUIST, V27, P87, DOI 10.1162/089120101300346813
   Rambow O., 1994, THESIS
   Rambow Owen, 1995, ACL 95, P151
   Rambow Owen, 1994, ACL, P263
   Salvati Sylvain, 2010, MINIMALIST GRA UNPUB
   SHIEBER SM, 1985, LINGUIST PHILOS, V8, P333, DOI 10.1007/BF00630917
   Sogaard Anders, 2007, RANLP 07, P548
   Stabler Edward, 1997, LECT NOTES ARTIF INT, V1328, P68, DOI DOI 10.1007/BFB0052152
   Verma KN, 2005, DISCRETE MATH THEOR, V7, P217
   Vijay-Shanker K., 1992, Computational Linguistics, V18, P481
   Yoshinaka R, 2005, LECT NOTES COMPUT SC, V3492, P330, DOI 10.1007/11422532_22
NR 55
TC 5
Z9 5
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 514
EP 524
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300053
DA 2019-06-15
ER

PT B
AU Sun, X
   Gao, JF
   Micol, D
   Quirk, C
AF Sun, Xu
   Gao, Jianfeng
   Micol, Daniel
   Quirk, Chris
GP Assoc Computat Linguist
TI Learning Phrase-Based Spelling Error Models from Clickthrough Data
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper explores the use of clickthrough data for query spelling correction. First, large amounts of query-correction pairs are derived by analyzing users' query reformulation behavior encoded in the clickthrough data. Then, a phrase-based error model that accounts for the transformation probability between multi-term phrases is trained and integrated into a query speller system. Experiments are carried out on a human-labeled data set. Results show that the system using the phrase-based error model outperforms significantly its baseline systems.
C1 [Sun, Xu] Univ Tokyo, Dept Math Informat, Tokyo, Japan.
   [Gao, Jianfeng; Quirk, Chris] Microsoft Res, Redmond, WA USA.
   [Micol, Daniel] Microsoft Corp, Munich, Germany.
RP Sun, X (reprint author), Univ Tokyo, Dept Math Informat, Tokyo, Japan.
EM xusun@mist.i.u-tokyo.ac.jp; jfgao@microsoft.com; danielmi@microsoft.com;
   chrisq@microsoft.com
CR Agichtein E., 2006, SIGIR 06, P19, DOI DOI 10.1145/1148170.1148177
   Ahmad F., 2005, HLT 05, P955
   Brill E., 2000, ACL 00, P286, DOI DOI 10.3115/1075218.1075255
   Chen Q., 2007, P 2007 JOINT C EMP M, P181
   Church K., 2007, EMNLP CONLL, P199
   Cucerzan S, 2004, EMNLP, V4, P293
   Gao J., 2009, SIGIR
   Golding A. R., 1996, INT C MACH LEARN, P182
   JOACHIMS T, 2002, SIGKDD, P133
   Kernighan M. D., 1990, COLING, P205
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   KUKICH K, 1992, ACM COMPUT SURV, V24, P377
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707, DOI DOI 10.1109/TVCG.2012.323
   LI M, 2006, ACL, P1025
   Mangu L., 1997, ICML 97, P187
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Och FJ, 2002, THESIS
   Okazaki N., 2008, EMNLP 08, P447
   Philips L., 1990, COMPUTER LANGUAGE MA, V7, P38
   Suzuki H., 2009, EMNLP
   Toutanova K., 2002, ACL PHIL PENNS, P144
   Wang Xuanhui, 2008, CIKM, P479
   Whitelaw C., 2009, EMNLP, P890
NR 23
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 266
EP 274
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300028
DA 2019-06-15
ER

PT B
AU Adler, M
   Elhadad, M
AF Adler, Meni
   Elhadad, Michael
GP COLING
TI An Unsupervised Morpheme-Based HMM for Hebrew Morphological
   Disambiguation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Morphological disambiguation is the process of assigning one set of morphological features to each individual word in a text. When the word is ambiguous (there are several possible analyses for the word), a disambiguation procedure based on the word context must be applied. This paper deals with morphological disambiguation of the Hebrew language, which combines morphemes into a word in both agglutinative and fusional ways.
   We present an unsupervised stochastic model - the only resource we use is a morphological analyzer which deals with the data sparseness problem caused by the affixational morphology of the Hebrew language. We present a text encoding method for languages with affixational morphology in which the knowledge of word formation rules (which are quite restricted in Hebrew) helps in the disambiguation. We adapt HMM algorithms for learning and searching this text representation, in such a way that segmentation and tagging can be learned in parallel in one step. Results on a large scale evaluation indicate that this learning improves disambiguation for complex tau, sets. Our method is applicable to other languages with affix morphology.
C1 [Adler, Meni; Elhadad, Michael] Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel.
RP Adler, M (reprint author), Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel.
EM adlerm@cs.bgu.ac.il; elhadad@cs.bgu.ac.il
OI Elhadad, Michael/0000-0002-5629-2351
CR ALLON E, 1995, UNVOCALIZED HEBREW W
   BARHAIM R, 2005, P ACL 2005 WORKSH CO
   Baum L. E., 1972, INEQUALITIES, V3, P1
   BENMORDECHAI N, 2005, THESIS BENGURION U N
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   CARMEL D, 1999, P NGITS 99
   CHEN SF, 1996, THESIS HARVARD U CAM
   DIAB M, 2004, P HLT NAACL 04
   DUH K, 2005, P ACL 05 WORKSH COMP
   ELHADAD M, 2005, HEBREW MORPHOLOGICAL
   ELWORTHY D, 1994, P ANLP 94
   HABASH N, 2005, P ACL 05
   Har'El  N., 2004, ISR SEM COMP LING DE
   Jurafsky D., 2000, SPEECH LANGUAGE PROC
   LEMBERSKY G, 2001, THESIS BENGURION U N
   LEVINGER M, 1995, COMPUT LINGUIST, V21, P383
   LEVINGER M, 1992, THESIS TECHNION HAIF
   Manning C.D., 1999, FDN STAT LANGUAGE PR
   Merialdo B., 1994, Computational Linguistics, V20, P155
   Ornan Uzi, 2002, LESONENU, VLXIV, P137
   Segal Erel, 2000, THESIS TECHNION HAIF
   THEDE SM, 1999, P ACL 99
   YONA S, 2005, P ACL 05 WORKSH COMP
NR 23
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 665
EP 672
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200084
DA 2019-06-15
ER

PT B
AU Bollegala, D
   Okazaki, N
   Ishizuka, M
AF Bollegala, Danushka
   Okazaki, Naoaki
   Ishizuka, Mitsuru
GP COLING
TI A Bottom-up Approach to Sentence Ordering for Multi-document
   Summarization
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Ordering information is a difficult but important task for applications generating natural-language text. We present a bottom-up approach to arranging sentences extracted for multi-document summarization. To capture the association and order of two textual segments (eg, sentences), we define four criteria, chronology, topical-closeness, precedence, and succession. These criteria are integrated into a criterion by a supervised learning approach. We repeatedly concatenate two textual segments into one segment based on the criterion until we obtain the overall segment with all sentences arranged. Our experimental results show a significant improvement over existing sentence ordering strategies.
C1 [Bollegala, Danushka; Okazaki, Naoaki; Ishizuka, Mitsuru] Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, Tokyo 1138656, Japan.
RP Bollegala, D (reprint author), Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
EM danushka@mi.ci.i.u-tokyo.ac.jp; okazaki@mi.ci.i.u-tokyo.ac.jp;
   ishizuka@i.u-tokyo.ac.jp
CR Barzilay R, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P113
   Barzilay R, 2002, J ARTIF INTELL RES, V17, P35, DOI 10.1613/jair.991
   DRAGOMIR R, 1999, COMPUTATIONAL LINGUI, V24, P469
   LAPATA M, 2003, P 41 M ASS COMP LING, P545
   LIN C, 2001, P DOC UND WORKSH DUC
   Mann W., 1988, TEXT, V8, P243
   MARCU D., 1997, P 14 NAT C ART INT P, P629
   MCKEOWN K, 1999, MULTIDOCUMENT SUMMAR, P453
   Okazaki N., 2004, P 20 INT C COMP LING, P750
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Vapnik V. N., 1998, STAT LEARNING THEORY
NR 11
TC 5
Z9 5
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 385
EP 392
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200049
DA 2019-06-15
ER

PT B
AU Curran, JR
   Clark, S
   Vadas, D
AF Curran, James R.
   Clark, Stephen
   Vadas, David
GP COLING
TI Multi-Tagging for Lexicalized-Grammar Parsing
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB With performance above 97% accuracy for newspaper text, part of speech (pos) tagging might be considered a solved problem. Previous studies have shown that allowing the parser to resolve Pos tag ambiguity does not improve performance. However, for grammar formalisms which use more fine-grained grammatical categories, for example TAG and CCG, tagging accuracy is much lower. In fact, for these formalisms, premature ambiguity resolution makes parsing infeasible.
   We describe a multi-tagging approach which maintains a suitable level of lexical category ambiguity for accurate and efficient CCG parsing. We extend this multitagging approach to the Pos level to overcome errors introduced by automatically assigned Pos tags. Although POS tagging accuracy seems high, maintaining some POS tag ambiguity in the language processing pipeline results in more accurate CCG supertagging.
C1 [Curran, James R.; Vadas, David] Univ Sydney, Sch IT, Sydney, NSW 2006, Australia.
RP Curran, JR (reprint author), Univ Sydney, Sch IT, Sydney, NSW 2006, Australia.
EM james@it.usyd.edu.au; sclark@comlab.ox.ac.uk; dvadas1@it.usyd.edu.au
CR BANGALORE S, 2000, NATURAL LANGUAGE ENV, V6, P113
   BRISCOE T, 2002, P 3 INT C LANG RES E, P1499
   Charniak E, 1996, ARTIF INTELL, V85, P45, DOI 10.1016/0004-3702(95)00108-5
   CHEN SF, 1999, GAUSSIAN PRIOR SMOOT
   Clark S, 2004, P 20 INT C COMP LING, P282
   Clark S, 2002, P 6 INT WORKSH TREE, P19
   Clark Stephen, 2004, P 42 ANN M ASS COMP, P104
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   CURRAN JR, 2003, P 11 ANN M EUR CHAPT, P91
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   HOCKENMAIER J, 2003, THESIS U EDINBURG
   Hockenmaier J., 2002, P 40 ANN M ASS COMP, P335
   Lafferty J. D., 2001, P 18 INT C MACH LEAR, P282
   Malouf R., 2002, P 6 C NAT LANG LEARN, P49, DOI DOI 10.3115/1118853.1118871
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Nocedal J., 1999, NUMERICAL OPTIMIZATI
   Prins R., 2003, TRAITEMENT AUTOMATIQ, V44, P121
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   Roth D., 2004, P ANN C COMP NAT LAN, P1
   SRINIVAS B, 1999, COMPUTATIONAL LINGUI, V25, P237
   Steedman M., 2000, SYNTACTIC PROCESS
   Toutanova K., 2003, P HLT NAACL, P252, DOI DOI 10.3115/1073445.1073478
   VADAS D, 2005, P AUSTR LANG TECHN W, P32
   WATSON R, 2006, P COMP LING UK C CLU
NR 24
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 697
EP 704
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200088
DA 2019-06-15
ER

PT B
AU Haghighi, A
   Klein, D
AF Haghighi, Aria
   Klein, Dan
GP COLING
TI Prototype-Driven Grammar Induction
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We investigate prototype-driven learning for primarily unsupervised grammar induction. Prior knowledge is specified declaratively, by providing a few canonical examples of each target phrase type. This sparse prototype information is then propagated across a corpus using distributional similarity features, which augment an otherwise standard PCFG model. We show that distributional features are effective at distinguishing bracket labels, but not determining bracket locations. To improve the quality of the induced trees, we combine our PCFG induction with the CCM model of Klein and Manning (2002), which has complementary stengths: it identifies brackets but does not label them. Using only a handful of prototypes, we show substantial improvements over naive PCFG induction for English and Chinese grammar induction.
C1 [Haghighi, Aria; Klein, Dan] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
RP Haghighi, A (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
EM aria42@cs.berkeley.edu; klein@cs.berkeley.edu
CR Abney Steven, 1987, THESIS MIT
   CARROLL G, 1992, CS9216
   CLARK A, 2001, CONLL
   CLARK A, 2000, CONLL, P91
   COLLINS M, 1999, THESIS U ROCHESTER
   Halliday M. A. K., 2004, INTRO FUNCTIONAL GRA
   Harris Z. S., 1954, DISTRIBUTIONAL STRUC
   IRCS NWX, 2002, BUILDING LARGE SCALE
   KLEIN D, 2005, THESIS STANFORD U
   Klein D., 2004, ACL
   KLEIN D, 2002, ACL
   Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313
   PEREIRA FCN, 1992, M ASS COMP LING, P128
   Radford A, 1988, TRANSFORMATIONAL GRA
   SCHUTZE H, 1995, EACL
   SMITH NA, 2004, WORK NOT IJCAI WORKS
NR 18
TC 5
Z9 5
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 881
EP 888
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200111
DA 2019-06-15
ER

PT B
AU Kelleher, JD
   Kruijff, GJM
   Costello, FJ
AF Kelleher, John D.
   Kruijff, Geert-Jan M.
   Costello, Fintan J.
GP COLING
TI Proximity in Context: an empirically grounded computational model of
   proximity for processing topological spatial expressions
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID ATTENTION
AB The paper presents a new model for context-dependent interpretation of linguistic expressions about spatial proximity between objects in a natural scene. The paper discusses novel psycholinguistic experimental data that tests and verifies the model. The model has been implemented, and enables a conversational robot to identify objects in a scene through topological spatial relations (e.g. "X near Y"). The model can help motivate the choice between topological and projective prepositions.
C1 [Kelleher, John D.] Dublin Inst Technol, Dublin, Ireland.
RP Kelleher, JD (reprint author), Dublin Inst Technol, Dublin, Ireland.
EM john.kelleher@comp.dit.ie; gj@dfki.de; fintan.costello@ucd.ie
RI Kelleher, John/N-6963-2017
OI Kelleher, John/0000-0001-6462-3248; Costello, Fintan/0000-0002-3953-7863
CR BALDRIDGE J, 2003, P EACL 2003 BUD HUNG
   BALDRIDGE J, 2002, P ACL 2002 PHIL PENN
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7
   Coventry KR, 2004, ESSAYS COGN PSYCHOL, P1
   DALE R, 1995, COGNITIVE SCI, V18, P233, DOI DOI 10.1207/S15516709COG1902_3
   DEVAULT D, 2004, P COLING 2004 GEN SW, V2, P1247
   GAPP KP, 1994, PROCEEDINGS OF THE TWELFTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P1393
   Gorniak P, 2004, J ARTIF INTELL RES, V21, P429, DOI 10.1613/jair.1327
   Hajicova E., 1993, THEORETICAL COMPUTAT, V2
   Herskovits A., 1986, STUDIES NATURAL LANG
   Kelleher J, 2004, ARTIF INTELL REV, V21, P253, DOI 10.1023/B:AIRE.0000036258.60851.83
   KELLEHER JD, 2006, P ACL COLING 06 SYDN
   KRAHMER E, 1999, WORKSH GEN NOM ESSLL
   Logan G. D., 1996, LANGUAGE SPACE, P493
   LOGAN GD, 1994, J EXP PSYCHOL HUMAN, V20, P1015, DOI 10.1037//0096-1523.20.5.1015
   LOGAN GD, 1980, COGNITIVE PSYCHOL, V12, P523, DOI 10.1016/0010-0285(80)90019-5
   MORATZ R, 2006, SPATIAL COGNITION CO
   Oates T., 2000, Proceedings of the Fourth International Conference on Autonomous Agents, P227, DOI 10.1145/336595.337389
   Regier T, 2001, J EXP PSYCHOL GEN, V130, P273, DOI 10.1037//0096-3445.130.2.273
   ROY D, 2002, COMPUTER SPEECH LANG, V16
   VANDERSLUIS IF, 2004, ICSLP04
NR 21
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 745
EP 752
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200094
DA 2019-06-15
ER

PT B
AU Malik, MGA
AF Malik, M. G. Abbas
GP COLING
TI Punjabi Machine Transliteration
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Machine Transliteration is to transcribe a word written in a script with approximate phonetic equivalence in another language. It is useful for machine translation, cross-lingual information retrieval, multilingual text and speech processing. Punjabi Machine Transliteration (PMT) is a special case of machine transliteration and is a process of converting a word from Shahmukhi (based on Arabic script) to Gurmukhi (derivation of Landa, Shardha and Takri, old scripts of Indian subcontinent), two scripts of Punjabi, irrespective of the type of word.
   The Punjabi Machine Transliteration System uses transliteration rules (character mappings and dependency rules) for transliteration of Shahmukhi words into Gurmukhi. The PMT system can transliterate every word written in Shahmukhi.
C1 Univ Paris 07, Dept Linguist, Paris, France.
RP Malik, MGA (reprint author), Univ Paris 07, Dept Linguist, Paris, France.
EM abbas.malik@gmail.com
CR ABDULJALEEL N, 2003, P 12 INT C INF KNOWL, P139
   BAKHSH MM, 2000, SAIF UL MALOOQ
   Bhatia Tej K., 2003, INT S IND SCRIPT FUT, P181
   FARID K, PUNJABI SHAHMUKHI
   Jung S. Y., 2000, P 18 C COMP LING, V1, P383
   Kang I H, 2000, P 18 C COMP LING, V1, P418
   Knight K, 1998, COMPUT LINGUIST, V24, P599
   KNIGHT K, 1998, P COLING ACL WORKSH
   KNIGHT K, 1997, P 35 ANN M ASS COMP, P128
   MALIK MGA, 2005, P 27 INT UN C 6 8 AP
   MAQBAL, PUNJABI MANUSCRIPT O
   NANAK BG, 1998, PUNJABI SHAHMUKHI
   Pirkola A., 2003, P 26 ANN INT ACM SIG, P345
   Qu Y., 2003, P 26 ANN INT ACM SIG, P353
   SHAH W, 1977, LEHRAN PUNJABI J LAH
   SHAH W, 1766, PUNJABI MANUSCRIPT O
   TARIQ R, 2004, SCALLA C COMP LING 5
   VIRGA P, 2003, P 26 ANN INT ACM SIG, P365
NR 18
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1137
EP 1144
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200143
DA 2019-06-15
ER

PT B
AU Moore, RC
   Yih, WT
   Bode, A
AF Moore, Robert C.
   Yih, Wen-tau
   Bode, Andreas
GP COLING
TI Improved Discriminative Bilingual Word Alignment
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB For many years, statistical machine translation relied on generative models to provide bilingual word alignments. In 2005, several independent efforts showed that discriminative models could be used to enhance or replace the standard generative approach. Building on this work, we demonstrate substantial improvement in word-alignment accuracy, partly though improved training methods, but predominantly through selection of more and better features. Our best model produces the lowest alignment error rate yet reported on Canadian Hansards bilingual data.
C1 [Moore, Robert C.; Yih, Wen-tau; Bode, Andreas] Microsoft Res, Redmond, WA 98052 USA.
RP Moore, RC (reprint author), Microsoft Res, Redmond, WA 98052 USA.
EM bobmoore@microsoft.com; scottyhi@microsoft.com; abodel@microsoft.com
CR Ayan N.F., 2005, P HLT EMNLP, P65
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHERRY C, 2003, P 41 ANN M ASS COMP, P88
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Fraser A., 2005, P ACL WORKSH BUILD U, P91
   Herbrich R, 2001, ADV NEUR IN, V13, P528
   ITTYCHERIAH A, 2005, P HLT EMNLP, P89
   Lacoste-Julien S., 2006, P HUM LANG TECHN C N, P112
   Liang P., 2006, P HUM LANG TECHN C N, P104
   Liu Y, 2005, P 43 ANN M ASS COMP, P459
   Mihalcea Rada, 2003, P HLT NAACL 2003 WOR, P1
   Moore R. C., 2005, P C HUM LANG TECHN E, P81, DOI DOI 10.3115/1220575.1220586
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   TASKAR B, 2005, P HUM LANG TECHN C C, P73
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
NR 15
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 513
EP 520
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200065
DA 2019-06-15
ER

PT B
AU Sagot, B
   de la Clergerie, E
AF Sagot, Benoit
   de la Clergerie, Eric
GP COLING
TI Error mining in parsing results
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We introduce an error mining technique for automatically detecting errors in resources that are used in parsing systems. We applied this technique on parsing results produced on several million words by two distinct parsing systems, which share the syntactic lexicon and the pre-parsing processing chain. We were thus able to identify missing and erroneous information in these resources.
C1 [Sagot, Benoit; de la Clergerie, Eric] Projet ATOLL NRIA, F-78153 Le Chesnay, France.
RP Sagot, B (reprint author), Projet ATOLL NRIA, BP 105, F-78153 Le Chesnay, France.
EM benoit.sagot@inria.fr; eric.de_la_clergerie@inria.fr
CR Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Boullier P., 2005, P IWPT 05 VANC CAN O
   BOULLIER P, 2005, TRAITEMENT AUTOMATIQ, V46
   Daume III H., 2004, NOTES CG LM BFGS OPT
   PAROUBEK P, 2005, P EASY WORKSH TALN 2
   SAGOT B, 2005, P L TC 2005 POZN POL
   SAGOT B, 2005, JOURN ET ATALA INT L
   Thomasset Francois, 2005, P TALN 05 DOURD FRAN
   van Noord G., 2004, P ACL 2004 BARC SPAI
   VILLEMONTE E, 2005, P 2 INT WORKSH CONST
NR 10
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 329
EP 336
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200042
DA 2019-06-15
ER

PT B
AU Watanabe, T
   Tsukada, H
   Isozaki, H
AF Watanabe, Taro
   Tsukada, Hajime
   Isozaki, Hideki
GP COLING
TI Left-to-Right Target Generation for Hierarchical Phrase-based
   Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a hierarchical phrase-based statistical machine translation in which a target sentence is efficiently generated in left-to-right order. The model is a class of synchronous-CFG with a Greibach Normal Form-like structure for the projected production rule: The paired target-side of a production rule takes a phrase prefixed form. The decoder for the target-normalized form is based on an Early-style top down parser on the source side. The target-normalized form coupled with our top down parser implies a left-to-right generation of translations which enables us a straightforward integration with ngram language models. Our model was experimented on a Japanese-to-English newswire translation task, and showed statistically significant performance improvements against a phrase-based translation system.
RP Watanabe, T (reprint author), 2-4 Hikaridai, Seika, Kyoto 6190237, Japan.
EM taro@cslab.kecl.ntt.co.jp; tsukada@cslab.kecl.ntt.co.jp;
   isozaki@cslab.kecl.ntt.co.jp
CR Aho A.V., 1969, J COMPUTER SYSTEM SC, V3, P37
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Collins M., 2005, P 43 ANN M ASS COMP, P531
   Gildea Daniel, 2005, P 9 INT WORKSH PARS, P65
   Koehn P., 2004, P 2004 C EMP METH NA, P388
   Koehn Philipp, 2003, P 2003 C N AM CHAPT, P48, DOI DOI 10.3115/1073445.1073462
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Och F. J., 2002, P 40 ANN M ASS COMP, P295
   TILLMAN C, 2004, HLT NAACL 2004 SHORT, P101
   UTIYAMA M, 2003, P 41 ANN M ASS COMP, P72
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   ZENS R, 2003, P ACL 2003, P144
NR 14
TC 5
Z9 5
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 777
EP 784
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200098
DA 2019-06-15
ER

PT B
AU Wellington, B
   Waxmonsky, S
   Melamed, ID
AF Wellington, Benjamin
   Waxmonsky, Sonjia
   Melamed, I. Dan
GP COLING
TI Empirical Lower Bounds on the Complexity of Translational Equivalence
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper describes a study of the patterns of translational equivalence exhibited by a variety of bitexts. The study found that the complexity of these patterns in every bitext was higher than suggested in the literature. These findings shed new light on why "syntactic" constraints have not helped to improve statistical translation models, including finite-state phrase-based models, tree-to-string models, and tree-to-tree models. The paper also presents evidence that inversion transduction grammars cannot generate some translational equivalence relations, even in relatively simple real bitexts in syntactically similar languages with rigid word order. Instructions for replicating our experiments are at http://nlp.cs.nyu.edu/GenPar/ACL06
C1 [Wellington, Benjamin; Melamed, I. Dan] NYU, Dept Comp Sci, New York, NY 10003 USA.
RP Wellington, B (reprint author), NYU, Dept Comp Sci, 550 1St Ave, New York, NY 10003 USA.
EM wellington@cs.nyu.edu; wax@cs.uchicago.edu; melamed@cs.nyu.edu
CR AYAN N, 2005, EMNLP
   BARZILAY R, 2001, ACL
   BIKEL D, 2004, EMNLP
   BURBANK A, 2005, FINAL REPORT STAT MA
   CALLISONBURCH C, 2005, ACL
   Chiang D., 2005, ACL
   Dorr B. J., 1994, Computational Linguistics, V20, P597
   FOX H, 2002, EMNLP
   GALLEY M, 2004, HLT NAACL
   GROVES D, 2004, COLING
   Koehn P., 2003, NAACL
   *LDC, 2002, LDC2002E53
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   MARTIN J, 2005, ACL WORKSH BUILD US
   MELAMED ID, 2005, 05001 NYU PROT PROJ
   MELAMED ID, 2004, ACL
   MELAMED ID, 1995, ACL WORKSH VER LARG
   MIHALCEA R, 2003, HLT NAACL WORKSH BUI
   SATTA G, 2005, EMNLP
   SIMARD M, 2005, EMNLP
   WAXMONSKY S, 2006, 06001 NYU PROT PROJ
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   YAMADA K, 2001, ACL
   ZENS R, 2003, ACL
   ZHANG H, 2006, HLT NAACL
   ZHANG H, 2004, COLING
NR 26
TC 5
Z9 5
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 977
EP 984
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200123
DA 2019-06-15
ER

PT B
AU Zanzotto, FM
   Pennacchiotti, M
   Pazienza, MT
AF Zanzotto, Fabio Massimo
   Pennacchiotti, Marco
   Pazienza, Maria Teresa
GP COLING
TI Discovering asymmetric entailment relations between verbs using
   selectional preferences
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper we investigate a novel method to detect asymmetric entailment relations between verbs. Our starting point is the idea that some point-wise verb selectional preferences carry relevant semantic information. Experiments using WordNet as a gold standard show promising results. Where applicable, our method, used in combination with other approaches, significantly increases the performance of entailment detection. A combined approach including our model improves the AROC of 5% absolute points with respect to standard models.
C1 [Zanzotto, Fabio Massimo] Univ Milano Bicocca, DISCo, Milan, Italy.
RP Zanzotto, FM (reprint author), Univ Milano Bicocca, DISCo, Via Bicocca Arcimboldi 8, Milan, Italy.
EM zanzotto@disco.unimib.it; pennacchiotti@info.uniroma2.it;
   pazienza@info.uniroma2.it
RI Zanzotto, Fabio Massimo/L-6634-2015
OI Zanzotto, Fabio Massimo/0000-0002-7301-3596
CR CHKLOVSKI T, 2004, P 2004 C EMP METH NA
   Church Kenneth Ward, 1989, P 27 ANN M ASS COMP
   GLICKMAN O, 2005, P 1 PASC CHALL WORKS
   Glickman Oren, 2003, P INT C REC ADV NAT
   Green DM, 1996, SIGNAL DETECTION THE
   Harris Z, 1964, PHILOS LINGUISTICS
   Hearst M.A., 1992, P 15 INT C COMP LING
   KELLER F, 2003, COMPUTATIONAL LINGUI, V29
   Lin Dekang, 2001, P ACM C KNOWL DISC D
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Minnen G., 2001, Natural Language Engineering, P207
   MORIN E, 1999, THESIS U NANTES
   Ravichandran Deepak, 2002, P 40 ACL M PHIL PENN
   RESNIK P, 2000, 22 ANN M COGN SCI SO
   Resnik Philip, 1993, THESIS U PENNSYLVANI
   ROBISON HR, 1970, INFORM STORAGE RET, V6, P273, DOI 10.1016/0020-0271(70)90002-1
   TURNEY PD, 2001, P 12 EUR C MACH LEAR
NR 17
TC 5
Z9 6
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 849
EP 856
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200107
DA 2019-06-15
ER

PT B
AU Fleischman, M
   Hovy, E
   Echihabi, A
AF Fleischman, M
   Hovy, E
   Echihabi, A
GP ACL
TI Offline strategies for online question answering: Answering questions
   before they are asked
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Recent work in Question Answering has focused on web-based systems that extract answers using simple lexico-syntactic patterns. We present an alternative strategy in which patterns are used to extract highly precise relational information offline, creating a data repository that is used to efficiently answer questions. We evaluate our strategy on a challenging subset of questions, i.e. "Who is..." questions, against a state of the art web-based Question Answering system. Results indicate that the extracted relations answer 25% more questions correctly and do so three orders of magnitude faster than the state of the art system.
C1 Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
CR BANKO M, 2001, P ASS COMP LING TOUL
   Berland M., 1999, P 37 ANN M ASS COMP
   BRILL E, 2001, P 2001 TEXT RETRIEVA
   BRILL E, 1994, P AAAI SEATTL WASH
   DEEPAK R, 2002, P 40 ACL C PHIL PA
   FLEISCHMAN M, 2002, 19 INT C COMP LING C
   Frank E., 1999, DATA MINING PRACTICA
   GIDEON S, 2002, SEMANET02 BUILDING U
   Hearst M. A., 1992, P 14 INT C COMP LING
   HERMJAKOB U, 2002, P TREC 2002 C NIST G
   LIN J, 2002, P 2002 TEXT RETR C T
NR 11
TC 5
Z9 6
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 1
EP 7
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500001
DA 2019-06-15
ER

PT B
AU Gardent, C
   Kallmeyer, L
AF Gardent, C
   Kallmeyer, L
GP ACL
TI Semantic construction in feature-based TAG
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We propose a semantic construction method for Feature-Based Tree Adjoining Grammar which is based on the derived tree, compare it with related proposals and briefly discuss some implementation possibilities.
C1 CNRS, F-54506 Vandoeuvre Les Nancy, France.
CR ABEILLE A, 2000, P TAG 5 PAR, P11
   Abeille Anne, 1991, THESIS U PARIS 7
   Bos J., 1995, P 10 AMST C, P133
   COPESTAKE A, 2001, P 39 ANN M ASS COMP
   Dalrymple Mary, 1999, SEMANTICS SYNTAX LEX
   FRANK A, 2001, P LEFG01 C HONG KONG
   HOCKEY BA, 2000, TREE ADJOINING GRAMM, P221
   Joshi Aravind K., 1997, HDB FORMAL LANGUAGES, V3, P69, DOI DOI 10.1007/978-3-642-59126-6_2
   KALLMEYER L, 2002, P KONVENS 2002 SAARB, P67
   KALLMEYER L, 2002, P TAG 6 WORKSH VEN, P127
   KALLMEYER L, 2002, IN PRESS RES LANGUAG
   MONTAGUE R, 1974, FORMAL PHILOS SELECT, P247
   PERRIER G, 2000, P 18 INT C COMP LING
   Vijay-Shanker K, 1988, P 12 INT C COMP LING, P714
   ZEEVAT H, 1987, CATEGORIAL GRAMMER U
NR 15
TC 5
Z9 5
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 123
EP 130
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200017
DA 2019-06-15
ER

PT B
AU Och, FJ
   Zens, R
   Ney, H
AF Och, FJ
   Zens, R
   Ney, H
GP ACL
TI Efficient search for interactive statistical machine translation
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB The goal of interactive machine translation is to improve the productivity of human translators. An interactive machine translation system operates as follows: the automatic system proposes a translation. Now, the human user has two options: to accept the suggestion or to correct it. During the post-editing process, the human user is assisted by the interactive system in the following way: the system suggests an extension of the current translation prefix. Then, the user either accepts this extension (completely or partially) or ignores it. The two most important factors of such an interactive system are the quality of the proposed extensions and the response time. Here, we will use a fully fledged translation system to ensure the quality of the proposed extensions. To achieve fast response times, we will use word hypotheses graphs as an efficient search space representation. We will show results of our approach on the Verbmobil task and on the Canadian Hansards task.
C1 Univ Technol, Rhein Westfal TH Aachen, Chair Comp Sci 6, Aachen, Germany.
CR Brown P. F., 1990, Computational Linguistics, V16, P79
   FOSTER G, 1996, COLING 96, P394
   FOSTER G, 2002, P 2002 C EMP METH NA, P46
   Foster S, 1997, INT CLIN PSYCHOPHARM, V12, P175, DOI 10.1097/00004850-199705000-00009
   LANGLAIS P, 2000, WORKSHOP EMBEDDED MA, P46
   Ney H., 1994, P ICSLP 94, P1355
   Ney H., 1999, P JOINT SIGDAT C EMP, P20
   SIXTUS A, 1999, P IEEE INT C AC SPEE, V2, P593
   Ueffing N, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P156
   Wahlster W., 2000, VERBMOBIL FDN SPEECH
   Wessel F, 2001, IEEE T SPEECH AUDI P, V9, P288, DOI 10.1109/89.906002
NR 11
TC 5
Z9 6
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 387
EP 393
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200050
DA 2019-06-15
ER

PT B
AU Steedman, M
   Osborne, M
   Sarkar, A
   Clark, S
   Hwa, R
   Hockenmaier, J
   Ruhlen, P
   Baker, S
   Crim, J
AF Steedman, M
   Osborne, M
   Sarkar, A
   Clark, S
   Hwa, R
   Hockenmaier, J
   Ruhlen, P
   Baker, S
   Crim, J
GP ACL
TI Bootstrapping statistical parsers from small datasets
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We present a practical co-training method for bootstrapping statistical parsers using a small amount of manually parsed training material and a much larger pool of raw sentences. Experimental results show that unlabelled sentences can be used to improve the performance of statistical parsers. In addition, we consider the problem of bootstrapping parsers when the manually parsed training material is in a different domain to either the raw sentences or the testing material. We show that bootstrapping continues to be useful, even though no manually produced parses from the target domain are used.
C1 Univ Edinburgh, Div Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
CR ABNEY S, 2002, P 40 ANN M ASS COMP, P360
   Black E., 1991, P DARPA SPEECH NAT L, P306
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Charniak E., 1997, P 14 NAT C ART INT, P598
   Collins M., 1999, P JOINT SIGDAT C EMP, P100
   Collins Michael, 1999, THESIS U PENNSYLVANI
   DASGUPTA S, 2002, ADV NEURAL INFORMATI, V14
   GILDEA D, 2001, P EMP METH NLP C PIT
   Goldman S., 2000, P 17 INT C MACH LEAR
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Nigam K., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P86, DOI 10.1145/354756.354805
   PIERCE D, 2001, P EMP METH NLP C PIT
   Sarkar Anoop, 2001, P 2 ANN M N AM CHAPT, P95
   YAROWSKY D, 1995, P 33 ANN M ASS COMP, P189, DOI DOI 10.3115/981658.981684
NR 14
TC 5
Z9 5
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 331
EP 338
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200043
DA 2019-06-15
ER

PT B
AU Widdows, D
AF Widdows, D
GP ACL
TI Orthogonal negation in vector spaces for modelling word-meanings and
   document retrieval
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
ID RELEVANCE FEEDBACK
AB Standard IR systems can process queries such as "web NOT internet", enabling users who are interested in arachnids to avoid documents about computing. The documents retrieved for such a query should be irrelevant to the negated query term. Most systems implement this by reprocessing results after retrieval to remove documents containing the unwanted string of letters.
   This paper describes and evaluates a theoretically motivated method for removing unwanted meanings directly from the original query in vector models, with the same vector negation operator as used in quantum logic. Irrelevance in vector spaces is modelled using orthogonality, so query vectors are made orthogonal to the negated term or terms.
   As well as removing unwanted terms, this form of vector negation reduces the occurrence of synonyms and neighbours of the negated terms by as much as 76% compared with standard Boolean methods. By altering the query vector itself, vector negation removes not only unwanted strings but unwanted meanings.
C1 Stanford Univ, Stanford, CA 94305 USA.
CR Birkhoff G, 1936, ANN MATH, V37, P823, DOI 10.2307/1968621
   Dunlop MD, 1997, ACM T INFORM SYST, V15, P137, DOI 10.1145/248625.248650
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   HERSH W, 1994, P 17 ANN INT ACM SIG, P192
   KOWALSKI G, 1997, INFORMATION RETRIEVA
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   RICARDO BY, 1999, MODERN INFORMATION R
   SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H
   SALTON G, 1983, COMMUN ACM, V26, P1022, DOI 10.1145/182.358466
   SALTON G, 1983, INTRO MODERN INFORMA
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Turtle H., 1989, Proceedings of the 13th International Conference on Research and Development in Information Retrieval, P1
   WIDDOWS D, 2003, UNS METH DEV TAX COM
   WIDDOWS D, 2003, MATH LANGUAGE, V8
NR 14
TC 5
Z9 5
U1 0
U2 2
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 136
EP 143
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500018
DA 2019-06-15
ER

PT S
AU Lambov, D
   Pais, S
   Dias, G
AF Lambov, Dinko
   Pais, Sebastiao
   Dias, Gael
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Merged Agreement Algorithms for Domain Independent Sentiment Analysis
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Sentiment Analysis; Subjectivity Classification; Multi-view Learning
AB In this paper, we consider the problem of building models that have high sentiment classification accuracy across domains. For that purpose, we present and evaluate three new algorithms based on multi-view learning using both high-level and low-level views, which show improved results compared to the state-of-the-art SAR algorithm [1] over cross-domain text subjectivity classification. Our experimental results present accuracy levels of 80% with two views, combining SVM classifiers over high-level features and unigrams compared to 77.1% for the SAR algorithm. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Lambov, Dinko; Pais, Sebastiao; Dias, Gael] HULTIG Univ Beira Interior, Covilha, Portugal.
EM dinko@hultig.di.ubi.pt; sebastiao@hultig.di.ubi.pt; ddg@hultig.di.ubi.pt
RI Pais, Sebastiao/J-4766-2017; Pais, Sebastiao/J-3781-2019
OI Pais, Sebastiao/0000-0003-2337-0779; Pais, Sebastiao/0000-0003-2337-0779
CR Aue A., 2005, P INT C REC ADV NAT, P207
   Blitzer J, 2007, P 45 ANN M ASS COMP, P187
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Boiy E., 2007, P 11 INT C EL PUBL, P349
   Chesley P., 2006, P AAAI CAAW 06 SPRIN, P27
   Finn A, 2006, J AM SOC INF SCI TEC, V57, P1506, DOI 10.1002/asi.20427
   Ganchev K., 2008, P 24 C UNC ART INT, P204
   Hatzivassiloglou V., 1997, P 35 ANN M ASS COMP, P174, DOI DOI 10.3115/976909.979640
   Hatzivassiloglou V, 2000, P 18 C COMP LING ASS, V1, P299, DOI DOI 10.3115/990820.990864
   Lambov D., 2009, P 14 PORT C ART INT
   Levin B., 1993, ENGLISH VERB CLASSES
   Liu H., 2004, MONTYLINGUA END END
   Miller G., INT J LEXICOGRAPHY, V3
   Pang B., 2004, P 42 ANN M ASS COMP, V42, P271, DOI DOI 10.3115/1218955.1218990
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Srihari R., 2006, NAT LANG ENG, V14, P33
   Strapparava C., 2004, P 4 INT C LANG RES E, P1083
   STRAPPARAVA C, 2008, P 2008 ACM S APPL CO, P1556
   Wan X., 2009, P JOINT C 47 ANN M A, V1, P235
NR 19
TC 4
Z9 4
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 248
EP 257
DI 10.1016/j.sbspro.2011.10.605
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700029
OA Other Gold
DA 2019-06-15
ER

PT S
AU Masuda, K
   Matsuzaki, T
   Tsujii, J
AF Masuda, Katsuya
   Matsuzaki, Takuya
   Tsujii, Jun'ichi
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Semantic Search based on the Online Integration of NLP Techniques
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Information Retrieval; Semantic Search; Tag Annotations
ID TEXT SEARCH; ALGEBRA
AB This paper introduces a framework for semantic information retrieval based on the integration of various natural language processing (NLP) techniques, each of which annotates a base text with different kinds of information extracted from the text. Instead of running the NLP modules on the fly for individual search requests, the NLP modules are applied to the text in advance and the results are indexed in a way that enables flexible and efficient integration of them. The query language is based on a variant of the region algebra, in which we can specify a substructure in the annotated text that may involve different kinds of annotations. Given a query, the retrieval engine searches for the sub-structure by aggregating the different kinds of annotations through a search algorithm for the extended region algebra. We demonstrate the effectiveness and flexibility of the proposed framework through experiments with TREC Genomics Track data. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Masuda, Katsuya] Univ Tokyo, Ctr Knowledge Struct, Bunkyo Ku, Tokyo 1138656, Japan.
   [Matsuzaki, Takuya] Univ Tokyo, Grad Sch Informat Sci & Technol, Dept Comp Sci, Tokyo 1138656, Japan.
   [Tsujii, Jun'ichi] Microsoft Res Asia, Beijing 100080, Peoples R China.
RP Masuda, K (reprint author), Univ Tokyo, Ctr Knowledge Struct, Bunkyo Ku, Tokyo 1138656, Japan.
EM masuda@cks.u-tokyo.ac.jp
FU KAKENHI [21500131]
FX This work was supported by KAKENHI (Grant-in-Aid for Scientific Research
   (C), No. 21500131).
CR ALINK W, 2006, P 5 WORKSH INLP XML, P3
   Chun HW, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S3-S4
   CLARKE CLA, 1995, COMPUT J, V38, P43, DOI 10.1093/comjnl/38.1.43
   Ferrucci D, 2004, IBM SYST J, V43, P455, DOI 10.1147/sj.433.0455
   Hersh W., 2005, TREC 2005 NOTEBOOK, P14
   Ishizuka M., 2008, P 3 INT JOINT C NAT, P381
   Kim JH, 2003, ELEC SOC S, V2003, P1
   Kim JD, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-10
   Masuda K, 2009, IEICE T INF SYST, VE92D, P2369, DOI 10.1587/transinf.E92.D.2369
   MIMA H, 2002, P COL 2002, P667
   Miwa Makoto, 2010, Journal of Bioinformatics and Computational Biology, V8, P131, DOI 10.1142/S0219720010004586
   Miyao Yusuke, 2005, P 43 ANN M ASS COMP, P83
   Robertson S. E., 1996, OKAPI AT TREC 3, V3, P109
   Siniakov P., 2006, P 5 WORKSH NLP XML N, P43
NR 14
TC 4
Z9 4
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 281
EP 290
DI 10.1016/j.sbspro.2011.10.609
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700033
OA Other Gold
DA 2019-06-15
ER

PT B
AU Berant, J
   Dagan, I
   Goldberger, J
AF Berant, Jonathan
   Dagan, Ido
   Goldberger, Jacob
GP Assoc Computat Linguist
TI Global Learning of Focused Entailment Graphs
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We propose a global algorithm for learning entailment relations between predicates. We define a graph structure over predicates that represents entailment relations as directed edges, and use a global transitivity constraint on the graph to learn the optimal set of edges, by formulating the optimization problem as an Integer Linear Program. We motivate this graph with an application that provides a hierarchical summary for a set of propositions that focus on a target concept, and show that our global algorithm improves performance by more than 10% over baseline algorithms.
C1 [Berant, Jonathan] Tel Aviv Univ, Tel Aviv, Israel.
   [Dagan, Ido; Goldberger, Jacob] Bar Ilan Univ, Ramat Gan, Israel.
RP Berant, J (reprint author), Tel Aviv Univ, Tel Aviv, Israel.
EM jonatha6@post.tau.ac.il; dagan@cs.biu.ac.il; goldbej@eng.biu.ac.il
CR Bentivogli Luisa, 2009, P TAC 09
   Bhagat R., 2007, P EMNLP CONLL
   Budanitsky A, 2006, COMPUT LINGUIST, V32, P13, DOI 10.1162/coli.2006.32.1.13
   Clarke James, 2008, J ARTIFICIAL INTELLI, V31, P273
   Connor Michael, 2007, P ECML
   Dagan Ido, 2010, Natural Language Engineering, V16, pi, DOI 10.1017/S1351324909990209
   Fellbaum C., 1998, LANGUAGE SPEECH COMM
   Finkel Jenny Rose, 2008, P ACL 08 HLT
   Hall M., 2009, SIGKDD EXPLORATIONS, V11, P1, DOI DOI 10.1145/1656274.1656278
   Hofmann Thomas, 1999, P IJCAI
   Joachims T., 2005, P ICML
   Kaki Mika, 2005, P CHI
   Lin D., 1998, P WORKSH EV PARS SYS
   LIN D, 2001, NAT LANG ENG, V7, P343
   Martins Andre, 2009, P ACL
   Nikulin Vladimir, 2008, International Journal of Data Warehousing and Mining, V4, P63, DOI 10.4018/jdwm.2008040108
   ROTH D, 2005, P INT C MACH LEARN I, P737
   Sekine S, 2005, P IWP
   Siegel S, 1988, NONPARAMETRIC STAT B
   Smith N. A., 2005, P ACL
   Snow Rion, 2005, P NIPS
   Snow Rion, 2006, P ACL
   Stoica Emilia, 2007, P NAACL HLT
   Szpektor Idan, 2009, P TEXTINFER 2009
   Szpektor Idan, 2004, P EMNLP
   Szpektor Idan, 2008, P COLING
   Van Hulse Jason, 2007, P ICML
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.2307/3001968
   Yates A, 2009, J ARTIFICIAL INTELLI, V34, P255
NR 29
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1220
EP 1229
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300124
DA 2019-06-15
ER

PT B
AU Davidov, D
   Rappoport, A
AF Davidov, Dmitry
   Rappoport, Ari
GP Assoc Computat Linguist
TI Extraction and Approximation of Numerical Attributes from the Web
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a novel framework for automated extraction and approximation of numerical object attributes such as height and weight from the Web. Given an object-attribute pair, we discover and analyze attribute information for a set of comparable objects in order to infer the desired value. This allows us to approximate the desired numerical values even when no exact values can be found in the text.
   Our framework makes use of relation defining patterns and Word Net similarity information. First, we obtain from the Web and Word Net a list of terms similar to the given object. Then we retrieve attribute values for each term in this list, and information that allows us to compare different objects in the list and to infer the attribute value range. Finally, we combine the retrieved data for all terms from the list to select or approximate the requested value.
   We evaluate our method using automated question answering, Word Net enrichment, and comparison with answers given in Wikipedia and by leading search engines. In all of these, our framework provides a significant improvement.
C1 [Davidov, Dmitry] Hebrew Univ Jerusalem, ICNC, Jerusalem, Israel.
   [Rappoport, Ari] Hebrew Univ Jerusalem, Inst Comp Sci, Jerusalem, Israel.
RP Davidov, D (reprint author), Hebrew Univ Jerusalem, ICNC, Jerusalem, Israel.
EM dmitry@alice.nc.huji.ac.il; arir@cs.huji.ac.il
CR Aramaki Eiji, 2007, P 4 INT WORKSH SEM E
   Banerjee Somnath, 2009, SIGIR 09
   Banko Michele, 2007, IJCAI 07
   BERLAND M, 1999, ACL 99
   Cafarella Michael, 2008, VLDB 08
   Chklovski Timothy, 2004, EMNLP 04
   Crestan Eric, 2010, WWW 10
   Davidov Dmitry, 2007, ACL 07
   Davidov Dmitry, 2006, ACL COLING 06
   Davidov Dmitry, 2008, ACL 08
   Girju Roxana, 2006, COMPUTATIONAL LINGUI, V32
   Hearst Marty, 1992, COLING 92
   Moriceau Veronique, 2006, EACL KRAQ06 06
   Pantel Patrick, 2006, COLING ACL 06
   Prager John, 2006, Foundations and Trends in Information Retrieval, V1, P91, DOI 10.1561/1500000001
   RAVICHANDRAN D, 2002, ACL 02
   RILOFF E, 1999, AAAI 99
   Rosenfeld Benjamin, 2007, CIKM 07
   Turney Peter, 2005, IJCAI 05
   Widdows Dominic, 2002, COLING 02
NR 20
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1308
EP 1317
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300133
DA 2019-06-15
ER

PT B
AU de Melo, G
   Weikum, G
AF de Melo, Gerard
   Weikum, Gerhard
GP Assoc Computat Linguist
TI Untangling the Cross-Lingual Link Structure of Wikipedia
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID CUT; INFORMATION
AB Wikipedia articles in different languages are connected by interwiki links that are increasingly being recognized as a valuable source of cross-lingual information. Unfortunately, large numbers of links are imprecise or simply wrong. In this paper, techniques to detect such problems are identified. We formalize their removal as an optimization task based on graph repair operations. We then present an algorithm with provable properties that uses linear programming and a region growing technique to tackle this challenge. This allows us to transform Wikipedia into a much more consistent multilingual register of the world's entities and concepts.
C1 [de Melo, Gerard; Weikum, Gerhard] Max Planck Inst Informat, Saarbrucken, Germany.
RP de Melo, G (reprint author), Max Planck Inst Informat, Saarbrucken, Germany.
EM demelo@mpi-inf.mpg.de; weikum@mpi-inf.mpg.de
CR Adar Eytan, 2009, P 2 ACM INT C WEB SE, P94
   Auer S., 2007, LECT NOTES COMPUTER, V4825
   Avidor A, 2007, THEOR COMPUT SCI, V377, P35, DOI 10.1016/j.tcs.2007.02.026
   Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95
   Bouma Gosse, 2009, CLIAWS3 09, P21
   Charikar M, 2005, J COMPUT SYST SCI, V71, P360, DOI 10.1016/j.jcss.2004.10.012
   Chawla S, 2005, ANN IEEE CONF COMPUT, P144, DOI 10.1109/CCC.2005.20
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Ferrandez S, 2007, LECT NOTES COMPUT SC, V4592, P352
   Garg Naveen, 1996, SIAM J COMPUT, V25, P698
   Karmarkar N., 1984, STOC 84, P302
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Khot S., 2002, STOC, P767
   Leighton T, 1999, J ACM, V46, P787, DOI 10.1145/331524.331526
   Mihalcea R., 2007, P 16 ACM C C INF KNO, P233, DOI DOI 10.1145/1321440.1321475
   Nguyen D, 2009, LECT NOTES COMPUT SC, V5706, P58
   Pasternack J., 2009, CIKM 09, P177
   Ponzetto S.P., 2007, AAAI, P1440
   Silberer Carina, 2008, P 6 INT LANG RES EV
   Sorg P., 2008, P AAAI 2008 WORKSH W
   Suchanek F., 2007, P 16 INT WORLD WID W
   Zeng Z., 2009, P VLDB ENDOW, V2, P25, DOI DOI 10.14778/1687627.1687631
NR 22
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 844
EP 853
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300087
DA 2019-06-15
ER

PT B
AU Durrani, N
   Sajjad, H
   Fraser, A
   Schmid, H
AF Durrani, Nadir
   Sajjad, Hassan
   Fraser, Alexander
   Schmid, Helmut
GP Assoc Computat Linguist
TI Hindi-to-Urdu Machine Translation Through Transliteration
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a novel approach to integrate transliteration into Hindi-to-Urdu statistical machine translation. We propose two probabilistic models, based on conditional and joint probability formulations, that are novel solutions to the problem. Our models consider both transliteration and translation when translating a particular Hindi word given the context whereas in previous work transliteration is only used for translating OOV (out-of-vocabulary) words. We use transliteration as a tool for disambiguation of Hindi homonyms which can be both translated or transliterated or transliterated differently based on different contexts. We obtain final BLEU scores of 19.35 (conditional probability model) and 19.00 (joint probability model) as compared to 14.30 for a baseline phrase-based system and 16.25 for a system which transliterates OOV words in the baseline system. This indicates that transliteration is useful for more than only translating OOV words for language pairs like Hindi-Urdu.
C1 [Durrani, Nadir; Sajjad, Hassan; Fraser, Alexander; Schmid, Helmut] Univ Stuttgart, Inst Nat Language Proc, Stuttgart, Germany.
RP Durrani, N (reprint author), Univ Stuttgart, Inst Nat Language Proc, Stuttgart, Germany.
EM durrani@ims.uni-stuttgart.de; sajjad@ims.uni-stuttgart.de;
   fraser@ims.uni-stuttgart.de; schmid@ims.uni-stuttgart.de
CR Abdul Jaleel Nasreen, 2003, CIKM, P139
   Al-Onaizan Y., 2002, P 40 ANN M ASS COMP, P400, DOI DOI 10.3115/1073083.1073150
   Ekbal Asif, 2006, P COLING ACL 2006 MA, P191
   Gupta Suvodeep, 2004, THESIS
   HERMJAKOB U, 2008, P 46 ACL, P389
   Jawaid Bushra, 2009, C LANG TECHN LAH PAK
   Kashani M. M., 2007, P 2 WORKSH STAT MACH, P17
   Knight K, 1998, COMPUT LINGUIST, V24, P599
   Koehn P., 2004, P 2004 C EMP METH NA, P388
   Koehn Philipp, 2007, P 45 ANN M ASS COMP
   Koehn Philipp, 2004, AMTA 2004, P115
   LI H, 2004, ACL 04 P 42 ANN M AS, P159
   Mahesh R., 2009, 3 WORKSH COMP APPR A
   Malik MG Abbas, 2008, P 22 INT C COMP LING
   Moore Robert C., 2002, C ASS MACH TRANSL AM
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Papineni Kishore A., 2001, RC22176W0109022 THOM
   PIRKOLA A, 2003, SIGIR 2003, P345
   Stolcke A., 2002, INT C SPOK LANG PROC
   VIRGA P, 2003, P 41 ACL WORKSH MULT, P57
   Zhao Bing, 2007, HUMAN LANGUAGE TECHN, P364
NR 21
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 465
EP 474
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300048
DA 2019-06-15
ER

PT B
AU Heinz, J
   Rogers, J
AF Heinz, Jeffrey
   Rogers, James
GP Assoc Computat Linguist
TI Estimating Strictly Piecewise Distributions
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID FINITE-STATE MACHINES; NATURAL-LANGUAGE; LOGIC
AB Strictly Piecewise (SP) languages are a subclass of regular languages which encode certain kinds of long-distance dependencies that are found in natural languages. Like the classes in the Chomsky and Subregular hierarchies, there are many independently converging characterizations of the SP class (Rogers et al., to appear). Here we define SP distributions and show that they can be efficiently estimated from positive data.
C1 [Heinz, Jeffrey] Univ Delaware, Newark, DE 19716 USA.
   [Rogers, James] Earlham Coll, Richmond, IN USA.
RP Heinz, J (reprint author), Univ Delaware, Newark, DE 19716 USA.
EM heinz@udel.edu; jrogers@quark.cs.earlham.edu
CR Applegate R.B., 2007, SAMALA ENGLISH DICT
   APPLEGATE RICHARD B, 1972, THESIS
   Bakovic Eric, 2000, THESIS
   BEAUQUIER D, 1991, THEOR COMPUT SCI, V84, P3, DOI 10.1016/0304-3975(91)90258-4
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   Brzozowski J. A., 1973, Discrete Mathematics, V4, P243, DOI 10.1016/S0012-365X(73)80005-6
   Chomsky Noam, 1956, IRE T INFORM THEORY
   COLEMAN J, 1997, COMPUTATIONAL PHONOL, P49
   de la Higuera Colin, GRAMMATICAL INFERENC
   GARCIA P, 1990, IEEE T PATTERN ANAL, V12, P920, DOI 10.1109/34.57687
   GARCIA P, 1990, P WORKSH ALG LEARN T, P325
   Garcia Pedro, 1996, LECT NOTES COMPUTER, V1147, P203
   Hansson Gunnar lafur, 2001, THESIS
   Hayes B, 2008, LINGUIST INQ, V39, P379, DOI 10.1162/ling.2008.39.3.379
   Heinz J., 2007, THESIS
   Heinz Jeffrey, LINGUISTIC IN PRESS
   Hopcroft J. E., 2001, INTRO AUTOMATA THEOR
   JELENIK F, 1997, STAT METHODS SPEECH
   Johnson CD, 1972, FORMAL ASPECTS PHONO
   Joshi A. K., 1985, NATURAL LANGUAGE PAR, P206, DOI DOI 10.1017/CBO9780511597855
   Jurafsky D, 2008, SPEECH LANGUAGE PROC
   Kaplan R. M., 1994, Computational Linguistics, V20, P331
   Kobele G. M., 2006, THESIS
   Kontorovich L, 2008, THEOR COMPUT SCI, V405, P223, DOI 10.1016/j.tcs.2008.06.037
   Lothaire M, 1997, COMBINATORICS WORDS
   Markov A. A., 1913, EXAMPLE STAT STUDY T
   McNaughton  Robert, 1971, COUNTER FREE AUTOMAT
   Newell A., 1998, NAT LANG ENG, V4, P1
   PERRIN D, 1986, J COMPUT SYST SCI, V32, P393, DOI 10.1016/0022-0000(86)90037-1
   Ringen C., 1988, VOWEL HARMONY THEORE
   ROGERS J, P 11 M ASS IN PRESS
   Rogers James, J LOGIC LANGUAGE INF
   Rose S, 2004, LANGUAGE, V80, P475, DOI 10.1353/lan.2004.0144
   Sakarovitch J., 1983, ENCY MATH ITS APPL, V17, P105
   SHIEBER SM, 1985, LINGUIST PHILOS, V8, P333, DOI 10.1007/BF00630917
   Simon I., 1975, Automata Theory and Formal Language 2nd GI Conference, P214
   Straubing H., 1994, FINITE AUTOMATA FORM
   THOMAS W, 1982, J COMPUT SYST SCI, V25, P360, DOI 10.1016/0022-0000(82)90016-2
   Vidal E, 2005, IEEE T PATTERN ANAL, V27, P1013, DOI 10.1109/TPAMI.2005.147
   Vidal E, 2005, IEEE T PATTERN ANAL, V27, P1026, DOI 10.1109/TPAMI.2005.148
NR 40
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 886
EP 896
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300091
DA 2019-06-15
ER

PT S
AU Janarthanam, S
   Lemon, O
AF Janarthanam, Srinivasan
   Lemon, Oliver
BE Krahmer, E
   Theune, M
TI Learning Adaptive Referring Expression Generation Policies for Spoken
   Dialogue Systems
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
DE Reinforcement Learning; Referring Expression Generation; Spoken Dialogue
   System
ID LANGUAGE
AB We address the problem that different users have different lexical knowledge about problem domains, so that automated dialogue systems need to adapt their generation choices online to the users' domain knowledge as it encounters them. We approach this problem using Reinforcement Learning in Markov Decision Processes (MDP). We present a reinforcement learning framework to learn adaptive referring expression generation (REG) policies that can adapt dynamically to users with different domain knowledge levels. In contrast to related work we also propose a new statistical user model which incorporates the lexical knowledge of different users. We evaluate this framework by showing that it allows us to learn dialogue policies that automatically adapt their choice of referring expressions online to different users, and that these policies are significantly better than hand-coded adaptive policies for this problem. The learned policies are consistently between 2 and 8 turns shorter than a range of different hand-coded but adaptive baseline REG policies.
C1 [Janarthanam, Srinivasan] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
   [Lemon, Oliver] Heriot Watt Univ, Sch Math & Comp Sci, Edinburgh EH14 4AS, Midlothian, Scotland.
RP Janarthanam, S (reprint author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
EM s.janarthanam@ed.ac.uk; o.lemon@hw.ac.uk
OI Lemon, Oliver/0000-0001-9497-4743
FU European Community's Seventh Framework (FP7) [216594]; EPSRC
   [EP/E019501/1]; British Council
FX The research leading to these results has received funding from the
   European Communitys Seventh Framework (FP7) under grant agreement no.
   216594 (CLASSiC Project www.classicproject.org), EPSRC project no.
   EP/E019501/1,and the British Council (UKIERI PhD Scholarships 2007-8).
CR BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   BELT A, 2007, P ENLG 2007
   BOYE J, 2007, P SIGDIAL 2007
   BRANIGAN HP, J PRAGMATIC IN PRESS
   Brennan S. E., 1991, User Modeling and User-Adapted Interaction, V1, P67, DOI 10.1007/BF00158952
   Bromme R, 2005, APPL COGNITIVE PSYCH, V19, P569, DOI 10.1002/acp.1099
   Buschmeier H, 2010, LECT NOTES ARTIF INT, V5790, P85, DOI 10.1007/978-3-642-15573-4_5
   Clark H. H., 1982, LANGUAGE COMPREHENSI
   Clark Herbert H., 1996, USING LANGUAGE
   DALE R, 1989, P ACL 1989
   GATT A, 2008, P INLG 2008
   GEORGILA K, 2005, P EUROSPEECH INTERSP
   HELLER D, 2009, P PRE COGSCI 2009
   Hinds PJ, 1999, J EXP PSYCHOL-APPL, V5, P205, DOI 10.1037//1076-898X.5.2.205
   ISAACS EA, 1987, J EXP PSYCHOL GEN, V116, P26, DOI 10.1037/0096-3445.116.1.26
   JANARTHANAM S, 2009, P SIGDIAL 2009
   JANARTHANAM S, 2008, P SEMDIAL 2008
   JANARTHANAM S, 2009, P ENLG 2009
   Komatani K, 2005, USER MODEL USER-ADAP, V15, P169, DOI 10.1007/s11257-004-5659-0
   Krahmer E, 2003, COMPUT LINGUIST, V29, P53, DOI 10.1162/089120103321337430
   LEMON O, 2008, P SEMDIAL 2008
   LEVIN E, 1997, P ASRU 1997
   MCKEOWN K, 1993, P ACL 1993
   MOLICH R, 1990, COMMUN ACM, V33, P338, DOI 10.1145/77481.77486
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   PORZEL R, 2006, P WORKSH EFF MULT DI
   REITER E, 1995, COGNITIVE SCI, V18, P233
   RIESER V, 2008, P ACL 2008
   RIESER V, 2009, P EACL 2009
   Rieser V, 2010, LECT NOTES ARTIF INT, V5790, P105, DOI 10.1007/978-3-642-15573-4_6
   SCHATZMANN J, 2006, KNOWL ENG REV, P97
   SCHATZMANN J, 2007, P HLT NAACL 2007
   SCHLANGEN D, 2004, P SIGDIAL 2004
   SHAPIRO D, 2002, P ICML 2002
   SIDDHARTHAN A, 2004, P ACL 2004
   Stoia L., 2006, P 4 INT NAT LANG GEN, P81
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   van Deemter K, 2002, COMPUT LINGUIST, V28, P37, DOI 10.1162/089120102317341765
   VANDEEMTER K, 2009, P ENLG 2009
   WILLIAMS J, 2007, P HLT NAACL WORKSH B
   Wittwer J., 2005, P COGSCI 2005
NR 41
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 67
EP +
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600004
DA 2019-06-15
ER

PT B
AU Johnson, M
AF Johnson, Mark
GP Assoc Computat Linguist
TI PCFGs, Topic Models, Adaptor Grammars and Learning Topical Collocations
   and the Structure of Proper Names
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper establishes a connection between two apparently very different kinds of probabilistic models. Latent Dirichlet Allocation (LDA) models are used as "topic models" to produce a low-dimensional representation of documents, while Probabilistic Context-Free Grammars (PCFGs) define distributions over trees. The paper begins by showing that LDA topic models can be viewed as a special kind of PCFG, so Bayesian inference for PCFGs can be used to infer Topic Models as well. Adaptor Grammars (AGs) are a hierarchical, non-parameteric Bayesian extension of PCFGs. Exploiting the close relationship between LDA and PCFGs just described, we propose two novel probabilistic models that combine insights from LDA and AG models. The first replaces the unigram component of LDA topic models with multi-word sequences or collocations generated by an AG. The second extension builds on the first one to learn aspects of the internal structure of proper names.
C1 [Johnson, Mark] Macquarie Univ, Dept Comp, N Ryde, NSW 2109, Australia.
RP Johnson, M (reprint author), Macquarie Univ, Dept Comp, N Ryde, NSW 2109, Australia.
EM mjohnson@science.mq.edu.au
OI Johnson, Mark/0000-0003-4809-8441
CR Beal MJ, 2002, ADV NEUR IN, V14, P577
   BERNSTEINRATNER N, 1987, CHILDRENS LANGUAGE, V6
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Elsner M, 2009, P HUM LANG TECHN 200, P164
   Fox E. B., 2008, P 25 INT C MACH LEAR, P312
   Goldwater S., 2006, P ADV NEUR INF PROC, V18, P459
   Griffiths T. L., 2004, PNAS, V101, P1
   Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211
   Johnson M., 2007, HUMAN LANGUAGE TECHN, P139
   Johnson M, 2009, P HUM LANG TECHN 200, P317
   Johnson M., 2008, P 46 ANN M ASS COMP
   Johnson M., 2007, ADV NEURAL INFORM PR, V19, P641
   Kurihara Kenichi, 2006, 8 INT C GRAMM INF
   Liang P, 2007, P 2007 JOINT C EMP M, P688
   Liang Percy, 2009, OXFORD HDB APPL BAYE
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   PETROV S, 2007, HUMAN LANGUAGE TECHN, P404
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Wang XR, 2007, IEEE DATA MINING, P697, DOI 10.1109/ICDM.2007.86
   WETHERELL CS, 1980, COMPUT SURV, V12, P361
NR 21
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1148
EP 1157
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300117
DA 2019-06-15
ER

PT B
AU Li, SS
   Lin, CY
   Song, YI
   Li, ZJ
AF Li, Shasha
   Lin, Chin-Yew
   Song, Young-In
   Li, Zhoujun
GP Assoc Computat Linguist
TI Comparable Entity Mining from Comparative Questions
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID INFORMATION EXTRACTION
AB Comparing one thing with another is a typical part of human decision making process. However, it is not always easy to know what to compare and what are the alternatives. To address this difficulty, we present a novel way to automatically mine comparable entities from comparative questions that users posted online. To ensure high precision and high recall, we develop a weakly-supervised bootstrapping method for comparative question identification and comparable entity extraction by leveraging a large online question archive. The experimental results show our method achieves F1-measure of 82.5% in comparative question identification and 83.3% in comparable entity extraction. Both significantly outperform an existing state-of-the-art method.
C1 [Li, Shasha] Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
   [Lin, Chin-Yew; Song, Young-In] Microsoft Res Asia, Beijing, Peoples R China.
   [Li, Zhoujun] Beihang Univ, Beijing, Peoples R China.
RP Li, SS (reprint author), Natl Univ Def Technol, Changsha, Hunan, Peoples R China.
EM shashali@nudt.edu.cn; cyl@microsoft.com; yosong@microsoft.com;
   lizj@buaa.edu.cn
CR Califf Mary Elaine, 1999, P AAAI 99 IAAI 99
   Cardie C, 1997, AI MAG, V18, P65
   Gusfield D., 1997, ALGORITHMS STRINGS T
   Haveliwala T. H., 2002, P 11 INT C WORLD WID, P517, DOI DOI 10.1145/511446.511513
   Jeh G., 2003, P 12 INT C WORLD WID, P271, DOI DOI 10.1145/775152.775191
   Jindal N., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P244, DOI 10.1145/1148170.1148215
   Jindal Nitin, 2006, P AAAI 06
   Kozareva Z., 2008, P ACL, V8, P1048
   Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344
   Mooney R. J., 2005, ACM SIGKDD EXP NEWSL, V7, P3, DOI DOI 10.1145/1089815.1089817
   Radev Dragomir, 2002, J AM SOC INFORM SCI, P408
   RAVICHANDRAN D, 2002, P 40 ANN M ASS COMP, P41, DOI DOI 10.3115/1073083.1073092
   Riloff E, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1044
   Riloff E, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P474
   Soderland S, 1999, MACH LEARN, V34, P233, DOI 10.1023/A:1007562322031
NR 15
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 650
EP 658
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300067
DA 2019-06-15
ER

PT B
AU McIntyre, N
   Lapata, M
AF McIntyre, Neil
   Lapata, Mirella
GP Assoc Computat Linguist
TI Plot Induction and Evolutionary Search for Story Generation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In this paper we develop a story generator that leverages knowledge inherent in corpora without requiring extensive manual involvement. A key feature in our approach is the reliance on a story planner which we acquire automatically by recording events, their participants, and their precedence relationships in a training corpus. Contrary to previous work our system does not follow a generate-and-rank architecture. Instead, we employ evolutionary search techniques to explore the space of possible stories which we argue are well suited to the story generation task. Experiments on generating simple children's stories show that our system outperforms previous data-driven approaches.
C1 [McIntyre, Neil; Lapata, Mirella] Univ Edinburgh, Sch Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
RP McIntyre, N (reprint author), Univ Edinburgh, Sch Informat, 10 Crichton St, Edinburgh EH8 9AB, Midlothian, Scotland.
EM n.d.mcintyre@sms.ed.ac.uk; mlap@inf.ed.ac.uk
CR Agudo Belen Diaz, 2004, P 7 EUR C CAS BAS RE, P142
   Barros Leandro Motta, 2007, COMPUTERS ENTERTAINM
   Barzilay Regina, 2007, COMPUTATIONAL LINGUI, V34, P1
   Carroll J. A., 2002, P 3 INT C LANG RES E, P1499
   CHAMBERS N., 2008, P 46 ANN M ASS COMP, P789
   Chambers N., 2009, P JOINT C 47 ANN M A, P602
   Cheng Hua, 2000, P 1 INT C NAT LANG G, P186
   Fellbaum, 1998, WORDNET ELECT LEXICA
   Fillmore CJ, 2003, INT J LEXICOGR, V16, P235, DOI 10.1093/ijl/16.3.235
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Grishman R., 1994, P 15 INT C COMP LING, P268
   Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI DOI 10.1145/775047.775067
   Karamanis Nikiforos, 2002, OP 2 INT NAT LANG GE, P81
   Keller F, 2009, BEHAV RES METHODS, V41, P1, DOI 10.3758/BRM.41.1.12
   Knight K., 1995, P 33 ANN M ASS COMP, P252
   Korhonen Y., 2006, P 5 LREC GEN IT
   Lavoie B., 1997, P 5 C APPL NAT LANG, P265
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   LIU H, 2002, P 18 NAT C ART INT A, P957
   McIntyre N., 2009, P JOINT C 47 ANN M A, P217
   Meehan J. R., 1977, P 5 INT JOINT C ART, P91
   Mellish C., 1998, P 9 INT WORKSH NAT L, P98
   Mitchell M, 1998, INTRO GENETIC ALGORI
   Pizzi D., 2007, P 2 INT C AFF COMP I, P630
   Reiter E., 2000, BUILDING NATURAL LAN
   Riedl Mark O., 2004, P NARR INT LEARN ENV, P41
   Shim Yunju, 2002, P PRIMA 2002 JAP, P151
   Swartjes I. M. T., 2008, P 20 BELG NETH C ART, P257
   Turner Scott R., 1992, MINISTREL COMPUTER M
   Wu Z., 1994, P 32 ANN M ASS COMP, P133, DOI DOI 10.3115/981732.981751
NR 31
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1562
EP 1572
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300158
DA 2019-06-15
ER

PT B
AU Rudolph, S
   Giesbrecht, E
AF Rudolph, Sebastian
   Giesbrecht, Eugenie
GP Assoc Computat Linguist
TI Compositional Matrix-Space Models of Language
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We propose CMSMs, a novel type of generic compositional models for syntactic and semantic aspects of natural language, based on matrix multiplication. We argue for the structural and cognitive plausibility of this model and show that it is able to cover and combine various common compositional NLP approaches ranging from statistical word space models to symbolic grammar formalisms.
C1 [Rudolph, Sebastian] Karlsruhe Inst Technol, Karlsruhe, Germany.
   [Giesbrecht, Eugenie] FZI Forschungszentrum Informat, Karlsuhe, Germany.
RP Rudolph, S (reprint author), Karlsruhe Inst Technol, Karlsruhe, Germany.
EM rudolph@kit.edu; giesbrecht@fzi.de
OI Rudolph, Sebastian/0000-0002-1609-2080
CR Antonellis Ioannis, 2006, CORR
   Baddeley Alan D., 2003, J COMMUN DISORD, V36, P198
   Cayley A., 1854, PHILOS MAG, V7, P40
   Clark S, 2008, P 2 S QUANT INT, P133
   Clark S., 2007, P AAAI SPRING S QUAN, P52
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dymetman M., 1998, Journal of Logic, Language and Information, V7, P461, DOI 10.1023/A:1008395026374
   Firth JR, 1957, STUDIES LINGUISTIC A, V1952-59, P1
   Gao K, 2004, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P845
   Gardenfors P, 2000, CONCEPTUAL SPACES GE
   Giesbrecht E, 2009, LECT NOTES ARTIF INT, V5662, P173, DOI 10.1007/978-3-642-03079-6_14
   Giesbrecht Eugenie, 2010, P HUM LANG TECHN 201
   Golan Jonathan S, 1992, THEORY SEMIRINGS APP
   Grefenstette G., 1994, EXPLORATIONS AUTOMAT
   Hopcroft JE, 1979, INTRO AUTOMATA THEOR
   Kintsch W, 2001, COGNITIVE SCI, V25, P173, DOI 10.1207/s15516709cog2502_1
   Lambek J., 1958, AM MATH MONTHLY, V65, P154, DOI [DOI 10.2307/2310058, 10.2307/2310058]
   Landauer TK, 1997, PSYCHOL REV
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   Mitchell J., 2008, P ACL COL OH, P236
   Pado S, 2007, COMPUT LINGUIST, V33, P161, DOI 10.1162/coli.2007.33.2.161
   PLATE TA, 1995, IEEE T NEURAL NETWOR, V6, P623, DOI 10.1109/72.377968
   POST EL, 1946, B AM MATH SOC, V52, P264, DOI 10.1090/S0002-9904-1946-08555-9
   Rendle S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P727
   Sahlgren M., 2008, P 30 ANN C COGN SCI, P1300
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Schutze H., 1993, ADV NEURAL INFORMATI, P895
   Strang Gilbert, 1993, INTRO LINEAR ALGEBRA
   Tucker Ledyard R., 1966, PSYCHOMETRIKA, V31
   WIDDOWS D, 2008, P 2 AAAI S QUANT INT
NR 30
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 907
EP 916
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300093
DA 2019-06-15
ER

PT B
AU Sagot, B
   Satta, G
AF Sagot, Benot
   Satta, Giorgio
GP Assoc Computat Linguist
TI Optimal rank reduction for Linear Context-Free Rewriting Systems with
   Fan-Out Two
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Linear Context-Free Rewriting Systems (LCFRSs) are a grammar formalism capable of modeling discontinuous phrases. Many parsing applications use LCFRSs where the fan-out (a measure of the discontinuity of phrases) does not exceed 2. We present an efficient algorithm for optimal reduction of the length of production right-hand side in LCFRSs with fan-out at most 2. This results in asymptotical running time improvement for known parsing algorithms for this class.
C1 [Sagot, Benot] INRIA, Le Chesnay, France.
   [Sagot, Benot] Univ Paris 07, Le Chesnay, France.
   [Satta, Giorgio] Univ Padua, Dept Informat Engn, I-35100 Padua, Italy.
RP Sagot, B (reprint author), INRIA, Le Chesnay, France.; Sagot, B (reprint author), Univ Paris 07, Le Chesnay, France.
EM benoit.sagot@inria.fr; satta@dei.unipd.it
CR Gildea Daniel, 2010, HUMAN LANGUAGE TECHN
   Gomez-Rodriguez Carlos, 2009, P N AM CHAPT ASS COM
   Gomez-Rodriguez Carlos, 2009, P JOINT C 47 ANN M A, P985
   Harrison M., 1978, INTRO FORMAL LANGUAG
   Joshi Aravind K., 1977, SIAM J COMPUTING
   Kuhlmann Marco, 2009, P 12 M EUR CHAPT ASS
   Maier Wolfgang, 2009, P 14 C FORM GRAMM FG
   Rambow O, 1999, THEOR COMPUT SCI, V223, P87, DOI 10.1016/S0304-3975(97)00190-4
   Satta Giorgio, 1992, P 30 M ASS COMP LING
   SEKI H, 1991, THEOR COMPUT SCI, V88, P191, DOI 10.1016/0304-3975(91)90374-B
   Sogaard Anders, 2008, P 13 C FORM GRAMM FG, P61
   Vijay-Shanker K., 1987, P 25 M ASS COMP LING
   Weir David J., 1992, P 30 M ASS COMP LING
NR 13
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 525
EP 533
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300054
DA 2019-06-15
ER

PT B
AU Sammons, M
   Vydiswaran, VGV
   Roth, D
AF Sammons, Mark
   Vydiswaran, V. G. Vinod
   Roth, Dan
GP Assoc Computat Linguist
TI Ask not what Textual Entailment can do for You...
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We challenge the NLP community to participate in a large-scale, distributed effort to design and build resources for developing and evaluating solutions to new and existing NLP tasks in the context of Recognizing Textual Entailment. We argue that the single global label with which RTE examples are annotated is insufficient to effectively evaluate RTE system performance; to promote research on smaller, related NLP tasks, we believe more detailed annotation and evaluation are needed, and that this effort will benefit not just RTE researchers, but the NLP community as a whole. We use insights from successful RTE systems to propose a model for identifying and annotating textual inference phenomena in textual entailment examples, and we present the results of a pilot annotation study that show this model is feasible and the results immediately useful.
C1 [Sammons, Mark; Vydiswaran, V. G. Vinod; Roth, Dan] Univ Illinois, Urbana, IL 61801 USA.
RP Sammons, M (reprint author), Univ Illinois, Urbana, IL 61801 USA.
EM mssammon@illinois.edu; vgvinodv@illinois.edu; danr@illinois.edu
OI Vydiswaran, V.G.Vinod/0000-0002-3122-1936
CR Bentivogli Luisa, 2009, NOTEBOOK PAPERS RESU, P14
   Chklovski T., 2004, P EMNLP, P33
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   DEMARNEFFE MC, 2008, P 46 ANN M ASS COMP, P1039
   Do Quang, 2010, COMPUTER SCI RES TEC
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Giampiccolo D., 2007, P ACL PASCAL WORKSH, P1
   Harabagiu S, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P905
   Hovy E., 2006, P HLT NAACL NEW YORK
   Lin Dekang, 2001, P ACM SIGKDD C KNOWL, P323, DOI [10.1145/502512.502559, DOI 10.1145/502512.502559]
   MacCartney Bill, 2009, 8 INT C COMP SEM IWC
   Magnini Bernardo, 2006, PASCAL RECOGNISING T, V3944
   Mirkin Shachar, 2009, ACL AFNLP, P791
   Pado S., 2009, P JOINT C 47 ANN M A, P297
NR 14
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1199
EP 1208
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300122
DA 2019-06-15
ER

PT B
AU Tata, S
   Di Eugenio, B
AF Tata, Swati
   Di Eugenio, Barbara
GP Assoc Computat Linguist
TI Generating Fine-Grained Reviews of Songs From Album Reviews
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Music Recommendation Systems often recommend individual songs, as opposed to entire albums. The challenge is to generate reviews for each song, since only full album reviews are available on-line. We developed a summarizer that combines information extraction and generation techniques to produce summaries of reviews of individual songs. We present an intrinsic evaluation of the extraction components, and of the informativeness of the summaries; and a user study of the impact of the song review summaries on users' decision making processes. Users were able to make quicker and more informed decisions when presented with the summary as compared to the full album review.
C1 [Tata, Swati; Di Eugenio, Barbara] Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA.
RP Tata, S (reprint author), Univ Illinois, Dept Comp Sci, Chicago, IL 60607 USA.
EM stata2@uic.edu; bdieugen@uic.edu
CR [Anonymous], 2008, UPNP DEVICE ARCHITEC
   Barzilay R, 2005, COMPUT LINGUIST, V31, P297, DOI 10.1162/089120105774321091
   Carenini Giuseppe, 2006, P EACL
   Clema Oscar, 2006, THESIS
   de Marnee Marie-Catherine, 2008, STANFORD TYPED DEPEN
   Downie J. Stephen, 2006, P 6 ACM IEEE CJ JOIN, P196
   Esuli A., 2006, EACL, V6, P2006
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Gamon M, 2005, LECT NOTES COMPUT SC, V3646, P121
   Giasson Frederick, 2007, MUSIC ONTOL IN PRESS
   Harnly Aaron, 2005, P C REC ADV NAT LANG
   Hearst Marti A., 1994, P 32 M ASS COMP LING
   Higashinaka Ryuichiro, 2006, COLING ACL06
   Hu M, 2004, P KDD
   Klein Dan, 2002, ADV NEURAL INFORM PR, V15, P3
   McRoy S. W., 2003, Natural Language Engineering, P381, DOI 10.1017/S1351324903003188
   Minnen G., 2000, P 1 INT NAT LANG GEN
   Mitchell T. M., 1997, MACHINE LEARNING
   Nastase Vivi, 2008, P C EMP METH NAT LAN
   Nguyen Patrick, 2007, MSRTR2007126
   Schedl Markus, 2007, P AUSTR COMP SOC
   Soubbotin M., 2005, DOC UND WORKSH DUC V
   Tata Swati, 2010, THESIS
   Zhuang Li, 2006, C INF KNOWL MAN ARL
NR 24
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1376
EP 1385
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300140
DA 2019-06-15
ER

PT B
AU Tomasoni, M
   Huang, ML
AF Tomasoni, Mattia
   Huang, Minlie
GP Assoc Computat Linguist
TI Metadata-Aware Measures for Answer Summarization in Community Question
   Answering
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper presents a framework for automatically processing information coming from community Question Answering (cQA) portals with the purpose of generating a trustful, complete, relevant and succinct summary in response to a question. We exploit the metadata intrinsically present in User Generated Content (UGC) to bias automatic multi-document summarization techniques toward high quality information. We adopt a representation of concepts alternative to n-grams and propose two concept-scoring functions based on semantic overlap. Experimental results on data drawn from Yahoo! Answers demonstrate the effectiveness of our method in terms of ROUGE scores. We show that the information contained in the best answers voted by users of cQA portals can be successfully complemented by our method.
C1 [Tomasoni, Mattia] Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
   [Huang, Minlie] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
RP Tomasoni, M (reprint author), Uppsala Univ, Dept Informat Technol, Uppsala, Sweden.
EM mattia.tomasoni.8371@student.uu.se; aihuang@tsinghua.edu.cn
CR Agichtein E., 2008, P INT C WEB SEARCH W, P183, DOI DOI 10.1145/1341531.1341557
   Akamine S., 2009, P ACL IJCNLP 2009 SO, P1
   Amini M.-R., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P105
   Gillick D., 2009, P WORKSH INT LIN PRO, P10
   Hu M., 2007, CIKM 07, P243
   Jiwoon Jeon, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P228, DOI 10.1145/1148170.1148212
   [李丽 LI Li], 2009, [高分子通报, Polymer Bulletin], P71, DOI 10.1145/1526709.1526720
   Liu Y, 2008, ACTA METEOROL SIN, V22, P22
   McDonald R, 2007, LECT NOTES COMPUT SC, V4425, P557
   McGuinness D., 2006, P WORKSH MOD TRUST W, P3
   Metzler D., 2008, P SIGIR LEARN RANK W
   Stvilia B., 2005, P INT C INF QUAL
   Suryanto M. A., 2009, P 2 ACM INT C WEB SE, P142
   Swaminathan A, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P173
   Wang CM, 2007, INT J STRUCT STAB DY, V7, P555, DOI 10.1142/S0219455407002423
   Wang D., 2008, P 31 ANN INT ACM SIG, P307, DOI DOI 10.1145/1390334.1390387
   Wang K, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P187, DOI 10.1145/1571941.1571975
   WANG XJ, 2009, P 32 ANN INT ACM, P179
   Wong K. F., 2008, P 22 INT C COMP LING, P985, DOI DOI 10.3115/1599081.1599205
   Zeng Honglei, 2006, PST 06, P8
   Zhou Liang, 2006, P 5 INT C LANG RES E
NR 21
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 760
EP 769
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300078
DA 2019-06-15
ER

PT S
AU Turner, R
   Sripada, S
   Reiter, E
AF Turner, Ross
   Sripada, Somayajulu
   Reiter, Ehud
BE Krahmer, E
   Theune, M
TI Generating Approximate Geographic Descriptions
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
DE data-to-text systems; georeferenced data; geographic descriptions
ID REFERRING EXPRESSIONS; SYSTEMS
AB Georeferenced data sets are often large and complex. Natural language generation (NLG) systems are beginning to emerge that generate texts from such data. One of the challenges these systems face is the generation of geographic descriptions that refer to the location of events or patterns in the data. Based on our studies in the domain of meteorology we present an approach to generating approximate geographic descriptions involving regions, which incorporates domain knowledge and task constraints to model the utility of a description. Our evaluations show that NLG systems, because they can analyse input data exhaustively, can produce more fine-grained geographic descriptions that are potentially more useful to end users than those generated by human experts.
C1 [Turner, Ross] Nokia Gate5 GmbH, Berlin, Germany.
   [Sripada, Somayajulu; Reiter, Ehud] Univ Aberdeen, Dept Comp Sci, Aberdeen AB9 1FX, Scotland.
RP Turner, R (reprint author), Nokia Gate5 GmbH, Berlin, Germany.
EM ross.turner@nokia.com; yaji.sripada@abdn.ac.uk; e.reiter@abdn.ac.uk
CR Benamara F, 2004, LECT NOTES ARTIF INT, V3123, P11
   Cimiano P, 2008, LECT NOTES COMPUT SC, V5039, P151
   Dale R, 2005, J RES PRACT INF TECH, V37, P89
   DALE R, 1995, COGNITIVE SCI, V19, P233
   EBERT C, 1996, P 1 EUR WORKSH COGN, P235
   GARDENT C, 2002, P 40 ANN M ASS COMP, P96
   Gatt Albert, 2007, Journal of Logic, Language and Information, V16, P423, DOI 10.1007/s10849-007-9047-0
   GATT A, 2006, P 28 ANN M COGN SCI, P255
   Grice H. P., 1975, SYNTAX SEMANTICS, P43
   Horacek H, 2004, LECT NOTES ARTIF INT, V3123, P70
   KELLEHER J, 2006, P 21 INT C COMP LING, P1041
   KHAN IH, 2006, P 4 INT NAT LANG GEN, P89
   Krahmer E, 2003, COMPUT LINGUIST, V29, P53, DOI 10.1162/089120103321337430
   Levinson S. C., 2003, SPACE LANGUAGE COGNI
   Miller HJ, 2003, ANN ASSOC AM GEOGR, V93, P574, DOI 10.1111/1467-8306.9303004
   Moulin B., 1999, Spatial Cognition and Computation, V1, P227, DOI 10.1023/A:1010045617505
   O'Sullivan D, 2003, GEOGRAPHIC INFORM AN
   Reiter E, 2005, ARTIF INTELL, V167, P137, DOI 10.1016/j.artint.2005.06.006
   SRIPADA SG, 2003, P 9 ACM SIGKDD INT C, P187
   Stone M., 2000, P 1 INT C NAT LANG G, P116
   THOMAS KE, 2008, P 5 INT C NAT LANG G, P113
   TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141
   Towns SG, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P112
   TRAFTON JG, 2007, P HUM FACT ERG SOC 5, P311
   TURNER R, 2008, P LREC 2008 WORKSH M, P28
   TURNER R, 2008, P 5 INT C NAT LANG G, P16
   TURNER R, 2009, THESIS U ABERDEEN
   TURNER R, 2006, P 11 C EUR CHAPT ASS, P163
   Tversky B., 1993, Spatial Information Theory. A Theoretical Basis for GIS. European Conference, COSIT '93 Proceedings, P14
   van Deemter K, 2002, COMPUT LINGUIST, V28, P37, DOI 10.1162/089120102317341765
   VARGES S, 2005, P 10 EUR WORKSH NAT, P207
   Varzi A., 2001, PHILOS GEOGRAPHY, V4, P49
   Viethen J., 2008, P 5 INT NAT LANG GEN, P59, DOI DOI 10.3115/1708322.1708334
NR 33
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 121
EP +
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600007
DA 2019-06-15
ER

PT B
AU Yeniterzi, R
   Oflazer, K
AF Yeniterzi, Reyyan
   Oflazer, Kemal
GP Assoc Computat Linguist
TI Syntax-to-Morphology Mapping in Factored Phrase-Based Statistical
   Machine Translation from English to Turkish
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a novel scheme to apply factored phrase-based SMT to a language pair with very disparate morphological structures. Our approach relies on syntactic analysis on the source side (English) and then encodes a wide variety of local and non-local syntactic structures as complex structural tags which appear as additional factors in the training data. On the target side (Turkish), we only perform morphological analysis and disambiguation but treat the complete complex morphological tag as a factor, instead of separating morphemes. We incrementally explore capturing various syntactic substructures as complex tags on the English side, and evaluate how our translations improve in BLEU scores. Our maximal set of source and target side transformations, coupled with some additional techniques, provide an 39% relative improvement from a baseline 17.08 to 23.78 BLEU, all averaged over 10 training and test sets. Now that the syntactic analysis on the English side is available, we also experiment with more long distance constituent reordering to bring the English constituent order close to Turkish, but find that these transformations do not provide any additional consistent tangible gains when averaged over the 10 sets.
C1 [Yeniterzi, Reyyan] Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
   [Oflazer, Kemal] Carnegie Mellon Univ Qatar, Comp Sci, Doha, Qatar.
RP Yeniterzi, R (reprint author), Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15213 USA.
EM reyyan@cs.cmu.edu; ko@cs.cmu.edu
CR Birch Alexandra, 2007, P SMT WORKSH 45 ACL
   Bisazza Arianna, 2009, P INT WORKSH SPOK LA
   Durgar- El- Kahlout Ilknur, 2010, IEEE T AUDI IN PRESS
   Fraser Alexander, 2009, P 4 WORKSH STAT MACH, P115
   Hassan H, 2007, P 45 ANN M ASS COMP, P288
   Koehn P., 2005, MT SUMMIT
   KOEHN P, 2007, P EMNLP
   Koehn P., 2008, P 46 ANN M ASS COMP, P763
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koehn Philipp, 2003, P HLT NAACL 2003
   Lee Y.-S., 2004, P HLT NAACL 2004 COM, P57
   McClosky D., 2005, P HUM LANG TECHN C C, P676
   Minkov E., 2007, ANN M ASS COMP LING, V45, P128
   Niessen S, 2004, COMPUT LINGUIST, V30, P181, DOI 10.1162/089120104323093285
   Nivre J., 2007, NAT LANG ENG, V13, P99
   Och F., 2009, P HUM LANG TECHN 200, P245
   Oflazer K., 1994, Literary & Linguistic Computing, V9, P137
   Oflazer K., 2007, P 2 WORKSH STAT MACH, P25
   Oflazer K, 2008, LECT NOTES COMPUT SC, V4919, P376, DOI 10.1007/978-3-540-78135-6_32
   PAPINENI K, 2001, P 40 ANN M ASS COMP, P311
   Popovi M, 2004, P 4 INT C LANG RES E, P1585
   Schmid Helmut, 1994, P INT C NEW METH LAN
   Toutanova K., 2003, P HLT NAACL, P252, DOI DOI 10.3115/1073445.1073478
   Yang M., 2006, P EACL, P41
   Yuret D., 2006, P HUM LANG TECHN C N, P328, DOI 10.3115/1220835.1220877
   Zollmann A, 2006, P HUM LANG TECHN C N, P201
NR 26
TC 4
Z9 4
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 454
EP 464
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300047
DA 2019-06-15
ER

PT B
AU Halpin, H
   Moore, JD
AF Halpin, Harry
   Moore, Johanna D.
GP COLING
TI Event Extraction in a Plot Advice Agent
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper we present how the automatic extraction of events from text can be used to both classify narrative texts according to plot quality and produce advice in an interactive learning environment intended to help students with story writing. We focus on the story rewriting task, in which an exemplar story is read to the students and the students rewrite the story in their own words. The system automatically extracts events from the raw text, formalized as a sequence of temporally ordered predicate-arguments. These events are given to a machine-learner that produces a coarse-grained rating of the story. The results of the machine-learner and the extracted events are then used to generate fine-grained advice for the students.
C1 [Halpin, Harry; Moore, Johanna D.] Univ Edinburgh, Sch Informat, Edinburgh EH8 9LW, Midlothian, Scotland.
RP Halpin, H (reprint author), Univ Edinburgh, Sch Informat, 2 Buccleuch Pl, Edinburgh EH8 9LW, Midlothian, Scotland.
EM H.Halpin@ed.ac.uk; J.Moore@ed.ac.uk
CR Abney S., 1995, COMPUTATIONAL LINGUI, P145
   BALDWIN B, 1997, COGNIAC HIGH PRECISI
   Bartlett F.C., 1932, REMEMBERING
   BOS J, 2004, P 20 INT C COMP LING
   Burstein J, 2003, IEEE INTELL SYST, V18, P32, DOI 10.1109/MIS.2003.1179191
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Graesser A., 2000, INTERACTIVE LEARNING, V8, P149
   GROVER C, 2000, P 2 LANG RES EV C
   HALPIN H, 2004, P EMP METH NAT LANG
   Hickmann M., 2003, CHILDRENS DISCOURSE
   Kamp Hans, 1993, DISCOURSE LOGIC
   Landauer TK, 1997, PSYCHOL REV
   LEMAIRE B, 2005, P 27 ANN M COGN SCI
   MCNEILL F, 2006, P KNOWL REPR REAS LA
   Mueller E.T., 2003, TEXT MEANING P HLT N, P46
   NENKOVA A, 2004, P JOINT C N AM ASS C
   Riloff Ellen, 1999, COMPUTATIONAL MODELS
   ROBERTSON J, 2003, NARRATIVE INTERACTIV
   ROBERTSON J, 2002, INT C INT TUT SYST B
   ROSE C, 2002, INT C INT TUT SYST B
NR 21
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 857
EP 864
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200108
DA 2019-06-15
ER

PT B
AU Higashinaka, R
   Prasad, R
   Walker, MA
AF Higashinaka, Ryuichiro
   Prasad, Rashmi
   Walker, Marilyn A.
GP COLING
TI Learning to Generate Naturalistic Utterances Using Reviews in Spoken
   Dialogue Systems
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Spoken language generation for dialogue systems requires a dictionary of mappings between semantic representations of concepts the system wants to express and realizations of those concepts. Dictionary creation is a costly process; it is currently done by hand for each dialogue domain. We propose a novel unsupervised method for learning such mappings from user reviews in the target domain, and test it on restaurant reviews. We test the hypothesis that user reviews that. provide individual ratings for distinguished attributes of the domain entity make it possible to map review sentences to their semantic representation with high precision. Experimental analyses show that the mappings learned cover most of the domain ontology, and provide good linguistic variation. A subjective user evaluation shows that the consistency between the semantic representations and the learned realizations is high and that the naturalness of the realizations is higher than a hand-crafted baseline.
C1 [Higashinaka, Ryuichiro] NTT Corp, Tokyo, Japan.
RP Higashinaka, R (reprint author), NTT Corp, Tokyo, Japan.
EM rh@cslab.kecl.ntt.co.jp; rjprasad@linc.cis.upenn.edu;
   walker@dcs.shef.ac.uk
CR Barzilay R, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P164
   BARZILAY R, 2001, P 39 ANN M ASS COMP, P50
   BARZILAY R, 2003, P HLT NAACL, P16
   CUNNINGHAM H, 2002, P 40 ACL
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Hirschberg Julia, 1987, P 25 ANN M ASS COMP, P163
   Hu M., 2005, P KDD, P168
   Knott A, 1996, THESIS U EDINBURGH E
   Lavoie B., 1997, P 5 C APPL NAT LANG, P265
   LIN D, 2001, NAT LANG ENG, V7, P343
   LIN DK, 1998, WORKSH EV PARS SYST
   MOORE JD, 2004, P 7 FLAIR
   Pang B., 2005, P 43 ANN M ASS COMP, P115, DOI DOI 10.3115/1219840.1219855
   POPESCU AM, 2005, P C HUM LANG TECHN E, P339, DOI DOI 10.3115/1220575.1220618
   Prasad R., 2005, P CORP LING WORKSH U
   SENEFF S, 2000, P ICSLP, V2, P767
   THEUNE M, 2003, AAAI 2003 SPRING S N, P141
   Turney Peter, 2002, P 40 ANN M ASS COMP, P417, DOI DOI 10.3115/1073083.1073153
   WALKER M, 2003, P EUROSPEECH, P1697
   White Michael, 1998, P 9 INT WORKSH NAT L, P266
   Wilson T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P761
NR 21
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 265
EP 272
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200034
DA 2019-06-15
ER

PT B
AU Lin, WH
   Hauptmann, A
AF Lin, Wei-Hao
   Hauptmann, Alexander
GP COLING
TI Are These Documents Written from Different Perspectives? A Test of
   Different Perspectives Based On Statistical Distribution Divergence
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper we investigate how to automatically determine if two document collections are written from different perspectives. By perspectives we mean a point of view, for example, from the perspective of Democrats or Republicans. We propose a test of different perspectives based on distribution divergence between the statistical models of two collections. Experimental results show that the test can successfully distinguish document collections of different perspectives from other types of collections.
C1 [Lin, Wei-Hao; Hauptmann, Alexander] Carnegie Mellon Univ, Sch Comp Sci, Language Technol Inst, Pittsburgh, PA 15213 USA.
RP Lin, WH (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Language Technol Inst, Pittsburgh, PA 15213 USA.
EM whlin@cs.cmu.edu; alex@cs.cmu.edu
CR Abelson R. P., 1973, COMPUTER MODELS THOU, P287
   Abelson R. P., 1965, AM BEHAV SCI, V8, P0
   BEINEKE P, 2004, P ASS COMP LING ACL
   Carbonell Jr J.G., 1978, COGNITIVE SCI, V2, P27
   Cover T. M., 1991, ELEMENTS INFORM THEO
   DAVE K, 2003, P 12 INT WORLD WID W
   FABRIZIO S, 2002, ACM COMPUT SURV, V34, P1, DOI DOI 10.1145/505282.505283
   Hu M., 2004, P 2004 ACM SIGKDD IN
   Kessler B., 1997, P 35 ANN M ASS COMP, P32, DOI DOI 10.3115/976909.979622
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   LEWIS DD, 1998, P 9 EUR C MACH LEARN
   Lin W.H., 2006, P 10 C NAT LANG LEAR
   MORINAGA S, 2002, P 2002 ACM SIGKDD IN
   Mullen T, 2004, P C EMP METH NAT LAN
   Nasukawa T., 2003, P 2 INT C KNOWL CAPT
   Pang B., 2002, P C EMP METH NAT LAN
   Pang B., 2004, P ASS COMP LING ACL
   Riloff E., 2003, P C EMP METH NAT LAN
   Riloff E., 2003, P 7 C NAT LANG LEARN
   Ripley B. D., 1987, STOCHASTIC SIMULATIO
   Schank R. C., 1977, SCRIPTS PLANS GOALS
   Turney PD, 2003, ACM T INFORM SYST, V21, P315, DOI 10.1145/944012.944013
   Verdonk P., 2002, STYLISTICS
   WIEBE J, 2004, COMPUTATIONAL LINGUI, V30
   Yu H., 2003, P C EMP METH NAT LAN
NR 25
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1057
EP 1064
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200133
DA 2019-06-15
ER

PT B
AU Nakatsu, C
   White, M
AF Nakatsu, Crystal
   White, Michael
GP COLING
TI Learning to Say It Well: Reranking Realizations by Predicted Synthesis
   Quality
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID GENERATION
AB This paper presents a method for adapting a language generator to the strengths and weaknesses of a synthetic voice, thereby improving the naturalness of synthetic speech in a spoken language dialogue system. The method trains a discriminative reranker to select paraphrases that are predicted to Sound natural when synthesized. The ranker is trained on realizer and synthesizer features in supervised fashion, using human judgements of synthetic voice quality on a sample of the paraphrases representative of the generator's capability. Results from a cross-validation study indicate that discriminative paraphrase reranking can achieve substantial improvements in naturalness on average, ameliorating the problem of highly variable synthesis quality typically encountered with today's unit selection synthesizers.
C1 [Nakatsu, Crystal; White, Michael] Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
RP Nakatsu, C (reprint author), Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
EM cnakatsu@ling.ohio-state.edu; mwhite@ling.ohio-state.edu
OI White, Michael/0000-0002-3062-1719
CR Barzilay R., 2005, P 43 ANN M ASS COMP
   BARZILAY R, 2001, P ACL EACL
   Beutnagel M, 1999, JOINT M ASA EAA DAGA
   BLACK A, 2000, P ICSLP2000 BEIJ CHI
   BLACK A, 2001, 4 ISCA SPEECH SYNTH
   BLACK A, 1997, EUROSPEECH 97
   Bulyko I, 2002, COMPUT SPEECH LANG, V16, P533, DOI 10.1016/S0885-2308(02)00023-2
   CLARK RAJ, 2004, 5 ISCA SPEECH SYNTH, P173
   Collins M., 2000, P ICML
   DAVIS JR, 1988, P ACL
   DENOS E, 2003, P ECHALLENGES 03
   FOSTER ME, 2004, P 4 NLPXML WORKSH
   FOSTER ME, 2005, P IJCAI 05 WORKSH KN
   FREUND Y, 1998, MACHINE LEARNING
   HITZEMAN J, 1998, P ICSLP 98
   HUNT A, 1996, P ICASSP 96 ATL GEOR
   Iordanskaja Lidija, 1991, NATURAL LANGUAGE GEN, P293
   Joachims  Thorsten, 2002, P KDD
   Langkilde  I., 1998, P COLING ACL
   Pan SM, 2002, COMPUT SPEECH LANG, V16, P457, DOI 10.1016/S0885-2308(02)00022-0
   PAN SM, 2002, P INT NAT LANG GEN C
   Pang Bo, 2003, P HLT NAACL
   PREVOST S, 1994, SPEECH COMMUN, V15, P139, DOI 10.1016/0167-6393(94)90048-5
   STONE M, 2004, ACM T GRAPHICS SIGGR, V23
   Taylor P., 1998, 3 INT WORKSH SPEECH
   Walker MA, 2002, COMPUT SPEECH LANG, V16, P409, DOI 10.1016/S0885-2308(02)00027-X
   WHITE M, 2004, P INLG 04
   WHITE M, 2006, RES LANGUAGE COMPUTA
   WHITE M, 2006, P INLG 06 IN PRESS
NR 29
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1113
EP 1120
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200140
DA 2019-06-15
ER

PT B
AU Pado, S
   Lapata, M
AF Pado, Sebastian
   Lapata, Mirella
GP COLING
TI Optimal Constituent Alignment with Edge Covers for Semantic Projection
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID DISTANCE
AB Given a parallel corpus, semantic projection attempts to transfer semantic role annotations from one language to another, typically by exploiting word alignments. In this paper, we present an improved method for obtaining constituent alignments between parallel sentences to guide the role projection task. Our extensions are twofold: (a) we model constituent alignment as minimum weight edge covers in a bipartite graph, which allows us to find a globally optimal solution efficiently; (b) we propose tree pruning as a promising strategy for reducing alignment noise. Experimental results on an English-German parallel corpus demonstrate improvements over state-of-the-art models.
C1 [Pado, Sebastian] Univ Saarland, D-6600 Saarbrucken, Germany.
RP Pado, S (reprint author), Univ Saarland, D-6600 Saarbrucken, Germany.
EM pado@coli.uni-sb.de; mlap@inf.ed.ac.uk
RI Pado, Sebastian/F-4883-2016
OI Pado, Sebastian/0000-0002-7529-6825
CR Bille P, 2005, THEOR COMPUT SCI, V337, P217, DOI 10.1016/j.tcs.2004.12.030
   Boas HC, 2005, INT J LEXICOGR, V18, P445, DOI 10.1093/ijl/eci043
   CARRERAS X, 2005, P CONLL SHAR TASK SE
   Collins M., 2005, P 43 ANN M ASS COMP, P531
   Collins M., 1997, P 35 ANN M ASS COMP, P16
   DUBEY A, 2005, P 43 ANN M ASS COMP, P314
   Eiter T, 1997, ACTA INFORM, V34, P109, DOI 10.1007/s002360050075
   Fillmore CJ, 2003, INT J LEXICOGR, V16, P235, DOI 10.1093/ijl/16.3.235
   FREDMAN ML, 1987, J ACM, V34, P596, DOI 10.1145/28869.28874
   FUNG P, 2004, P 20 INT C COMP LING, P931
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   GILDEA D, 2003, P 41 ANN M ASS COMP, P80
   GILDEA D, 2004, P EMNLP, P214
   HI C, 2005, P JOINT HUM LANG TEC, P851
   JONKER R, 1987, COMPUTING, V38, P325, DOI 10.1007/BF02278710
   KOEHN P, 2003, P HLT NAACL, P127
   Koehn P., 2005, P MT SUMM 10 PHUK TH
   MELAMED ID, 1998, 9807 IRCS TR U PENNS
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Pado S, 2005, P HUM LANG TECHN C C, P859
   Resnik Philip, 2002, P 40 ANN M ASS COMP, P392
   Wicentowski Richard, 2001, P 1 INT C HUM LANG T, P161
   Xia Fei, 2004, P 20 INT C COMP LING, P508, DOI DOI 10.3115/1220355.1220428
   Xue Nianwen, 2004, P EMNLP 2004, P88
NR 24
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1161
EP 1168
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200146
DA 2019-06-15
ER

PT B
AU Roy, S
   Subramaniam, LV
AF Roy, Shourya
   Subramaniam, L. Venkata
GP COLING
TI Automatic Generation of Domain Models for Call Centers from Noisy
   Transcriptions
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Call centers handle customer queries from various domains such as computer sales and support, mobile phones, car rental, etc. Each such domain generally has a domain model which is essential to handle customer complaints. These models contain common problem categories, typical customer issues and their solutions, greeting styles. Currently these models are manually created over time. Towards this, we propose an unsupervised technique to generate domain models automatically from call transcriptions. We use a state of the art Automatic Speech Recognition system to transcribe the calls between agents and customers, which still results in high word error rates (40%) and show that even from these noisy transcriptions of calls we can automatically build a domain model. The domain model is comprised of primarily a topic taxonomy where every node is characterized by topic(s), typical Questions-Answers (Q&As), typical actions and call statistics. We show how such a domain model can be used for topic identification of unseen calls. We also propose applications for aiding agents while handling calls and for agent monitoring based on the domain model.
C1 [Roy, Shourya; Subramaniam, L. Venkata] Indian Inst Technol, IBM Res, India Res Lab, New Delhi 110016, India.
RP Roy, S (reprint author), Indian Inst Technol, IBM Res, India Res Lab, Block 1, New Delhi 110016, India.
EM rshourya@in.ibm.com; lvsubram@in.ibm.com
CR BECHET F, 2004, C EMP METH NAT LANG
   Douglas S, 2005, IEEE T SPEECH AUDI P, V13, P652, DOI 10.1109/TSA.2005.851878
   HAFFNER P, 2003, IEEE INT C AC SPEECH
   JIANG X, 2005, IEEE INT C DAT MIN N
   KUMMAMURU K, 2004, INT C WORLD WID WEB
   Kuo HKJ, 2003, IEEE T SPEECH AUDI P, V11, P24, DOI 10.1109/TSA.2002.807352
   LAWSON AD, 2003, EFFECT FOREIGN ACCEN
   MISHNE G, 2005, C INF KNOWL MAN OCT
   Padmanabhan M, 2002, IEEE T SPEECH AUDI P, V10, P433, DOI 10.1109/TSA.2002.804303
   TANG M, 2003, AUT SPEECH REC UND W
   WRIGHT J, 1997, AUTOMATIC ACQUISITIO
NR 11
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 737
EP 744
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200093
DA 2019-06-15
ER

PT B
AU Sadat, F
   Habash, N
AF Sadat, Fatiha
   Habash, Nizar
GP COLING
TI Combination of Arabic Preprocessing Schemes for Statistical Machine
   Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Statistical machine translation is quite robust when it comes to the choice of input representation. It only requires consistency between training and testing. As a result, there is a wide range of possible preprocessing choices for data used in statistical machine translation. This is even more so for morphologically rich languages such as Arabic. In this paper, we study the effect of different word-level preprocessing schemes for Arabic on the quality of phrase-based statistical machine translation. We also present and evaluate different methods for combining preprocessing schemes resulting in improved translation quality.
C1 [Sadat, Fatiha] Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada.
RP Sadat, F (reprint author), Natl Res Council Canada, Inst Informat Technol, Ottawa, ON K1A 0R6, Canada.
EM fatiha.sadat@cnrc-nrc.gc.ca; habash@cs.columbia.edu
CR BANGALORE S, 2001, P IEEE AUT SPEECH RE
   BUCKWALTER T, 2002, LDC2002L49 U PENNS
   CALLISONBURCH C, 2006, P EUR CHAPT ASS COMP
   DIAB M, 2004, P N AM CHAPT ASS COM
   FREDERKING R, 2005, P APPL NAT LANG PROC
   GOLDWATER S, 2005, P EMP METH NAT LANG
   HABASH N, 2006, P NAACL BROOKL NEW Y
   Habash N, 2004, P TRAIT AUT LANG NAT
   JAYARAMAN S, 2005, P ASS COMP LING ACL
   KOEHN P, 2004, P ASS MACH TRANSL AM
   KOEHN P, 2004, P EMNLP BARC SPAIN
   Lee Y., 2004, P NAACL BOST MA
   LEE Y, 2005, P INT WORKSH SPOK LA
   Maamouri M., 2004, P NEMLAR C AR LANG R
   MATUSOV E, 2006, P EACL TRENT IT
   NIESSEN S, 2004, COMPUTATIONAL LINGUI, V30
   NOMOTO T, 2004, P ACL BARC SPAIN
   OCH F, 2003, P ACL SAPP JAP
   Och FJ, 2005, MT EV WORKSH UNPUB
   PAPINENI K, 2001, RC22176W0109022 IBM
   PAUL M, 2005, P IWSLT
   POPOVIC M, 2004, P LANG RES EV LREC L
   Rambow Owen, 2005, P ASS COMP LING ACL
   SADAT F, 2005, P ACL WORKSH BUILD U
   Stolcke A., 2002, P INT C SPOK LANG PR
NR 25
TC 4
Z9 4
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1
EP 8
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200001
DA 2019-06-15
ER

PT B
AU Shen, D
   Klakow, D
AF Shen, Dan
   Klakow, Dietrich
GP COLING
TI Exploring Correlation of Dependency Relation Paths for Answer Extraction
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper, we explore correlation of dependency relation paths to rank candidate answers in answer extraction. Using the correlation measure, we compare dependency relations of a candidate answer and mapped question phrases in sentence with the corresponding relations in question. Different from previous studies, we propose an approximate phrase mapping algorithm and incorporate the mapping score into the correlation measure. The correlations are further incorporated into a Maximum Entropy-based ranking model which estimates path weights from training. Experimental results show that our method significantly outperforms state-of-the-art syntactic relation-based methods by up to 20% in MRR.
C1 [Shen, Dan] Univ Saarland, Dept Computat Linguist, D-6600 Saarbrucken, Germany.
RP Shen, D (reprint author), Univ Saarland, Dept Computat Linguist, D-6600 Saarbrucken, Germany.
EM dshen@coli.uni-sb.de; klakow@lsv.uni-saarland.de
CR Adams ME, 1996, P EDINBURGH MATH SOC, V39, P71, DOI 10.1017/S0013091500022793
   CUI H, 2004, P TREC2004 NIST
   KAISSER M, 2004, P TREC2004 NIST
   LIN D, 1994, P 15 INT C COMP LING, P42
   MOLDOVAN D, 2002, P COLING2002
   RABINER LR, 1978, P IEEE T ACOUSTICS S
   RAVICHANDRAN D, 2003, P ACL2003 WORKSH MUL
   SHEN D, 2005, P IJCNLP2005
   TANEV H, 2004, P TREC2004 NIST
   WU M, 2005, P TREC2005 NIST
NR 10
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 889
EP 896
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200112
DA 2019-06-15
ER

PT B
AU Soricut, R
   Marcu, D
AF Soricut, Radu
   Marcu, Daniel
GP COLING
TI Stochastic Language Generation Using WIDL-expressions and its
   Application in Machine Translation and Summarization
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We propose WIDL-expressions as a flexible formalism that facilitates the integration of a generic sentence realization system within end-to-end language processing applications. WIDL-expressions represent compactly probability distributions over finite sets of candidate realizations, and have optimal algorithms for realization via interpolation with language model probability distributions. We show the effectiveness of a WIDL-based NLG system in two sentence realization tasks: automatic translation and headline generation.
C1 [Soricut, Radu; Marcu, Daniel] Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Soricut, R (reprint author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
EM radu@isi.edu; marcu@isi.edu
CR BANGALORE S, 2000, P 5 INT WORKSH TREE
   Cormen T. H., 2001, INTRO ALGORITHMS
   CORSTONOLIVER S, 2002, P INLG
   David Zajic B.J.D., 2004, P 2004 DOC UND C DUC, P112
   ELHADAD M, 1991, CUCS03891 COL U DEP
   Germann U, 2004, ARTIF INTELL, V154, P127, DOI 10.1016/j.artint.2003.06.001
   HABASH N, 2003, P AMTA
   HAJIC J, 2002, SUMM WORKSH FIN REP
   KKOEHN P, 2003, P HLT NAACL, P127
   KNIGHT K, 1995, P ACL
   Koehn P., 2004, P 6 C ASS MACH TRANS, P115
   LANGKILDEGEARY I, 2002, THESIS U SO CALIFORN
   LIN CY, 2004, P WORKSH TEXT SIM BR
   Matthiessen C. M. I. M., 1991, TEXT GENERATION SYST
   Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184
   NEDERHOF MJ, 2004, J ARTIFICIAL INTELLI, P287
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Russell S. J., 1995, ARTIFICIAL INTELLIGE
   SORICUT R, 2006, THESIS U SO CALIFORN
   Soricut Radu, 2005, P 43 ANN M ASS COMP, P66
   Zajic David, 2003, P HLT NAACL TEXT SUM, V5, P1, DOI DOI 10.3115/1119467.1119468
   ZHOU L, 2003, P NAACL WORKSH DOC U
NR 23
TC 4
Z9 4
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1105
EP 1112
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200139
DA 2019-06-15
ER

PT B
AU Zanzotto, FM
   Moschitti, A
AF Zanzotto, Fabio Massimo
   Moschitti, Alessandro
GP COLING
TI Automatic learning of textual entailments with cross-pair similarities
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper we define a novel similarity measure between examples of textual entailments and we use it as a kernel function in Support Vector Machines (SVMs). This allows us to automatically learn the rewrite rules that describe a non trivial set of entailment cases. The experiments with the data sets of the RTE 2005 challenge show an improvement of 4.4% over the state-of-the-art methods.
C1 [Zanzotto, Fabio Massimo] Univ Milano Bicocca, DISCo, Milan, Italy.
RP Zanzotto, FM (reprint author), Univ Milano Bicocca, DISCo, Milan, Italy.
EM zanzotto@disco.unimib.it; moschitti@info.uniroma2.it
RI Zanzotto, Fabio Massimo/L-6634-2015
OI Zanzotto, Fabio Massimo/0000-0002-7301-3596; Moschitti,
   Alessandro/0000-0003-2216-8034
CR Abney S., 1996, CORPUS BASED METHODS
   BAYER S, 2005, P 1 RTE WORKSH SOUTH
   BOS J, 2005, P HLT EMNLP C CAN
   BOUGHORBEL S, 2004, P BMVC 2004
   BRAZ RD, 2005, P RTE WORKSH SOUTH U
   CHARNIAK E, 2000, P 1 NAACL SEATTL WAS
   Chierchia G., 2001, MEANING GRAMMAR INTR
   Collins M., 2002, P ACL02
   Corley C., 2005, P ACL WORKSH EMP MOD
   DAGAN I, 2004, P WORKSH LEARN METH
   DAGAN I, 2005, RTE WORKSH SOUTH UK
   GLICKMAN O, 2005, P RTE WORKSH SOUTH U
   HAASDONK B, 2005, IEEE T PATTERN ANAL
   HAIM RB, 2006, RTE WORKSH VEN IT
   HEARST MA, 1992, P 15 COLING NANT FRA
   JIANG JJ, 1997, P 10 ROCLING TAP TAI
   Joachims T, 1999, ADV KERNEL METHODS S
   KOUYLEKOV M, 2005, P RANLP 2005 BOR BUL
   MILLER GA, 1995, COMMUNICATIONS A NOV
   MINNEN G, 2001, NATURAL LANGUAGE ENG
   MOSCHITTI A, 2006, P EACL06 TRENT IT
   Pedersen Ted, 2004, P 5 NAACL BOST MA
   Vapnik VN, 1995, NATURE STAT LEARNING
   Zaenen A., 2005, P ACL WORKSH EMP MOD
NR 24
TC 4
Z9 4
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 401
EP 408
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200051
DA 2019-06-15
ER

PT B
AU Hildebrandt, W
   Katz, B
   Lin, J
AF Hildebrandt, W
   Katz, B
   Lin, J
GP acl
TI Answering definition questions using multiple knowledge sources
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB Definition questions represent a largely unexplored area of question answering-they are different from factoid questions in that the goal is to return as many relevant "nuggets" of information about a concept as possible. We describe a multi-strategy approach to answering such questions using a database constructed offline with surface patterns, a Web-based dictionary, and an off-the-shelf document retriever. Results are presented from component-level evaluation and from an end-to-end evaluation of our implemented system at the TREC 2003 Question Answering Track.
C1 MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
RP Hildebrandt, W (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, 32 Vassar St, Cambridge, MA 02139 USA.
CR BRILL E, 2001, P 10 TEST RETR C TRE
   FLEISCHMAN M, 2003, P 41 ANN M ASS COMP
   HERMJAKOB U, 2002, P 11 TEXT RETR C TRE
   KATZ B, 2003, P 12 TEXT RETR C TRE
   LIN J, 2003, P 12 INT C INF KNOWL
   MANN G, 2002, P SEM 02 WORKSH COLI
   MARTIN M, 2001, P 10 TEXT RETR C TRE
   Voorhees E., 2003, P 12 TEXT RETR C TRE
   VOORHEES EM, 2002, P 12 TEXT RETR C TRE
   XU J, 2003, P 12 TEXT RETR C TRE
NR 10
TC 4
Z9 4
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 49
EP 56
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100007
DA 2019-06-15
ER

PT B
AU Bod, R
AF Bod, R
GP ACL
TI An efficient implementation of a new DOP model
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Two apparently opposing DOP models exist in the literature: one which computes the parse tree involving the most frequent subtrees from a treebank and one which computes the parse tree involving the fewest subtrees from a treebank. This paper proposes an integration of the two models which outperforms each of them separately. Together with a PCFG-reduction of DOP we obtain improved accuracy and efficiency on the Wall Street Journal treebank. Our results show an 11% relative reduction in error rate over previous models, and an average processing time of 3.6 seconds per WSJ sentence.
C1 Univ Amsterdam, ILLC, NL-1018 WV Amsterdam, Netherlands.
   Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
CR BLACK E, 1993, STAT DRIVEN COMPUTER
   BLACK E, 1992, P ACL 92 NEW DEL
   Bod R, 2002, J ARTIF INTELL RES, V17, P289, DOI 10.1613/jair.1076
   BOD R, 2000, P COLING 2000 SAARBR
   Bod R, 1998, GRAMMAR EXPERIENCE B
   Bod R, 2003, DATA ORIENTED PARSIN
   BOD R, 1992, P COLING 92 NANT FRA
   BOD R, 1993, P AAAI 93 WASH DC
   BOD R, 2003, IN PRESS NATURAL LAN, V9
   Bod Rens, 2003, PROBABILISTIC LINGUI
   BONNEMA R, 1999, P 12 AMST COLL AMST
   BONNEMA R, 1997, P ACL EACL 97 MADR S
   BRISCOE T, 1992, AAAI WORKSH NOT STAT
   CHAPPELIER J, 2002, P 7 C FORM GRAMM
   Chappelier JC, 2000, LECT NOTES ARTIF INT, V1835, P106
   CHARNIAK E, 1997, P AAAI 97 MENL PARK
   CHARNIAK E, 1996, P AAAI 96 MENL PARK
   CHARNIAK E, 2000, P ANLP NAACL 2000 SE
   CHIANG D, 2000, P ACL 2000 HONG KONG
   COLLINS M, 1997, P ACL 97 MADR SPAIN
   COLLINS M, 2002, P ACL 2002 PHIL PA
   COLLINS M, 2000, P ICML 2000 STANF CA
   COLLINS M, 1996, P ACL 96 SANT CRUZ C
   Collins Michael, 1999, THESIS U PENNSYLVANI
   EISNER J, 1996, P COLING 96 COP DENM
   EISNER J, 1997, P 5 INT WORKSH PARS
   FUJISAKI T, 1989, P 1 INT WORKSH PARS
   GOODMAN J, 1996, P EMP METH NAT LANG
   GOODMAN J, 1998, THESIS HARVARD U MAS
   GOODMAN J, 2002, DATA ORIENTED PARSIN
   Johnson M, 2002, COMPUT LINGUIST, V28, P71, DOI 10.1162/089120102317341783
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   JOHNSON M, 1998, DOP ESTIMATION METHO
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Marcus M., 1993, COMPUTATIONAL LINGUI, V19
   PEREIRA F, 1992, P ACL 92 NEW DEL
   Scha Remko, 1990, COMPUTERTOEPASSINGEN
   SCHABES Y, 1992, P COLING 92 NANT FRA
   SIMAAN K, 1999, THESIS U AMSTERDAM T
   SIMAAN K, 1995, P INT C REC ADV NAT
   SIMAAN K, 2000, P ACL 2000 HONG KONG
   SIMAAN K, 1996, P COLING 96 COP DENM
NR 42
TC 4
Z9 4
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 19
EP 26
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200004
DA 2019-06-15
ER

PT B
AU Brockmann, C
   Lapata, M
AF Brockmann, C
   Lapata, M
GP ACL
TI Evaluating and combining approaches to selectional preference
   acquisition
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Previous work on the induction of selectional preferences has been mainly carried out for English and has concentrated almost exclusively on verbs and their direct objects. In this paper, we focus on class-based models of selectional preferences for German verbs and take into account not only direct objects, but also subjects and prepositional complements. We evaluate model performance against human judgments and show that there is no single method that overall performs best. We explore a variety of parametrizations for our models and demonstrate that model combination enhances agreement with human ratings.
C1 Univ Edinburgh, Sch Informat, Edinburgh EH8 9LW, Midlothian, Scotland.
CR Abney S., 1999, P ACL WORKSH UNS LEA, P1
   Bard EG, 1996, LANGUAGE, V72, P32, DOI 10.2307/416793
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Carroll J, 2000, COMPUT HUMANITIES, V34, P109, DOI 10.1023/A:1002415205081
   CIARAMITA M, 2000, P 18 INT C COMP LING, P187
   Clark S, 2002, COMPUT LINGUIST, V28, P187, DOI 10.1162/089120102760173643
   Cowart W., 1997, EXPT SYNTAX APPL OBJ
   Greiff W., 2002, COGNITIVE SCI, V87, P1
   Hamp B, 1997, P ACL WORKSH AUT INF, P9
   Keller F, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P230
   KELLER F, 1998, HCRCTR99 U ED HUM CO
   LAPATA M, 2001, P 39 ANN M ASS COMP, P346
   Lapata M., 1999, P 9 C EUR CHAPT ASS, P30
   Li H, 1998, COMPUT LINGUIST, V24, P217
   MCCARTHY D, 2001, THESIS U SUSSEX UK
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Neumann G., 1997, P 5 C APPL NAT LANG, P209
   Pereira Fernando, 1993, P 31 ANN M ASS COMP, P183, DOI DOI 10.3115/981574.981598
   Resnik P., 1997, P ACL SIGLEX WORKSH, P52
   RESNIK PS, THESIS U PENNSYLVANI
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Stevens S. S, 1975, PSYCHOPHYSICS INTRO
   WAGNER A, 2000, P ECAI 2000 WORKSH O, P37
   Weiss SM, 1991, COMPUTER SYSTEMS LEA
NR 24
TC 4
Z9 4
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 27
EP 34
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200005
DA 2019-06-15
ER

PT B
AU Curran, JR
   Clark, S
AF Curran, JR
   Clark, S
GP ACL
TI Investigating GIS and smoothing for maximum entropy taggers
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
ID NATURAL-LANGUAGE; MODELS
AB This paper investigates two elements of Maximum Entropy tagging: the use of a correction feature in the Generalised Iterative Scaling (GIS) estimation algorithm, and techniques for model smoothing. We show analytically and empirically that the correction feature, assumed to be required for the correctness of GIS, is unnecessary. We also explore the use of a Gaussian prior and a simple cutoff for smoothing. The experiments are performed with two tagsets: the standard Penn Treebank POS tagset and the larger set of lexical types from Combinatory Categorial Grammar.
C1 Univ Edinburgh, Sch Informat, Edinburgh EH8 9LW, Midlothian, Scotland.
CR BERGER A, 1997, UNPUB IMPROVED ITERA
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Brants T., 2000, P 6 C APPL NAT LANG
   CHEN SF, 1999, GAUSSIAN PRIOR SMOOT
   Clark S, 2002, P 6 INT WORKSH TREE, P19
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   Goodman J., 2002, P 40 ANN M ASS COMP, P9
   HOCKENMAIER J, 2002, P 3 LREC C LAS PALM
   Johnson Mark, 1999, P 37 ANN M ASS COMP, P535
   Koeling R., 2000, P CONLL 2000 LLL 200, P139
   Malouf R., 2002, P 6 C NAT LANG LEARN, P49, DOI DOI 10.3115/1118853.1118871
   NIGAM K, 1999, P IJCAI 99 WORKSH MA, P61
   PIETRA SD, 1997, IEEE T PATTERN ANAL, V19, P380
   Ratnaparkhi A, 1999, MACH LEARN, V34, P151, DOI 10.1023/A:1007502103375
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   Ratnaparkhi Adwait, 1998, THESIS U PENNSYLVANI
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   Steedman M., 2000, SYNTACTIC PROCESS
   TOUTANOVA K, 2000, P EMNLP C HONG KONG
   van Halteren H, 2001, COMPUT LINGUIST, V27, P199, DOI 10.1162/089120101750300508
NR 22
TC 4
Z9 4
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 91
EP 98
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200013
DA 2019-06-15
ER

PT B
AU Rogati, M
   McCarley, S
   Yang, YM
AF Rogati, M
   McCarley, S
   Yang, YM
GP ACL
TI Unsupervised learning of arabic stemming using a parallel corpus
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper presents an unsupervised learning approach to building a non-English (Arabic) sternmer. The stemming model is based on statistical machine translation and it uses an English sternmer and a small (10K sentences) parallel corpus as its sole training resources. No parallel text is needed after the training phase. Monolingual, unannotated text can be used to further improve the sternmer by allowing it to adapt to a desired domain or genre. Examples and results will be given for Arabic, but the approach is applicable to any language that needs affix removal. Our resource-frugal approach results in 87.5% agreement with a state of the art, proprietary Arabic sternmer built using rules, affix lists, and human annotated text, in addition to an unsupervised component. Task-based evaluation using Arabic information retrieval indicates an improvement of 22-38% in average precision over unstemmed text, and 96% of the performance of the proprietary stemmer above.
C1 Carnegie Mellon Univ, Dept Comp Sci, Pittsburgh, PA 15213 USA.
CR Brown P., 1993, COMPUTATIONAL LINGUI, P263
   BUCKWALTER T, 1999, BUCKWALTER TRANSLITE
   Clark A, 2001, ACL, P55
   DIAB M, 2002, P 40 ANN M ASS COMP, P255
   GOLDSMITH J, 2001, COMPUTATIONAL LINGUI
   Larkey, SIGIR 2002, P275
   LEE YS, IN PRESS ACL
   SCHONE M, 2000, THESIS WASHINGTON U
   YAROWSKY D, 2000, INDUCING MULTILINGUA
NR 9
TC 4
Z9 4
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 391
EP 398
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500050
DA 2019-06-15
ER

PT B
AU Strube, M
   Muller, C
AF Strube, M
   Muller, C
GP ACL
TI A machine learning approach to pronoun resolution in spoken dialogue
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We apply a decision tree based approach to pronoun resolution in spoken dialogue. Our system deals with pronouns with NP and non-NP-antecedents. We present a set of features designed for pronoun resolution in spoken dialogue and determine the most promising features. We evaluate the system on twenty Switchboard dialogues and show that it compares well to Byron's (2002) manually tuned system.
C1 European Media Lab GmbH, D-69118 Heidelberg, Germany.
CR Allen J., 1998, NEW APPROACHES DISCO, P68
   Asher Nicholas, 1993, REFERENCE ABSTRACT O
   BIMAN L, 1984, CLASSIFICATION REGRE
   Briscoe Ted, 1997, P 5 ACL C APPL NAT L, P356
   Byron D. K., 2002, P 40 ANN M ASS COMP, P80
   Dagan I., 1991, Artificial Intelligence and Computer Vision. Proceedings of the Seventh Israeli Conference, P125
   Eckert M., 2000, J SEMANT, V17, P51, DOI DOI 10.1093/JOS/17.1.51
   Ihaka R., 1996, J COMPUTATIONAL GRAP, V5, P299, DOI DOI 10.1080/10618600.1996.10474713
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Muller Christoph, 2002, P 40 ANN M ASS COMP, P352
   Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102
   PAUL M, 1999, P ACL WORKSH C ITS A, P47
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Strube M, 2002, P 2002 C EMP METH NA, P312, DOI DOI 10.3115/1118693.1118733
   Tetreault JR, 2001, COMPUT LINGUIST, V27, P507, DOI 10.1162/089120101753342644
   Therneau T.M., 1997, INTRO RECURSIVE PART
   Vilain M., 1995, P 6 MESS UND C MUC 6, P45, DOI DOI 10.3115/1072399.1072405
   WEBBER BL, 1991, LANG COGNITIVE PROC, V6, P107, DOI 10.1080/01690969108406940
NR 18
TC 4
Z9 4
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 168
EP 175
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500022
DA 2019-06-15
ER

PT B
AU Ueffing, N
   Ney, H
AF Ueffing, N
   Ney, H
GP ACL
TI Using POS information for statistical machine translation into
   morphologically rich languages
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB When translating from languages with hardly any inflectional morphology like English into morphologically rich languages, the English word forms often do not contain enough information for producing the correct fullform in the target language. We investigate methods for improving the quality of such translations by making use of part-of-speech information and maximum entropy modeling. Results for translations from English into Spanish and Catalan are presented on the LC-STAR corpus which consists of spontaneously spoken dialogues in the domain of appointment scheduling and travel planning.
C1 Univ Technol, Rhein Westfal TH Aachen, Dept Comp Sci, Lehrstuhl Informat 6, Aachen, Germany.
CR Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BROWN P, 1992, P 4 INT C THEOR METH, P83
   Brown P. F., 1993, Computational Linguistics, V19, P263
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   GARCIAVAREA I, 2001, P 39 ANN M ASS COMP, P204
   GERMANN U, 2001, P 39 ANN M ASS COMP, P228
   Ney H., 1999, P JOINT SIGDAT C EMP, P20
   Niessen S, 2000, P 2 INT C LANG RES E, P39
   NIESSEN S, 2001, 39 ANN M ASS COMP LI, P47
   NIESSEN S, 2001, P MT SUMMIT, V8, P247
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   RATNAPARKHI A, 1997, 9708 U PENN I RES CO
   TILLMANN C, 2002, I PRESS COMPUTATIONA
   Toutanova K, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P87
   VOGEL S, 2000, VERBMOBIL FDN SPEECH, P377
   Wang Y., 1997, P 35 ANN C ASS COMP, P366
NR 17
TC 4
Z9 4
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 347
EP 354
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200045
DA 2019-06-15
ER

PT S
AU Hadano, M
   Shimada, K
   Endo, T
AF Hadano, Masashi
   Shimada, Kazutaka
   Endo, Tsutomu
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Aspect identification of sentiment sentences using a clustering
   algorithm
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Sentiment analysis; Aspect identification; Clustering
AB Reviews contain aspect information of a product, such as "image quality" and "usability" of a camera. In this paper, we propose an aspect identification method for sentiment sentences in review documents. Machine learning methods usually require a large amount of training data for generating a classifier with high accuracy. However, preparing training data by hand is costly. To solve this problem, we apply a clustering approach to the aspect identification method. Our system acquires new training data from non-tagged data by using the clustering approach. As compared with a baseline method, which does not use the acquisition approach, our method obtained high accuracy. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Hadano, Masashi; Shimada, Kazutaka; Endo, Tsutomu] Kyushu Inst Technol, Dept Artificial Intelligence, Iizuka, Fukuoka 8208502, Japan.
EM shimada@pluto.ai.kyutech.ac.jp
CR Blair-Goldensohn S., 2008, WWW WORKSH NLP INF E
   Kobayashi N., 2007, P 2007 JOINT C EMP M, P1065
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79
   Quinlan J. R, 1993, C4 5 PROGRAMS MACHIN
   Settles B., 2009, 1648 U WISC MAD
   Tadano R., 2009, P 11 C PAC ASS COMP, P211
   Tadano R, 2010, P 24 PAC AS C LANG I
   Titov I., 2008, P ANN M ASS COMP LIN, V8, P308
   Turney Peter, 2002, P 40 ANN M ASS COMP, P417, DOI DOI 10.3115/1073083.1073153
   Vapnik V., 1999, STAT LEARNING THEORY
NR 10
TC 3
Z9 3
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 22
EP 31
DI 10.1016/j.sbspro.2011.10.579
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700003
OA Other Gold
DA 2019-06-15
ER

PT S
AU Ota, S
   Mima, H
AF Ota, Susumu
   Mima, Hideki
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Machine Learning-based Syllabus Classification toward Automatic
   Organization of Issue-oriented Interdisciplinary Curricula
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Education; Machine Learning; Classification; Automatic Term Recognition
AB The purpose of this study is to organize issue-oriented interdisciplinary curricula, in which natural language processing, and machine learning-based automatic classification are combined. The recent explosion in scientific knowledge due to the rapid advancement of academia and society makes it difficult for learners and educators to recognize the overall picture of syllabus. In addition, the growing amount of interdisciplinary research makes it harder for learners to find subjects that suit their needs from the syllabi. In an attempt to present clear directions to suitable subjects, issue-oriented interdisciplinary curricula are expected to be more efficient in learning and education. However, these curricula normally require all the syllabi be manually categorized in advance, which is generally time consuming. Thus, this emphasizes the importance of developing efficient methods for (semi-) automatic syllabus classification in order to accelerate syllabus retrieval. In this paper, we introduce design and implementation of an issue-oriented automatic syllabus classification. Preliminary experiments using more than 850 engineering syllabi of the University of Tokyo show that our proposed syllabus classification system obtains sufficient accuracy. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Ota, Susumu; Mima, Hideki] Univ Tokyo, Sch Engn, Bunkyo Ku, Tokyo 1138656, Japan.
EM ota@t-adm.t.u-tokyo.ac.jp
CR CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Isbell C., 1998, ADV NEURAL INFORM PR, V11
   Kudoh Taku, TINYSVM
   Mima H, 2006, P 7 APRU DIST LEARN
   Mima H., 2000, INT J TERMINOLOGY, V6, P175
   Moschitti A., 2004, P 26 EUR C INF RETR
   SALTON G, 1991, SCIENCE, V253, P974, DOI 10.1126/science.253.5023.974
   Taira H, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P480
   Vapnik VN, 1995, NATURE STAT LEARNING
   Yoshida M., 2007, P 8 APRU DIST LEARN
NR 10
TC 3
Z9 3
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 241
EP 247
DI 10.1016/j.sbspro.2011.10.604
PG 7
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700028
OA Other Gold
DA 2019-06-15
ER

PT S
AU Belz, A
   Kow, E
AF Belz, Anja
   Kow, Eric
BE Krahmer, E
   Theune, M
TI Assessing the Trade-Off between System Building Cost and Output Quality
   in Data-to-Text Generation
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
AB Data-to-text generation systems tend to be knowledge-based and manually built, which limits their reusability and makes them time and cost-intensive to create and maintain. Methods for automating (part of) the system building process exist, but do such methods risk a loss in output quality? In this paper, we investigate the cost/quality trade-off in generation system building. We compare six data-to-text systems which were created by predominantly automatic techniques against six systems for the same domain which were created by predominantly manual techniques. We evaluate the systems using intrinsic automatic metrics and human quality ratings. We find that there is some correlation between degree of automation in the system-building process and output quality (more automation tending to mean lower evaluation scores). We also find that there are discrepancies between the results of the automatic evaluation metrics and the human-assessed evaluation experiments. We discuss caveats in assessing system-building cost and implications of the discrepancies in automatic and human evaluation.
C1 [Belz, Anja; Kow, Eric] Univ Brighton, Nat Language Technol Grp, Sch Comp Math & Informat Sci, Brighton BN2 3PB, E Sussex, England.
RP Belz, A (reprint author), Univ Brighton, Nat Language Technol Grp, Sch Comp Math & Informat Sci, Brighton BN2 3PB, E Sussex, England.
CR Belz Anja, 2008, Natural Language Engineering, P431, DOI 10.1017/S1351324907004664
   BELZ A, 2010, LNCS LNAI, V5790, P294
   Belz A., 2006, P 11 C EUR CHAPT ASS, P313
   Belz A., 2009, NLTG0901 CMIS U BRIG
   BELZ A, 2009, P 12 EUR WORKSH NAT
   Belz A, 2009, COMPUT LINGUIST, V35, P111, DOI 10.1162/coli.2009.35.1.111
   Bertoldi N., 2009, PRAGUE B MATH LINGUI, V91, P7
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Callison-Burch Chris, 2006, P EACL 2006
   Chiang D., 2006, INTRO SYNCHRONOUS GR
   Doddington George, 2002, P ARPA WORKSH HUM LA
   GATT A, 2010, LNCS LNAI, V5790, P264
   KNIGHT K, 1998, P 36 ANN M ASS COMP, P704
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koehn Philipp, 2003, P 2003 C N AM CHAPT, P48, DOI DOI 10.3115/1073445.1073462
   Langkilde I, 2000, P 6 APPL NAT LANG PR, P170
   Maxwell John T., 2005, P ACL WORKSH INTR EX, P57
   OCH F, 2003, P 41 ANN M ASS COMP, V1, P167
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Papineni K., 2001, BLEU METHOD AUTOMATI
   PARMENTIER Y, 2005, P 17 EUR SUMM SCH LO
   Reidsma D., 2008, P COLING 08 WORKSH H, P8
   Reiter E, 2005, ARTIF INTELL, V167, P137, DOI 10.1016/j.artint.2005.06.006
   Reiter E., 1997, Natural Language Engineering, P57, DOI 10.1017/S1351324997001502
   REITER E, 2009, COMPUTATIONAL LINGUI, V35
   Sripada S., 2002, AUCSTR0201 U AB COMP
   Wong Y. W., 2007, P HUM LANG TECHN C N, P172
   Wong Y. W., 2006, P HUM LANG TECHN C N, P439
NR 28
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 180
EP 200
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600010
DA 2019-06-15
ER

PT S
AU Buschmeier, H
   Bergmann, K
   Kopp, S
AF Buschmeier, Hendrik
   Bergmann, Kirsten
   Kopp, Stefan
BE Krahmer, E
   Theune, M
TI Modelling and Evaluation of Lexical and Syntactic Alignment with a
   Priming-Based Microplanner
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
DE interactive alignment model; lexical and syntactic alignment;
   adaptation; microplanning
AB Alignment of interlocutors is a well known psycholinguistic phenomenon of great relevance for dialogue systems in general and natural language generation in particular. In this chapter, we present the alignment-capable microplanner SPUD prime. Using a priming-based model of interactive alignment, it is flexible enough to model the alignment behaviour of human speakers to a high degree. We demonstrate that SPUD prime can account for lexical as well as syntactic alignment and present an evaluation on corpora of task-oriented dialogue that were collected in two experiments designed to investigate the alignment behaviour of humans in a controlled fashion. This will allow for further investigation of which parameters are important to model alignment and how the human-computer interaction changes when the computer aligns to its users.
C1 [Buschmeier, Hendrik; Bergmann, Kirsten; Kopp, Stefan] Univ Bielefeld, CITEC, Sociable Agents Grp, D-33501 Bielefeld, Germany.
RP Buschmeier, H (reprint author), Univ Bielefeld, CITEC, Sociable Agents Grp, POB 10 01 31, D-33501 Bielefeld, Germany.
EM hbuschme@TechFak.Uni-Bielefeld.DE; kbergman@TechFak.Uni-Bielefeld.DE;
   skopp@TechFak.Uni-Bielefeld.DE
OI Buschmeier, Hendrik/0000-0002-9613-5713
CR BATEMAN JA, 2006, PEOPLE TALK COMPUTER, P157
   Bergmann K., 2009, P 9 INT C INT VIRT A, P76
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6
   BOCK JK, 2000, J EXPT PSYCHOL GEN, V129, P177, DOI DOI 10.1037/0096-3445.129.2.177
   Branigan HP, 1999, PSYCHON B REV, V6, P635, DOI 10.3758/BF03212972
   BRANIGAN HP, J PRAGMATIC IN PRESS
   Brennan S. E., 1991, User Modeling and User-Adapted Interaction, V1, P67, DOI 10.1007/BF00158952
   Brennan SE, 1996, J EXP PSYCHOL LEARN, V22, P1482, DOI 10.1037//0278-7393.22.6.1482
   Brockmann C., 2005, P WORKSH AD INT STYL
   Clark Herbert H., 1996, USING LANGUAGE
   DALE R, 2010, LNCS LNAI, V5790, P163
   De Jong M, 2008, P 7 INT C AUT AG MUL, P207
   Gill AJ, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P464
   Isard A., 2006, P NAT LANG GEN 4 INT, P25
   JANARTHANAM S, 2010, LNCS LNAI, V5790, P67
   KOPP S, SPEECH COMMUNI UNPUB
   LEVELT WJM, 1982, COGNITIVE PSYCHOL, V14, P78, DOI 10.1016/0010-0285(82)90005-6
   Pickering MJ, 2004, BEHAV BRAIN SCI, V27, P169
   PICKERING MJ, 2003, P 9 ANN C ARCH MECH, P126
   Purver Matthew, 2006, RES LANGUAGE COMPUTA, V4, P289, DOI DOI 10.1007/S11168006-9007X
   Reitter David, 2008, THESIS U EDINBURGH
   Stone M, 2003, COMPUT INTELL-US, V19, P311
   Stone Matthew, 2002, P ACL 2002 WORKSH EF, P77
   WEISS P, 2009, P C EMB SIT LANG PRO, P16
   WEISS P, 2008, P 8 ANN C COGN SCI S, P4
NR 25
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 85
EP 104
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600005
DA 2019-06-15
ER

PT B
AU de Marneffe, MC
   Manning, CD
   Potts, C
AF de Marneffe, Marie-Catherine
   Manning, Christopher D.
   Potts, Christopher
GP Assoc Computat Linguist
TI "Was it good? It was provocative." Learning the meaning of scalar
   adjectives
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID SEMANTICS
AB Texts and dialogues often express information indirectly. For instance, speakers' answers to yes/no questions do not always straightforwardly convey a 'yes' or 'no' answer. The intended reply is clear in some cases (Was it good? It was great!) but uncertain in others (Was it acceptable? It was unprecedented.). In this paper, we present methods for interpreting the answers to questions like these which involve scalar modifiers. We show how to ground scalar modifier meaning based on data collected from the Web. We learn scales between modifiers and infer the extent to which a given answer conveys 'yes' or 'no'. To evaluate the methods, we collected examples of question-answer pairs involving scalar modifiers from CNN transcripts and the Dialog Act corpus and use response distributions from Mechanical Turk workers to assess the degree to which each answer conveys 'yes' or 'no'. Our experimental results closely match the Turkers' response data, demonstrating that meanings can be learned from Web data and that such meanings can drive pragmatic inference.
C1 [de Marneffe, Marie-Catherine; Manning, Christopher D.; Potts, Christopher] Stanford Univ, Dept Linguist, Stanford, CA 94305 USA.
RP de Marneffe, MC (reprint author), Stanford Univ, Dept Linguist, Stanford, CA 94305 USA.
EM mcdm@stanford.edu; manning@stanford.edu; cgpotts@stanford.edu
CR ALLEN JF, 1980, ARTIF INTELL, V15, P143, DOI 10.1016/0004-3702(80)90042-9
   Asher Nicholas, 2003, LOGICS CONVERSATION
   Blair-Goldensohn S., 2008, WWW WORKSH NLP INF E
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Chevalier JA, 2006, J MARKETING RES, V43, P345, DOI 10.1509/jmkr.43.3.345
   CLARK HH, 1979, COGNITIVE PSYCHOL, V11, P430, DOI 10.1016/0010-0285(79)90020-3
   de Marneffe M. - C., 2006, P 5 INT C LANG RES E
   de Marneffe Marie-Catherine, 2009, P 10 ANN SIGDIAL M D
   FAUCONNIER G, 1975, LINGUIST INQ, V6, P353
   Green N, 1999, COMPUT LINGUIST, V25, P389
   GREEN N, 1994, P 32 ANN M ASS COMP, P58
   Hockey Beth Ann, 1997, P 5 EUR C SPEECH COM, P2267
   Horn L. R., 1972, THESIS
   Hu N., 2006, P 7 ACM C EL COMM, P324, DOI DOI 10.1145/1134707.1134743
   JURAFSKY D, 1997, 9702 U COL BOULD I C
   KAMP H, 1995, COGNITION, V57, P129, DOI 10.1016/0010-0277(94)00659-9
   Kennedy C, 2005, LANGUAGE, V81, P345, DOI 10.1353/lan.2005.0071
   Kennedy C, 2007, LINGUIST PHILOS, V30, P1, DOI 10.1007/s10988-006-9008-0
   Klein D., 2003, P 41 M ASS COMP LING
   Levinson S. C., 2000, PRESUMPTIVE MEANINGS
   Mohammad Saif, 2008, P C EMP METH NAT LAN
   Munro Robert, 2010, NAACL 2010 WORKSH CR
   Ng A., 2008, P C EMP METH NAT LAN
   PERRAULT CR, 1980, AM J COMPUTATIONAL L, V6, P167
   Sheng Victor S., 2008, P KDD 2008
   Zeevat Henk, 1994, P INT WORKSH COMP SE, P211
NR 26
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 167
EP 176
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300018
DA 2019-06-15
ER

PT B
AU Garoufi, K
   Koller, A
AF Garoufi, Konstantina
   Koller, Alexander
GP Assoc Computat Linguist
TI Automated planning for situated natural language generation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID SYSTEM
AB We present a natural language generation approach which models, exploits, and manipulates the non-linguistic context in situated communication, using techniques from AI planning. We show how to generate instructions which deliberately guide the hearer to a location that is convenient for the generation of simple referring expressions, and how to generate referring expressions with context-dependent adjectives. We implement and evaluate our approach in the framework of the Challenge on Generating Instructions in Virtual Environments, finding that it performs well even under the constraints of realtime generation.
C1 [Garoufi, Konstantina; Koller, Alexander] Univ Saarland, Cluster Excellence Multimodal Comp & Interact, Saarbrucken, Germany.
RP Garoufi, K (reprint author), Univ Saarland, Cluster Excellence Multimodal Comp & Interact, Saarbrucken, Germany.
EM garoufi@mmci.uni-saarland.de; koller@mmci.uni-saarland.de
CR Appelt D. E, 1985, PLANNING ENGLISH SEN
   ARECES C, 2008, P 5 INT NAT LANG GEN, P42, DOI 10.3115/1708322.1708332
   Benotti Luciana, 2009, P 2009 SIGDIAL C DIS, P196
   Brenner M., 2008, P 12 WORKSH SEM PRAG
   Chen David, 2009, 1 GIVE CHALLENGE SYS
   DALE R, 1995, COGNITIVE SCI, V19, P233
   Dornhege C., 2009, P INT C AUT PLANN SC, P114
   Hoffmann J, 2001, J ARTIF INTELL RES, V14, P253, DOI 10.1613/jair.855
   HOFFMANN J, 2002, P 15 EUR C ART INT L
   Joshi Aravind K., 1997, HDB FORMAL LANGUAGES, V3, P69, DOI DOI 10.1007/978-3-642-59126-6_2
   KAMP H, 1995, COGNITION, V57, P129, DOI 10.1016/0010-0277(94)00659-9
   Koller A., 2010, EMPIRICAL METHODS NA, V5790, P337
   Koller A., 2010, P 20 INT C AUT PLANN
   Koller A., 2010, P 14 WORKSH SEM PRAG
   Koller Alexander, 2007, P 45 ANN M ASS COMP
   Krahmer E, 2003, COMPUT LINGUIST, V29, P53, DOI 10.1162/089120103321337430
   KRAHMER E, 2002, INFORM SHARING REFER, P223
   MITCHELL M., 2009, P 12 EUR WORKSH NAT, P50
   Nau Dana, 2004, AUTOMATED PLANNING T
   PERRAULT CR, 1980, AM J COMPUTATIONAL L, V6, P167
   Portner P., 2007, NAT LANG SEMANT, V15, P351, DOI [10.1007/s11050-007-9022-y, DOI 10.1007/S11050-007-9022-Y]
   Shaw J., 1999, P 37 ANN M ASS COMP, P135
   Steedman M., 2007, P 8 SIGDIAL WORKSH D, P265
   Stoia Laura, 2008, P 6 INT C LANG RES E
   Stoia Laura, 2006, NAACL 06, P157
   Stone M, 2003, COMPUT INTELL-US, V19, P311
   van Deemter Kees, 2006, COMPUTATIONAL LINGUI, V32
NR 27
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1573
EP 1582
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300159
DA 2019-06-15
ER

PT B
AU Hall, D
   Klein, D
AF Hall, David
   Klein, Dan
GP Assoc Computat Linguist
TI Finding Cognate Groups using Phylogenies
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB A central problem in historical linguistics is the identification of historically related cognate words. We present a generative phylogenetic model for automatically inducing cognate group structure from unaligned word lists. Our model represents the process of transformation and transmission from ancestor word to daughter word, as well as the alignment between the words lists of the observed languages. We also present a novel method for simplifying complex weighted automata created during inference to counteract the otherwise exponential growth of message sizes. On the task of identifying cognates in a dataset of Romance words, our model significantly outperforms a baseline approach, increasing accuracy by as much as 80%. Finally, we demonstrate that our automatically induced groups can be used to successfully reconstruct ancestral words.
C1 [Hall, David; Klein, Dan] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
RP Hall, D (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
EM dlwh@cs.berkeley.edu; klein@cs.berkeley.edu
CR Bloomfield Leonard, 1938, LANGUAGE
   Bouchard-Cote Alexandre, 2007, EMNLP
   Bouchard-Cote Alexandre, 2009, NAACL09, P65
   Daume III H, 2007, C ASS COMP LING ACL
   Daume III Hal, 2009, NAACL
   Dreyer Markus, 2009, EMNLP
   Eisner Jason, 2002, ACL
   Eisner Jason, 2001, FSMNLP
   Kondrak Grzegorz, 2003, NAACL
   Kondrak Grzegorz, 2001, NAACL
   Kuhn H. W., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109
   Li Zhifei, 2009, EMNLP
   Lowe J. B., 1994, Computational Linguistics, V20, P381
   Mann G. S., 2001, NAACL 01, P1
   Minka T.P., 2001, UNCERTAINTY ARTIFICI, V17, P362
   Mohri M, 2009, MONOGR THEOR COMPUT, P213, DOI 10.1007/978-3-642-01492-5_6
   Mohri Mehryar, 1996, ECAI 96 WORKSH
   Mulloni A, 2007, P 45 ANN M ACL STUD, P25
   Nerbonne John, 2010, PHILOS T ROYAL SOC B
   Oakes MP, 2000, J QUANT LINGUIST, V7, P233
   OED, 1989, OXF ENGL DICT ONL
   Ohala J., 1993, HIST LINGUISTICS PRO, P237
   Oncina Jose, 2006, PATTERN RECOGNITION, V39
   Ringe D, 2002, T PHILOL SOC, V100, P59, DOI 10.1111/1467-968X.00091
   Ross Alan S. C., 1950, J ROYAL STAT SOC B
   Yarowsky David, 2000, NAACL
NR 26
TC 3
Z9 3
U1 0
U2 3
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1030
EP 1039
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300105
DA 2019-06-15
ER

PT B
AU Janarthanam, S
   Lemon, O
AF Janarthanam, Srinivasan
   Lemon, Oliver
GP Assoc Computat Linguist
TI Learning to Adapt to Unknown Users: Referring Expression Generation in
   Spoken Dialogue Systems
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a data-driven approach to learn user-adaptive referring expression generation (REG) policies for spoken dialogue systems. Referring expressions can be difficult to understand in technical domains where users may not know the technical 'jargon' names of the domain entities. In such cases, dialogue systems must be able to model the user's (lexical) domain knowledge and use appropriate referring expressions. We present a reinforcement learning (RL) framework in which the system learns REG policies which can adapt to unknown users online. Furthermore, unlike supervised learning methods which require a large corpus of expert adaptive behaviour to train on, we show that effective adaptive policies can be learned from a small dialogue corpus of non-adaptive human-machine interaction, by using a RL framework and a statistical user simulation. We show that in comparison to adaptive hand-coded baseline policies, the learned policy performs significantly better, with an 18.6% average increase in adaptation accuracy. The best learned policy also takes less dialogue time (average 1.07 min less) than the best hand-coded policy. This is because the learned policies can adapt online to changing evidence about the user's domain expertise.
C1 [Janarthanam, Srinivasan] Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
   [Lemon, Oliver] Heriot Watt Univ, Interact Lab, Math & Comp Sci MACS, Edinburgh EH14 4AS, Midlothian, Scotland.
RP Janarthanam, S (reprint author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9YL, Midlothian, Scotland.
EM s.janarthanam@ed.ac.uk; o.lemon@hw.ac.uk
CR Ai H., 2007, P INT 2007 ANTW BELG
   Akiba T., 1994, P 15 C COMP LING KYO, V2
   BELL A, 1984, LANG SOC, V13, P145, DOI 10.1017/S004740450001037X
   Cawsey A., 1993, User Modeling and User-Adapted Interaction, V3, P221, DOI 10.1007/BF01257890
   Clark H. H., 1982, LANGUAGE COMPREHENSI
   Cuayahuitl H., 2009, THESIS
   DALE R, 1989, P ACL 1989
   Georgila K., 2005, P EUR INT
   Hernandez F., 2003, LNCS, V2702/ 2003
   ISAACS EA, 1987, J EXP PSYCHOL GEN, V116, P26, DOI 10.1037/0096-3445.116.1.26
   Janarthanam S., 2009, P SIGDIAL 09
   Janarthanam S., 2009, P ENLG 09
   Lemon Oliver, 2010, COMPUTER SP IN PRESS
   Levin E., 1997, P ASRU97
   MCKEOWN K, 1993, P ACL 1993
   Paris C. L., 1987, THESIS
   Reiter E., 1991, CURRENT RES NATURAL, P257
   Rieser V., 2009, P EACL 09
   Rieser V., 2010, P ACL IN PRESS
   SCHATZMANN J, 2006, KNOWL ENG REV, P97
   SCHATZMANN J, 2007, P HLT NAACL 2007
   Shapiro D., 2002, P ICML 02
   Sutton R. S., 1998, REINFORCEMENT LEARNI
NR 23
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 69
EP 78
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300008
DA 2019-06-15
ER

PT B
AU Jiampojamarn, S
   Kondrak, G
AF Jiampojamarn, Sittichai
   Kondrak, Grzegorz
GP Assoc Computat Linguist
TI Letter-Phoneme Alignment: An Exploration
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Letter-phoneme alignment is usually generated by a straightforward application of the EM algorithm. We explore several alternative alignment methods that employ phonetics, integer programming, and sets of constraints, and propose a novel approach of refining the EM alignment by aggregation of best alignments. We perform both intrinsic and extrinsic evaluation of the assortment of methods. We show that our proposed EM-Aggregation algorithm leads to the improvement of the state of the art in letter-to-phoneme conversion on several different data sets.
C1 [Jiampojamarn, Sittichai; Kondrak, Grzegorz] Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
RP Jiampojamarn, S (reprint author), Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E8, Canada.
EM sj@cs.ualberta.ca; kondrak@cs.ualberta.ca
CR Bisani M, 2008, SPEECH COMMUN, V50, P434, DOI 10.1016/j.specom.2008.01.002
   Black Alan W., 1998, 3 ESCA WORKSH SPEECH, P77
   Daelemans Walter, 2009, ILK RES GROUP TECHNI
   Daelemans Walter, 1997, PROGR SPEECH SYNTHES, P77
   Damper R.I., 2005, J SPEECH TECHNOLOGY, V8, P147
   Demberg Vera, 2007, P 45 ANN M ASS COMP, P96
   Engelbrecht Herman, 2005, INT WORKSH SPOK LANG
   Jiampojamarn  S., 2008, P ACL, P905
   Jiampojamarn S., 2007, HUMAN LANGUAGE TECHN, P372
   Kondrak G, 2000, P 1 N AM CHAPT ASS C, P288
   Li Haizhou, 2009, P JOINT C 47 ANN M A, P136
   Marchand Y, 2000, COMPUT LINGUIST, V26, P195, DOI 10.1162/089120100561674
   Marchand Yannick, 2006, NAT LANG ENG, V13, P1
   Richmond K, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1295
   SCHROETER J, 2002, IEEE 2002 WORKSH SPE
   Sejnowski T. J., 1987, Complex Systems, V1, P145
   Taylor P., 2005, P 9 EUR C SPEECH COM
   Toutanova Kristina, 2001, ACL 02 P 40 ANN M AS, P144
   VANDENBOSCH A, 2006, P 8 M ACL SPEC INT G, P41
   Zens R, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P257
NR 20
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 780
EP 788
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300080
DA 2019-06-15
ER

PT S
AU Koller, A
   Striegnitz, K
   Byron, D
   Cassell, J
   Dale, R
   Moore, J
   Oberlander, J
AF Koller, Alexander
   Striegnitz, Kristina
   Byron, Donna
   Cassell, Justine
   Dale, Robert
   Moore, Johanna
   Oberlander, Jon
BE Krahmer, E
   Theune, M
TI The First Challenge on Generating Instructions in Virtual Environments
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
AB This paper describes the First Challenge on Generating Instructions in Virtual Environments (GIVE-1). GIVE is a shared task for generation systems which give real-time natural-language instructions to users in a virtual 3D world. These systems are evaluated by connecting users and NLG systems over the Internet. We describe the design and results of GIVE-1 as well as the participating NLG systems, and validate the experimental methodology by comparing the results collected over the Internet with results from a more traditional laboratory-based experiment.
C1 [Koller, Alexander] Univ Saarland, D-6600 Saarbrucken, Germany.
   [Striegnitz, Kristina] Union Coll, Schenectady, NY USA.
   [Byron, Donna] Northeastern Univ, Boston, MA USA.
   [Cassell, Justine] Northwestern Univ, Evanston, IL USA.
   [Dale, Robert] Macquarie Univ, N Ryde, NSW 2109, Australia.
   [Moore, Johanna; Oberlander, Jon] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
RP Koller, A (reprint author), Univ Saarland, D-6600 Saarbrucken, Germany.
RI Cassell, Justine/B-7123-2009
OI Dale, Robert/0000-0001-7864-6942
FU University of Edinburgh and by the Cluster of Excellence; Multimodal
   Computing and Interaction" at Saarland University
FX The creation of the GIVE infrastructure was supported in part by a Small
   Projects grant from the University of Edinburgh and by the Cluster of
   Excellence Multimodal Computing and Interaction at Saarland University.
CR Bangalore Srinivas, 2000, P 1 INT C NAT LANG G, P1
   BELZ A, 2008, P 46 ANN M ASS COMP, P197
   BELZ A, 2006, P EACL 2006 TRENT IT, P249
   Belz A, 2010, LECT NOTES ARTIF INT, V5790, P180, DOI 10.1007/978-3-642-15573-4_10
   Belz A, 2010, LECT NOTES ARTIF INT, V5790, P294, DOI 10.1007/978-3-642-15573-4_15
   Belz A, 2009, COMPUT LINGUIST, V35, P111, DOI 10.1162/coli.2009.35.1.111
   Cahill A, 2010, LECT NOTES ARTIF INT, V5790, P201, DOI 10.1007/978-3-642-15573-4_11
   CALLISONBURCH C, 2006, P 11 C EUR CHAPT ASS, P249
   CHAMBERLAIN J, 2008, P S SEM TEXT PROC ST, P375
   CHEN D, 2009, P 1 NLG CHALL GEN IN
   DALE R, 1995, COGNITIVE SCI, V19, P233
   DALE R, 2007, P NSF SIGGEN WORKSH
   DIONNE D, 2009, P 1 NLG CHALL GEN IN
   FOSTER ME, 2008, P 5 INT NAT LANG GEN, P95
   GATT A, 2009, P 12 EUR WORKSH NAT, P174
   Gatt A, 2010, LECT NOTES ARTIF INT, V5790, P264, DOI 10.1007/978-3-642-15573-4_14
   Hsu C. W., 2006, P 5 INT PLANN COMP 1, P39
   Keller F, 2009, BEHAV RES METHODS, V41, P1, DOI 10.3758/BRM.41.1.12
   KOLLER A, 2008, P SPARK 2008 ICAPS 2
   Moffat SD, 1998, EVOL HUM BEHAV, V19, P73, DOI 10.1016/S1090-5138(97)00104-9
   Orkin J., 2007, J GAME DEV, V3, P39
   ROOKHUISZEN RB, 2009, P 1 NLG CHALL GEN IN
   Stent A, 2005, LECT NOTES COMPUT SC, V3406, P341
   STOIA L, 2006, P 4 INT NAT LANG GEN
   STRIEGNITZ K, 2009, P 1 NLG CHALL GEN IN
   VONAHN L, 2004, P ACM CHI C
   WALKER M, 2002, ICSLP 2002, V1, P273
   Walker M., 1997, P 35 ANN M ASS COMP, DOI [10.3115/976909.979652, DOI 10.3115/976909.979652]
NR 28
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 328
EP +
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600016
DA 2019-06-15
ER

PT B
AU Laskowski, K
AF Laskowski, Kornel
GP Assoc Computat Linguist
TI Modeling Norms of Turn-Taking in Multi-Party Conversation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID UNITS
AB Substantial research effort has been invested in recent decades into the computational study and automatic processing of multi-party conversation. While most aspects of conversational speech have benefited from a wide availability of analytic, computationally tractable techniques, only qualitative assessments are available for characterizing multi-party turn-taking. The current paper attempts to address this deficiency by first proposing a framework for computing turn-taking model perplexity, and then by evaluating several multi-participant modeling approaches. Experiments show that direct multi-participant models do not generalize to held out data, and likely never will, for practical reasons. In contrast, the Extended-Degree-of-Overlap model represents a suitable candidate for future work in this area, and is shown to successfully predict the distribution of speech in time and across participants in previously unseen conversations.
C1 [Laskowski, Kornel] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
RP Laskowski, K (reprint author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
EM kornel@cs.cmu.edu
CR BRADY PT, 1969, AT&T TECH J, V48, P2445, DOI 10.1002/j.1538-7305.1969.tb01181.x
   DABBS JM, 1987, ADV EXP SOC PSYCHOL, V20, P123, DOI 10.1016/S0065-2601(08)60413-X
   EDELSKY C, 1981, LANG SOC, V10, P383, DOI 10.1017/S004740450000885X
   Fay N, 2000, PSYCHOL SCI, V11, P481, DOI 10.1111/1467-9280.00292
   Goodwin C, 1981, CONVERSATIONAL ORG I
   Grothendieck J, 2009, INT CONF ACOUST SPEE, P4745, DOI 10.1109/ICASSP.2009.4960691
   Jaffe J., 1970, RHYTHMS OF DIALOGUE
   Janin A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P364
   Jelinek F., 1999, STAT METHODS SPEECH
   Koiso H, 1998, LANG SPEECH, V41, P295, DOI 10.1177/002383099804100404
   Laskowski K., 2007, P INTERSPEECH, P1258
   Laskowski K, 2006, INT CONF ACOUST SPEE, P993
   Laskowski Kornel, 2007, LNCS, V4892, P259
   Levinson Stephen C., 1983, PRAGMATICS
   National Institute of Standards and Technology, 2002, RICH TRANSCR EV PROJ
   Norwine AC, 1938, BELL SYST TECH J, V17, P281, DOI 10.1002/j.1538-7305.1938.tb00432.x
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Raux A., 2008, THESIS
   SACKS H, 1974, LANGUAGE, V50, P696, DOI 10.2307/412243
   Schegloff EA, 2007, SEQUENCE ORGANIZATION IN INTERACTION: A PRIMER IN CONVERSATION ANALYSIS I, P1, DOI 10.2277/ 0521532795
   Seligman M, 1997, LECT NOTES ARTIF INT, V1236, P100
   Shriberg E., 2001, P EUR, P1359
   Shriberg Elizabeth, 2004, P 5 SIGDIAL WORKSH D, P97
   Traum DR, 1997, LECT NOTES ARTIF INT, V1236, P125
   Wrede B., 2003, P EUR C SPEECH COMM, P2805
   Yngve VH., 1970, 6 REG M CHIC LING SO, P567
NR 26
TC 3
Z9 3
U1 1
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 999
EP 1008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300102
DA 2019-06-15
ER

PT B
AU Li, JH
   Zhou, GD
   Ng, HT
AF Li, Junhui
   Zhou, Guodong
   Ng, Hwee Tou
GP Assoc Computat Linguist
TI Joint Syntactic and Semantic Parsing of Chinese
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID ROLES
AB This paper explores joint syntactic and semantic parsing of Chinese to further improve the performance of both syntactic and semantic parsing, in particular the performance of semantic parsing (in this paper, semantic role labeling). This is done from two levels. Firstly, an integrated parsing approach is proposed to integrate semantic parsing into the syntactic parsing process. Secondly, semantic information generated by semantic parsing is incorporated into the syntactic parsing model to better capture semantic information in syntactic parsing. Evaluation on Chinese TreeBank, Chinese PropBank, and Chinese NomBank shows that our integrated parsing approach outperforms the pipeline parsing approach on n-best parse trees, a natural extension of the widely used pipeline parsing approach on the top-best parse tree. Moreover, it shows that incorporating semantic role-related information into the syntactic parsing model significantly improves the performance of both syntactic parsing and semantic parsing. To our best knowledge, this is the first research on exploring syntactic parsing and semantic role labeling for both verbal and nominal predicates in an integrated way.
C1 [Li, Junhui; Zhou, Guodong] Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
   [Ng, Hwee Tou] Natl Univ Singapore, Dept Comp Sci, Singapore 117417, Singapore.
RP Li, JH (reprint author), Soochow Univ, Sch Comp Sci & Technol, Suzhou 215006, Peoples R China.
EM lijunhui@suda.edu.cn; gdzhou@suda.edu.cn; nght@comp.nus.edu.sg
CR Baker C. F, 1998, P COLING ACL 1998
   Carreras Xavier, 2004, P CONLL 2004
   Charniak E., 2001, P ACL 2001
   Collins M., 1999, THESIS
   Finkel Jenny Rose, 2009, P NAACL 2009
   Hajic Jan, 2009, P CONLL 2009
   Jiang Zheng Ping, 2006, P EMNLP 2006
   Kong Fang, 2009, P EMNLP 2009
   Koomen Peter, 2005, P CONLL 2005
   Li Junhui, 2009, P EMNLP 2009
   Liu Chang, 2007, P ACL 2007
   Marquez Lluis, 2005, P CONLL 2005
   Merlo Paola, 2005, P EMNLP 2005
   Merlo Paola, 2008, P CONLL 2008
   MEYERS A, 2004, P LREC 2004
   Miller Scott, 2000, P ANLP 2000
   Narayanan Srini, 2004, P COLING 2004
   Ng Hwee Tou, 2004, P EMNLP 2004
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Petrov Slav, 2007, P NAACL 2007
   Pradhan S, 2005, MACH LEARN, V60, P11, DOI 10.1007/s10994-005-0912-2
   Ratnaparkhi A, 1999, MACH LEARN, V34, P151, DOI 10.1023/A:1007502103375
   Surdeanu M., 2003, P ACL 2003
   Surdeanu Mihai, 2008, P CONLL 2008
   Sutton Charles, 2005, P CONLL 2005
   Xue N., 2006, P LREC 2006
   Xue N, 2008, COMPUT LINGUIST, V34, P225, DOI 10.1162/coli.2008.34.2.225
   Xue Nianwen, 2003, P 2 SIGHAN WORKSH CH
   Yi Szu-ting, 2005, P CONLL 2005
   Zhang Yue, 2008, P ACL 2008
NR 30
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1108
EP 1117
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300113
DA 2019-06-15
ER

PT S
AU Marsi, E
   Krahmer, E
   Hendrickx, I
   Daelemans, W
AF Marsi, Erwin
   Krahmer, Emiel
   Hendrickx, Iris
   Daelemans, Walter
BE Krahmer, E
   Theune, M
TI On the Limits of Sentence Compression by Deletion
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
AB Data-driven approaches to sentence compression define the task as dropping any subset of words from the input sentence while retaining important information and grammaticality. We show that only 16% of the observed compressed sentences in the domain of subtitling can be accounted for in this way. We argue that this is partly due to the lack of appropriate evaluation material and estimate that a deletion model is in fact compatible with approximately 55% of the observed data. We analyse the remaining cases in which deletion only failed to provide the required level of compression. We conclude that in those cases word order changes and paraphrasing are crucial. We therefore argue for more elaborate sentence compression models which include paraphrasing and word reordering. We report preliminary results of applying a recently proposed more powerful compression model in the context of subtitling for Dutch.
C1 [Marsi, Erwin; Krahmer, Emiel] Tilburg Univ, NL-5000 LE Tilburg, Netherlands.
   [Hendrickx, Iris; Daelemans, Walter] Antwerp Univ, Antwerp, Belgium.
RP Marsi, E (reprint author), Tilburg Univ, NL-5000 LE Tilburg, Netherlands.
EM emarsi@uvt.nl; ekrahmer@uvt.nl; iris.hendrickx@ua.ac.be;
   walter.daelemans@ua.ac.be
RI Daelemans, Walter/N-5785-2014
OI Daelemans, Walter/0000-0002-9832-7890
FU STEVIN program (De Neder-landse Taalunie)
FX This work was conducted within the DAESO project funded by the STEVIN
   program (De Neder-landse Taalunie).
CR BARZILAY R, 2003, P HLT NAACL, P16
   Belz A., 2006, P 11 C EUR CHAPT ASS, P313
   Bouma G, 2001, LANG COMPUT, P45
   Charniak E., 2005, P 43 ANN M ASS COMP, P290
   CLARKE J, 2006, P 21 INT C COMP LING, P377
   Clarke J, 2008, J ARTIF INTELL RES, V31, P399, DOI 10.1613/jair.2433
   COHN T, 2008, P 22 INT C COMP LING, V1, P137
   Cohn T, 2009, J ARTIF INTELL RES, V34, P637, DOI 10.1613/jair.2655
   Corston-Oliver S, 2001, P NAACL WORKSH AUT S, P89
   DAELEMANS W, 2004, P 4 INT C LANG RES E, P1045
   Dolan B., 2004, P 20 INT C COMP LING, DOI [10.3115/1220355.1220406, DOI 10.3115/1220355.1220406]
   EISNER J, 2003, P 41 ANN M ASS COMP, P205
   FILIPPOVA K, 2009, NAACL 2009, P225
   FILIPPOVA K, 2008, EMNLP 2008, P177
   GATT A, 2008, P 5 INT NAT LANG GEN, P50
   IBRAHIM A, 2003, P 2 INT WORKSH PAR S, V16, P57
   INUI K, 1992, P 6 INT WORKSH NAT L, P215
   JING H, 2000, P 1 N AM CHAPT ASS C, P178
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   Le NM, 2003, PACLIC 17: Language, Information and Computation, Proceedings, P290
   Lin CL, 2003, IEEE ASME INT C ADV, P1
   LIN D, 2001, NAT LANG ENG, V7, P343
   MARSI E, 2008, COMPUTATIONAL LINGUI, P69
   MARSI E, 2007, P 6 INT WORKSH TREEB, P85
   Nomoto T., 2009, P 2009 C EMP METH NA, P391
   ORDELMAN R, 2007, ELRA NEWSLETTER, V12, P4
   Vandeghinste V., 2004, P LREC 2004
   VANDEGHINSTE V, 2004, P ACL WORKSH TEXT SU, P89
   Wan S, 2010, LECT NOTES ARTIF INT, V5790, P13, DOI 10.1007/978-3-642-15573-4_2
   Zajic D, 2007, INFORM PROCESS MANAG, V43, P1549, DOI 10.1016/j.ipm.2007.01.016
NR 30
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 45
EP +
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600003
DA 2019-06-15
ER

PT B
AU Rieser, V
   Lemon, O
   Liu, XK
AF Rieser, Verena
   Lemon, Oliver
   Liu, Xingkun
GP Assoc Computat Linguist
TI Optimising Information Presentation for Spoken Dialogue Systems
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a novel approach to Information Presentation (IP) in Spoken Dialogue Systems (SDS) using a data-driven statistical optimisation framework for content planning and attribute selection. First we collect data in a Wizard-of-Oz (WoZ) experiment and use it to build a supervised model of human behaviour. This forms a baseline for measuring the performance of optimised policies, developed from this data using Reinforcement Learning (RL) methods. We show that the optimised policies significantly outperform the baselines in a variety of generation scenarios: while the supervised model is able to attain up to 87.6% of the possible reward on this task, the RL policies are significantly better in 5 out of 6 scenarios, gaining up to 91.5% of the total possible reward. The RL policies perform especially well in more complex scenarios. We are also the first to show that adding predictive " lower level" features (e. g. from the NLG realiser) is important for optimising IP strategies according to user preferences. This provides new insights into the nature of the IP problem for SDS.
C1 [Rieser, Verena] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
   [Lemon, Oliver; Liu, Xingkun] Heriot Watt Univ, Edinburgh, Midlothian, Scotland.
RP Rieser, V (reprint author), Univ Edinburgh, Edinburgh, Midlothian, Scotland.
EM verena.rieser@ed.ac.uk; o.lemon@hw.ac.uk; x.liu@hw.ac.uk
OI Rieser, Verena/0000-0001-6117-4395; Lemon, Oliver/0000-0001-9497-4743
CR Boidin C., 2009, P INT ICSLP SPEC SES
   Chung Grace, 2004, P ANN M ASS COMP LIN
   Clarkson P., 1997, P ESCA EUR
   Cohen W.W., 1995, P 12 INT C MACH LEAR
   Cuayahuitl Heriberto, 2005, P IEEE WORKSH AUT SP
   Demberg Vera, 2006, P EACL
   Eckert W., 1997, P IEEE WORKSH AUT SP
   Gasic M., 2008, P SIGDIAL WORKSH DIS
   Henderson James, 2008, P ACL
   Janarthanam Srini, 2010, P ACL
   Janarthanam Srinivasan, 2009, P SIGDIAL
   Jung S, 2009, COMPUT SPEECH LANG, V23, P479, DOI 10.1016/j.csl.2009.03.002
   KOLLER A, 2008, ICAPS
   LEMON O, 2008, P SEMDIAL
   LEMON O, 2006, IEEE ACL SPOKEN LANG
   Lemon Oliver, 2010, COMPUTER SP IN PRESS
   Liu X., 2009, P 1 INT WORKSH SPOK
   Nakatsu C., 2008, P SIGDIAL WORKSH DIS
   Polifroni J., 2006, P IEEE ACL WORKSH SP
   Polifroni Jseph, 2008, P ACL
   RIESER V, 2009, P EACL
   RIESER V, 2008, P ACL
   Rieser Verena, 2009, TECHNICAL REPORT
   Shapiro Dn, 2002, P 19 INT C MACH LEAR
   STENT A, 2004, ASS COMPUTATIONAL LI
   Sutton R. S., 1998, REINFORCEMENT LEARNI
   van Deemter Kees, 2009, 12 EUR WORKSH NAT LA
   Walker M., 2001, P ANN M ASS COMP LIN
   WALKER MA, 2000, NATURAL LANGUAGE ENG, V6
   Walker M, 2007, J ARTIF INTELL RES, V30, P413, DOI 10.1613/jair.2329
   Whittaker S., 2002, P INT C LANG RES EV
   Winterboer Andi, 2007, P 10 INT C SPOK LANG
   Young SJ, 2007, ICASSP 2007
NR 33
TC 3
Z9 3
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1009
EP 1018
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300103
DA 2019-06-15
ER

PT B
AU Santamaria, C
   Gonzalo, J
   Artiles, J
AF Santamaria, Celina
   Gonzalo, Julio
   Artiles, Javier
GP Assoc Computat Linguist
TI Wikipedia as Sense Inventory to Improve Diversity in Web Search Results
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Is it possible to use sense inventories to improve Web search results diversity for one word queries? To answer this question, we focus on two broad-coverage lexical resources of a different nature: WordNet, as a de-facto standard used in Word Sense Disambiguation experiments; and Wikipedia, as a large coverage, updated encyclopaedic resource which may have a better coverage of relevant senses in Web pages.
   Our results indicate that (i) Wikipedia has a much better coverage of search results, (ii) the distribution of senses in search results can be estimated using the internal graph structure of the Wikipedia and the relative number of visits received by each sense in Wikipedia, and (iii) associating Web pages to Wikipedia senses with simple and efficient algorithms, we can produce modified rankings that cover 70% more Wikipedia senses than the original search engine rankings.
C1 [Santamaria, Celina; Gonzalo, Julio; Artiles, Javier] UNED, C Juan Rosal,16, Madrid 28040, Spain.
RP Santamaria, C (reprint author), UNED, C Juan Rosal,16, Madrid 28040, Spain.
EM celina.santamaria@gmail.com; julio@lsi.uned.es; javart@bec.uned.es
CR Agrawal R., 2009, P WSDM 09
   Anick P., 2003, P 26 ANN INT ACM SIG, P88
   Artiles  J., 2009, 2 WEB PEOPL SEARCH E
   Brants T., 2006, WEB IT 5 GRAM VERSIO
   Carmel D, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P139, DOI 10.1145/1571941.1571967
   Carpineto C., 2009, ACM COMPUTING SURVEY, V41
   Chen Y., 2009, P WWW 09 WEPS 2 WORK
   Clarke, 2008, P SIGIR 08, P659
   Clough P., 2009, P SIGIR 2009
   Daelemans W., 2001, TECHNICAL REPORT
   Gollapudi S., 2009, P 18 INT C WORLD WID, P381, DOI DOI 10.1145/1526709.1526761
   Markovitch S., 2007, P 20 INT JOINT C ART
   Mihalcea R., 2007, P NAACL HLT, V2007
   Miller G., 1990, INT J LEXICOGRAPH, V3
   Miller G. A, 1993, P ARPA WORKSHOP HUM
   Paramita M.L., 2009, DIVERSITY PHOTO RETR
   Ruiz-Casado M., 2005, ADV WEB INTELLIGENCE, V3528, P380
   SANDERSON M, 2000, INFORMATION RETRIEVA, V2, P49
   Sanderson Mark, 2008, P 31 ANN INT ACM SIG, P499
   Santamaria C, 2003, COMPUT LINGUIST, V29, P485, DOI 10.1162/089120103322711613
   Syed Z. S., 2008, P ICWSM 08
NR 21
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1357
EP 1366
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300138
DA 2019-06-15
ER

PT B
AU Seaghdha, DO
AF Seaghdha, Diarmuid O.
GP Assoc Computat Linguist
TI Latent variable models of selectional preference
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID TOPICS
AB This paper describes the application of so-called topic models to selectional preference induction. Three models related to Latent Dirichlet Allocation, a proven method for modelling document-word co-occurrences, are presented and evaluated on datasets of human plausibility judgements. Compared to previously proposed techniques, these models perform very competitively, especially for infrequent predicate-argument combinations where they exceed the quality of Web-scale predictions while using relatively little data.
C1 [Seaghdha, Diarmuid O.] Univ Cambridge, Comp Lab, Cambridge CB2 1TN, England.
RP Seaghdha, DO (reprint author), Univ Cambridge, Comp Lab, Cambridge CB2 1TN, England.
EM do242@cl.cam.ac.uk
CR Bergsma Shane, 2008, P EMNLP 08 HON HI
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boyd-Graber Jordan, 2007, P EMNLP CONLL 07 PRA
   Briscoe Ted, 2006, P ACL 06 INT PRES SE
   Brody Samuel, 2009, P EACL 09 ATH GREEC
   Burnard L., 1995, USERS GUIDE BRIT NAT
   Chang Jonathan, 2009, P NIPS 09 VANC BC
   Clark S, 2002, COMPUT LINGUIST, V28, P187, DOI 10.1162/089120102760173643
   Erk Katrin, 2007, P ACL 07 PRAG CZECH
   Finkel Jenny Rose, 2007, P ACL 07 PRAG CZECH
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Goldwater S, 2009, COGNITION, V112, P21, DOI 10.1016/j.cognition.2009.03.008
   Griffiths TL, 2007, PSYCHOL REV, V114, P211, DOI 10.1037/0033-295X.114.2.211
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   HOLMES VM, 1989, J MEM LANG, V28, P668, DOI 10.1016/0749-596X(89)90003-X
   Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604
   Lin Wei-Hao, 2006, P CONLL 06 NEW YORK
   Mausam Alan Ritter, 2010, P ACL 10 UPPS SWED
   MENG XL, 1992, PSYCHOL BULL, V111, P172, DOI 10.1037/0033-2909.111.1.172
   Pado Sebastian, 2007, P EMNLP CONLL 07 PRA
   Pantel Patrick, 2007, P NAACL HLT 07 ROCH
   Rayner K, 2004, J EXP PSYCHOL LEARN, V30, P1290, DOI 10.1037/0278-7393.30.6.1290
   Reisinger Joseph, 2009, P ACL IJCNLP 09 SING
   Resnik P., 1993, THESIS
   Rooth Mats, 1999, P ACL 99 COLL PARK M
   Teh YW, 2006, J AM STAT ASSOC, V101, P1566, DOI 10.1198/016214506000000302
   Walde Sabine Schulte im, 2008, P ACL 08 HLT COL OH
   Wallach H, 2009, P NIPS 09 VANC BC
   Wallach Hanna, 2006, P ICML 06 PITTSB PA
   WILKS Y, 1978, ARTIF INTELL, V11, P197, DOI 10.1016/0004-3702(78)90001-2
   Yao Limin, 2009, P KDD 09 PAR FRANC
   Zapirain Benat, 2009, P ACL IJCNLP 09 SING
   Zhang Huibin, 2009, P ACL IJCNLP 09 SING
NR 33
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 435
EP 444
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300045
DA 2019-06-15
ER

PT B
AU Snyder, B
   Barzilay, R
   Knight, K
AF Snyder, Benjamin
   Barzilay, Regina
   Knight, Kevin
GP Assoc Computat Linguist
TI A Statistical Model for Lost Language Decipherment
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In this paper we propose a method for the automatic decipherment of lost languages. Given a non-parallel corpus in a known related language, our model produces both alphabetic mappings and translations of words into their corresponding cognates. We employ a non-parametric Bayesian framework to simultaneously capture both low-level character mappings and highlevel morphemic correspondences. This formulation enables us to encode some of the linguistic intuitions that have guided human decipherers. When applied to the ancient Semitic language Ugaritic, the model correctly maps 29 of 30 letters to their Hebrew counterparts, and deduces the correct Hebrew cognate for 60% of the Ugaritic words which have cognates in Hebrew.
C1 [Snyder, Benjamin; Barzilay, Regina] MIT, CSAIL, Cambridge, MA 02139 USA.
   [Knight, Kevin] Univ Southern Calif, ISI, Los Angeles, CA USA.
RP Snyder, B (reprint author), MIT, CSAIL, Cambridge, MA 02139 USA.
EM bsnyder@csail.mit.edu; regina@csail.mit.edu; knight@isi.edu
CR ANTONIAK CE, 1974, ANN STAT, V2, P1152, DOI 10.1214/aos/1176342871
   Bouchard-Cote A., 2007, P 2007 JOINT C EMP M, P887
   Creutz Mathis, 2007, ASS COMPUTING MACHIN, V4, P1, DOI DOI 10.1145/1217098.1217101
   Cunchillos Jesus-Luis, 2002, UGARITIC DATA BANK
   Fung P., 1997, P 5 ANN WORKSH VER L, P192
   Geman S., 1984, IEEE T PATTERN ANAL, VPAMI-12, P609
   Groves Alan, 2006, WESTMINSTER HEBREW B
   Guy Jacques B. M., 1994, J QUANT LINGUIST, V1, P35
   Haghighi A., 2008, ACL, P771
   Hetzron Robert, 1997, SEMITIC LANGUAGES
   Ishwaran H, 2005, ANN STAT, V33, P730, DOI 10.1214/009053604000001147
   Knight Kevin, 1999, ACL WORKSH UNS LEARN
   Knight Kevin, 2006, P JOINT C INT COMM C, P499
   Koehn P., 2002, P ACL WORKSH UNS LEX, P9
   Kondrak G., 2001, P NAACL 2 2 M N AM C, P1
   Kondrak G, 2009, TRAIT AUTOM LANG, V50, P201
   Lete Gregoria del Olo, 2004, HDB ORIENTAL STUDIES
   Lowe J. B., 1994, Computational Linguistics, V20, P381
   Rapp R, 1999, P 37 ANN M ASS COMP, P519, DOI DOI 10.3115/1034678.1034756
   Robinson A, 2002, LOST LANGUAGES ENIGM
   Schniedewind W.M., 2007, PRIMER UGARITIC LANG
   Smith Mark S., 1955, UNTOLD STORIES BIBLE
   Snyder B., 2008, P AAAI 2008, V2, P848
   Sproat R, 2009, WRITING SYSTEMS TRAN
   Watson Wilfred G. E., 1999, HDB UGARITIC STUDIES
   Yarowsky David, 2000, P HLT, P161
NR 26
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1048
EP 1057
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300107
DA 2019-06-15
ER

PT B
AU Sun, J
   Zhang, M
   Tan, CL
AF Sun, Jun
   Zhang, Min
   Tan, Chew Lim
GP Assoc Computat Linguist
TI Exploring Syntactic Structural Features for Sub-Tree Alignment using
   Bilingual Tree Kernels
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We propose Bilingual Tree Kernels (BTKs) to capture the structural similarities across a pair of syntactic translational equivalences and apply BTKs to sub-tree alignment along with some plain features. Our study reveals that the structural features embedded in a bilingual parse tree pair are very effective for sub-tree alignment and the bilingual tree kernels can well capture such features. The experimental results show that our approach achieves a significant improvement on both gold standard tree bank and automatically parsed tree pairs against a heuristic similarity based method. We further apply the sub-tree alignment in machine translation with two methods. It is suggested that the subtree alignment benefits both phrase and syntax based systems by relaxing the constraint of the word alignment.
C1 [Sun, Jun; Zhang, Min] Inst Infocomm Res, Singapore, Singapore.
   [Sun, Jun; Tan, Chew Lim] Natl Univ Singapore, Sch Comp, Singapore 117548, Singapore.
RP Sun, J (reprint author), Inst Infocomm Res, Singapore, Singapore.
EM sunjun@comp.nus.edu.sg; mzhang@i2r.a-star.edu.sg; tancl@comp.nus.edu.sg
CR Burkett David, 2008, P 2008 C EMP METH NA, P877
   Collins Michael, 2001, P NIPS 01
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   GROVES D, 2004, P 20 INT C COMP LING, P1072
   Imamura Kenji, 2001, P 6 NAT LANG PROC PA, P377
   Joachims T, 1999, ADV KERNEL METHODS S
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koehn Philipp, 2003, P 2003 C N AM CHAPT, P48, DOI DOI 10.3115/1073445.1073462
   Moschitti Alessandro, 2004, P ACL 04
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Stolcke A., 2002, P INT C SPOK LANG PR, P901
   Sun Jun, 2009, P ACL, P914
   Tinsley John, 2009, P CICLING 09
   Tinsley John, 2007, P MT SUMM
   Zhang M., 2007, P MT SUMM, VXI, P535
   Zhang M, 2008, ACLHLT, V08, P559
   Zhang M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P825
NR 18
TC 3
Z9 3
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 306
EP 315
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300032
DA 2019-06-15
ER

PT B
AU Thater, S
   Furstenau, H
   Pinkal, M
AF Thater, Stefan
   Fuerstenau, Hagen
   Pinkal, Manfred
GP Assoc Computat Linguist
TI Contextualizing Semantic Representations Using Syntactically Enriched
   Vector Models
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a syntactically enriched vector model that supports the computation of contextualized semantic representations in a quasi compositional fashion. It employs a systematic combination of first- and second-order context vectors. We apply our model to two different tasks and show that (i) it substantially outperforms previous work on a paraphrase ranking task, and (ii) achieves promising results on a word-sense similarity task; to our knowledge, it is the first time that an unsupervised method has been applied to this task.
C1 [Thater, Stefan; Fuerstenau, Hagen; Pinkal, Manfred] Univ Saarland, Dept Computat Linguist, D-66123 Saarbrucken, Germany.
RP Thater, S (reprint author), Univ Saarland, Dept Computat Linguist, D-66123 Saarbrucken, Germany.
EM stth@coli.uni-saarland.de; hagenf@coli.uni-saarland.de;
   pinkal@coli.uni-saarland.de
CR BUCKLEY C, 2000, P 23 ANN INT ACM SIG, P33, DOI DOI 10.1145/345508.345543
   Church K. W., 1990, Computational Linguistics, V16, P22
   Cui W., 2017, P 5 INT C LANG RES E, P565
   Dligach D., 2008, P ACL 08, P29
   Erk Katrin, 2009, P WORKSH GEOM MOD NA
   Erk Katrin, 2008, P 2008 C EMP METH NA
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Kintsch W, 2001, COGNITIVE SCI, V25, P173, DOI 10.1207/s15516709cog2502_1
   Kishida K., 2005, PROPERTY AVERAGE PRE
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   Lin D, 1998, P 36 ANN M ASS COMP, P768, DOI DOI 10.3115/980691.980696
   Lin Dekang, 1993, P 31 ANN M ASS COMP, P112, DOI [10.3115/981574.981590, DOI 10.3115/981574.981590]
   Manning C. D., 2008, INTRO INFORM RETRIEV
   McCarthy D, 2003, COMPUT LINGUIST, V29, P639, DOI 10.1162/089120103322753365
   McCarthy Diana, 2007, P SEMEVAL PRAG CZECH
   McCarthy Diana, 2009, P 2009 C EMP METH NA, P440
   Mitchell J., 2008, P ACL COL OH, P236
   Montague R., 1973, APPROACHES NATURAL L, V49, P221, DOI DOI 10.1007/978-94-010-2506-5_10
   Noreen E. W., 1989, COMPUTER INTENSIVE M
   Pado S, 2007, COMPUT LINGUIST, V33, P161, DOI 10.1162/coli.2007.33.2.161
   Pennacchiotti M., 2008, P 2008 C EMP METH NA, P457
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Thater Stefan, 2009, P 2009 WORKSH APPL T, P44
NR 23
TC 3
Z9 3
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 948
EP 957
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300097
DA 2019-06-15
ER

PT B
AU Tomanek, K
   Hahn, U
   Lohmann, S
   Ziegler, J
AF Tomanek, Katrin
   Hahn, Udo
   Lohmann, Steffen
   Ziegler, Juergen
GP Assoc Computat Linguist
TI A Cognitive Cost Model of Annotations Based on Eye-Tracking Data
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID MOVEMENTS; AMBIGUITIES; SENTENCES
AB We report on an experiment to track complex decision points in linguistic meta-data annotation where the decision behavior of annotators is observed with an eye-tracking device. As experimental conditions we investigate different forms of textual context and linguistic complexity classes relative to syntax and semantics. Our data renders evidence that annotation performance depends on the semantic and syntactic complexity of the decision points and, more interestingly, indicates that full-scale context is mostly negligible - with the exception of semantic high-complexity cases. We then induce from this observational data a cognitively grounded cost model of linguistic meta-data annotations and compare it with existing non-cognitive models. Our data reveals that the cognitively founded model explains annotation costs (expressed in annotation time) more adequately than non- cognitive ones.
C1 [Tomanek, Katrin; Hahn, Udo] Univ Jena, Language & Informat Engn JULIE Lab, Jena, Germany.
   [Lohmann, Steffen; Ziegler, Juergen] Univ Duisburg Essen, Dept Comp Sci & Appl Cognit Sci, Duisburg, Germany.
RP Tomanek, K (reprint author), Univ Jena, Language & Informat Engn JULIE Lab, Jena, Germany.
CR Altmann Gerry, 2007, J MEM LANG, V31, P685
   [Anonymous], 2005, P ACL WORKSH FEAT EN
   Arora S, 2009, P NAACL HLT 2009 WOR, P18
   CHEUNG H, 1992, APPL PSYCHOLINGUIST, V13, P53, DOI 10.1017/S0142716400005427
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   FRAZIER L, 1987, J MEM LANG, V26, P505, DOI 10.1016/0749-596X(87)90137-9
   Hachey B., 2005, CONLL 2005, P144
   Klare G. R., 1963, MEASUREMENT READABIL
   Lin Dekang, 1996, COLING 1996, P729
   Linguistic Data Consortium, 2001, MESS UND C MUC 7
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Rayner K, 2006, BRIT J PSYCHOL, V97, P467, DOI 10.1348/000712605X89363
   Ringger E, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P3318
   Roark B, 2007, P WORKSH BIONLP 2007, P1, DOI 10.1.1.63.1182
   Settles B., 2008, P NIPS WORKSH COST S, P1
   Sturt P, 2007, COGNITION, V105, P477, DOI 10.1016/j.cognition.2006.10.009
   Szmrecsanyi Benedikt, 2004, POIDS MOTS, V2, P1032
   Tomanek K., 2009, ACL IJCNLP 2007, P1039
   Tomanek K., 2010, LREC 2010
   Traxler MJ, 2008, MEM COGNITION, V36, P314, DOI 10.3758/MC.36.2.314
NR 20
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1158
EP 1167
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300118
DA 2019-06-15
ER

PT B
AU Wang, J
   Li, Q
   Chen, YP
   Lin, ZX
AF Wang, Jia
   Li, Qing
   Chen, Yuanzhu Peter
   Lin, Zhangxi
GP Assoc Computat Linguist
TI Recommendation in Internet Forums and Blogs
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID NEWS RECOMMENDER; WEB
AB The variety of engaging interactions among users in social medial distinguishes it from traditional Web media. Such a feature should be utilized while attempting to provide intelligent services to social media participants. In this article, we present a framework to recommend relevant information in Internet forums and blogs using user comments, one of the most representative of user behaviors in online discussion. When incorporating user comments, we consider structural, semantic, and authority information carried by them. One of the most important observation from this work is that semantic contents of user comments can play a fairly different role in a different form of social media. When designing a recommendation system for this purpose, such a difference must be considered with caution.
C1 [Wang, Jia; Li, Qing] Southwestern Univ Finance & Econ China, Chengdu, Sichuan, Peoples R China.
   [Chen, Yuanzhu Peter] Mem Univ Newfoundland, St John, NF A1C 5S7, Canada.
   [Lin, Zhangxi] Texas Tech Univ, Lubbock, TX 79409 USA.
RP Wang, J (reprint author), Southwestern Univ Finance & Econ China, Chengdu, Sichuan, Peoples R China.
EM wj96@sina.cn; liq_t@swufe.edu.cn; yzchen@mun.ca; zhangxi.lin@ttu.edu
CR Agarwal N, 2010, INFORM SCIENCES, V180, P39, DOI 10.1016/j.ins.2009.07.010
   Ahn J., 2007, P 16 INT C WORLD WID, P11
   Allan James, 2002, EXPLORATIONS TOPIC T, P197
   Baeza-Yates R., 1999, MODERN INFORM RETRIE
   Bogers T, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P141
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Candan KS, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1508850.1508853
   CANTADOR I, 2008, P 2008 IEEE WIC ACM, P562
   Chiang JH, 2004, INT J INTELL SYST, V19, P201, DOI 10.1002/int.10136
   Claypool M, 1999, P ACM SIGIR WORKSH R
   Das A. S., 2007, P 16 INT C WORLD WID, P271
   Del Corso Gianna M., 2005, P 14 INT C WORLD WID, P97
   Esmaili Kyumars Sheykh, 2006, ECAI 2006 WORKSH REC
   Hayes C, 2007, LECT NOTES ARTIF INT, V4737, P1
   Hu M, 2007, P 16 ACM C C INF KNO, P901
   HULL D, 1993, P 16 ANN INT ACM SIG, V16, P329
   Karypis G., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P247, DOI 10.1145/502585.502627
   Lai H. J., 2003, P 5 INT C EL COMM IC, P225
   Lavrenko V., 2000, Proceedings of the Ninth International Conference on Information and Knowledge Management. CIKM 2000, P389, DOI 10.1145/354756.354845
   Lavrenko V, 2001, P 24 ANN INT ACM SIG, P120, DOI DOI 10.1145/383952.383972
   Lee HJ, 2007, EXPERT SYST APPL, V32, P143, DOI 10.1016/j.eswa.2005.11.010
   Leek Tim, 2002, TOPIC DETECTION TRAC, P67
   Li YM, 2009, EXPERT SYST APPL, V36, P6536, DOI 10.1016/j.eswa.2008.07.077
   Ponte J. M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P275, DOI 10.1145/290941.291008
   Qiu Jing, 2009, P 4 ROUGH SETS KNOWL
   ROBERTSON SE, 1994, P 17 ANN INT ACM SIG, P232
   Wang Jia, 2010, P 33 ACM SIGIR C RES, P295
   Wang WQ, 2007, J MANAGE INFORM SYST, V23, P217, DOI [10.2753/MIS0742-1222230410, 10.2753/MIS0742-122230410]
   Yang YM, 1999, IEEE INTELL SYST APP, V14, P32, DOI 10.1109/5254.784083
   Zobel J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P307, DOI 10.1145/290941.291014
NR 30
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 257
EP 265
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300027
DA 2019-06-15
ER

PT B
AU Dagan, I
   Glickman, O
   Gliozzo, A
   Marmorshtein, E
   Strapparava, C
AF Dagan, Ido
   Glickman, Oren
   Gliozzo, Alfio
   Marmorshtein, Efrat
   Strapparava, Carlo
GP COLING
TI Direct Word Sense Matching for Lexical Substitution
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper investigates conceptually and empirically the novel sense matching task, which requires to recognize whether the senses of two synonymous words match in context. We suggest direct approaches to the problem, which avoid the intermediate step of explicit word sense disambiguation, and demonstrate their appealing advantages and stimulating potential for future research.
C1 [Dagan, Ido; Glickman, Oren; Marmorshtein, Efrat] Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel.
RP Dagan, I (reprint author), Bar Ilan Univ, Dept Comp Sci, IL-52900 Ramat Gan, Israel.
CR Dagan I., 2005, P PASCAL CHALL WORKS
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   GONZALO J, 1998, ACL
   Joachims Thorsten, 1999, ADV KERNEL METHODS S, P169
   LESK M, 1986, P ACM SIGDOC C TOR C
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   McCarthy D., 2004, P COLING, P1220
   McCarthy D., 2002, P ACL WORKSH WORD SE, P109
   Mihalcea Rada, 2004, P SENSEVAL 3 3 INT W
   Moldovan DI, 2000, IEEE INTERNET COMPUT, V4, P34, DOI 10.1109/4236.815847
   NEGRI M, 2004, SIGIR 2004 WORKSH IN
   PEDERSEN T, 1997, EMNLP
   SANDERSON M, 1994, SIGIR
   Scholkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Schutze H, 1995, P 4 ANN S DOC AN INF
   Schutze H., 1998, COMPUTATIONAL LINGUI, V24
   VOORHEES E, 1994, P 17 ACM SIGIR C DUB
   Voorhees E. M., 1993, SIGIR
   YAROWSKY D, 1994, ACL, P88
NR 19
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 449
EP 456
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200057
DA 2019-06-15
ER

PT B
AU Hockenmaier, J
AF Hockenmaier, Julia
GP COLING
TI Creating a CCGbank and a wide-coverage CCG lexicon for German
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present an algorithm which creates a German CCGbank by translating the syntax graphs in the German Tiger corpus into CCG derivation trees. The resulting corpus contains 46,628 derivations, covering 95% of all complete sentences in Tiger. Lexicons extracted from this corpus contain correct lexical entries for 94% of all known tokens in unseen text.
C1 Univ Penn, Inst Res Cognit Sci, Philadelphia, PA 19104 USA.
RP Hockenmaier, J (reprint author), Univ Penn, Inst Res Cognit Sci, Philadelphia, PA 19104 USA.
EM juliahr@cis.upenn.edu
CR Baldridge J., 2002, THESIS U EDINBURGH
   BOHOMVA A, 2003, TREE BANKS BUILDING
   BRANTS S, 2002, WORKSH TREEB LING TH
   CAHILL A, 2005, J RES LANGUAGE COMPU
   Cakici R., 2005, ACL STUD RES WORKSH, P73
   CARPENTER B, 1992, FORMAL GRAMMAR THEOR, pCH3
   CHEN J, 2005, NATURAL LANGUAGE ENG
   Clark S., 2004, P 42 ANN M ASS COMP
   DUBEY A, 2003, P 41 ANN M ASS COMP, P96
   Gazdar Gerald, 1985, GEN PHRASE STRUCTURE
   Hockenmaier J., 2002, P 3 INT C LANG RES E
   HOCKENMAIER J, 2005, MSCIS0509 U PENNS
   Hockenmaier J., 2002, P 40 ANN M ASS COMP, P335
   Hoffman Beryl, 1995, 9517 IRCS
   Levy Roger, 2004, P 42 ANN M ASS COMP
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   MIYAO Y, 2004, P 1 INT JOINT C NAT
   Miyao Yusuke, 2005, P 43 ANN M ASS COMP, P83
   MOORTGAT M, 2002, P 3 INT C LANG RES E
   O'Donovan R, 2005, COMPUT LINGUIST, V31, P329, DOI 10.1162/089120105774321073
   RAMBOW O, 1994, THESIS U PENNSYLVANI
   SHEN L, 2005, P HUM LANG TECHN C C
   SKUT W, 1997, 5 C APPL NAT LANG PR
   Steedman M., 1996, LINGUISTIC INQUIRY M
   Steedman M., 2000, SYNTACTIC PROCESS
   STEEDMAN MJ, 1990, LINGUIST PHILOS, V13, P207, DOI 10.1007/BF00630734
   Xia F., 1999, P 5 NAT LANG PROC PA
NR 27
TC 3
Z9 3
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 505
EP 512
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200064
DA 2019-06-15
ER

PT B
AU Li, JF
   Wang, HF
   Ren, DJ
   Li, GH
AF Li, Jianfeng
   Wang, Haifeng
   Ren, Dengjun
   Li, Guohua
GP COLING
TI Discriminative Pruning of Language Models for Chinese Word Segmentation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents a discriminative pruning method of n-gram language model for Chinese word segmentation. To reduce the size of the language model that is used in a Chinese word segmentation system, importance of each bigram is computed in terms of discriminative pruning criterion that is related to the performance loss caused by pruning the bigram. Then we propose a step-by-step growing algorithm to build the language model of desired size. Experimental results show that the discriminative pruning method leads to a much smaller model compared with the model pruned using the state-of-the-art method. At the same Chinese word segmentation F-measure, the number of bigrams in the model can be reduced by up to 90%. Correlation between language model perplexity and word segmentation performance is also discussed.
C1 [Li, Jianfeng; Wang, Haifeng; Ren, Dengjun; Li, Guohua] Toshiba China Res & Dev Ctr, Beijing 100738, Peoples R China.
RP Li, JF (reprint author), Toshiba China Res & Dev Ctr, 5-F Tower W2,Oriental Plaza 1,E Chang An Ave, Beijing 100738, Peoples R China.
EM lijianfeng@rdc.toshiba.com.cn; wanghaifeng@rdc.toshiba.com.cn;
   rendengjun@rdc.toshiba.com.cn; liguohua@rdc.toshiba.com.cn
CR Clarkson P., 1997, P EUR 97 RHOD GREEC, P2707
   COLLINS M, 2000, MACH LEARN, P175
   Gao J.F., 2002, P 40 ANN M ASS COMP, P176
   Gao JF, 2005, COMPUT LINGUIST, V31, P531, DOI 10.1162/089120105775299177
   GAO JF, 2000, P 38 ANN M ASS COMP, P579
   GAO JF, 2003, P 41 ANN M ASS COMP, P272
   HONGKWANG J, 2002, P 27 INT C AC SPEECH, P325
   Jelinek F., 1990, READINGS SPEECH RECO, P450
   MCCALLUNM A, 2004, P 20 INT C COMP LING, P562
   Och F. J., 2002, P 40 ANN M ASS COMP, P295
   Roark B., 2004, P ACL, P47
   Seymore K, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P232, DOI 10.1109/ICSLP.1996.607084
   Sproat R, 1996, COMPUT LINGUIST, V22, P377
   Stolcke A., 1998, P DARPA BROADC NEWS, P270
   Sun M., 2001, CONT LINGUISTICS, V3, P22
   Yu S., 2003, J CHINESE LANGUAGE C, V13, P121
   Zhang H.-P., 2003, P 2 SIGHAN WORKSH CH, V17, P184, DOI DOI 10.3115/1119250.1119280
NR 17
TC 3
Z9 3
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1001
EP 1008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200126
DA 2019-06-15
ER

PT B
AU Lu, ZM
   Wang, HF
   Yao, JM
   Liu, T
   Li, S
AF Lu, Zhimao
   Wang, Haifeng
   Yao, Jianmin
   Liu, Ting
   Li, Sheng
GP COLING
TI An Equivalent Pseudoword Solution to Chinese Word Sense Disambiguation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents a new approach based on Equivalent Pseudowords (EPs) to tackle Word Sense Disambiguation (WSD) in Chinese language. EPs are particular artificial ambiguous words, which can be used to realize unsupervised WSD. A Bayesian classifier is implemented to test the efficacy of the EP solution on Senseval-3 Chinese test set. The performance is better than state-of-the-art results with an average F-measure of 0.80. The experiment verifies the value of EP for unsupervised WSD.
C1 [Lu, Zhimao; Liu, Ting; Li, Sheng] Harbin Inst Technol, Sch Comp Sci & Technol, Informat Retrieval Lab, Harbin 150006, Peoples R China.
RP Lu, ZM (reprint author), Harbin Inst Technol, Sch Comp Sci & Technol, Informat Retrieval Lab, Harbin 150006, Peoples R China.
EM lzm@ir-lab.org; wanghaifeng@rdc.toshiba.com.cn; jyao@suda.edu.cn;
   tliu@ir-lab.org; lisheng@ir-lab.org
CR Brown PF, 1991, P 29 ANN M ASS COMP, P264
   DIAB M, 2002, P 40 ANN M ASS COMP, P255
   Diab M., 2004, P WORKSH AR BAS SCRI, P43
   Diab M., 2004, P 42 ANN M ASS COMP, P303
   Diab M.T., 2003, THESIS U MARYLAND CO
   Gale W. A., 1992, P AAAI FALL S PROB A, P54
   Gale W.A., 1992, P 30 ANN M ASS COMP, P249
   GALE WA, 1992, P 4 INT C THEOR METH, P101
   Gaustad T., 2001, P STUD RES WORKSH AC, P61
   Ide Nancy, 2002, WORKSH WORD SENS DIS, P54
   LI C, 2002, P 40 ANN M ASS COMP, P343
   MIHALCEA R, 2002, P 3 INT C LANG RES E, P1407
   MIHALCEA R, 2000, P FLOR ART INT RES S, P219
   Ng H. T., 2003, P 41 ANN M ASS COMP, P455
   Niu Z. -Y., 2005, P 43 ANN M ASS COMP, P395
   PRESLAV I, 2003, P HLT NAACL 2003 SHO
   QIN Y, 2005, P JOINT S COMP LING, P127
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Tufis D, 2001, P 6 NAT LANG PROC PA, P83
   YAROWSKY D, 1995, P 33 ANN M ASS COMP, P189, DOI DOI 10.3115/981658.981684
   Yarowsky David, 1994, P 32 ANN M ASS COMP, P88
NR 21
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 457
EP 464
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200058
DA 2019-06-15
ER

PT B
AU Lv, YH
   Sun, L
   Zhang, JL
   Nie, JY
   Chen, W
   Zhang, W
AF Lv, Yuanhua
   Sun, Le
   Zhang, Junlin
   Nie, Jian-Yun
   Chen, Wan
   Zhang, Wei
GP COLING
TI An Iterative Implicit Feedback Approach to Personalized Search
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID WEB SEARCH
AB General information retrieval systems are designed to serve all users without considering individual needs. In this paper, we propose a novel approach to personalized search. It can, in a unified way, exploit and utilize implicit feedback information, such as query logs and immediately viewed documents. Moreover, our approach can implement result re-ranking and query expansion simultaneously and collaboratively. Based on this approach, we develop a client-side personalized web search agent PAIR (Personalized Assistant for Information Retrieval), which supports both English and Chinese. Our experiments on TREC and HTRDP collections clearly show that the new approach is both effective and efficient.
C1 [Lv, Yuanhua] Chinese Acad Sci, Inst Software, Beijing 100080, Peoples R China.
RP Lv, YH (reprint author), Chinese Acad Sci, Inst Software, Beijing 100080, Peoples R China.
EM lvyuanhua@gmail.com; sunle@iscas.cn; junlin01@iscas.cn;
   nie@iro.umontreal.ca; chenwan@nus.edu.sq; zhangwei04@iscas.cn
CR Beaulieu M, 1998, INTERACT COMPUT, V10, P237, DOI 10.1016/S0953-5438(98)00008-3
   Bharat K, 2000, COMPUT NETW, V33, P493, DOI 10.1016/S1389-1286(00)00047-5
   Hawking D, 1999, COMPUT NETW, V31, P1321, DOI 10.1016/S1389-1286(99)00024-9
   Joachims T., 2005, P 28 ANN INT ACM SIG, P154, DOI DOI 10.1145/1076034.1076063
   KLEINBERG J, 1999, ACM, V46, P604
   KRITIKOPOULS A, 2003, P ITWP WORKSH INT TE, P229
   Liu F., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P558
   Morita M., 1994, P 17 ANN INT ACM SIG, P272, DOI DOI 10.1007/978-1-4471-2099-5_28
   Pitkow J, 2002, COMMUN ACM, V45, P50
   ROBERTSON SE, 1976, J AM SOC INFORM SCI, V27, P129, DOI 10.1002/asi.4630270302
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H
   Salton  G., 1983, INTRO MODERN INFORM
   Shen X, 2005, P 14 ACM INT C INF K, P824, DOI [10.1145/1099554.1099747, DOI 10.1145/1099554.1099747]
   SPERETTA M, 2005, WEB INTELLIGENCE, P622
   Sugiyama K., 2004, P 13 INT C WORLD WID, P675, DOI DOI 10.1145/988672.988764
   TANUDJAJA F, 2002, PERSONA CONTEXTUAL I
   Teevan J., 2005, P 28 ANN INT ACM SIG, P449, DOI DOI 10.1145/1076034.1076111
   WHITE RW, 2002, P 24 BCS IRSG EUR C, P93
NR 19
TC 3
Z9 3
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 585
EP 592
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200074
DA 2019-06-15
ER

PT B
AU Nagata, M
   Saito, K
   Yamamoto, K
   Ohashi, K
AF Nagata, Masaaki
   Saito, Kuniko
   Yamamoto, Kazuhide
   Ohashi, Kazuteru
GP COLING
TI A Clustered Global Phrase Reordering Model for Statistical Machine
   Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper, we present a novel global reordering model that can be incorporated into standard phrase-based statistical machine translation. Unlike previous local reordering models that emphasize the reordering of adjacent phrase pairs (Tillmann and Zhang, 2005), our model explicitly models the reordering of long distances by directly estimating the parameters from the phrase alignments of bilingual training sentences. In principle, the global phrase reordering model is conditioned on the source and target phrases that are currently being translated, and the previously translated source and target phrases. To cope with sparseness, we use N-best phrase alignments and bilingual phrase clustering, and investigate a variety of combinations of conditioning factors. Through experiments, we show, that the global reordering model significantly improves the translation accuracy of a standard Japanese-English translation task.
C1 [Nagata, Masaaki] NTT Commun Sci Labs, Seika, Kyoto 6190237, Japan.
RP Nagata, M (reprint author), NTT Commun Sci Labs, 2-4 Hikaridai, Seika, Kyoto 6190237, Japan.
EM nagata.masaaki@labs.ntt.co.jp; saito.kuniko@labs.ntt.co.jp;
   ykaz@nlp.nagaokaut.ac.jp; ohashi@nlp.nagaokaut.ac.jp
CR Eck M, 2005, P INT WORKSH SPOK LA, P11
   KOEHN P, 2003, P HLT NAACL, P127
   Ney H., 1999, P JOINT SIGDAT C EMP, P20
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   OHASHI K, 2005, P INT WORKSH SPOK LA, P128
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Sumita E., 2004, P 20 INT C COMP LING, P205
   Tillmann C., 2005, P 43 ANN M ASS COMP, P557
   Ueffing N, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P156
   VOGEL S, 2003, P MT SUMMIT, V9
NR 11
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 713
EP 720
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200090
DA 2019-06-15
ER

PT B
AU Pan, F
   Mulkar, R
   Hobbs, JR
AF Pan, Feng
   Mulkar, Rutu
   Hobbs, Jerry R.
GP COLING
TI Learning Event Durations from Event Descriptions
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We have constructed a corpus of news articles in which events are annotated for estimated bounds on their duration. Here we describe a method for measuring inter-annotator agreement for these event duration distributions. We then show that machine learning techniques applied to this data yield coarse-grained event duration information, considerably outperforming a baseline and approaching human performance.
C1 [Pan, Feng; Mulkar, Rutu; Hobbs, Jerry R.] Univ So Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
RP Pan, F (reprint author), Univ So Calif, Inst Informat Sci, 4676 Admiralty Way, Marina Del Rey, CA 90292 USA.
EM pan@isi.edu; rutu@isi.edu; hobbs@isi.edu
CR Boguraev B., 2005, P INT JOINT C ART IN
   Brill E, 1992, P 3 C APPL NAT LANG
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Duda RO, 1973, PATTERN CLASSIFICATI
   Filatova E, 2001, P ACL WORKSH TEMP SP
   FORTEMPS P, 1997, IEEE T FUZZY SYSTEMS, V5
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   GODO L, 1995, P INT JOINT C ART IN
   HERMJAKOB U, 1997, P 35 ANN M ASS COMP
   HITZEMAN J, 1995, P EACL DUBL IR
   HOBBS JR, 2001, P JOINT 9 IFSA WORLD
   Krippendorf K., 1980, CONTENT ANAL INTRO I
   Mani I., 2000, P 38 ANN M ASS COMP
   MILLER G, 1990, INT J LEXICOGRAPHY, V3
   PAN F, 2006, P 5 INT C LANG RES E
   PUSTEJOVSKY J., 2003, CORPUS LINGUISTICS
   Quinlan J. R, 1993, C4 5 PROGRAMS MACHIN
   RIEGER CJ, 1974, AIM233
   Vapnik VN, 1995, NATURE STAT LEARNING
   Witten IH, 2005, DATA MINING PRACTICA
NR 20
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 393
EP 400
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200050
DA 2019-06-15
ER

PT B
AU Park, J
   Brew, C
AF Park, Jihyun
   Brew, Chris
GP COLING
TI A Finite-State Model of Human Sentence Processing
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID EYE-MOVEMENTS; COMPREHENSION; SUBJECT; ACCESS
AB It has previously been assumed in the psycholinguistic literature that finite-state models of language are crucially limited in their explanatory power by the locality of the probability distribution and the narrow scope of information used by the model. We show that a simple computational model (a bigram part-of-speech tagger based on the design used by Corley and Crocker (2000)) makes correct predictions on processing difficulty observed in a wide range of empirical sentence processing data. We use two modes of evaluation: one that relies on comparison with a control sentence, paralleling practice in human studies; another that measures probability drop in the disambiguating region of the sentence. Both are surprisingly good indicators of the processing difficulty of garden-path sentences. The sentences tested are drawn from published sources and systematically explore five different types of ambiguity: previous studies have been narrower in scope and smaller in scale. We do not deny the limitations of finite-state models, but argue that our results show that their usefulness has been underestimated.
C1 [Park, Jihyun; Brew, Chris] Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
RP Park, J (reprint author), Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
EM park@ling.ohio-state.edu; cbrew@ling.ohio-state.edu
CR Bangalore S, 1999, COMPUT LINGUIST, V25, P237
   BEVER TG, 1988, LINGUIST INQ, V19, P35
   Burnard L., 1995, USERS GUIDE BRIT NAT
   CORLEY S, 2000, ARCHITECTURES MECH L
   CROCKER WC, 2000, WIDE COVERAGE PROBAB
   FERREIRA F, 1986, J MEM LANG, V25, P348, DOI 10.1016/0749-596X(86)90006-9
   FERREIRA F, 1990, J EXP PSYCHOL LEARN, V16, P555, DOI 10.1037/0278-7393.16.4.555
   FRAZIER L, 1982, COGNITIVE PSYCHOL, V14, P178, DOI 10.1016/0010-0285(82)90008-1
   FRAZIER L, 1978, THESIS U MASSACHUSET
   Frazier L., 1996, CONSTRUAL
   HALE J, 2001, P NAACL 2001
   HOMES VM, 1981, J VERB LEARN VERB BE, V20, P417
   JOSHI A, 1994, P 15 INT C COMP LING, P154
   JULIANO C, 1994, J PSYCHOLINGUIST RES, V23, P459, DOI 10.1007/BF02146685
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   KIM AE, 2002, LEXICAL BASIS SENTEN, P109
   KING J, 1991, J MEM LANG, V30, P580, DOI 10.1016/0749-596X(91)90027-H
   MacWhinney B., 1982, LANGUAGE DEV, V1, P73
   Mak WM, 2002, J MEM LANG, V47, P50, DOI 10.1006/jmla.2001.2837
   Manning C.D., 1999, FDN STAT NATURAL LAN
   NARAYANAN S, 2002, P ADV NEUR INF PROC
   Roark B, 2001, COMPUT LINGUIST, V27, P249, DOI 10.1162/089120101750300526
   Traxler MJ, 2002, J MEM LANG, V47, P69, DOI 10.1006/jmla.2001.2836
   TRUESWELL JC, 1996, J MEM LANG, V35, P556
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
NR 25
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 49
EP 56
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200007
DA 2019-06-15
ER

PT B
AU Pasca, M
   Lin, D
   Bigham, J
   Lifchits, A
   Jain, A
AF Pasca, Marius
   Lin, Dekang
   Bigham, Jeffrey
   Lifchits, Andrei
   Jain, Alpa
GP COLING
TI Names and Similarities on the Web: Fact Extraction in the Fast Lane
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In a new approach to large-scale extraction of facts from unstructured text, distributional similarities become an integral part of both the iterative acquisition of high-coverage contextual extraction patterns, and the validation and ranking of candidate facts. The evaluation measures the quality and coverage of facts extracted from one hundred million Web documents, starting from ten seed facts and using no additional knowledge, lexicons or complex tools.
C1 [Pasca, Marius; Lin, Dekang; Bigham, Jeffrey; Lifchits, Andrei; Jain, Alpa] Google Inc, Mountain View, CA 94043 USA.
RP Pasca, M (reprint author), Google Inc, Mountain View, CA 94043 USA.
EM mars@google.com; lindek@google.com; jbigham@cs.washington.edu;
   alifchit@cs.ubc.ca; alpa@cs.columbia.edu
CR Agichtein E., 2000, P 5 ACM INT C DIG LI, P85, DOI DOI 10.1145/336597.336644
   BRANTS T, 2000, P 6 C APPL NAT LANG, P224, DOI DOI 10.3115/974147.974178
   Cafarella M. J., 2005, P C HUM LANG TECHN E, P563
   Collins M., 1999, P JOINT SIGDAT C EMP, P189
   Fleischman Michael, 2003, P 41 ANN M ASS COMP, P1
   Grefenstette G., 1994, EXPLORATIONS AUTOMAT
   HASEGAWA T, 2004, P 42 ANN M ASS COMP
   Hindle D., 1990, P 28 ANN M ASS COMP, P268
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   LITA L, 2004, P C EMP METH NAT LAN, P396
   Pereira Fernando, 1993, P 31 ANN M ASS COMP, P183, DOI DOI 10.3115/981574.981598
   Riloff E, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P474
   Stevenson M., 2005, P 43 ANN M ASS COMP, P379, DOI DOI 10.3115/1219840.1219887
   Thelen M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P214
   Voorhees E. M., 2000, P 23 ANN INT ACM SIG, P200
NR 15
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 809
EP 816
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200102
DA 2019-06-15
ER

PT B
AU Sudoh, K
   Tsukada, H
   Isozaki, H
AF Sudoh, Katsuhito
   Tsukada, Hajime
   Isozaki, Hideki
GP COLING
TI Incorporating speech recognition confidence into discriminative named
   entity recognition of speech data
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper proposes a named entity recognition (NER) method for speech recognition results that uses confidence on automatic speech recognition (ASR) as a feature. The ASR confidence feature indicates whether each word has been correctly recognized. The NER model is trained using ASR results with named entity (NE) labels as well as the corresponding transcriptions with NE labels. In experiments using support vector machines (SVMs) and speech data from Japanese newspaper articles, the proposed method outperformed a simple application of text-based NER to ASR results in NER F-measure by improving precision. These results show that the proposed method is effective in NER for noisy inputs.
C1 [Sudoh, Katsuhito; Tsukada, Hajime; Isozaki, Hideki] NTT Corp, NTT Commun Sci Labs, Keihanna Sci City, Kyoto 6190237, Japan.
RP Sudoh, K (reprint author), NTT Corp, NTT Commun Sci Labs, 2-4 Hikaridai,Seika Cho, Keihanna Sci City, Kyoto 6190237, Japan.
EM sudoh@cslab.kecl.ntt.co.jp; tsukada@cslab.kecl.ntt.co.jp;
   isozaki@cslab.kecl.ntt.co.jp
CR Bechet F, 2004, SPEECH COMMUN, V42, P207, DOI 10.1016/j.specom.2003.07.003
   Borthwick A., 1999, THESIS NEW YORK U
   Favre B., 2005, P C HUM LANG TECHN E, P491
   Hai Leong Chieu, 2003, P CONLL 2003, V4, P160
   Hori T., 2004, P ICSLP, V1, P289
   Horlock J., 2003, P EUROSPEECH, P2765
   HORLOCK J, 2003, P INT 2003 EUR, P1265
   ISOZAKI H, 2002, P COLING 2002, P390
   KAMPPARI SO, 2000, P ICASSP, V3, P1799
   Mccallum A., 2003, P 7 C NAT LANG LEARN, P188, DOI DOI 10.3115/1119176.1119206
   Miller D., 1999, P DARPA BROADC NEWS, P37
   PALMER DD, 2001, P HLT, P156
   SCHAAF T, 1997, P 1997 ICASSP MUN AP, V2, P875
   Sekine S., 1998, P 6 WORKSH VER LARG, P171
   Sekine S., 2000, P COLING 2000, P25
   Wessel F, 2001, IEEE T SPEECH AUDI P, V9, P288, DOI 10.1109/89.906002
   Zhai L., 2004, P HLT NAACL, P37
   Zhang Rong, 2001, P EUR C SPEECH COMM, P2105
NR 18
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 617
EP 624
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200078
DA 2019-06-15
ER

PT B
AU Talbot, D
   Osborne, M
AF Talbot, David
   Osborne, Miles
GP COLING
TI Modelling lexical redundancy for machine translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Certain distinctions made in the lexicon of one language may be redundant when translating into another language. We quantify redundancy among source types by the similarity of their distributions over target types. We propose a language-independent framework for minimising lexical redundancy that can be optimised directly from parallel text. Optimisation of the source lexicon for a given target language is viewed as model selection over a set of cluster-based translation models.
   Redundant distinctions between types may exhibit monolingual regularities, for example, inflexion patterns. We define a prior over model structure using a Markov random field and learn features over sets of monolingual types that are predictive of bilingual redundancy. The prior makes model selection more robust without the need for language-specific assumptions regarding redundancy. Using these models in a phrase-based SMT system, we show significant improvements in translation quality for certain language pairs.
C1 [Talbot, David; Osborne, Miles] Univ Edinburgh, Sch Informat, Edinburgh EH8 9LW, Midlothian, Scotland.
RP Talbot, D (reprint author), Univ Edinburgh, Sch Informat, 2 Buccleuch Pl, Edinburgh EH8 9LW, Midlothian, Scotland.
EM d.r.talbot@sms.ed.ac.uk; miles@inf.ed.ac.uk
CR Basu S., 2004, P 10 ACM SIGKDD INT
   BESAG J, 1986, J ROY STAT SOC B MET, V48, P259
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHOU PA, 1999, IEEE T PATTERN ANAL, V13
   Cmejrek Martin, 2004, 4 INT C LANG RES EV
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GOLDWATER S, 2005, P 2002 C EMP METH NA
   KOEHN P, 2004, P AMTA 2004
   Koehn Philipp, 2003, P HLT NAACL 2003
   Koehn Philipp, 2005, MT SUMM 2005
   Niessen S, 2004, COMPUT LINGUIST, V30, P181, DOI 10.1162/089120104323093285
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   OCH FJ, 1998, P EUR CHAPT ASS COMP
   Wang Y. Y., 1996, P 4 INT C SPOK LANG
   WOLPERT DH, 1995, 15 INT WORKSH MAX EN
   YANG M, 2006, P EUR CHAPT ASS COMP
   ZENS R, 2004, P HUM LANG TECHN C H
NR 17
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 969
EP 976
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200122
DA 2019-06-15
ER

PT B
AU Tillmann, C
   Zhang, T
AF Tillmann, Christoph
   Zhang, Tong
GP COLING
TI A Discriminative Global Training Algorithm for Statistical MT
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents a novel training algorithm for a linearly-scored block sequence translation model. The key component is a new procedure to directly optimize the global scoring function used by a SMT decoder. No translation, language, or distortion model probabilities are used as in earlier work on SMT. Therefore our method, which employs less domain specific knowledge, is both simpler and more extensible than previous approaches. Moreover, the training procedure treats the decoder as a black-box, and thus can be used to optimize any decoding scheme. The training algorithm is evaluated on a standard Arabic-English translation task.
C1 [Tillmann, Christoph] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Tillmann, C (reprint author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM ctill@us.ibm.com; tzhang@yahoo-inc.com
CR ALONAIZAN Y, 2004, NIST 2004 MT WORKSH
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   COLLINS M, 2002, P EMNLP 02 PHIL PA
   ITTYCHERIAH A, 2005, P HLT EMNLP, P89
   Koehn P, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P127
   KUMAR S, 2005, P HUM LANG TECHN C C, P161
   Lewis D. D., 1994, P 11 INT C MACH LEAR, P148
   McDonald R., 2005, P 43 ANN M ASS COMP, P91, DOI DOI 10.3115/1219840.1219852
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   SHEN L, 2004, P HLT NAACL, P177
   Tillmann C., 2005, P 43 ANN M ASS COMP, P557
NR 13
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 721
EP 728
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200091
DA 2019-06-15
ER

PT B
AU Bangalore, S
   Johnston, M
AF Bangalore, S
   Johnston, M
GP acl
TI Balancing data-driven and rule-based approaches in the context of a
   multimodal conversational system
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB Moderate-sized rule-based spoken language models for recognition and understanding are easy to develop and provide the ability to rapidly prototype conversational applications. However, scalability of such systems is a bottleneck due to the heavy cost of authoring and maintenance of rule sets and inevitable brittleness due to lack of coverage in the rule sets. In contrast, data-driven approaches are robust and the procedure for model building is usually simple. However, the lack of data in a particular application domain limits the ability to build data-driven models. In this paper, we address the issue of combining data-driven and grammar-based models for rapid prototyping of robust speech recognition and understanding models for a multimodal conversational system. We also present methods that reuse data from different domains and investigate-the limits of such models in the context of a particular application domain.
C1 AT&T Labs Res, Florham Pk, NJ 07932 USA.
RP Bangalore, S (reprint author), AT&T Labs Res, 180 Pk Ave, Florham Pk, NJ 07932 USA.
EM srini@research.att.com; johnston@research.att.com
CR ALLEN J, 2000, JNLE, V6
   BACCHIANI M, 2003, P INT C AC SPEE SIGN
   BANGALORE S, 1999, COMPUTATIONAL LINGUI, V25
   Beutnagel M, 1999, JOINT M ASA EAA DAGA
   BINGALORE S, 2000, P ICSLP BEIJ CHIN
   BOROS M, 1996, P ICSLP PHIL
   CLARK S, 2002, P LREC 2002 PARS WOR
   Dowding J., 1993, P 31 ANN M ASS COMP, P54
   FERNANDO CN, 1997, FINITE STATE LANGUAG, P431
   FLICKINGER D, 2000, VERBMOBIL FDN SPEECH, P254
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   GALESCU L, 1998, P ELRA 1 INT C LANG
   JOHNSTON M, 2002, P ACL PHIL
   JOHNSTON M, 2002, P ICSLP DENV CO
   JOHNSTON M, 2000, P COLING SAARBR GERM
   LAVIE A, 1996, THESIS CARNEGIE MELL
   NEDERHOF MJ, 1997, P INT WORKSH PARS TE
   RAMBOW O, 2002, P 19 INT C COMP LING
   Ramshaw L. A., 1995, P 3 WORKSH VER LARG
   RAYNER M, 2003, P EACL 2003
   SENEFF S, 1992, P SPEECH NAT WORKSH
   SHARP RD, 1997, P INT C AC SPEECH SI, P4065
   SOUVIGNIER B, 1998, INT C SPOKEN LANGUAG
   WANG Y, 2003, P EUR C GEN SWITZ
   WANG YY, 2000, P ICASSP
   *XTAG, 2001, LEX TREE ADJ GRAMM E
NR 26
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 33
EP 40
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100005
DA 2019-06-15
ER

PT B
AU Kaplan, RM
   Riezler, S
   King, FH
   Maxwell, JT
   Vasserman, A
   Crouch, R
AF Kaplan, RM
   Riezler, S
   King, FH
   Maxwell, JT
   Vasserman, A
   Crouch, R
GP acl
TI Speed and accuracy in shallow and deep stochastic parsing
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB This paper reports some experiments that compare the accuracy and performance of two stochastic parsing systems. The currently popular Collins parser is a shallow parser whose output contains more detailed semantically-relevant information than other such parsers. The XLE parser is a deep-parsing system that couples a Lexical Functional Grammar to a log-linear disambiguation component and provides much richer representations theory. We measured the accuracy of both systems against a gold standard of the PARC 700 dependency bank, and also measured their processing times. We found the deep-parsing system to be more accurate than the Collins parser with only a slight reduction in parsing speed.(1).
C1 Palo Alto Res Ctr, Palo Alto, CA 94304 USA.
RP Kaplan, RM (reprint author), Palo Alto Res Ctr, 3333 Coyote Hill Rd, Palo Alto, CA 94304 USA.
CR Collins Michael, 1999, THESIS U PENNSYLVANI
   CROUCH D, 2002, P SCAL NAT LANG UND
   DAUME H, 2002, P 40 ANN M ASS COMP
   FRANK A, 1998, P 3 LFG C
   GEMAN S, 2002, P 40 ANN M ASS COMP
   GILDEA D, 2002, P 40 ANN M ASS COMP
   HARABAGIU S, 2001, P 39 ANN M 10 C EUR
   King T. H., 2003, P WORKSH LING INT CO
   Kingsbury P., 2002, P 3 INT C LANG RES E
   Maxwell J. T.  III, 1993, Computational Linguistics, V19, P571
   MILLER S, 2000, P 1 C N AM CHAPT ASS
   Miyao Y., 2002, P HUM LANG TECHN C H
   RATNAPARKHI A, 1996, P EMNLP 1
   Riezler S., 2002, P 40 ANN M ASS COMP
   RIEZLER S, 2004, UNPUB GRADIENT FEATU
   Rohrer Christian, 2002, P COLING 2002 WORKSH, P1
   YAMADA K, 2001, P 39 ANN M 10 C EUR
NR 17
TC 3
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 97
EP 104
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100013
DA 2019-06-15
ER

PT B
AU Kehler, A
   Appelt, D
   Taylor, L
   Simma, A
AF Kehler, A
   Appelt, D
   Taylor, L
   Simma, A
GP acl
TI The (Non)utility of predicate-argument frequencies for pronoun
   interpretation
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB State-of-the-art pronoun interpretation systems rely predominantly on morphosyntactic contextual features. While the use of deep knowledge and inference to improve these models would appear technically infeasible, previous work has suggested that predicate-argument statistics mined from naturally-occurring data could provide a useful approximation to such knowledge. We test this idea in several system configurations, and conclude from our results and subsequent error analysis that such statistics offer little or no predictive information above that provided by morphosyntax.
C1 Univ Calif San Diego, Dept Linguist, San Diego, CA 92103 USA.
RP Kehler, A (reprint author), Univ Calif San Diego, Dept Linguist, San Diego, CA 92103 USA.
EM akehler@ucsd.edu; appelt@ai.sri.com; lmtaylor@ucsd.edu; asimma@ucsd.edu
CR Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Chen SF, 2000, IEEE T SPEECH AUDI P, V8, P37, DOI 10.1109/89.817452
   Dagan I, 1995, APPL ARTIF INTELL, V9, P633, DOI 10.1080/08839519508945492
   Dagan I., 1990, P 13 INT C COMP LING, P330
   GE N, 1998, P 6 WORKSH VER LARG
   HOBBS JR, 1978, LINGUA, V44, P311, DOI 10.1016/0024-3841(78)90006-2
   KELLER F, 2003, COMPUTATIONAL LINGUI, V29
   Kennedy C, 1996, P 16 INT C COMP LING
   Lappin S., 1994, Computational Linguistics, V20, P535
   Mitkov  R., 2002, ANAPHORA RESOLUTION
   Pereira Fernando, 1993, P 31 ANN M ASS COMP, P183, DOI DOI 10.3115/981574.981598
NR 11
TC 3
Z9 3
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 289
EP 296
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100037
DA 2019-06-15
ER

PT B
AU Kim, J
   Schwarm, SE
   Ostendorf, M
AF Kim, J
   Schwarm, SE
   Ostendorf, M
GP acl
TI Detecting structural metadata with decision trees and
   transformation-based learning
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
ID SPEECH
AB The regular occurrence of disfluencies is a distinguishing characteristic of spontaneous speech. Detecting and removing such disfluencies can substantially improve the usefulness of spontaneous speech transcripts. This paper presents a system that detects various types of disfluencies and other structural information with cues obtained from lexical and prosodic information sources. Specifically, combinations of decision trees and language models are used to predict sentence ends and interruption points and, given these events, transformation based learning is used to detect edit disfluencies and conversational fillers. Results are reported on human and automatic transcripts of conversational telephone speech.
C1 Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
RP Kim, J (reprint author), Univ Washington, Dept Elect Engn, Seattle, WA 98195 USA.
CR BEAR J, 1992, M ACL, P56
   Breiman L., 1984, CLASSIFICATION REGRE
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   BUNTINE W, 1991, FIA9128 TR NASA AM R
   CHARNIAK E, 2001, P 2 M N AM CHAPT ASS, P118
   Godfrey J. J., 1992, IEEE INT C AC SPEECH, V1, P517, DOI DOI 10.1109/ICASSP.1992.225858
   HEEMAN PA, 1996, P ICSLP, V1, P362
   Hemphill C. T., 1990, P DARPA SPEECH NAT L, P96
   HINLE D, 1983, M ACL, P123
   Jones D., 2003, P EUR, P1585
   Kim J. H., 2001, P EUR, P2757
   Kneser R., 1995, P IEEE INT C AC SPEE, V1, P181, DOI DOI 10.1109/ICASSP.1995.479394
   Liu Y., 2003, P EUR, P957
   MANGU L, 1997, P 14 INT C MACH LEAR, P187
   MANGU L, 2001, P ICASSP, P29
   METEER M, 1995, DYSFLUENCY ANNOTATIO
   NAKATANI C, 1994, J ACOUST SOC AM, P1603
   NGAI G, 2001, P 2 ANN M N AM CHAPT, P40
   *NIST, 2003, RICH TRANSC FALL 200
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   Shriberg E, 2000, SPEECH COMMUN, V32, P127, DOI 10.1016/S0167-6393(00)00028-5
   Shriberg E., 1997, P EUR, V5, P2383
   Shriberg E., 1994, THESIS U CALIFORNIA
   Sonmez K., 1998, P INT C SPOK LANG PR, V7, p[9192, 1998, 3189]
   Srivastava A., 2003, P EUR, P949
   Stolcke A., 2002, P INT C SPOK LANG PR, P901
   Stolcke A., 1998, P INT C SPOK LANG PR, V2, P2247
   STOLCKE A, 1996, P INT C SPOK LANG PR, V2, P1005
   STRASSEL S, 2003, SIMPLE METADATA ANNO
NR 29
TC 3
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 137
EP 144
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100018
DA 2019-06-15
ER

PT B
AU Osborne, M
   Baldridge, J
AF Osborne, M
   Baldridge, J
GP acl
TI Ensemble-based active learning for parse selection
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB Supervised estimation methods are widely seen as being superior to semi and fully unsupervised methods. However, supervised methods crucially rely upon training sets that need to be manually annotated. This can be very expensive, especially when skilled annotators are required. Active learning (AL) promises to help reduce this annotation cost. Within the complex domain of HPSG parse selection, we show that ideas from ensemble learning can help further reduce the cost of annotation. Our main results show that at times, an ensemble model trained with randomly sampled examples can outperform a single model trained using AL. However, converting the single-model AL method into an ensemble-based AL method shows that even this much stronger baseline model can be improved upon. Our best results show a 73% reduction in annotation cost compared with single-model random sampling.
C1 Univ Edinburgh, Sch Informat, Edinburgh EH8 9LW, Midlothian, Scotland.
RP Osborne, M (reprint author), Univ Edinburgh, Sch Informat, Edinburgh EH8 9LW, Midlothian, Scotland.
CR Argamon-Engelson S, 1999, J ARTIF INTELL RES, V11, P335, DOI 10.1613/jair.612
   BALDRIDGE J, 2003, P 7 C NAT LANG LEARN
   BARAM Y, 2003, P 20 INT C MACH LEAR, P19
   COHN DA, 1995, ADV NEURAL INFORM PR, V7, P705
   COPESTAKE A, 2001, P 39 ANN M ASS COMP, P132
   FLICKINGER D, 2000, NAT LANG ENG, V6, P15
   Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534
   HINTON GE, 1999, P 9 INT C ART NEUR N, P1
   HWA R, 2003, P ICML WORKSH CONT L, P95
   HWA R, 2000, P 2000 JOINT SIGDAT, P42
   JOHNSON M, 1999, 37 ANN M ACL
   Malouf R., 2002, P 6 C NAT LANG LEARN, P49, DOI DOI 10.3115/1118853.1118871
   MCCALLUM A, 1998, P INT C MACH LEARN
   Oepen S., 2002, P 19 INT C COMP LING
   PEREIRA F, 1993, P ANN M ACL
   Roy N., 2001, P 18 INT C MACH LEAR, P441
   Seung H., 1992, COMPUTATIONAL LEARNI, P287
   TANG M, 2002, P 40 ANN M ASS COMP, P120
   THOMPSON CA, 1999, P 16 INT C MACH LEAR, P406
   Tong S., 2000, P 17 INT C MACH LEAR, P999
   TOUTANOVA K, 2003, P 14 EUR C MACH LEAR
NR 21
TC 3
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 89
EP 96
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100012
DA 2019-06-15
ER

PT B
AU Raux, A
   Eskenazi, M
AF Raux, A
   Eskenazi, M
GP acl
TI Non-native users in the let's go!! spoken dialogue system: Dealing with
   linguistic mismatch
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB This paper describes the CMU Let's Go!! bus information system, an experimental system designed to study the use of spoken dialogue interfaces by non-native speakers. The differences in performance of the speech recognition and language understanding modules of the system when confronted with native and non-native spontaneous speech are analyzed. Focus is placed on the linguistic mismatch between the user input and the system's expectations, and on its implications in terms of language modeling and parsing performance. The effect of including non-native data when building the speech recognition and language understanding modules is discussed. In order to close the gap between non-native and native input, a method is proposed to automatically generate confirmation prompts that are both close to the user's input and covered by the system's language model and grammar, in order to help the user acquire idiomatic expressions appropriate to the task.
C1 Carnegie Mellon Univ, Language Technol Inst, Pittsburgh, PA 15232 USA.
RP Raux, A (reprint author), Carnegie Mellon Univ, Language Technol Inst, 5000 Forbes Ave, Pittsburgh, PA 15232 USA.
CR Black  A., 1998, FESTIVAL SPEECH SYNT
   Bohus D., 2003, P 8 EUR C SPEECH COM, P597
   Bortfeld H, 1997, DISCOURSE PROCESS, V23, P119, DOI 10.1080/01638537709544986
   Byrne William, 1998, P SPEECH TECHN LANG, P37
   CLARK HH, 1986, COGNITION, V22, P1, DOI 10.1016/0010-0277(86)90010-7
   Eskenazi M., 1998, P SPEECH TECHN LANG, P77
   FISCHER V, 2001, P ASRU 01 MAD CAMP I
   FURUI S, 2001, P 6 NAT LANG PROC PA, P19
   Gustafson J., 1997, P EUR RHOD GREEC, P2275
   Huang X., 1992, COMPUTER SPEECH LANG, V7, P137
   Littlewood  W., 1981, COMMUNICATIVE LANGUA
   Raux A., 2003, P INT, P753
   Raux A., 2003, P WORKSH AUT SPEECH, P700
   RUDNICKY A, 2000, P ICSLP 2000 BEIJ CH
   Seneff S., 1998, P ICSLP 98 SYDN AUST
   TOMOKIYO LM, 2001, P MULTILINGUALITY SP
   Wang Z., 2003, P EUR 03 GEN SWITZ, P1449
   Ward W., 1994, P WORKSH HUM LANG TE, P213
   Witt S., 1997, P EUR, P633
NR 19
TC 3
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 217
EP 224
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100028
DA 2019-06-15
ER

PT B
AU Kepser, S
AF Kepser, S
GP ACL
TI Finite structure query: A tool for querying syntactically annotated
   corpora
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Finite structure query (fsq for short) is a tool for querying syntactically annotated corpora. fsq employs a query language of high expressive power, namely full first order logic. It can be used to query arbitrary finite structures, not just trees.
C1 Univ Tubingen, SFB 441, D-72074 Tubingen, Germany.
CR ABEILLE A, 1999, P EACL LINC
   BRANTS T, 1999, P ATALA TREEB WORKSH, P69
   BRANTS T, 1997, 98 CLAUS U SAARL COM
   HINRICHS E, 2000, P KONVENS 2000
   HOHLE T, 1985, KONTROVERSEN ALTE NE, V7, P329
   KALLMEYER L, 2003, TRAITEMENT AUTOMATIQ, V43
   Konig E., 2000, P COLING 2000, P1056
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   MIROVSKY J, 2002, P TREEB LING THEOR, P114
   PLAEHN O, 2000, 6 C APPL NAT LANG PR
   RANDALL B, 2000, CORPUSSEARCH USERS M
   ROHDE D, 2001, TGREP 2 TECHNICAL RE
   SCHILLER A, 1995, UNPUB GUIDLINES TAGG
   STEGMANN R, 2000, 239 SFS U TUB
   STOLBOUSHKIN A, 1994, LNCS, V933, P242
   Vardi M, 1982, P 14 ACM S THEOR COM, P137, DOI DOI 10.1145/800070.802186
   Wallis S., 2000, Literary & Linguistic Computing, V15, P339, DOI 10.1093/llc/15.3.339
NR 17
TC 3
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 179
EP 186
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200024
DA 2019-06-15
ER

PT B
AU Kruijff-Korbayova, I
   Ericsson, S
   Rodriguez, KJ
   Karagjosova, E
AF Kruijff-Korbayova, I
   Ericsson, S
   Rodriguez, KJ
   Karagjosova, E
GP ACL
TI Producing contextually appropriate intonation in an information-state
   based dialogue system
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Our goal is to improve the contextual appropriateness of spoken output in a dialogue system. We explore the use of the information state to determine the information structure of system utterances. We concentrate on the realization of information structure by intonation. We present the results of evaluating the contextual appropriateness of varied system output produced with a text-to-speech synthesis system that supports intonation annotation.
C1 Univ Saarland, D-6600 Saarbrucken, Germany.
CR Buring D., 1997, MEANING TOPIC FOCUS
   Ginzburg Jonathan, 1996, HDB CONT SEMANTIC TH
   GRICE M, IN PRESS PROSODIC TY
   HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C
   KRUIJFFKORBAYOV.I, 2003, P EACL 03 BUD HUNG
   LARSSON S, 2002, THESIS GOTEBORG U
   MONAGHAN A, 1994, P AAAI ESCA IEEE C S, P171
   PREVOST S, 1995, THESIS U PENNSYLVANI
   Rooth Mats, 1992, NAT LANG SEMANT, V1, P75, DOI DOI 10.1007/BF02342617
   SCHRODER M, 2001, P 4 ISCA WSH SPEECH
   Steedman M, 2000, LINGUIST INQ, V31, P649, DOI 10.1162/002438900554505
   STEEDMAN M, 2003, IN PRESS J LOGIC LAN
   Uhmann S., 1991, FOKUSPHONOLOGIE
NR 13
TC 3
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 227
EP 234
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200030
DA 2019-06-15
ER

PT B
AU Moore, RC
AF Moore, RC
GP ACL
TI Learning translations of named-entity phrases from parallel corpora
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We develop a new approach to learning phrase translations from parallel corpora, and show that it performs with very high coverage and accuracy in choosing French translations of English named-entity phrases in a test corpus of software manuals. Analysis of a subset of our results suggests that the method should also perform well on more general phrase translation tasks.
C1 Microsoft Res, Redmond, WA 98052 USA.
CR Al-Onaizan Y., 2002, P 40 ANN M ASS COMP, P400, DOI DOI 10.3115/1073083.1073150
   CHINCHOR N, 1997, P 7 MESS UND C
   Dagan I., 1997, Machine Translation, V12, P89, DOI 10.1023/A:1007926723945
   Dunning T., 1993, Computational Linguistics, V19, P61
   Kupiec J., 1993, P 31 ANN M ASS COMP, P17, DOI DOI 10.3115/981574.981577
   Melamed ID, 2000, COMPUT LINGUIST, V26, P221, DOI 10.1162/089120100561683
   MELAMED ID, 1997, P 2 C ENP METH NAT L
   Smadja F, 1996, COMPUT LINGUIST, V22, P1
   WU D, 1995, P TMI 95 6 INT C THE, V2, P354
   Yamamoto Kaoru, 2001, P WORKSH DAT DRIV MA, P87
NR 10
TC 3
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 259
EP 266
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200034
DA 2019-06-15
ER

PT B
AU Pado, S
   Lapata, M
AF Pado, S
   Lapata, M
GP ACL
TI Constructing semantic space models from parsed corpora
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Traditional vector-based models use word co-occurrence counts from large corpora to represent lexical meaning. In this paper we present a novel approach for constructing semantic spaces that takes syntactic relations into account. We introduce a formalisation for this class of models and evaluate their adequacy on two modelling tasks: semantic priming and automatic discrimination of lexical relations.
C1 Univ Saarland, Dept Computat Linguist, D-66041 Saarbrucken, Germany.
RI Pado, Sebastian/F-4883-2016
OI Pado, Sebastian/0000-0002-7529-6825
CR BALOTA DA, 1986, J EXP PSYCHOL LEARN, V12, P336, DOI 10.1037//0278-7393.12.3.336
   BURNARD L, 1995, BRIT NAT CORP CONS O
   Choi FYY, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P109
   Dunning T., 1993, Computational Linguistics, V19, P61
   Grefenstette G., 1994, EXPLORATIONS AUTOMAT
   HODGSON JM, 1991, LANG COGNITIVE PROC, V6, P169, DOI 10.1080/01690969108406942
   JONES MP, 1997, P 5 C APPL NAT LANG, P116
   KEENAN E, 1977, LINGUIST INQ, P62
   Kilgarriff A., 2000, P 2 INT C LANG RES E, P1371
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   Lee L, 1999, P 37 ANN M ASS COMP, P25, DOI DOI 10.3115/1034678.1034693
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   Livesay K, 1997, PROCEEDINGS OF THE NINETEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P436
   LOWE W, 2000, P 22 ANN C COGN SCI, P675
   Lowe W., 2001, P 23 ANN C COGN SCI, P576
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   McDonald S, 2000, THESIS U EDINBURGH
   PATEL M, 1998, P 4 NEUR COMP PSYCH, P199
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Schutze H, 1998, COMPUT LINGUIST, V24, P97
   Tesniere Lucien., 1959, ELEMENTS SYNTAXE STR
NR 21
TC 3
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 128
EP 135
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500017
DA 2019-06-15
ER

PT B
AU Wu, H
   Zhou, M
AF Wu, H
   Zhou, M
GP ACL
TI Synonymous collocation extraction using translation information
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Automatically acquiring synonymous collocation pairs such as <turn on, OBJ, light> and <switch on, OBJ, light> from corpora is a challenging task. For this task, we can, in general, have a large monolingual corpus and/or a very limited bilingual corpus. Methods that use monolingual corpora alone or use bilingual corpora alone are apparently inadequate because of low precision or low coverage. In this paper, we propose a method that uses both these resources to get an optimal compromise of precision and coverage. This method first gets candidates of synonymous collocation pairs based on a monolingual corpus and a word thesaurus, and then selects the appropriate pairs from the candidates using their translations in a second language. The translations of the candidates are obtained with a statistical translation model which is trained with a small bilingual corpus and a large monolingual corpus. The translation information is proved as effective to select synonymous collocation pairs. Experimental results indicate that the average precision and recall of our approach are 74% and 64% respectively, which outperform those methods that only use monolingual corpora and those that only use bilingual corpora.
C1 Microsoft Res Asia, Sigma Ctr 5F, Beijing 100080, Peoples R China.
CR BARZILAY R, 2001, P ACL EACL
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CAROLYN J, 1992, P 15 ANN INT ACM SIG, P77
   DRAGOMIR R, 2001, ACM CIKM 2001 10 INT
   Fung P., 1997, Machine Translation, V12, P53, DOI 10.1023/A:1007974605290
   Gasperin Caroline, 2001, WORKSH KNOWL ACQ CAT
   Grefenstette G., 1994, EXPLORATIONS AUTOMAT
   KIYOTA Y, 2002, P 19 INT C COMP LING
   KOEHN P, 2000, NAT C ART INT AAAI 2
   LANGKILDE I, 1998, P COLING ACL 1998
   Lin Dekang, 1998, P 36 ANN M ASS COMP
   SHIMOHATA M, 2002, P 3 INT C LANG RES E
   WANG W, 2001, P 6 NAT LANG PROC PA
   Zhou Ming, 2001, COMPUTATIONAL LINGUI, V6, P1, DOI 10.1.1.329.8202.
NR 14
TC 3
Z9 4
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 120
EP 127
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500016
DA 2019-06-15
ER

PT B
AU Abend, O
   Rappoport, A
AF Abend, Omri
   Rappoport, Ari
GP Assoc Computat Linguist
TI Fully Unsupervised Core-Adjunct Argument Classification
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID MODEL
AB The core-adjunct argument distinction is a basic one in the theory of argument structure. The task of distinguishing between the two has strong relations to various basic NLP tasks such as syntactic parsing, semantic role labeling and subcategorization acquisition. This paper presents a novel unsupervised algorithm for the task that uses no supervised models, utilizing instead state-of-the-art syntactic induction algorithms. This is the first work to tackle this task in a fully unsupervised scenario.
C1 [Abend, Omri; Rappoport, Ari] Hebrew Univ Jerusalem, Inst Comp Sci, Jerusalem, Israel.
RP Abend, O (reprint author), Hebrew Univ Jerusalem, Inst Comp Sci, Jerusalem, Israel.
EM omria01@cs.huji.ac.il; arir@cs.huji.ac.il
CR Abend Omri, 2010, ACL 10
   Abend Omri, 2009, ACL 09
   Baker Collin F., 1998, ACLCOLING 98
   Baldwin T, 2009, COMPUT LINGUIST, V35, P119, DOI 10.1162/coli.2009.35.2.119
   Boukobza Ram, 2009, EMNLP 09
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   Briscoe Ted, 1997, APPL NLP 97
   BURNARD L, 2000, USER REFERENCE GUIDE
   Carreras Xavier, 2005, CONLL 05
   Clark Alexander, 2003, EACL 03
   Collins M., 1999, THESIS
   Dowty David, 2000, DUAL ANAL ADJUNCTS C
   Erk Katrin, 2007, ACL 07
   Gabrilovich Evgeniy, 2005, IJCAI 05
   Graff David, 1995, LDC95T21
   Grenager Trond, 2006, EMNLP 06
   Hindle D., 1993, Computational Linguistics, V19, P103
   Hockenmaier J, 2003, THESIS
   Kipper Karin, 2000, AAAI 00
   Korhonen A., 2002, THESIS
   Li H, 1998, COMPUT LINGUIST, V24, P217
   Li Wei, 2003, ACL 03
   LIN D, 1998, COLING ACL 98
   Litkowski Ken, 2005, ACL SIGSEM WORKSH LI
   McCarthy D., 2001, THESIS
   Merlo P, 2006, COMPUT LINGUIST, V32, P341, DOI 10.1162/coli.2006.32.3.341
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Pradhan SS, 2008, COMPUT LINGUIST, V34, P289, DOI 10.1162/coli.2008.34.2.289
   Punyakanok V, 2008, COMPUT LINGUIST, V34, P257, DOI 10.1162/coli.2008.34.2.257
   RATNAPARKHI A, 1996, EMNLP 96
   Reichart Roi, 2010, CONLL 10
   Resnik P, 1996, COGNITION, V61, P127, DOI 10.1016/S0010-0277(96)00722-6
   Saint-Dizier Patrick, 2006, LREC 06
   SARKAR A, 2000, COLING 00
   Seginer Yoav, 2007, ACL 07
   Sporleder Caroline, 2009, EACL 09
   Swier Robert S., 2005, EMNLP 05
   Swier Robert S., 2004, EMNLP 04
   Toutanova K, 2008, COMPUT LINGUIST, V34, P161, DOI 10.1162/coli.2008.34.2.161
   Villavicencio Aline, 2002, CONLL 02
   Walde Sabine Schulte im, 2008, ACL 08
   Willis Dave, 2004, COLLINS COBUILD INTE
   Xue Nianwen, 2004, EMNLP 04
   Zapirain Benat, 2009, ACL 09
NR 44
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 226
EP 236
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300024
DA 2019-06-15
ER

PT B
AU Abend, O
   Reichart, R
   Rappoport, A
AF Abend, Omri
   Reichart, Roi
   Rappoport, Ari
GP Assoc Computat Linguist
TI Improved Unsupervised POS Induction through Prototype Discovery
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a novel fully unsupervised algorithm for POS induction from plain text, motivated by the cognitive notion of prototypes. The algorithm first identifies landmark clusters of words, serving as the cores of the induced POS categories. The rest of the words are subsequently mapped to these clusters. We utilize morphological and distributional representations computed in a fully unsupervised manner. We evaluate our algorithm on English and German, achieving the best reported results for this task.
C1 [Abend, Omri; Rappoport, Ari] Hebrew Univ Jerusalem, Inst Comp Sci, IL-91905 Jerusalem, Israel.
   [Reichart, Roi] Hebrew Univ Jerusalem, ICNC, IL-91905 Jerusalem, Israel.
RP Abend, O (reprint author), Hebrew Univ Jerusalem, Inst Comp Sci, IL-91905 Jerusalem, Israel.
EM omria01@cs.huji.ac.il; roiri@cs.huji.ac.il; arir@cs.huji.ac.il
CR Banko Michele, 2004, COLING 04
   Baroni Marco, 2009, LANGUAGE RESOURCES E
   Biemann Chris, 2006, COLING ACL 06 STUD R
   Brants Thorsten, 1997, NEGRA EXPORT FORMAT
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Clark Alexander, 2003, EACL 03
   Creutz Mathias, 2005, AKRR 05
   Dasgupta Sajib, 2007, EMNLP CONLL 07
   Freitag Dayne, 2004, COLING 04
   Gao Jianfeng, 2008, EMNLP 08
   Goldberg Yoav, 2008, ACL 08
   Goldsmith J, 2001, COMPUT LINGUIST, V27, P153, DOI 10.1162/089120101750300490
   Goldwater Sharon, 2007, ACL 07
   Graca Joao, 2009, NIPS 09
   Graff David, 1995, LDC95T21
   Haghighi Aria, 2006, HLT NAACL 06
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jiang Wenbin, 2009, ACL 09
   Johnson Mark, 2007, EMNLP CONLL 07
   Kuhn H. W., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109
   Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013
   Merialdo B., 1994, Computational Linguistics, V20, P155
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Ravi Sujith, 2009, ACL 09
   Reichart Roi, 2008, COLING 08
   Reichart Roi, 2010, CONLL 10
   Reichart Roi, 2009, CONLL 09
   Rosenberg Andrew, 2007, EMNLP 07
   Schutze Hinrich, 1995, EACL 95
   Seginer Yoav, 2007, ACL 07
   Smith Noah A., 2005, ACL 05
   Taylor John R., 2003, LINGUISTIC CATEGORIZ
   Van Gael Jurgen, 2009, EMNLP 09
   Wang Qin Iris, 2005, IEEE NLP KE 05
   Zhao Qiuye, 2009, EMNLP 09
NR 35
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1298
EP 1307
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300132
DA 2019-06-15
ER

PT B
AU Bansal, M
   Klein, D
AF Bansal, Mohit
   Klein, Dan
GP Assoc Computat Linguist
TI Simple, Accurate Parsing with an All-Fragments Grammar
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a simple but accurate parser which exploits both large tree fragments and symbol refinement. We parse with all fragments of the training set, in contrast to much recent work on tree selection in data-oriented parsing and tree-substitution grammar learning. We require only simple, deterministic grammar symbol refinement, in contrast to recent work on latent symbol refinement. Moreover, our parser requires no explicit lexicon machinery, instead parsing input sentences as character streams. Despite its simplicity, our parser achieves accuracies of over 88% F1 on the standard English WSJ task, which is competitive with substantially more complicated state-of-theart lexicalized and latent-variable parsers. Additional specific contributions center on making implicit all-fragments parsing efficient, including a coarse-to-fine inference scheme and a new graph encoding.
C1 [Bansal, Mohit; Klein, Dan] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
RP Bansal, M (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
EM mbansal@cs.berkeley.edu; klein@cs.berkeley.edu
CR Bod Rens, 2001, P ACL
   Bod Rens, 1993, P EACL
   Charniak E., 1998, P 6 WORKSH VER LARG
   Charniak Eugene, 2000, P NAACL
   Charniak Eugene, 2006, P HLT NAACL
   Charniak Eugine, 2005, P ACL
   CHIANG D, 2005, P ACL
   Chiang David, 2003, DATA ORIENTED PARSIN
   Cohn Trevor, 2009, P NAACL
   COLLINS M, 2002, P ACL
   Collins M., 1999, THESIS
   Deneefe Steve, 2009, P EMNLP
   Galley M, 2004, P HLT NAACL
   Goodman J., 2003, DATA ORIENTED PARSIN
   Goodman Joshua, 1996, P ACL
   Goodman Joshua, 1996, P EMNLP
   Henderson James, 2004, P ACL
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Johnson Mark, 2002, COMPUTATIONAL LINGUI, V28
   Klein D., 2003, P ACL
   Koehn P., 2003, P HLT NAACL
   Matsuzaki Takuya, 2005, P ACL
   Petrov S., 2006, P COLING ACL
   Petrov Slav, 2008, P EMNLP
   Petrov Slav, 2007, P NAACL HLT
   Post Matt, 2009, P ACL IJCNLP
   Resnik Philip, 1992, P COLING
   Scha Remko, 1990, COMPUTERTOEPASSINGEN
   Sima'an K., 1996, P COLING
   Simaan Khalil, 2000, P ACL
   Zollmann A., 2005, Journal of Automata, Languages and Combinatorics, V10, P367
   Zuidema W., 2007, P EMNLP CONLL
NR 32
TC 2
Z9 2
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1098
EP 1107
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300112
DA 2019-06-15
ER

PT S
AU Barzilay, R
AF Barzilay, Regina
BE Krahmer, E
   Theune, M
TI Probabilistic Approaches for Modeling Text Structure and Their
   Application to Text-to-Text Generation
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
ID LOCAL COHERENCE
AB Since the early days of generation research, it has been acknowledged that modeling the global structure of a document is crucial for producing coherent, readable output. However, traditional knowledge-intensive approaches have been of limited utility in addressing this problem since they cannot be effectively scaled to operate in domain-independent, large-scale applications. Due to this difficulty, existing text-to-text generation systems rarely rely on such structural information when producing an output text. Consequently, texts generated by these methods do not match the quality of those written by humans - they are often fraught with severe coherence violations and disfluencies.
   In this chapter,(1) I will present probabilistic models of document structure that can be effectively learned from raw document collections. This feature distinguishes these new models from traditional knowledge intensive approaches used in symbolic concept-to-text generation. Our results demonstrate that these probabilistic models can be directly applied to content organization, and suggest that these models can prove useful in an even broader range of text-to-text applications than we have considered here.
C1 MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
RP Barzilay, R (reprint author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
CR Althaus E., 2004, P 42 ANN M ASS COMP, P399
   Barzilay R, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P113
   Barzilay R, 2008, COMPUT LINGUIST, V34, P1, DOI 10.1162/coli.2008.34.1.1
   CHEN H, 2009, J ARTIF INTELL RES, P129
   Elsner M., 2007, P HLT NAACL, P436
   FLIGNER MA, 1986, J R STAT SOC B, V48, P359
   Foltz PW, 1998, DISCOURSE PROCESS, V25, P285, DOI 10.1080/01638539809545029
   Grosz B. J., 1986, Computational Linguistics, V12, P175
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   Halliday M. A. K., 1976, COHESION ENGLISH
   Harris Z, 1982, SUBLANGUAGE STUDIES, P231
   Hasler L., 2004, P 7 ANN CLUK RES C U, P100
   KARAMANIS N, 2001, P CLUK 4, P18
   KARAMANIS N, 2004, P ACL 04 BARC SPAIN, P391
   Kittredge R., 1991, Computational Intelligence, V7, P305, DOI 10.1111/j.1467-8640.1991.tb00403.x
   LAPATA M, 2003, P 41 M ASS COMP LING, P545
   Lin C.-Y., 2004, P WORKSH TEXT SUMM B, P74
   Mani I, 1999, ADV AUTOMATIC TEXT S
   Mann W, 1988, TEXT, V8, P243, DOI DOI 10.1515/TEXT.1.1988.8.3.243
   Marcu D., 2000, THEORY PRACTICE DISC
   MARCU D, 1997, P 35 ANN M ASS COMP, P96
   McKeown KR, 1985, TEXT GENERATION USIN
   MILTSAKAKI E, 2000, P 38 ANN M ASS COMP, P408
   Poesio M, 2004, COMPUT LINGUIST, V30, P309, DOI 10.1162/0891201041850911
   RAMBOW O, 1990, 5 INT WORKSH NAT LAN, P87
   Sauper C., 2009, P JOINT C 47 ANN M A, P208
   SPROAT R, 1993, MORPHOLOGY COMPUTATI
NR 27
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 1
EP 12
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600001
DA 2019-06-15
ER

PT S
AU Cahill, A
   Forst, M
AF Cahill, Aoife
   Forst, Martin
BE Krahmer, E
   Theune, M
TI Human Evaluation of a German Surface Realisation Ranker
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
DE generation evaluation; surface realisation; human evaluation; German;
   human judgements; automatic metrics; correlation
AB In this chapter we present a human-based evaluation of surface realisation alternatives. We examine the relative rankings of naturally occurring corpus sentences and automatically generated strings chosen by statistical models (language model, log-linear model), as well as the naturalness of the strings chosen by the log-linear model. We also investigate to what extent preceding context has an effect on choice. We show that native speakers do accept quite some variation in word order, but that there are clearly also factors that make certain realisation alternatives more natural than others. We then examine correlations between native speaker judgements of automatically generated German text and automatic evaluation metrics. We look at a number of metrics from the MT and Summarisation communities and find that for a relative ranking task, most automatic metrics perform equally well and have fairly strong correlations to the human judgements. In contrast, on a. naturalness judgement task, the correlation between the human judgements and the automatic metrics was quite weak, the General Text Matcher (GTM) tool providing the only metric that correlates with the human judgements at a statistically significant level.
C1 [Cahill, Aoife] Univ Stuttgart, IMS, D-70174 Stuttgart, Germany.
   [Forst, Martin] Microsoft, Powerset, San Francisco, CA 94304 USA.
RP Cahill, A (reprint author), Univ Stuttgart, IMS, D-70174 Stuttgart, Germany.
EM aoife.cahill@ims.uni-stuttgart.de; martin.forst@microsoft.com
OI Cahill, Aoife/0000-0002-3519-7726
FU Collaborative Research Centre at the University of Stuttgart. [SFB 732]
FX This work was partly funded by the Collaborative Research Centre (SFB
   732) at the University of Stuttgart.
CR Bangalore Srinivas, 2000, P 1 INT C NAT LANG G, P1
   Belz A., 2006, P 11 C EUR CHAPT ASS, P313
   Belz A, 2010, LECT NOTES ARTIF INT, V5790, P180, DOI 10.1007/978-3-642-15573-4_10
   Brants S., 2002, P WORKSH TREEB LING, P24
   Bresnan J., 2001, LEXICAL FUNCTIONAL S
   Cahill A., 2007, P 11 EUR WORKSH NAT, P17
   Cahill Aoife, 2009, P JOINT C 47 ANN M A, P817
   CALLAWAY C, 2003, P 18 INT JOINT C ART, P811
   Crouch R., 2002, P LREC PARSEVAL WORK, P67
   Dorr Bonnie, 2006, P ASS MACH TRANSL AM, P223
   Filippova K., 2007, P 45 ANN M ASS COMP, P320
   Gatt A, 2010, LECT NOTES ARTIF INT, V5790, P264, DOI 10.1007/978-3-642-15573-4_14
   Hall J., 2008, P WORKSH PARS GERM A, P47
   HOVY E, 2005, P DUC 2005
   Lin C. - Y, 2004, TEXT SUMMARIZATION B, P74
   MELAMED ID, 2003, NAACL 2003, P61
   Nakanishi H., 2005, P 9 INT WORKSH PARS, P93, DOI DOI 10.3115/1654494.1654504
   Nenkova A, 2010, LECT NOTES ARTIF INT, V5790, P222, DOI 10.1007/978-3-642-15573-4_12
   Owczarzak K, 2009, P JOINT C 47 ANN M A, P190
   OWCZARZAK K, 2008, MACHINE TRANSLATION, V21, P95
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Reiter E., 2002, P 2 INT C NAT LANG G, P97
   ROHRER C, 2006, P LANG RES EV C LREC, P2206
   STENT A, 2005, P CICLING 2005 MEX C, P341
   VELLDAL E, 2008, THESIS U OSLO
   Velldal E, 2006, P 2006 C EMP METH NA, P517
NR 26
TC 2
Z9 2
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 201
EP +
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600011
DA 2019-06-15
ER

PT B
AU Chiarcos, C
AF Chiarcos, Christian
GP Assoc Computat Linguist
TI Towards robust multi-tool tagging. An OWL/DL-based approach
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper describes a series of experiments to test the hypothesis that the parallel application of multiple NLP tools and the integration of their results improves the correctness and robustness of the resulting analysis.
   It is shown how annotations created by seven NLP tools are mapped onto toolindependent descriptions that are defined with reference to an ontology of linguistic annotations, and how a majority vote and ontological consistency constraints can be used to integrate multiple alternative analyses of the same token in a consistent way.
   For morphosyntactic (parts of speech) and morphological annotations of three German corpora, the resulting merged sets of ontological descriptions are evaluated in comparison to (ontological representation of) existing reference annotations.
C1 [Chiarcos, Christian] Univ Potsdam, Potsdam, Germany.
RP Chiarcos, C (reprint author), Univ Potsdam, Potsdam, Germany.
EM chiarcos@uni-potsdam.de
CR Aschenbrenner A, 2006, P INT WORKSH DIG LIB, P27
   Bakker D., 1993, TECHNICAL REPORT
   Bickel B., 2000, GOALS PRINCIPLES AUT
   Bickel Balthasar, 2002, P LREC 2002 WORKSH R
   Borin L., 2000, P 2 INT C LANG RES E
   Brants S., 2002, P WORKSH TREEB LING, P24
   Brants Sabine, 2002, P 3 C LANG RES EV LR, P1643
   Brill E., 1998, P COLING ACL 98, V1, P191
   Buitelaar Paul, 2006, P 5 INT C LANG RES E
   Buyko E., 2008, P INT C LANG RES EV
   Carl M., 2000, Machine Translation, V15, P223, DOI 10.1023/A:1011663225529
   Chiarcos C., 2008, TRAITEMENT AUTOMATIQ, V49
   Chiarcos C., 2010, WORKSH LANG RES LANG
   Chiarcos C., 2010, 4 LING ANN WORKSH LA
   Chiarcos C., 2008, LDV FORUM, V23, P1
   Cimiano P., 2003, P LORR SAARL WORKSH, P33
   Crysmann B., 2002, P 40 ANN M ACL PHIL, P441
   Davis B., 2008, P 6 INT C LANG RES E
   de Cea G. Aguado, 2002, P ECAI 2002 WORKSH S
   de Cea G. Aguado, 2004, P INT C INF TECHN CO
   de Cea G. Aguado, 2008, P 6 INT C LANG RES E
   Dipper S., 2007, WORKING PAPERS SFB, V632, P7
   Egner M. T., 2007, P 7 IEEE INT S CLUST, P317
   Gangemi Aldo, 2003, P INT C ONT DAT APPL, P820
   Gietz P., 2006, P 2 IEEE INT C E SCI, P133
   Heid U., 2008, P 3 INT JOINT C NLP
   Hellmann S., 2010, 7 SEM WEB C ESWC 201
   Hinrichs E., 2006, P E MELD WORKSH DIG
   Hovy E., 2006, COMPANION VOLUME SHO, P57
   Ide Nancy, 2004, P 4 INT LANG RES EV, P135
   Jarvinen Timo, 1997, P 5 C APPL NAT LANG, P64, DOI DOI 10.3115/974557.974568
   Kemps-Snijders Marc, 2009, International Journal of Metadata, Semantics and Ontologies, V4, P261, DOI 10.1504/IJMSO.2009.029230
   Kermes H., 2002, P 3 INT C LANG RES E, P1805
   Kim JD, 2003, BIOINFORMATICS, V19, pi180, DOI 10.1093/bioinformatics/btg1023
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   Langendoen D. Terence, 2003, EMELD WORKSH DIG ANN
   Leech G., 1996, EAGLES RECOMMENDATIO
   Luis T., 2009, P 3 LING ANN WORKSH, P99
   Mandel M., 2006, TEXT MINING ONTOLOGI
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Meyer R., 2003, LINGUISTISCHE BEITRA, P92
   Petrov S., 2007, P NAACL HLT 2007, P404
   Petrova S, 2009, TRAIT AUTOM LANG, V50, P47
   Rehm G., 2007, P REC ADV NAT LANG P
   Sampson G., 1995, ENGLISH COMPUTER SUS
   Saulwick A., 2005, P 17 C ADV INF SYST
   Scheffczyk J., 2006, P 4 INT C FORM ONT I, P289
   Schiller A., 1999, TECHNICAL REPORT
   Schmid H., 1994, P INT C NEW METH LAN, P44
   Schmid H., 2008, P 22 INT C COMP LING
   Sharoff S., 2008, P 6 INT C LANG RES E
   Sirin E, 2007, J WEB SEMANT, V5, P51, DOI 10.1016/j.websem.2007.03.004
   Skut W., 1998, P ESSLLI WORKSH REC
   Stede M., 2004, P ACL WORKSH DISC AN, P96
   Toutanova K., 2003, P 2003 C N AM ASS CO
   Tufis D., 2000, P LREC 2000 ATH, P1105
   van Halteren H, 2001, COMPUT LINGUIST, V27, P199, DOI 10.1162/089120101750300508
   van Halteren H., 1998, P 36 ANN M ASS COMP
   Wagner A., 2004, 4 INT C LANG RES EV
   Zavrel J., 2000, P 2 INT C LANG RES E
   Zielinski A., 2008, P C FIN STAT METH NA
NR 61
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 659
EP 670
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300068
DA 2019-06-15
ER

PT B
AU Chinnakotla, MK
   Raman, K
   Bhattacharyya, P
AF Chinnakotla, Manoj K.
   Raman, Karthik
   Bhattacharyya, Pushpak
GP Assoc Computat Linguist
TI Multilingual Pseudo-Relevance Feedback: Performance Study of Assisting
   Languages
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID INFORMATION-RETRIEVAL
AB In a previous work of ours Chinnakotla et al. (2010) we introduced a novel framework for Pseudo-Relevance Feedback (PRF) called MultiPRF. Given a query in one language called Source, we used English as the Assisting Language to improve the performance of PRF for the source language. MulitiPRF showed remarkable improvement over plain Model Based Feedback (MBF) uniformly for 4 languages, viz., French, German, Hungarian and Finnish with English as the assisting language. This fact inspired us to study the effect of any source-assistant pair on MultiPRF performance from out of a set of languages with widely different characteristics, viz., Dutch, English, Finnish, French, German and Spanish. Carrying this further, we looked into the effect of using two assisting languages together on PRF.
   The present paper is a report of these investigations, their results and conclusions drawn therefrom. While performance improvement on MultiPRF is observed whatever the assisting language and whatever the source, observations are mixed when two assisting languages are used simultaneously. Interestingly, the performance improvement is more pronounced when the source and assisting languages are closely related, e.g., French and Spanish.
C1 [Chinnakotla, Manoj K.; Raman, Karthik; Bhattacharyya, Pushpak] Indian Inst Technol, Dept Comp Sci & Engn, Bombay, Maharashtra, India.
RP Chinnakotla, MK (reprint author), Indian Inst Technol, Dept Comp Sci & Engn, Bombay, Maharashtra, India.
EM manoj@cse.iitb.ac.in; karthikr@cse.iitb.ac.in; pb@cse.iitb.ac.in
CR Amati Giambattista, 2004, ECIR 04, P127
   Birch Alexandra, 2008, EMNLP 08, P745
   Braschler M, 2004, INFORM RETRIEVAL, V7, P7, DOI 10.1023/B:INRT.0000009438.69013.fa
   Braschler Martin, 1998, ECDL 98, P183
   BUCKLEY C, 1994, TREC 94, P69
   Cao G., 2008, P 31 ANN INT ACM SIG, P243, DOI DOI 10.1145/1390334.1390377
   Chinnakotla Manoj K., 2010, SIGIR 10
   COLLINSTHOMPSON K, 2005, CIKM 05, P704
   Cronen-Townsend Steve, 2004, CIKM, P236
   Dagan Ido, 1991, ACL 91 MORR NJ US, P130
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Dumais T. Susan, 1997, AAAI 97, P18
   Gao Wei, 2008, INEWS 08 ACM WORKSH, P17
   Hawking D., 1999, Information Retrieval, V1, P115, DOI 10.1023/A:1009938405269
   Hieu Hoang, 2007, ACL 07, P177
   Jourlin P, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P283, DOI 10.1145/312624.312701
   Lafferty J., 2001, SIGIR Forum, P111
   Lafferty John, 2003, KLUWER INT SERIES IR, P1
   Lavrenko V., 2001, SIGIR Forum, P120
   LAVRENKO V, 2002, SIGIR 2002, P175
   Meij Edgar, 2009, INFORM PROCESSING MA
   Metzler D, 2007, SIGIR, P311
   MITRA M, 1998, SIGIR 98, P206
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Ounis I, 2005, LECT NOTES COMPUT SC, V3408, P517
   Philipp Koehn, 2005, MT SUMM 05
   ROBERTSON S, 2006, CIKM 2006, P78
   Sakai T., 2005, ACM T ASIAN LANGUAGE, V2, P111, DOI DOI 10.1145/1105696.1105699
   Sparck-Jones K, 2000, INFORM PROCESS MANAG, V36, P779, DOI 10.1016/S0306-4573(00)00015-7
   Talvensaari T, 2007, ACM T INFORM SYST, V25, DOI 10.1145/1198296.1198300
   TAO T, 2006, SIGIR 2006, P162
   Tiedemann Jrg, 2001, COMPLEX 01, P143
   Voorhees E. M., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P61
   VOORHEES EM, 2006, TREC 2005
   Wu Dan, 2008, INEWS 08 ACM WORKSH, P71
   XU J, 2002, SIGIR 02, P269
   Xu JX, 2000, ACM T INFORM SYST, V18, P79, DOI 10.1145/333135.333138
   Xu Y, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P59, DOI 10.1145/1571941.1571954
   ZHAI C, 2001, CIKM, P403, DOI DOI 10.1145/502585.502654
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
NR 40
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1346
EP 1356
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300137
DA 2019-06-15
ER

PT B
AU DeNero, J
   Klein, D
AF DeNero, John
   Klein, Dan
GP Assoc Computat Linguist
TI Discriminative Modeling of Extraction Sets for Machine Translation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a discriminative model that directly predicts which set of phrasal translation rules should be extracted from a sentence pair. Our model scores extraction sets: nested collections of all the overlapping phrase pairs consistent with an underlying word alignment. Extraction set models provide two principle advantages over word-factored alignment models. First, we can incorporate features on phrase pairs, in addition to word links. Second, we can optimize for an extraction-based loss function that relates directly to the end task of generating translations. Our model gives improvements in alignment quality relative to state-of-the-art unsupervised and supervised baselines, as well as providing up to a 1.4 improvement in BLEU score in Chinese-to-English translation experiments.
C1 [DeNero, John; Klein, Dan] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
RP DeNero, J (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
EM denero@cs.berkeley.edu; klein@cs.berkeley.edu
CR Ayan Necip Fazil, 2006, P ANN C ASS COMP LIN
   Ayan Necip Fazil, 2005, P C HUM LANG TECHN E
   Birch Alexandra, 2006, P C ASS MACH TRANSL
   Blunsom Phil, 2009, P ANN C ASS COMP LIN
   Charniak Eugene, 1998, COMPUTATIONAL LINGUI
   Cherry Colin, 2007, P ANN C N AM CHAPT A
   Cherry Colin, 2006, P ANN C ASS COMP LIN
   Chiang D, 2008, P C EMP METH NAT LAN
   Chiang David, 2007, COMPUTATIONAL LINGUI
   Crammer K, 2003, J MACH LEARN RES, V3, P951, DOI 10.1162/jmlr.2003.3.4-5.951
   DeNero John, 2008, P C EMP METH NAT LAN
   DeNero John, 2006, P NAACL WORKSH STAT
   DeNero John, 2008, P ANN C ASS COMP LIN
   DeNero John, 2007, P ANN C ASS COMP LIN
   Deng Yonggang, 2009, P ANN C ASS COMP LIN
   Fraser A., 2007, P JOINT C EMP METH N
   Fraser Alexander, 2006, P ANN C ASS COMP LIN
   Galley Michel, 2006, P ANN C ASS COMP LIN
   Goodman Joshua, 1996, P ANN M ASS COMP LIN
   Haghighi Aria, 2009, P ANN C ASS COMP LIN
   Huang Liang, 2007, P ANN C ASS COMP LIN
   Kaariainen Matti, 2009, P C EMP METH NAT LAN
   Klein Dan, 2003, P C N AM CHAPT ASS C
   Koehn Philipp, 2007, P ANN C ASS COMP LIN
   Koehn Philipp, 2009, P WORKSH STAT MACH T
   Koehn Philipp, 2003, P C N AM CHAPT ASS C
   Lacoste-Julien Simon, 2006, P ANN C N AM CHAPT A
   Li Z., 2009, P WORKSH STAT MACH T
   Liang Percy, 2006, P ANN C N AM CHAPT A
   Lopez Adam, 2007, P C EMP METH NAT LAN
   MARCU D, 2002, P C EMP METH NAT LAN
   Melamed I. Dan, 2000, COMPUTATIONAL LINGUI
   Moore R. C., 2007, P MT SUMM 11
   Moore Robert C., 2005, P C EMP METH NAT LAN
   Ney Hermann, 1996, P C COMP LING
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och Franz Josef, 1999, P C EMP METH NAT LAN
   Papineni Kishore, 2002, P ANN C ASS COMP LIN
   Stolcke A., 2002, P INT C SPOK LANG PR
   Taskar Ben, 2005, P C EMP METH NAT LAN
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   Zhang Hao, 2008, P ANN C ASS COMP LIN
   Zhang Hao, 2006, P C EMP METH NAT LAN
   Zhang Hao, 2005, P ANN C ASS COMP LIN
NR 44
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1453
EP 1463
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300147
DA 2019-06-15
ER

PT B
AU Gerber, M
   Chai, JY
AF Gerber, Matthew
   Chai, Joyce Y.
GP Assoc Computat Linguist
TI Beyond NomBank: A Study of Implicit Arguments for Nominal Predicates
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Despite its substantial coverage, NomBank does not account for all withinsentence arguments and ignores extrasentential arguments altogether. These arguments, which we call implicit, are important to semantic processing, and their recovery could potentially benefit many NLP applications. We present a study of implicit arguments for a select group of frequent nominal predicates. We show that implicit arguments are pervasive for these predicates, adding 65% to the coverage of NomBank. We demonstrate the feasibility of recovering implicit arguments with a supervised classification model. Our results and analyses provide a baseline for future work on this emerging task.
C1 [Gerber, Matthew; Chai, Joyce Y.] Michigan State Univ, Dept Comp Sci, E Lansing, MI 48824 USA.
RP Gerber, M (reprint author), Michigan State Univ, Dept Comp Sci, E Lansing, MI 48824 USA.
EM gerberm2@cse.msu.edu; jchai@cse.msu.edu
CR Burchardt A., 2005, P 6 INT WORKSH COMP
   CARRERAS X, 2005, INTRO CONLL 2005 SHA
   CHAMBERS N., 2008, P 46 ANN M ASS COMP, P789
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P3746
   Efron B., 1993, INTRO BOOTSTRAP
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Fillmore C.J., 2001, P WORNET OTH LEX RES
   Gerber Matthew, 2009, ASS COMPUTATIONAL LI, P146
   Graff D., 2003, ENGLISH GIGAWORD LIN
   Hajic Jan, 2009, P 13 C COMP NAT LANG, V13, P1
   Iida Ryu, 2007, P LING ANN WORKSH AC
   Imamura Kenji, 2009, ASS COMPUTATIONAL LI, P85
   Kingsbury P., 2002, P HUM LANG TECHN C H
   Kipper K., 2005, THESIS
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Meyers A., 2007, TECHNICAL REPORT
   Palmer M. S., 1986, P 24 ANN M ASS COMP, P10, DOI 10.3115/981131.981135
   Pantel P, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P321
   Prasad R., 2008, PENN DISCOURSE TREEB
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Punyakanok V, 2008, COMPUT LINGUIST, V34, P257, DOI 10.1162/coli.2008.34.2.257
   Ruppenhofer J., 2009, P WORKSH SEM EV REC, P106
   Sasano Ryohei, 2004, P 20 INT C COMP LING, P1201
   Surdeanu Mihai, 2008, CONLL 2008, P159
NR 25
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1583
EP 1592
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300160
DA 2019-06-15
ER

PT B
AU Guo, WW
   Diab, M
AF Guo, Weiwei
   Diab, Mona
GP Assoc Computat Linguist
TI Combining Orthogonal Monolingual and Multilingual Sources of Evidence
   for AllWords WSD
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Word Sense Disambiguation remains one of the most complex problems facing computational linguists to date. In this paper we present a system that combines evidence from a monolingual WSD system together with that from a multilingual WSD system to yield state of the art performance on standard All-Words data sets. The monolingual system is based on a modification of the graph based state of the art algorithm In-Degree. The multilingual system is an improvement over an AllWords unsupervised approach, SALAAM. SALAAM exploits multilingual evidence as a means of disambiguation. In this paper, we present modifications to both of the original approaches and then their combination. We finally report the highest results obtained to date on the SENSEVAL 2 standard data set using an unsupervised method, we achieve an overall F measure of 64.58 using a voting scheme.
C1 [Guo, Weiwei] Columbia Univ, Dept Comp Sci, New York, NY 10115 USA.
   [Diab, Mona] Columbia Univ, Ctr Computat Learning Syst, New York, NY 10115 USA.
RP Guo, WW (reprint author), Columbia Univ, Dept Comp Sci, New York, NY 10115 USA.
EM weiwei@cs.columbia.edu; mdiab@ccls.columbia.edu
CR Carpuat M, 2007, P 2007 JOINT C EMP M, P61
   CHAN YS, 2007, P 45 ANN M ASS COMP, P33
   DIAB M, 2002, P 40 ANN M ASS COMP, P255
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Guo Weiwei, 2009, P WORKSH SEM EV REC, P64
   Ide N, 1998, COMPUT LINGUIST, V24, P1
   Jiang J. J., 1997, P INT C RES COMP LIN
   Leacock C., 1998, WORDNET ELECT LEXICA
   LESK ME, 1986, P SIGDOC C TOR JUN
   Mihalcea R., 2005, P C HUM LANG TECHN E, P411, DOI DOI 10.3115/1220575.1220627
   Miller George A., 1990, COMMUN ACM, P39
   Navigli R., 2009, ACM COMPUT SURV, V1, P1, DOI DOI 10.1145/1459352.1459355
   Navigli R, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1683
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   PALMER M, 2001, P ACL SIGLEX SENS 2
   PEDERSEN T, 2005, 200525 UMSI
   Pradhan  S., 2007, P 4 INT WORKSH SEM E, P87
   Sinha R., 2007, P IEEE INT C SEM COM
   SNYDER B, 2004, SENSEVAL 3, P41
NR 19
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1542
EP 1551
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300156
DA 2019-06-15
ER

PT B
AU Honnibal, M
   Curran, JR
   Bos, J
AF Honnibal, Matthew
   Curran, James R.
   Bos, Johan
GP Assoc Computat Linguist
TI Rebanking CCGbank for improved NP interpretation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID TREEBANK; CORPUS; CCG
AB Once released, treebanks tend to remain unchanged despite any shortcomings in their depth of linguistic analysis or coverage of specific phenomena. Instead, separate resources are created to address such problems. In this paper we show how to improve the quality of a treebank, by integrating resources and implementing improved analyses for specific constructions. We demonstrate this rebanking process by creating an updated version of CCG-bank that includes the predicate-argument structure of both verbs and nouns, base-NP brackets, verb-particle constructions, and restrictive and non-restrictive nominal modifiers; and evaluate the impact of these changes on a statistical parser.
C1 [Honnibal, Matthew; Curran, James R.] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
   [Bos, Johan] Univ Groningen, NL-9700 AB Groningen, Netherlands.
RP Honnibal, M (reprint author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
EM mhonn@it.usyd.edu.au; james@it.usyd.edu.au; bos@meaningfactory.com
CR Bies Ann, 1995, MSCIS9506 U PENNS
   Boxwell SA, 2008, SIXTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, LREC 2008, P3112
   Butt Miriam, 2006, LEXICAL SEMANTICS LF
   Cahill A, 2008, COMPUT LINGUIST, V34, P81, DOI 10.1162/coli.2008.34.1.81
   Clark S, 2007, COMPUT LINGUIST, V33, P493, DOI 10.1162/coli.2007.33.4.493
   Constable James, 2009, P AUSTR LANG TECHN A, P114
   Curran J. R, 2007, P C PAC ASS COMP LIN, P210
   DORAN C, 1994, P COLING KY JAP, P922
   FLICKINGER D, 2000, NAT LANG ENG, V6, P15
   Gildea D, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P57
   HINDLE D, 1983, 7590142 NAV RES LAB
   Hockenmaier J, 2003, THESIS
   Hockenmaier J, 2007, COMPUT LINGUIST, V33, P355, DOI 10.1162/coli.2007.33.3.355
   Hockenmaier Julia, 2002, P 3 INT C LANG RES E, P1974
   Kaplan Ronald, 1982, MENTAL REPRESENTATIO, P173
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Martin Paul, 2002, WALL STREET J GUIDE
   Meyers Adam, 2004, FRONTIERS CORPUS ANN, P24
   MIYAO Y, 2004, P 1 INT JOINT C NAT, P684
   Oepen S., 2004, RES LANGUAGE COMPUTA, V2, P575
   Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264
   Pollard C., 1994, HEAD DRIVEN PHRASE S
   Shen LB, 2008, LANG RESOUR EVAL, V42, P1, DOI 10.1007/s10579-007-9043-7
   Shieber S. M., 1986, CSLI LECT NOTES, V4
   Steedman M., 2000, SYNTACTIC PROCESS
   Tse Daniel, 2008, P AUSTR LANG TECHN W, V6, P151
   Vadas D., 2008, P ACL 08 HLT COL OH, P335
   Vadas D., 2007, P 45 ANN M ASS COMP, P240
NR 28
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 207
EP 215
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300022
DA 2019-06-15
ER

PT B
AU Kim, J
   Li, JJ
   Lee, JH
AF Kim, Jungi
   Li, Jin-Ji
   Lee, Jong-Hyeok
GP Assoc Computat Linguist
TI Evaluating Multilanguage-Comparability of Subjectivity Analysis Systems
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Subjectivity analysis is a rapidly growing field of study. Along with its applications to various NLP tasks, much work have put efforts into multilingual subjectivity learning from existing resources. Multilingual subjectivity analysis requires language-independent criteria for comparable outcomes across languages. This paper proposes to measure the multilanguage-comparability of subjectivity analysis tools, and provides meaningful comparisons of multilingual subjectivity analysis from various points of view.
C1 [Kim, Jungi; Li, Jin-Ji; Lee, Jong-Hyeok] Pohang Univ Sci & Technol, Div Elect & Comp Engn, Pohang, South Korea.
RP Kim, J (reprint author), Pohang Univ Sci & Technol, Div Elect & Comp Engn, Pohang, South Korea.
EM yangpa@postech.ac.kr; ljj@postech.ac.kr; jhlee@postech.ac.kr
CR Abbasi A, 2008, ACM T INFORM SYST, V26, DOI 10.1145/1344411.1344413
   Banea C., 2008, P C EMP METH NAT LAN, P127
   Bautin M, 2008, P INT C WEBL SOC MED
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Brooke Julian, 2009, P RANLP 2009 BOR BUL
   Cesarano Carmine, 2007, P INT C WEBL SOC MED
   Esuli A., 2006, P 5 INT C LANG RES E, V6, P417, DOI DOI 10.1155/2015/715730
   Kim J, 2009, LECT NOTES ARTIF INT, V5459, P112
   Kim S.-M., 2006, P MAIN C HUM LANG TE, P200
   Mihalcea Rada, 2007, P ANN M ASS COMP LIN, P976
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79
   Riloff E., 2003, P C EMP METH NAT LAN
   Wan X., 2008, P C EMP METH NAT LAN, P553, DOI DOI 10.3115/1613715.1613783
   Wan X., 2009, P JOINT C 47 ANN M A, V1, P235
   Wiebe J, 2005, LECT NOTES COMPUT SC, V3406, P486
   Wiebe Janyce, 2003, P 2003 AAAI SPRING S
   Wilson TS, 2005, PHIL EDUC, P347, DOI 10.3115/1220575.1220619
NR 17
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 595
EP 603
DI 10.1115/PVP2010-25404
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300061
DA 2019-06-15
ER

PT B
AU Lin, SH
   Chen, B
AF Lin, Shih-Hsiang
   Chen, Berlin
GP Assoc Computat Linguist
TI A Risk Minimization Framework for Extractive Speech Summarization
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID TEXT
AB In this paper, we formulate extractive summarization as a risk minimization problem and propose a unified probabilistic framework that naturally combines supervised and unsupervised summarization models to inherit their individual merits as well as to overcome their inherent limitations. In addition, the introduction of various loss functions also provides the summarization framework with a flexible but systematic way to render the redundancy and coherence relationships among sentences and between sentences and the whole document, respectively. Experiments on speech summarization show that the methods deduced from our framework are very competitive with existing summarization approaches.
C1 [Lin, Shih-Hsiang; Chen, Berlin] Natl Taiwan Normal Univ, Taipei, Taiwan.
RP Lin, SH (reprint author), Natl Taiwan Normal Univ, Taipei, Taiwan.
EM shlin@csie.ntnu.edu.tw; berlin@csie.ntnu.edu.tw
CR Berger J. O., 1985, STAT DECISION THEORY, DOI 10.1007/978-1-4757-4286-2
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Chen B., 2009, ACM T ASIAN LANG INF, V8, P2
   Chen YT, 2009, IEEE T AUDIO SPEECH, V17, P95, DOI 10.1109/TASL.2008.2005031
   Conroy J. M., 2001, P 24 ANN INT ACM SIG, P406
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Fattah MA, 2009, COMPUT SPEECH LANG, V23, P126, DOI 10.1016/j.csl.2008.04.002
   Ferrier  L., 2001, MAXIMUM ENTROPY APPR
   Furui S, 2004, IEEE T SPEECH AUDI P, V12, P401, DOI 10.1109/TSA.2004.828699
   Galley M., 2006, P EMP METH NAT LANG, P364
   Goel V, 2000, COMPUT SPEECH LANG, V14, P115, DOI 10.1006/csla.2000.0138
   Gong Y., 2001, P 24 ANN INT ACM SIG, P19, DOI DOI 10.1145/383952.383955
   Inoue Akira, 2004, P ICASSP, P599
   Kolcz A., 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P365
   Koumpis Konstantinos, 2000, P ICSLP 2000, P688
   Kumar S., 2004, P HLT NAACL, P169
   Kupiec J., 1999, P ANN INT ACM SIGIR, P68
   Lin C.-Y, 2004, P WORKSH TEXT SUMM B
   Lin Shih-Hsiang, 2009, P ANN C INT SPEECH C, P1507
   Lin Shih-Hsiang, 2009, ACM T ASIAN LANG INF, V8
   Mani I, 1999, ADV AUTOMATIC TEXT S
   Maskey Sameer R., 2003, P EUR GEN SWITZ SEP, P1173
   McKeown K, 2005, INT CONF ACOUST SPEE, P997
   Mihalcea Rada, 2005, P C EMP METH NAT LAN, P404
   Radev DR, 2004, INFORM PROCESS MANAG, V40, P919, DOI 10.1016/j.ipm.2003.10.006
   Shen D., 2007, INT JOINT C ART INT, P2862
   Wang HM, 2005, INT J COMPUT LINGUIS, V10, P219
   Zhai C., 2008, STAT LANGUAGE MODELS
   Zhai CX, 2006, INFORM PROCESS MANAG, V42, P31, DOI 10.1016/j.ipm.2004.11.003
   ZHANG JJ, 2007, 2007 IEEE WORKSH, P195
NR 30
TC 2
Z9 2
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 79
EP 87
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300009
DA 2019-06-15
ER

PT B
AU Reiter, N
   Frank, A
AF Reiter, Nils
   Frank, Anette
GP Assoc Computat Linguist
TI Identifying Generic Noun Phrases
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper presents a supervised approach for identifying generic noun phrases in context. Generic statements express rule-like knowledge about kinds or events. Therefore, their identification is important for the automatic construction of knowledge bases. In particular, the distinction between generic and non-generic statements is crucial for the correct encoding of generic and instance-level information. Generic expressions have been studied extensively in formal semantics. Building on this work, we explore a corpus-based learning approach for identifying generic NPs, using selections of linguistically motivated features. Our results perform well above the baseline and existing prior work.
C1 [Reiter, Nils; Frank, Anette] Heidelberg Univ, Dept Computat Linguist, Bergheimer Str 58, D-69115 Heidelberg, Germany.
RP Reiter, N (reprint author), Heidelberg Univ, Dept Computat Linguist, Bergheimer Str 58, D-69115 Heidelberg, Germany.
EM reiter@cl.uni-heidelberg.de; frank@cl.uni-heidelberg.de
CR Baayen R. H., 1996, CELEX2
   Bos J, 2009, J APPL LOGIC, V7, P100, DOI 10.1016/j.jal.2007.07.008
   Butt Miriam, 2002, P GRAMM ENG EV WORKS
   Carlson G, 1977, THESIS
   Cimiano  P., 2006, ONTOLOGY LEARNING PO
   Crouch Dick, 2010, XLE DOCUMENTATION
   Dahl Osten, 1975, FORMAL SEMANTICS NAT, P99
   DECLERCK R, 1991, LINGUISTICS, V29, P79, DOI 10.1515/ling.1991.29.1.79
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Ferro Lisa, 2005, ACE ENGLISH TRAINING
   Gelfond M., 2007, HDB KNOWLEDGE REPRES
   Hearst M.A., 1992, P 14 INT C COMP LING, P539, DOI DOI 10.3115/992133.992154
   Heim I., 1982, THESIS
   Herbelot Aurelie, 2008, FRUITS EMPIRICAL LIN, V1
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   Krifka Manfred, 1995, GENERIC BOOK
   LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745
   Lifschitz V, 2002, ARTIF INTELL, V138, P39, DOI 10.1016/S0004-3702(02)00186-8
   Lifschitz Vladimir, 2008, P AAAI
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Mathew Thomas, 2009, 6 MEDW COMP LING C
   Mitchell A., 2003, ACE 2 VERSION 1 0
   Niles I., 2001, P INT C FORM ONT INF, P2, DOI DOI 10.1145/505168.505170
   Pappas A, 1998, J CHILD LANG, V25, P19, DOI 10.1017/S0305000997003292
   Ponzetto S., 2007, P 22 NAT C ART INT A, P1440
   Quine Willard Van Orman, 1960, WORD OBJECT
   REITER R, 1980, ARTIF INTELL, V13, P81, DOI 10.1016/0004-3702(80)90014-4
   Schmid Helmut, 1994, P C NEW METH LANG PR, P12
   Suh Soyoung, 2006, THESIS
   Witten I. H., 2002, SIGMOD REC, V31, P76, DOI DOI 10.1145/507338.507355
   Zirn Cacilia, 2008, P 5 EUR SEM WEB C
NR 31
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 40
EP 49
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300005
DA 2019-06-15
ER

PT B
AU Riesa, J
   Marcu, D
AF Riesa, Jason
   Marcu, Daniel
GP Assoc Computat Linguist
TI Hierarchical Search for Word Alignment
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present a simple yet powerful hierarchical search algorithm for automatic word alignment. Our algorithm induces a forest of alignments from which we can efficiently extract a ranked kappa-best list. We score a given alignment within the forest with a flexible, linear discriminative model incorporating hundreds of features, and trained on a relatively small amount of annotated data. We report results on Arabic-English word alignment and translation tasks. Our model outperforms a GIZA++ Model-4 baseline by 6.3 points in F-measure, yielding a 1.1 BLEU score increase over a state-of-the-art syntax-based machine translation system.
C1 [Riesa, Jason; Marcu, Daniel] Univ Southern Calif, Viterbi Sch Engn, Inst Informat Sci, Los Angeles, CA 90089 USA.
RP Riesa, J (reprint author), Univ Southern Calif, Viterbi Sch Engn, Inst Informat Sci, Los Angeles, CA 90089 USA.
EM riesa@isi.edu; marcu@isi.edu
CR Blunsom Phil, 2006, P 44 ANN M ACL SYDN
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Cherry Colin, 2006, P 44 ANN M ACL SYDN
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Chiang David, 2008, P EMNLP HON HI US
   Collins M, 2003, PLOUGHSHARES, V29, P29
   COLLINS M, 2002, P C EMP METH NAT LAN
   DeNero John, 2007, P 45 ANN M ACL PRAG
   Fossum Victoria, 2008, P 3 WORKSH STAT MACH
   Fraser Alexander, 2007, P EMNLP CONLL PRAG C
   Galley Michel, 2004, P NAACL
   Galley Michel, 2006, P 44 ANN M ACL SYDN
   Haghighi Aria, 2009, P ACL IJCNLP 2009 SI
   HUANG L, 2005, P 9 INT WORKSH PARS
   Huang Liang, 2008, P 46 ANN M ACL COL O
   Huang Liang, 2007, P 45 ANN M ACL PRAG
   Ittycheriah Abraham, 2005, P HLT EMNLP VANC BC
   Klein D., 2001, P 7 INT WORKSH PARS
   Lacoste-Julien Simon, 2006, P HLT EMNLP NEW YORK
   Liu Yang, 2005, P 43 ANN M ACL ANN A
   Moore Robert C., 2006, P 44 ANN M ACL SYDN
   Moore Robert C., 2005, P EMNLP VANC BC CAN
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Papineni Kishore, 2002, P 40 ANN M ACL PHIL
   Petrov Slav, 2006, P 44 ANN M ACL SYDN
   Talbot David, 2008, P ACL 08 HLT COL OH
   Taskar Ben, 2005, P HLT EMNLP VANC BC
   Wu D, 1997, COMPUT LINGUIST, V23, P377
NR 28
TC 2
Z9 2
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 157
EP 166
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300017
DA 2019-06-15
ER

PT B
AU Rudzicz, F
AF Rudzicz, Frank
GP Assoc Computat Linguist
TI Correcting errors in speech recognition with articulatory dynamics
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We introduce a novel mechanism for incorporating articulatory dynamics into speech recognition with the theory of task dynamics. This system reranks sentence-level hypotheses by the likelihoods of their hypothetical articulatory realizations which are derived from relationships learned with aligned acoustic/articulatory data. Experiments compare this with two baseline systems, namely an acoustic hidden Markov model and a dynamic Bayes network augmented with discretized representations of the vocal tract. Our system based on task dynamics reduces word-error rates significantly by 10.2% relative to the best baseline models.
C1 [Rudzicz, Frank] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
RP Rudzicz, F (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
EM frank@cs.toronto.edu
CR Browman Catherine, 1986, PHONOLOGY YB, V3, P219, DOI DOI 10.1017/S0952675700000658
   D'Ausillo A, 2009, CURR BIOL, V19, P381, DOI 10.1016/j.cub.2009.01.017
   Deng Jianping, 2005, AC SPEECH SIGN PROC, V1, p[1121, 18]
   Friedland B, 2005, CONTROL SYSTEM DESIG
   Ghahramani Z, 1998, LECT NOTES ARTIF INT, V1387, P168
   Goldstein L, 2006, ACTION TO LANGUAGE VIA THE MIRROR NEURON SYSTEM, P215, DOI 10.1017/CBO9780511541599.008
   Goldstein Louis, 2003, PHONETICS PHONOLOGY
   Guenther F., 2004, SPEECH MOTOR CONTROL, P29
   Hardcastle W. J., 1999, COARTICULATION THEOR
   Hasegawa-Johnson Mark, 2007, INT SPEECH LEXICON P
   Hogden J, 2001, IEEE IMTC P, P1105, DOI 10.1109/IMTC.2001.928251
   Kirchhoff K., 1999, THESIS
   LIBERMAN AM, 1985, COGNITION, V21, P1, DOI 10.1016/0010-0277(85)90021-6
   Markov K, 2006, SPEECH COMMUN, V48, P161, DOI 10.1016/j.specom.2005.07.003
   Murphy K.P., 1998, TECHNICAL REPORT
   Murphy K. P., 2002, THESIS
   NAM H, 2003, P 15 INT C PHON SCI, P2253
   Nam H., 2006, TADA TASK DYNAMICS A
   O'Shaughnessy D, 2000, SPEECH COMMUNICATION
   Richmond K, 2003, COMPUT SPEECH LANG, V17, P153, DOI 10.1016/S0885-2308(03)00005-6
   Roweis S., 1999, THESIS
   Rudzicz F., 2008, P 8 INT SEM SPEECH P
   Rudzicz Frank, 2009, P 2009 IEEE INT C AC
   Sakoe  H., 1978, IEEE T ACOUSTICS SPE
   Saltzman E. L., 1989, ECOL PSYCHOL, V1, P333, DOI [10.1207/s15326969eco0104_2, DOI 10.1207/S15326969EC00104_]
   Saltzman Elliot M., 1986, TASK DYNAMIC COORDIN, P129
   Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001
   Wrench A., 1999, MOCHA TIMIT ARTICULA
   Yunusova Y, 2009, J SPEECH LANG HEAR R, V52, P547, DOI 10.1044/1092-4388(2008/07-0218)
   Zue V., 1989, P ESCA TUT RES WORKS, V2, P35
NR 30
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 60
EP 68
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300007
DA 2019-06-15
ER

PT B
AU Seeker, W
   Rehbein, I
   Kuhn, J
   van Genabith, J
AF Seeker, Wolfgang
   Rehbein, Ines
   Kuhn, Jonas
   van Genabith, Josef
GP Assoc Computat Linguist
TI Hard Constraints for Grammatical Function Labelling
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID INFERENCE
AB For languages with (semi-) free word order (such as German), labelling grammatical functions on top of phrase-structural constituent analyses is crucial for making them interpretable. Unfortunately, most statistical classifiers consider only local information for function labelling and fail to capture important restrictions on the distribution of core argument functions such as subject, object etc., namely that there is at most one subject (etc.) per clause. We augment a statistical classifier with an integer linear program imposing hard linguistic constraints on the solution space output by the classifier, capturing global distributional restrictions. We show that this improves labelling quality, in particular for argument grammatical functions, in an intrinsic evaluation, and, importantly, grammar coverage for treebank-based (Lexical-Functional) grammar acquisition and parsing, in an extrinsic evaluation.
C1 [Seeker, Wolfgang; Kuhn, Jonas] Univ Stuttgart, Inst Maschinelle Sprachverarbeitung, Stuttgart, Germany.
   [Rehbein, Ines] Univ Saarland, Dept Comp Linguist & Phonet, D-66123 Saarbrucken, Germany.
   [van Genabith, Josef] Dublin City Univ, CNGL, Dublin 9, Ireland.
   [van Genabith, Josef] Dublin City Univ, Sch Comp, Dublin 9, Ireland.
RP Seeker, W (reprint author), Univ Stuttgart, Inst Maschinelle Sprachverarbeitung, Stuttgart, Germany.
EM seeker@ims.uni-stuttgart.de; rehbein@coli.uni-sb.de;
   jonas@ims.uni-stuttgart.de; josef@computing.dcu.ie
CR Benson Steven J., 2001, TECHNICAL REPORT
   Berger Adam L., 1996, COMPUTATIONAL LINGUI, V22, P71
   Blaheta D., 2000, P 1 ANN M N AM CHAPT, P234
   Brants Sabine, 2002, P WORKSH TREE BANKS, P2441
   Brants Thorsten, 1997, P EMNLP, V97, P64
   Bresnan J., 2001, LEXICAL FUNCTIONAL S
   Butt Miriam, 2002, COLING 02 GRAMMAR EN, V15, P7
   Cahill A, 2008, COMPUT LINGUIST, V34, P81, DOI 10.1162/coli.2008.34.1.81
   Cahill Aoife, 2003, P WORKSH ID STRAT MU, P1724
   Cahill Aoife, 2004, THESIS
   Cahill Aoife, 2004, P 42 ANN M ASS COMP, P319
   Chrupala Grzegorz, 2006, ASS COMPUTATIONAL LI
   CLARK S, 2002, P LREC 2002 PARS WOR, P60
   Clarke J, 2008, J ARTIF INTELL RES, V31, P399, DOI 10.1613/jair.2433
   Crouch R., 2002, P LREC PARSEVAL WORK, P67
   Eisenberg Peter, 2006, GRUNDRISS DTSCH GRAM
   Forst Martin, 2007, P ACL 2007
   Forst Martin, 2004, P COLING WORKSH LING
   Kazama Jun'Ichi, 2005, MACH LEARN, V60
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   Klenner Manfred, 2007, P ACL 2007 DEM POST
   Klenner Manfred, 2005, P RANLP 2005
   Koo T., 2005, P C HUM LANG TECHN E, P507
   Kubler Sandra, 2005, P RANLP 2005 BOR BUL
   Magerman David M., 1995, P 33 ANN M ASS COMP
   Martins Andre F. T., 2009, P ACL 2009
   McDonald Ryan, 2006, P EACL, V6
   Miyao Yusuke, 2003, P C REC ADV NAT LANG, V2
   Nivre J., 2007, Natural Language Engineering, P95, DOI 10.1017/S1351324906004505
   Petrov S, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P433
   Punyakanok V, 2004, P 20 INT C COMP LING
   Punyakanok V, 2008, COMPUT LINGUIST, V34, P257, DOI 10.1162/coli.2008.34.2.257
   Ratnaparkhi A., 1998, THESIS
   Rehbein I., 2009, THESIS
   Rehbein Ines, 2009, P LFG C 2009
   Roth Dan, 2004, P CONNL 2004
   Schiller A., 1994, TECHNICAL REPORT
   Schiller A., 1999, TECHNICAL REPORT
   Schmid H., 1994, P INT C NEW METH LAN, V12
   Sima'an Khalil, 2008, P 22 INT C COMP LING, P889
NR 40
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1087
EP 1097
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300111
DA 2019-06-15
ER

PT B
AU Sonderegger, M
   Niyogi, P
AF Sonderegger, Morgan
   Niyogi, Partha
GP Assoc Computat Linguist
TI Combining data and mathematical models of language change
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID ENGLISH; STRESS; EVOLUTION
AB English noun/verb (N/V) pairs (contract, cement) have undergone complex patterns of change between 3 stress patterns for several centuries. We describe a longitudinal dataset of N/V pair pronunciations, leading to a set of properties to be accounted for by any computational model. We analyze the dynamics of 5 dynamical systems models of linguistic populations, each derived from a model of learning by individuals. We compare each model's dynamics to a set of properties observed in the N/V data, and reason about how assumptions about individual learning affect population-level dynamics.
C1 [Sonderegger, Morgan; Niyogi, Partha] Univ Chicago, Chicago, IL 60637 USA.
RP Sonderegger, M (reprint author), Univ Chicago, Chicago, IL 60637 USA.
EM morgan@cs.uchicago.edu; niyogi@cs.uchicago.edu
CR Arciuli J, 2003, LANG SPEECH, V46, P353, DOI 10.1177/00238309030460040101
   Baayen R.H., 1996, CELEX2 CD ROM
   Baker A, 2008, LANG LINGUIST COMPAS, V2, P289, DOI 10.1111/j.1749-818x.2008.00054.x
   Baxter GJ, 2009, LANG VAR CHANGE, V21, P257, DOI 10.1017/S095439450999010X
   Berwick R. C., 1995, 1516 AI MIT
   Blevins J, 2006, THEOR LINGUIST, V32, P117, DOI 10.1515/TL.2006.009
   Choudhury M., 2007, THESIS
   Choudhury M., 2007, P 9 M ACL SPEC INT G, P65
   Choudhury M, 2006, JASSS-J ARTIF SOC S, V9
   Daland Robert, 2007, P 45 ANN M ASS COMP, V45, P936
   de Boer B., 2009, ILLC PREPRINT SERIES
   Griffiths TL, 2007, COGNITIVE SCI, V31, P441, DOI 10.1080/15326900701326576
   Guion SG, 2003, LANG SPEECH, V46, P403, DOI 10.1177/00238309030460040301
   Hansson GO, 2008, LANG LINGUIST COMPAS, V2, P859, DOI 10.1111/j.1749-818x.2008.00077.x
   Hirsch M.W., 2004, DIFFERENTIAL EQUATIO
   Hock Hans Henrich, 1991, PRINCIPLES HIST LING
   Kalish ML, 2007, PSYCHON B REV, V14, P288, DOI 10.3758/BF03194066
   KELLY MH, 1989, J MEM LANG, V28, P690, DOI 10.1016/0749-596X(89)90004-1
   KELLY MH, 1988, J EXP PSYCHOL HUMAN, V14, P389, DOI 10.1037/0096-1523.14.3.389
   KELLY MH, 1988, COGNITION, V30, P107, DOI 10.1016/0010-0277(88)90037-6
   Kirby S, 2008, P NATL ACAD SCI USA, V105, P10681, DOI 10.1073/pnas.0707835105
   KLEIN S, 1966, MECH TRANSL, V9, P67
   KLEIN S, 1974, TOMORROWS LINGUISTIC, P276
   Klein S., 1969, P 1969 C COMP LING, P1
   Kokeritz Helge, 1953, SHAKESPEARES PRONUNC
   Komarova NL, 2001, J THEOR BIOL, V209, P43, DOI 10.1006/jtbi.2000.2240
   Landsbergen F., 2009, THESIS
   Lass R., 1992, CAMBRIDGE HIST ENGLI, V3, P1476
   Lass Roger, 1992, CAMBRIDGE HIST ENGLI, V2, P23, DOI DOI 10.1017/CH0L9780521264754.003
   Levens P., MANIPULUS VOCABULORU
   MacMahon M., 1998, CAMBRIDGE HIST ENGLI, V4, P1476
   McMahon Michael K. C., 1998, CAMBRIDGE HIST ENGLI, VIV, P373
   Minett JW, 2008, LINGUA, V118, P19, DOI 10.1016/j.lingua.2007.04.001
   Minkova Donka, 1997, ENGL LANG LINGUIST, V1, P135
   Mitchener W. Garrett, 2005, P 2 WORKSH PSYCH MOD, P10
   Niyogi P, 2006, CURR STUD LINGUIST, V43, P1
   Niyogi P, 1996, COGNITION, V61, P161, DOI 10.1016/S0010-0277(96)00718-4
   Ohala J., 1981, PAPERS PARASESSION L, P178
   Pearl L, 2007, LANG LEARN DEV, V3, P43, DOI 10.1080/15475440709337000
   PHILLIPS BS, 1984, LANGUAGE, V60, P320, DOI 10.2307/413643
   Ross John R, 1973, FESTSCHRIFT M HALLE, P166
   SHERMAN D, 1975, LINGUISTICS, P43
   Sonderegger M., 2010, ORIGINS SOUND PATTER
   Sonderegger M., 2009, DYNAMICAL SYSTEMS MO
   Sonderegger M., 2010, P BERKELEY IN PRESS, V36
   Strogatz S. H., 1994, NONLINEAR DYNAMICS C
   Wang W.S.Y., 2005, COMPUTATIONAL LINGUI, P65
   Yang C., 2001, LANG VAR CHANGE, V12, P231, DOI DOI 10.1017/S0954394500123014
   Yang C, 2002, KNOWLEDGE LEARNING N
NR 49
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1019
EP 1029
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300104
DA 2019-06-15
ER

PT S
AU van der Sluis, I
   Mellish, C
AF van der Sluis, Ielka
   Mellish, Chris
BE Krahmer, E
   Theune, M
TI Towards Empirical Evaluation of Affective Tactical NLG
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
ID STEREOTYPE THREAT; NEGATIVE AFFECT; GENERATION
AB One major aim of research in affective natural language generation is to be able to use language intelligently to induce effects on the emotions of the reader/hearer. Although varying the content of generated language ("strategic" choices) might be expected to change the effect on emotions, it is not obvious that varying the form of the language ("tactical" choices) can do this. This chapter discusses two experiments carried out to show emotional effects of tactical variations. With the first experiment we were not able to show clear, statistically significant differences between the effects of the different texts in readers. We discuss a number of possible reasons and, building on our discoveries, we present a second experiment which does demonstrate such effects. This represents an important step towards the empirical evaluation of affective NLG systems.
C1 [van der Sluis, Ielka] Trinity Coll Dublin, Dept Comp Sci, Dublin, Ireland.
   [Mellish, Chris] Univ Aberdeen, Dept Comp Sci, Aberdeen, Scotland.
RP van der Sluis, I (reprint author), Trinity Coll Dublin, Dept Comp Sci, Dublin, Ireland.
EM ielka.vandersluis@cs.tcd.ie; c.mellish@abdn.ac.uk
FU EPSRC [EP/E011764/1]; Science Foundation Ireland under a CSET
   (CNGL/CSET)
FX This work was supported by the EPSRC platfrom grant Affecting people
   with natural language (EP/E011764/1) and also in part by Science
   Foundation Ireland under a CSET grant (CNGL/CSET). We would like to
   thank the people who contributed to this study, most notably Louise
   Phillips,Emiel Krahmer, Linda Moxey, Graeme Ritchie, Judith Masthoff,
   Albert Gatt, Kees van Deemter and Nikiforos Karamanis.
CR Bard EG, 1996, LANGUAGE, V72, P32, DOI 10.2307/416793
   Brown RP, 2003, J EXP SOC PSYCHOL, V39, P626, DOI 10.1016/S0022-1031(03)00039-8
   Cacioppo J. T., 2000, HDB EMOTIONS, P173
   Cadinu M, 2005, PSYCHOL SCI, V16, P572, DOI 10.1111/j.0956-7976.2005.01577.x
   CARENINI G, 2000, P 38 ANN M ASS COMP, P150
   de Rosis F, 1999, ARTIF INTELL MED, V17, P1, DOI 10.1016/S0933-3657(99)00014-7
   de Rosis F., 2000, LECT NOTES ARTIF INT, V1814, P204
   Finucane ML, 2000, HEALTH RISK SOC, V2, P159, DOI 10.1080/713670162
   FLEISCHMAN M, 2002, P 2 INT NAT LANG GEN
   GRAFF D, 2000, PHILOS TOPICS, V28, P45
   HOVY EH, 1990, ARTIF INTELL, V43, P153, DOI 10.1016/0004-3702(90)90084-D
   Kennedy C, 2007, LINGUIST PHILOS, V30, P1, DOI 10.1007/s10988-006-9008-0
   Lang P. J., 1980, TECHNOLOGY MENTAL HL, P119
   Lazarus R. S., 1980, EMOTION THEORY RES E, V1, P189
   Levin IP, 1998, ORGAN BEHAV HUM DEC, V76, P149, DOI 10.1006/obhd.1998.2804
   Mackinnon A, 1999, PERS INDIV DIFFER, V27, P405, DOI 10.1016/S0191-8869(98)00251-7
   Mairesse F., 2008, P 46 ANN M ASS COMP, P165
   MOORE J, 2004, P 7 INT FLOR ART INT, P123
   Moxey LM, 2000, APPL COGNITIVE PSYCH, V14, P237, DOI 10.1002/(SICI)1099-0720(200005/06)14:3<237::AID-ACP641>3.0.CO;2-R
   O'Hara LA, 2000, CREATIVITY RES J, V13, P197
   RUSSELL JA, 1989, J PERS SOC PSYCHOL, V57, P493, DOI 10.1037/0022-3514.57.3.493
   Teigen KH, 2003, J BEHAV DECIS MAKING, V16, P53, DOI 10.1002/bdm.432
   THOMPSON H, 1977, P CHIC LING SOC CHIC
   TVERSKY A, 1981, SCIENCE, V211, P453, DOI 10.1126/science.7455683
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037//0022-3514.54.6.1063
   Watson D, 1999, MANUAL POSITIVE NEGA
   WILSON E, 2007, HDB EMOTION ELICITAT
NR 27
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 242
EP +
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600013
DA 2019-06-15
ER

PT B
AU Yamangil, E
   Shieber, SM
AF Yamangil, Elif
   Shieber, Stuart M.
GP Assoc Computat Linguist
TI Bayesian Synchronous Tree-Substitution Grammar Induction and its
   Application to Sentence Compression
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We describe our experiments with training algorithms for tree-to-tree synchronous tree-substitution grammar (STSG) for monolingual translation tasks such as sentence compression and paraphrasing. These translation tasks are characterized by the relative ability to commit to parallel parse trees and availability of word alignments, yet the unavailability of large-scale data, calling for a Bayesian tree-to-tree formalism. We formalize nonparametric Bayesian STSG with epsilon alignment in full generality, and provide a Gibbs sampling algorithm for posterior inference tailored to the task of extractive sentence compression. We achieve improvements against a number of baselines, including expectation maximization and variational Bayes training, illustrating the merits of nonparametric inference over the space of grammars as opposed to sparse parametric inference with a fixed grammar.
C1 [Yamangil, Elif; Shieber, Stuart M.] Harvard Univ, Cambridge, MA 02138 USA.
RP Yamangil, E (reprint author), Harvard Univ, Cambridge, MA 02138 USA.
EM elif@seas.harvard.edu; shieber@seas.harvard.edu
OI Shieber, Stuart/0000-0002-7733-8195
CR CLARKE J., 2006, P COLING ACL MAIN C, P144
   Clarke J, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P377
   Cohn T., 2007, P C EMP METH NAT LAN, P73
   Cohn Trevor, 2009, EMNLP 09, P352
   Cohn Trevor, 2008, COLING 2008, P137
   Cohn Trevor, 2009, NAACL 09, P548
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   DeNero John, 2008, EMNLP 08, P314
   DeNero John, 2006, STATMT 06, P31
   Eisner Jason, 2003, ACL 03, P205
   Galley M, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P273
   Galley M., 2007, HUMAN LANGUAGE TECHN, P180
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gildea D., 2009, P ACL IJCNLP 2009 C, P45
   Goldwater S, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P673
   JING H, 2000, P 6 C APPL NAT LANG, P310
   Klein D., 2003, P ADV NEUR INF PROC, V15, P3
   Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9
   Lari K., 1990, Computer Speech and Language, V4, P35, DOI 10.1016/0885-2308(90)90022-X
   Liu Ding, 2009, P 2009 C EMP METH NA, P1308
   MacKay D. J. C., 1997, TECHNICAL REPORT
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Riezler Stefan, 2003, NAACL 03, P118
   Turner Jenine, 2005, ACL 2005, P290
   Yamangil Elif, 2008, P 46 ANN M ASS COMP, P137
NR 25
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 937
EP 947
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300096
DA 2019-06-15
ER

PT B
AU Ayan, NF
   Dorr, BJ
AF Ayan, Necip Fazil
   Dorr, Bonnie J.
GP COLING
TI Going Beyond AER: An Extensive Analysis of Word Alignments and Their
   Impact on MT
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents an extensive evaluation of five different alignments and investigates their impact on the corresponding MT system output. We introduce new measures for intrinsic evaluations and examine the distribution of phrases and untranslated words during decoding to identify which characteristics of different alignments affect translation. We show that precision-oriented alignments yield better MT output (translating more words and using longer phrases) than recall-oriented alignments.
C1 [Ayan, Necip Fazil; Dorr, Bonnie J.] Univ Maryland, Inst Adv Comp Studies UMIACS, College Pk, MD 20742 USA.
RP Ayan, NF (reprint author), Univ Maryland, Inst Adv Comp Studies UMIACS, College Pk, MD 20742 USA.
EM nfa@umiacs.umd.edu; bonnie@umiacs.umd.edu
CR Ayan N.F., 2005, P HLT EMNLP, P65
   BENTASKAR, 2005, P EMNLP 2005
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CALLISONBURCH C, 2004, P ACL 2004
   Chiang David, 2005, P ACL 2005
   Franz B, 2003, J ETHN MIGR STUD, V29, P5, DOI 10.1080/1369183032000076696
   Goutte Cyril, 2004, P ACL, P502
   ITTYCHERIAH A, 2005, P EMNLP 2005
   KOEHN P, 2003, P HLTNAACL 2003
   KOEHN P, 2004, P AMTA 2004
   Lavie Alon, 2005, P WORKSH INTR EXTR E
   MARCU D, 2002, P EMNLP 2002
   Melamed ID, 2000, COMPUT LINGUIST, V26, P221, DOI 10.1162/089120100561683
   MOORE RC, 2005, P EMNLP 2005
   Och F J, 2000, GIZA TRAINING STAT T
   Och F. J, 2003, P ACL 2003
   OCH FJ, 2000, P COLING 2000
   Papineni Kishore, 2002, P ACL 2002
   Vogel S., 1996, P 16 INT C COMP LING, P836
NR 19
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 9
EP 16
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200002
DA 2019-06-15
ER

PT B
AU Blache, P
   Hemforth, B
   Rauzy, S
AF Blache, Philippe
   Hemforth, Barbara
   Rauzy, Stephane
GP COLING
TI Acceptability Prediction by Means of Grammaticality Quantification
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We propose in this paper a method for quantifying sentence grammaticality. The approach based on Property Grammars, a constraint-based syntactic formalism, makes it possible to evaluate a grammaticality index for any kind of sentence, including ill-formed ones. We compare on a sample of sentences the grammaticality indices obtained from PG formalism and the acceptability judgements measured by means of a psycholinguistic analysis. The results show that the derived grammaticality index is a fairly good tracer of acceptability scores.
C1 [Blache, Philippe; Hemforth, Barbara; Rauzy, Stephane] Univ Aix Marseille 1, CNRS, Lab Parole & Langage, F-13621 Aix En Provence, France.
RP Blache, P (reprint author), Univ Aix Marseille 1, CNRS, Lab Parole & Langage, 29 Ave Robert Schuman, F-13621 Aix En Provence, France.
EM blache@lpl.univ-aix.fr; hemforth@lpl.univ-aix.fr; rauzy@lpl.univ-aix.fr
RI Rauzy, Stephane/D-6960-2018
OI Rauzy, Stephane/0000-0003-1098-515X
CR BARD E, 1996, LANGUAGE, V72, P1
   BLACHE P, 2005, LECT NOTES COMPUTER
   BLACHE P, 2006, P ROB METH AN NAT LA
   Chomsky Noam, 1975, LOGICAL STRUCTURE LI
   Croft W., 2003, COGNITIVE LINGUISTIC
   FILLMORE C, 1998, LEXICAL CONSTRUCTION
   FOTH K, 2005, LECT NOTES COMPUTER
   KAY P, 1999, LANGUAGE
   KELLER F, 2003, P ACCSS 03
   Keller Frank, 2000, THESIS U EDINBURGH
   MENZEL W, 1998, P COLINGACL WORKSH P
   PRINCE A, 1993, TR2 RUCCS
   Sag Ivan A., 2003, SYNTACTIC THEORY FOR
   SCHRODER I, 2002, THESIS U HAMBURG
   SORACE A, 2005, LINGUA, V115
NR 15
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 57
EP 64
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200008
DA 2019-06-15
ER

PT B
AU Cetinoglu, O
   Oflazer, K
AF Cetinoglu, Oezlem
   Oflazer, Kemal
GP COLING
TI Morphology-Syntax Interface for Turkish LFG
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper investigates the Use Of sublexical units as a solution to handling the complex morphology with productive derivational processes, in the development of a lexical functional grammar for Turkish. Such sublexical units make it possible to expose the internal structure of words with multiple derivations to the grammar rules in a uniform manner. This in turn leads to more succinct and manageable rules. Further, the semantics of the derivations can also be systematically reflected in a compositional way by constructing PRED values on the fly. We illustrate how we use sublexical units for handling simple productive derivational morphology and more interesting cases such as causativization, etc., which change verb valency. Our priority is to handle several linguistic phenomena in order to observe the effects of our approach on both the c-structure and the f-structure representation, and grammar writing, leaving the coverage and evaluation issues aside for the moment.
C1 [Cetinoglu, Oezlem; Oflazer, Kemal] Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Istanbul, Turkey.
RP Cetinoglu, O (reprint author), Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Istanbul, Turkey.
EM ozlemc@su.sabanciuniv.edu; oflazer@sabanciuniv.edu
CR Abeille Anne, 2003, BUILDING EXPLOITING
   BARKER C, 1990, GRAMMATICAL RELATION
   Bozsahin C, 2002, COMPUT LINGUIST, V28, P145, DOI 10.1162/089120102760173634
   BUTT M, 2005, P 10 INT LFG C BERG
   Cakici Ruket, 2005, P ACL STUD RES WORKS, P73
   Dalrymple M, 2001, SYNTAX SEMANTICS, V34, pIX
   Eryigit G., 2006, P EACL 2006 11 C EUR
   FRANK A, 2003, TREEBANKS
   GUNGORDU Z, 1995, MACHINE TRANSLATION, V10, P515
   GUNGORDU Z, 1998, JOINT C FORM GRAMM H
   KABAK B, 2007, LINGUISTICS IN PRESS, V45
   KAPLAN RM, 1988, ALTERNATIVE CONCEPTI
   Kaplan Ronald, 1982, MENTAL REPRESENTATIO, P173
   MAXWELL JT, 1996, P LFG 96 C RANK XER
   O'Donovan R, 2005, COMPUT LINGUIST, V31, P329, DOI 10.1162/089120105774321073
   Oflazer K, 2003, COMPUT LINGUIST, V29, P515, DOI 10.1162/089120103322753338
   Oflazer K., 1994, Literary & Linguistic Computing, V9, P137
NR 17
TC 2
Z9 2
U1 0
U2 4
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 153
EP 160
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200020
DA 2019-06-15
ER

PT B
AU Foth, K
   By, T
   Menzel, W
AF Foth, Kilian
   By, Tomas
   Menzel, Wolfgang
GP COLING
TI Guiding a Constraint Dependency Parser with Supertags
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We investigate the utility of supertag information for guiding an existing dependency parser of German. Using weighted constraints to integrate the additionally available information, the decision process of the parser is influenced by changing its preferences, without excluding alternative structural interpretations from being considered. The paper reports on a series of experiments using varying models of supertags that significantly increase the parsing accuracy. In addition, an upper bound on the accuracy that can be achieved with perfect supertags is estimated.
C1 [Foth, Kilian; By, Tomas; Menzel, Wolfgang] Univ Hamburg, Dept Informat, Hamburg, Germany.
RP Foth, K (reprint author), Univ Hamburg, Dept Informat, Hamburg, Germany.
EM foth@informatik.uni-hamburg.de; by@informatik.uni-hamburg.de;
   menzel@informatik.uni-hamburg.de
CR Bangalore S, 1999, COMPUT LINGUIST, V25, P237
   Brants Sabine, 2002, P WORKSH TREEB LING
   BRANTS T, 2000, P 6 C APPL NAT LANG, P224, DOI DOI 10.3115/974147.974178
   BRANTS T, 1997, NEGRA ANNOTATIONSSCH
   CHEN J, 2002, P 6 INT WORKSH TREE
   Clark S., 2004, P 20 INT C COMP LING
   CLARK S, 2004, P 42 M ACL
   DAUM M, 2003, P 11 C EACL BUD HUNG
   DAUM M, 2004, P 4 INT C LANG RES E, P99
   FOTH K, 2004, 7 K VER NAT SPRACH K, P45
   Foth K. A., 2006, P 21 INT C COMP LING
   FOTH KA, 2002, 2 WORKSH ROB METH AN, P21
   MCDONALD R, 2005, P HUM LANG TECHN C H
   NASR A, 2004, COL WORKSH REC ADV D, P17
   SARKAR A, 2000, P COLING WORKSH EFF
   SCHABES Y, 1991, CURRENT ISSUES PARSI
   SCHRODER I, 2000, TRAITEMENT AUTOMATIQ, V41, P97
   Wang W, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P238
   Wang W., 2004, P ACL WORKSH INCR PA, P42
   WHITE CM, 2000, THESIS PURDUE U WEST
NR 20
TC 2
Z9 2
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 289
EP 296
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200037
DA 2019-06-15
ER

PT B
AU Gu, ZM
   Cercone, N
AF Gu, Zhenmei
   Cercone, Nick
GP COLING
TI Segment-based Hidden Markov Models for Information Extraction
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Hidden Markov models (HMMs) are powerful statistical models that have found successful applications in Information Extraction (IE). In current approaches to applying HMMs to IE, an HMM is used to model text at the document level. This modelling might cause undesired redundancy in extraction in the sense that more than one filler is identified and extracted. We propose to use HMMs to model text at the segment level, in which the extraction process consists of two steps: a segment retrieval step followed by an extraction step. In order to retrieve extraction-relevant segments from documents, we introduce a method to use HMMs to model and retrieve segments. Our experimental results show that the resulting segment HMM IE system not only achieves near zero extraction redundancy, but also has better overall extraction performance than traditional document HMM IE systems.
C1 [Gu, Zhenmei] Univ Waterloo, David R Cheriton Sch Comp Sci, Waterloo, ON N2I 3G1, Canada.
RP Gu, ZM (reprint author), Univ Waterloo, David R Cheriton Sch Comp Sci, Waterloo, ON N2I 3G1, Canada.
EM z2gu@uwaterloo.ca; nick@cs.dal.ca
CR BIKEL DM, 1997, P 5 C APPL NAT LANG, P194
   FREITAG D, 1999, P AAAI 99 WORKSH MAC
   Gale William A., 1995, J QUANT LINGUIST, V2, P217, DOI DOI 10.1080/09296179508590051
   GU Z, 2006, P 2006 IEEE INT C FU
   Jelinek F., 1980, Pattern Recognition in Practice. Proceedings of an International Workshop, P381
   Leek T. R., 1997, THESIS UC SAN DIEGO
   MCCALLUM A, 2000, P ICML 2000
   McCallum A., 2003, 19 C UNC ART INT UAI
   PENG F, 2004, P HUM LANG TECHN C N
   Peshkin Leonid, 2003, P 18 INT JOINT C ART
   Rabiner L. R., 1989, P IEEE, V77
NR 11
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 481
EP 488
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200061
DA 2019-06-15
ER

PT B
AU Iida, R
   Inui, K
   Matsumoto, Y
AF Iida, Ryu
   Inui, Kentaro
   Matsumoto, Yuji
GP COLING
TI Exploiting Syntactic Patterns as Clues in Zero-Anaphora Resolution
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We approach the zero-anaphora resolution problem by decomposing it into intra-sentential and inter-sentential zero-anaphora resolution. For the former problem, syntactic patterns of the appearance of zero-pronouns and their antecedents are useful clues. Taking Japanese as a target language, we empirically demonstrate that incorporating rich syntactic pattern features in a state-of-the-art learning-based anaphora resolution model dramatically improves the accuracy of intra-sentential zero-anaphora, which consequently improves the overall performance of zero-anaphora resolution.
C1 [Iida, Ryu; Inui, Kentaro; Matsumoto, Yuji] Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara 6300192, Japan.
RP Iida, R (reprint author), Nara Inst Sci & Technol, Grad Sch Informat Sci, 8916-5 Takayama, Nara 6300192, Japan.
EM ryu-i@is.naist.jp; inui@is.naist.jp; matsu@is.naist.jp
CR ASAHARA M, 2003, IPADIC USER MANUAL
   BALDWIN B, 1995, THESIS U PENNSYLVANI
   Carreras X., 2005, P 9 C COMP NAT LANG, P152
   COLLINS M, 2001, P NEUR INF PROC SYST, P625
   FUJITA A, 2004, P 1 INT JOINT C NAT, P14
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   Iida R., 2003, P EACL WORKSH COMP T, P23
   Iida R., 2005, ACM T ASIAN LANGUAGE, V4, P417
   Ikehara S., 1997, NIHONGO GOI TAIKEI
   *JAP EL DICT RES I, 1995, EDR EL DICT TECHN GU
   KAMEYAMA M, 1986, P 24 ANN M ASS COMP, P200
   KUDO T, 2004, P 2004 C EMP METH NA, P301
   Lappin S., 1994, Computational Linguistics, V20, P535
   MCCALLUM A, 2003, P KDD 2003 WORKSH DA, P19
   McCarthy J, 1995, P 14 INT JOINT C ART, P1050
   MITKOV R, 1997, P ACL 97 EACL 97 WOR
   NAKAIWA H, 1996, P 16 INT C COMP LING, P812
   NG V, 2004, P 42 ANN M ASS COMP, P152
   Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102
   Okumura M., 1996, P 16 INT C COMP LING, P871
   Poesio M., 2004, P ACL WORKSH REF RES, P47
   SEKI K, 2002, P 19 INT C COMP LING, P911
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Strube M., 2003, P 41 ANN M ASS COMP, P168
   SUZUKI J, 2003, P 41 ANN M ASS COMP, P32
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Yang X, 2003, P 41 ANN M ASS COMP, P176, DOI [10.3115/1075096.1075119, DOI 10.3115/1075096.1075119]
NR 28
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 625
EP 632
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200079
DA 2019-06-15
ER

PT B
AU Kahane, S
AF Kahane, Sylvain
GP COLING
TI Polarized Unification Grammars
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID LOGIC
AB This paper proposes a generic mathematical formalism for the combination of various structures: strings, trees, dags, graphs and products of them. The polarization of the objects of the elementary structures controls the saturation of the final structure. This formalism is both elementary and powerful enough to strongly simulate many grammar formalisms, such as rewriting systems, dependency grammars, TAG, HPSG and LFG.
C1 Univ Paris 10, F-92001 Nanterre, France.
RP Kahane, S (reprint author), Univ Paris 10, F-92001 Nanterre, France.
EM sk@ccr.jussieu.fr
CR Ajdukiewicz Kazimierz, 1935, STUDIA PHILOS, V1, P1
   BONFANTE G, 2004, P COLING GEN SWITZ, P303
   Bresnan J., 2001, LEXICAL FUNCTIONAL S
   BURRONI A, 1993, THEOR COMPUT SCI, V115, P43, DOI 10.1016/0304-3975(93)90054-W
   DUCHIER D, 1999, NLULP 1999 NATURAL L
   DYMETMAN M, 1999, P MOL 6 6 M MATH LAN
   GIRARD JY, 1987, THEOR COMPUT SCI, V50, P1, DOI 10.1016/0304-3975(87)90045-4
   KAHANE S, 2005, 2 INT C MEAN TEXT TH, P197
   KAPLAN RM, 1989, ALTERNATIVE CONCEPTIONS OF PHRASE STRUCTURE, P17
   KEPSER S, 2003, P FORM GRAMM VIENN A, P115
   NASR A, 1995, P 4 INT WORKSH PARS
   PERRIER G, 2000, P COLING SARR
   SHICBER SM, 1990, P COLING HELS FINL, V3, P253
   Tesniere Lucien, 1934, B FAC LETT STRASBOUR, V7, P219
   van Kampen ER, 1933, AM J MATH, V55, P268
   Vijay-Shanker K., 1992, Computational Linguistics, V18, P481
NR 16
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 137
EP 144
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200018
DA 2019-06-15
ER

PT B
AU Khaltar, BO
   Fujii, A
   Ishikawa, T
AF Khaltar, Badam-Osor
   Fujii, Atsushi
   Ishikawa, Tetsuya
GP COLING
TI Extracting loanwords from Mongolian corpora and producing a
   Japanese-Mongolian bilingual dictionary
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper proposes methods for extracting loanwords, from Cyrillic Mongolian corpora and producing a Japanese-Mongolian bilingual dictionary. We extract loanwords from Mongolian corpora using our own handcrafted rules. To complement the rule-based extraction, we also extract words m Mongolian corpora that are phonetically similar to Japanese Katakana words as loanwords. In addition, we correspond the extracted loanwords to Japanese words and produce a bilingual dictionary. We propose a stemming method for Mongolian to extract loanwords correctly. We verify the effectiveness of our methods experimentally.
C1 [Khaltar, Badam-Osor; Fujii, Atsushi] Univ Tsukuba, Grad Sch Lib Informat & Media Studies, Tsukuba, Ibaraki 3058550, Japan.
RP Khaltar, BO (reprint author), Univ Tsukuba, Grad Sch Lib Informat & Media Studies, 1-2 Kasuga, Tsukuba, Ibaraki 3058550, Japan.
EM khab23@slis.tsukuba.ac.jp; fujii@slis.tsukuba.ac.jp;
   ishikawa@hi.u-tokyo.ac.jp
CR BAYARMAA T, 2002, MONGOLIAN GRAMMAR 1
   EHARA T, 2004, P NOLTA, P709
   Frangolias DD, 1996, SPORTS MED, V22, P38, DOI 10.2165/00007256-199622010-00004
   FUJII A, 2004, P 3 INT WORKSH COMP, P71
   FUNG P, 1996, P 5 ANN WORKSH VER L, P53
   LAM W, 2004, P 27 ANN INT ACM SIG, P289
   MYAENG SH, 1999, INFORM PROCESSING MA, V35, P523
   Oh Jong-Hoon, 2001, P INT C COMP PROC OR, P433
   OZAWA S, 2000, MODERN MONGOLIAN DIC
   Robertson S. E., 1995, NIST SPECIAL PUBLICA, P109
   SANDUIJAV E, 2005, J NATURAL LANGUAGE P, V12, P185
NR 11
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 657
EP 664
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200083
DA 2019-06-15
ER

PT B
AU Korhonen, A
   Krymolowski, Y
   Collier, N
AF Korhonen, Anna
   Krymolowski, Yuval
   Collier, Nigel
GP COLING
TI Automatic Classification of Verbs in Biomedical Texts
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Lexical classes, when tailored to the application and domain in question, can provide an effective means to deal with a number of natural language processing (NI-P) tasks. While manual construction of such classes is difficult, recent research shows that it is possible to automatically induce verb classes from cross-domain corpora with promising accuracy. We report a novel experiment where similar technology is applied to the important, challenging domain of biomedicine. We show that the resulting classification, acquired from a corpus of biomedical journal articles, is highly accurate and strongly domain-specific. It can be used to aid BIO-NLP directly or as useful material for investigating the syntax and semantics of verbs in biomedical texts.
C1 [Korhonen, Anna] Univ Cambridge, Comp Lab, Cambridge CB3 0GD, England.
RP Korhonen, A (reprint author), Univ Cambridge, Comp Lab, 15 JJ Thomson Ave, Cambridge CB3 0GD, England.
EM alk23@cl.cam.ac.uk; yuvalkr@cs.technion.ac.il; collier@nii.ac.jp
CR BREW C, 2002, C EMP METH NAT LANG
   BRISCOE EJ, 2002, 3 INT C LANG RES EV, P1499
   BRISCOE EJ, 1997, 5 ACL C APPL NAT LAN, P356
   Dimitrov AG, 2001, NETWORK-COMP NEURAL, V12, P441, DOI 10.1088/0954-898X/12/4/303
   Dorr B. J., 1997, Machine Translation, V12, P271, DOI 10.1023/A:1007965530302
   Friedman C, 2002, J BIOMED INFORM, V35, P222, DOI 10.1016/S1532-0464(03)00012-1
   Hatzivassiloglou V, 2002, INT J MED INFORM, V67, P19, DOI 10.1016/S1386-5056(02)00054-0
   Hirschman L, 2002, BIOINFORMATICS, V18, P1553, DOI 10.1093/bioinformatics/18.12.1553
   HOFFMAN T, 2001, MACH LEARN, V42, P177
   Jackendoff R., 1990, SEMANTIC STRUCTURES
   KORHONEN A, 2002, THESIS U CAMBRIDGE U
   Korhonen A., 2003, P 41 ANN M ASS COMP, P64
   LEASE M, 2005, 2 INT JOINT C NAT LA, P58
   Leech G., 1992, LANGUAGE RES, V28, P1
   Levin B., 1993, ENGLISH VERB CLASSES
   Merlo P, 2001, COMPUT LINGUIST, V27, P373, DOI 10.1162/089120101317066122
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Prescher D., 2000, 18 INT C COMP LING S, P649
   Spasic I, 2005, BIOINFORMATICS, V21, P2748, DOI 10.1093/bioinformatics/bti338
   TISHBY N, 1999, P 37 ANN ALL C COMM, P368
   VLACHOS A, 2006, PAC S BIOC
NR 21
TC 2
Z9 2
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 345
EP 352
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200044
DA 2019-06-15
ER

PT B
AU Noro, T
   Inui, T
   Takamura, H
   Okumura, M
AF Noro, Taichi
   Inui, Takashi
   Takamura, Hiroya
   Okumura, Manabu
GP COLING
TI Time Period Identification of Events in Text
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This study aims at identifying when an event written in text occurs. In particular, we classify a sentence for an event into four time-slots; morning, daytime, evening, and night. To realize our goal, we focus on expressions associated with time-slot (time-associated words). However, listing up all the time-associated words is impractical, because there are numerous time-associated expressions. We therefore use a semi-supervised learning method, the Naive Bayes classifier backed up with the Expectation Maximization algorithm, in order to iteratively extract time-associated words while improving the classifier. We also propose to use Support Vector Machines to filter out noisy instances that indicates no specific time period. As a result of experiments, the proposed method achieved 0.864 of accuracy and outperformed other methods.
C1 [Noro, Taichi] Tokyo Inst Technol, Interdisciplinary Grad Sch Sci & Engn, Midori Ku, Kanagawa, Japan.
RP Noro, T (reprint author), Tokyo Inst Technol, Interdisciplinary Grad Sch Sci & Engn, Midori Ku, 4259 Nagatsuta Cho, Kanagawa, Japan.
EM norot@lr.pi.titech.ac.jp; tinui@lr.pi.titech.ac.jp;
   takamura@pi.titech.ac.jp; oku@pi.titech.ac.jp
RI Takamura, Hiroya/L-6935-2018; Okumura, Manabu/E-3878-2014
OI Takamura, Hiroya/0000-0002-3244-8294; 
CR Abe N., 2004, P 10 ACM SIGKDD INT, P3
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   FAN W, 1999, P 16 INT C MACH LEAR, P97
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   JAPKOWICZ N, 2000, P AAAI WORKSH LEARN, P10
   Kamakura K, 2000, INTERNAL MED, V39, P2, DOI 10.2169/internalmedicine.39.2
   Kudoh Taku, 2000, P CONLL 2000 LLL 200, P142
   Lafferty J. D., 2001, P 18 INT C MACH LEAR, P282
   MANI I, 2000, P 38 ANN M ASS COMP, P69
   NANNO T, 2004, J JAPANESE SOC ARTIF, V19, P511
   SEKINE S, 1999, P IREX WORKSH
   SETZER A, 2001, P ACL 2001 WORKSH TE, P88
   TSUCHIYA S, 2005, IPSG SIG TECHNICAL R, P113
   Zhang J, 2003, P ICML 2003 WORKSH L, P42
NR 14
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1153
EP 1160
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200145
DA 2019-06-15
ER

PT B
AU Novischi, A
   Moldovan, D
AF Novischi, Adrian
   Moldovan, Dan
GP COLING
TI Question Answering with Lexical Chains Propagating Verb Arguments
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper describes an algorithm for propagating verb arguments along lexical chains consisting of WordNet relations. The algorithm creates verb argument structures using VerbNet syntactic patterns. In order to increase the coverage, a larger set of verb senses were automatically associated with the existing patterns from VerbNet. The algorithm is used in an in-house Question Answering system for re-ranking the set of candidate answers. Tests on factoid questions from TREC 2004 indicate that the algorithm improved the system performance by 2.4%.
C1 [Novischi, Adrian; Moldovan, Dan] Language Comp Corp, Richardson, TX 75080 USA.
RP Novischi, A (reprint author), Language Comp Corp, 1701 N Collins Blvd, Richardson, TX 75080 USA.
EM adrian@languagecomputer.com; moldovan@languagecomputer.com
CR Ahn K., 2005, P TREC 2005
   BAKER Collin F., 1998, P COLING ACL MONTR C
   CUI H, 2004, P 13 TEXT RETR C TRE
   DAGAN I, 2005, RECOGNISING TEXTUAL
   Kingsbury P., 2002, P 3 INT C LANG RES E
   KIPPER K, 2000, P 17 NAT C ART INT A, P691
   KIPPER K, 2000, P 5 TAG WORKSH
   Lin D., 1998, P COLING ACL 98 MONT
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Moldovan D., 2002, P COLING 2002, P674
   MOLDOVAN D, 2004, P TEXT RETR C 2004
   MOLDOVAN D, 2005, P 19 INT JOINT C ART, P1099
   MOLDOVAN DI, 2001, P ACL 2001 TOUL FRAN
   MOLDOVAN DI, 2003, P HLT NAACL 2003 EDM
   Quinlan R., 1998, C5 0 INFORMAL TUTORI
   TANEV H, 2004, P 13 TEXT RETR C TRE, P429
   VOORHEES EM, 2004, P 13 TEXT RETR C TRE, P83
NR 17
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 897
EP 904
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200113
DA 2019-06-15
ER

PT B
AU Smith, NA
   Eisner, J
AF Smith, Noah A.
   Eisner, Jason
GP COLING
TI Annealing Structural Bias in Multilingual Weighted Grammar Induction
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID EM ALGORITHM
AB We first show how a structural locality bias can improve the accuracy of state-of-the-art dependency grammar induction models trained by EM from unannotated examples (Klein and Manning, 2004). Next, by annealing the free parameter that controls this bias, we achieve further improvements. We then describe an alternative kind of structural bias, toward "broken" hypotheses consisting of partial structures over segmented sentences, and show a similar pattern of improvement. We relate this approach to contrastive estimation (Smith and Eisner, 2005a), apply the latter to grammar induction in six languages, and show that our new approach improves accuracy by 1-17% (absolute) over CE (and 8-30% over EM), achieving to our knowledge the best results on this task to date. Our method, structural annealing, is a general technique with broad applicability to hidden-structure discovery problems.
C1 [Smith, Noah A.; Eisner, Jason] Johns Hopkins Univ, Ctr Language & Speech Proc, Dept Comp Sci, Baltimore, MD 21218 USA.
RP Smith, NA (reprint author), Johns Hopkins Univ, Ctr Language & Speech Proc, Dept Comp Sci, Baltimore, MD 21218 USA.
EM nasmith@cs.jhu.edu; jason@cs.jhu.edu
CR Abeille Anne, 2003, BUILDING EXPLOITING
   Alshawi H., 1996, P ACL
   Atalay N. B., 2003, P LINC
   BAKER JK, 1979, P AC SOC AM
   Brants Sabine, 2002, P WORKSH TREEB LING
   BRILL E, 1992, P DARPA WORKSH SPEEC
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Charniak E, 1993, STAT LANGUAGE LEARNI
   COLLINS M, 1997, P ACL
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   EISNER J, 1997, P  IWPT
   EISNER J, 2005, P IWPT
   EISNER J, 2005, P HLT EMNLP
   Eisner Jason, 1999, P ACL
   Elidan G, 2005, J MACH LEARN RES, V6, P81
   HINDLE D, 1990, P ACL
   Klein D., 2002, P ACL
   KLEIN D, 2003, NIPS 15
   Manning C. D., 2004, P ACL
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Marsi E., 2006, P CONLL
   McDonald R., 2005, P ACL
   Rose K, 1998, P IEEE, V86, P2210, DOI 10.1109/5.726788
   Santos D., 2002, P LREC
   SIMOV K, 2003, P LINC
   SIMOV K, 2004, J RES LANGUAGE COMPU, V2, P495
   Simov K., 2002, RAINBOW CORPORA CORP, P135
   Smith N. A., 2005, P ACL
   Smith N. A., 2005, P IJCAI WORKSH GRAMM
   SMITH NA, 2004, P ACL
   STEEDMAN M, 2003, P EACL
   Ueda N, 1998, NEURAL NETWORKS, V11, P271, DOI 10.1016/S0893-6080(97)00133-0
   Xue N., 2004, NAT LANG ENG, V10, P1
   YAROWSKY D, 1995, P ACL
NR 34
TC 2
Z9 2
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 569
EP 576
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200072
DA 2019-06-15
ER

PT B
AU Zhu, J
   Wang, HF
AF Zhu, Jiang
   Wang, Haifeng
GP COLING
TI The Effect of Translation Quality in MT-Based Cross-Language Information
   Retrieval
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper explores the relationship between the translation quality and the retrieval effectiveness in Machine Translation (MT) based Cross-Language Information Retrieval (CLIR). To obtain MT systems of different translation quality, we degrade a rule-based MT system by decreasing the size of the rule base and the size of the dictionary. We use the degraded MT systems to translate queries and submit the translated queries of varying quality to the IR system. Retrieval effectiveness is found to correlate highly with the translation quality of the queries. We further analyze the factors that affect the retrieval effectiveness. Title queries are found to be preferred in MT-based CLIR. In addition, dictionary-based degradation is shown to have stronger impact than rule-based degradation in MT-based CLIR.
C1 [Zhu, Jiang; Wang, Haifeng] Toshiba China Res & Dev Ctr, Beijing 100738, Peoples R China.
RP Zhu, J (reprint author), Toshiba China Res & Dev Ctr, 5-F,Tower W2,Oriental Pl,1 E Chang Ave, Beijing 100738, Peoples R China.
EM zhujiang@rdc.toshiba.com.cn; wanghaifeng@rdc.toshiba.com.cn
CR AMANO S, 1989, FUTURE COMPUTING SYS, V2, P227
   Davidson L, 1996, PSYCHIATR REHABIL J, V19, P49, DOI 10.1037/h0101295
   DEMNERFUSHMAN D, 2003, P 36 HAW INT C SYST, P108
   Doddington George, 2002, P 2 INT C HUM LANG T, P138, DOI DOI 10.3115/1289189.1289273
   FLUHR C, 1997, SURVEY STATE ART HUM, P261
   FRANZ M, 2001, P ACM SIGIR C, P398
   GIORGIO M, 2005, WORK NOT CLEF 2005 W
   JONES G, 1999, P MT SUMM 7 WORKSH M, P15
   Kishida Kazuaki, 2005, P NTCIR 5 NII TOK, P1
   KRAAIJ W, 2001, P CLEF 2001, P78
   Kwok KL, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P34, DOI 10.1145/258525.258531
   McNamee P., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P159
   Nie JY, 2000, P 5 INT WORKSH INF R, P141
   SAKAI T, 2003, P 3 NTCIR WORKSH RES, P51
   STEPHEN E, 1999, P 8 TEXT RETR C TREC, P151
   STEPHEN E, 1997, 356 U CAMBR COMP LAB
   Voorhees E., 2003, P 12 TEXT RETR C TRE, P1
   Xu JX, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P95
NR 18
TC 2
Z9 2
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 593
EP 600
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200075
DA 2019-06-15
ER

PT B
AU Eisenstein, J
   Christoudias, CM
AF Eisenstein, J
   Christoudias, CM
GP acl
TI A salience-based approach to gesture-speech alignment
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB One of the first steps towards understanding natural multimodal language is aligning gesture and speech, so that the appropriate gestures ground referential pronouns in the speech. This paper presents a novel technique for gesture-speech alignment, inspired by salience-based approaches to anaphoric pronoun resolution. We use a hybrid between data-driven and knowledge-based methods: the basic structure is derived from a set of rules about gesture salience, but the salience weights themselves are learned from a corpus. Our system achieves 95% recall and precision on a corpus of transcriptions of unconstrained multimodal monologues, significantly outperforming a competitive baseline.
C1 MIT, Com Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
RP Eisenstein, J (reprint author), MIT, Com Sci & Artificial Intelligence Lab, 32 Vassar St, Cambridge, MA 02139 USA.
EM jacobe@csail.mit.edu; cmch@csail.mit.edu
CR Bolt R. A., 1980, Computer Graphics, V14, P262
   Cassell J., 1998, COMPUTER VISION HUMA, P191
   Chai J. Y., 2004, P 9 INT C INT US INT, P70, DOI DOI 10.1145/964442.964457
   Chovil N., 1991, RES LANG SOC INTERAC, V25, P163, DOI DOI 10.1080/08351819109389361
   Cohen PR, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P31, DOI 10.1145/266180.266328
   COHEN PR, 2002, IEEE C MULT INT
   EISENSTEIN J, 2003, UIST 03 SUPPL P, P69
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   JOHNSTON M, 2000, P COLING 2000
   KETTEBEKOV S, 2002, INT C MULT INT ICMI, P161
   KETTEBEKOV SANS, 2001, ENG HUM COMP INT EHC
   Koons D, 1993, INTELLIGENT MULTIMED, P257
   Lappin S., 1994, Computational Linguistics, V20, P535
   McNeill D, 1992, HAND MIND
   MITKOV R, 1998, COLING ACL, P869
   MITKOV R, 2002, INTELLIGENT TEXT PRO, P17
   Niyu G., 1998, P 6 WORKSH VER LARG, P161
   OVIATT S, 1997, HUMAN FACTORS COMPUT, P415
   QUEK F, 2002, T COMPUTER HUMAN INT, V9, P171
   RICH E, 1988, P 2 C APPL NAT LANG, P18, DOI DOI 10.3115/974235.974239
   Wu LZ, 1999, IEEE T MULTIMEDIA, V1, P334, DOI 10.1109/6046.807953
NR 21
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 25
EP 32
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100004
DA 2019-06-15
ER

PT B
AU Huang, F
   Vogel, S
   Waibel, A
AF Huang, F
   Vogel, S
   Waibel, A
GP acl
TI Improving named entity translation combining phonetic and semantic
   similarities
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB This paper describes an approach to translate rarely occurring named entities (NE) by combining phonetic and semantic similarities. The phonetic similarity is estimated from a surface string transliteration model, and the semantic similarity is calculated from a context vector semantic model. Given a source (Chinese) NE and its context, this approach first generates queries in the target (English) language according to the context translation hypotheses, then searches for relevant documents from a target language corpus. Target NEs in retrieved documents are compared with the source NE based on their phonetic and contextual semantic similarities, and the best-matched one is selected as the correct translation. Experiments show that this approach achieves 67% accuracy on translating rarely occurring NEs, and consistently improves the translation quality on different tasks over a state-of-the-art statistical machine translation system.
C1 Carnegie Mellon Univ, Language Technol Inst, Sch Comp Sci, Pittsburgh, PA 15213 USA.
RP Huang, F (reprint author), Carnegie Mellon Univ, Language Technol Inst, Sch Comp Sci, Pittsburgh, PA 15213 USA.
CR Al-Onaizan Y., 2002, P 40 ANN M ASS COMP, P400, DOI DOI 10.3115/1073083.1073150
   BIKEL DM, 1997, P 5 C APPL NAT LANG, P194
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHINCHOR N, 1998, P 7 MESS UND C MUC 7
   Huang Fei, 2003, P ACL 03 WORKSH MULT
   KNIGHT K, 1997, P 35 ANN M ASS COMP, P128
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   MENG H, 2001, P AUT SPEECH REC UND
   MOORE RC, 2003, P 10 C EUR CHAPT ACL
   Ogilvie P., 2002, P 2001 TEXT RETR C T, P103
   Stalls B., 1998, P COLING ACL WORKSH
   VOGEL S, 2003, P MT SUMM 9 C NEW OR
NR 13
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 281
EP 288
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100036
DA 2019-06-15
ER

PT B
AU Sun, H
   Jurafsky, D
AF Sun, H
   Jurafsky, D
GP acl
TI Shallow semantic parsing of Chinese
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB In this paper we address the question of assigning semantic roles to sentences in Chinese. We show that good semantic parsing results for Chinese can be achieved with a small 1100-sentence training set. In order to extract features from Chinese, we describe porting the Collins parser to Chinese, resulting in the best performance currently reported on Chinese syntactic parsing; we include our head-rules in the appendix. Finally, we compare English and Chinese semantic-parsing performance. While slight differences in argument labeling make a perfect comparison impossible, our results nonetheless suggest significantly better performance for Chinese. We show that much of this difference is due to grammatical differences between English and Chinese, such as the prevalence of passive in English, and the strict word order constraints on adjuncts in Chinese.
C1 Univ Colorado, Ctr Spoken Language Res, Boulder, CO 80309 USA.
RP Sun, H (reprint author), CUNY, Dept Comp Sci, Queens Coll, New York, NY 10021 USA.
CR Baker Collin F., 1998, P COLING ACL
   BIKEL DM, 2000, P 2 CHIN LANG PROC W, P1
   Chiang David, 2002, P COLING 2002, P183
   COLLINS M, 1999, THESIS U PENNSYLVANN
   COLLINS M, 1999, P 37 ANN M ASS COMP, P505
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   GILDEA D, 2002, P 40 ANN M ASS COMP, P239
   KINGSBURY P, 2002, P HLT 02
   KUDO T, 2001, P 2 M N AM CHAPT ASS, P192
   Kudoh Taku, 2000, P CONLL 2000 LLL 200, P142
   Levy R., 2003, ACL, P439
   PARDHAN S, 2003, P INT C DAT MIN MELB
   SURDEANU M, 2003, P ACL
   Xue Nianwen, 2003, P 2 SIGHAN WORKSH CH
   XUE NW, 2002, GUIDELINES PENN CHIN
   XUE NW, 2002, P COLING 2002
NR 16
TC 2
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 249
EP 256
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100032
DA 2019-06-15
ER

PT B
AU Baldwin, T
   Bond, F
AF Baldwin, T
   Bond, F
GP ACL
TI Learning the countability of English nouns from corpus data
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper describes a method for learning the countability preferences of English nouns from raw text corpora. The method maps the corpus-attested lexico-syntactic properties of each noun onto a feature vector, and uses a suite of memory-based classifiers to predict membership in 4 countability classes. We were able to assign countability to English nouns with a precision of 94.6%.
C1 Stanford Univ, CSLI, Stanford, CA USA.
CR BALDWIN T, 2003, P 2003 C EMP METH NA
   Bond F., 1994, P COLING 94, P32
   BOND F, 2002, P 19 INT C COMP LING
   BOND F, 2001, THESIS U QUEENSLAND
   BRISCOE T, 2002, P 3 INT C LANG RES E, P1499
   BURNARD L, 2000, USER REFERENCE GUIDE
   Copestake A., 1995, J SEMANT, V12, P15, DOI DOI 10.1093/J0S/12.1.15
   DAELEMANS W, 2002, TIMBL TILBURG MEMORY
   GRISHMAN R, 1998, COMLEX SYNTAX REFERE
   IKEHARA S, 1991, P 3 MACH TRANSL SUMM, P101
   KEITH A, 1980, LANGUAGE, V56, P541
   LANE OB, 2002, THESIS CAMBRIDGE U C
   LIGHT M, 1996, P 34 ANN M ACL SANT, P25
   Minnen G., 2001, Natural Language Engineering, P207
   NGAI G, 2001, P 2 ANN M N AM CHAPT, P40
   OHARA T, 2003, P 5 INT WORKSH COMP
   SANG EFT, 2000, P 4 C COMP NAT LANG
   Siegel EV, 2000, COMPUT LINGUIST, V26, P595, DOI 10.1162/089120100750105957
   Wierzbicka Anna, 1988, SEMANTICS GRAMMAR
NR 19
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 463
EP 470
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500059
DA 2019-06-15
ER

PT B
AU Burstein, J
   Wolska, M
AF Burstein, J
   Wolska, M
GP ACL
TI Toward evaluation of writing style: Finding overly repetitive word use
   in student essays
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Automated essay scoring is now an established capability used from elementary school through graduate school for purposes of instruction and assessment. Newer applications provide automated diagnostic feedback about student writing. Feedback includes errors in grammar, usage, and mechanics, comments about writing style, and evaluation of discourse structure. This paper reports on a system that evaluates a characteristic of lower quality essay writing style: repetitious word use. This capability is embedded in a commercial writing assessment application, Criterion(SM). The system uses a machine-learning approach with word-based features to model repetitious word use in an essay. System performance well exceeds several baseline algorithms. Agreement between the system and a single human judge exceeds agreement between two human judges.
C1 Educ Testing Serv, Princeton, NJ 08541 USA.
RI wolska, magdalena/R-7661-2016
CR BURSTEIN J, 2003, NATURAL LANGUAGE JAN
   Burstein J, 2001, P 39 ANN M ASS COMP
   BURSTEIN J, 1998, P 36 ANN M ASS COMP, P206
   Burstein J., 2003, AUTOMATED ESSAY SCOR
   Chodorow M., 2000, P 1 M N AM CHAPT ASS, P140
   Elliott S., 2003, AUTOMATED ESSAY SCOR
   Foltz PW, 1998, DISCOURSE PROCESS, V25, P285, DOI 10.1080/01638539809545029
   Krippendorff K., 1980, CONTENT ANAL INTRO I
   MACDONALD NH, 1982, IEEE T COMMUN, V30, P105, DOI 10.1109/TCOM.1982.1095380
   Page E. B, 1966, PHI DELTA KAPPAN, V48, P238
   UEBERSAX JS, 1982, EDUC PSYCHOL MEAS, V42, P181, DOI 10.1177/0013164482421018
NR 11
TC 2
Z9 2
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 35
EP 42
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200006
DA 2019-06-15
ER

PT B
AU Dubey, A
   Keller, F
AF Dubey, A
   Keller, F
GP ACL
TI Probabilistic parsing for German using sister-head dependencies
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We present a probabilistic parsing model for German trained on the Negra tree-bank. We observe that existing lexicalized parsing models using head-head dependencies, while successful for English, fail to outperform an unlexicalized baseline model for German. Learning curves show that this effect is not due to lack of training data. We propose an alternative model that uses sister-head dependencies instead of head-head dependencies. This model outperforms the baseline, achieving a labeled precision and recall of up to 74%. This indicates that sister-head dependencies are more appropriate for treebanks with very flat structures such as Negra.
C1 Univ Saarland, Dept Computat Linguist, D-66041 Saarbrucken, Germany.
CR BECKER M, 2002, P 19 INT C COMP LING
   BEIL F, 1999, P 37 ANN M ASS COMP
   BEIL F, 2002, P LREC WORKSH PARS I
   BIKEL DM, 2000, P 2 ACL WORKSH CHIN
   Brants T., 2000, P 6 C APPL NAT LANG
   CARROLL G, 1998, P C EMP METH NAT LAN
   CHARNIAK E, 1997, P 14 NAT C ART INT
   Charniak E, 1993, STAT LANGUAGE LEARNI
   Charniak E., 2000, P 1 C N AM CHAPT ASS
   Collins M, 1999, P 37 ANN M ASS COMP
   Collins M., 1997, P 35 ANN M ASS COMP
   Gildea D., 2001, P C EMP METH NAT LAN
   HOCKENMAIER J, 2002, P 40 ANN M ASS COMP
   Marcus M., 1993, COMPUTATIONAL LINGUI, V19
   SCHMID H, 2000, UNPUB LOPAR DESIGN I
   Skut W., 1998, P 6 WORKSH VER LARG
   Skut W, 1997, P 5 C APPL NAT LANG
   USZKOREIT H, 1987, CSLI PUBLICATIONS
NR 18
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 96
EP 103
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500013
DA 2019-06-15
ER

PT B
AU Farahat, A
   Chen, F
   Brants, T
AF Farahat, A
   Chen, F
   Brants, T
GP ACL
TI Optimizing story link detection is not equivalent to optimizing new
   event detection
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Link detection has been regarded as a core technology for the Topic Detection and Tracking tasks of new event detection. In this paper we formulate story link detection and new event detection as information retrieval task and hypothesize on the impact of precision and recall on both systems. Motivated by these arguments, we introduce a number of new performance enhancing techniques including part of speech tagging, new similarity measures and expanded stop lists. Experimental results validate our hypothesis.
C1 PARC, Palo Alto, CA 94304 USA.
CR ALLAN J, 1999, TOPIC BASED NOVELTY
   ALLAN J, 2002, ACM SIGIR2002
   Allan J., 2000, CIKM 2000, P374
   Allan James, 2000, P TOP DET TRACK WORK
   Brants T., 2002, INT C INF KNOWL MAN
   CARBONELL J, 2001, TDT 2001 M CMU
   CHEN F, 2003, P NAACL HLT 2002 EDM
   CROF WB, 2001, DELOS WORKSH PERS RE
   Dunning T., 1993, Computational Linguistics, V19, P61
   KRAAIJ W, 1996, ACM SIGIR1996
   Lavrenko V., 2002, P HLT 2002 SAN DIEG
   Pirkola A, 1996, INFORM PROCESS MANAG, V32, P199, DOI 10.1016/S0306-4573(96)85006-0
   PRESS WH, 1993, NUMERICAL RECIPES
   Wayne C.L., 2000, LANG RES EV C LREC, P1487
   Xu JX, 1998, ACM T INFORM SYST, V16, P61, DOI 10.1145/267954.267957
   YANG Y, 1998, P SIGIR 98 MELB AUST
NR 16
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 232
EP 239
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500030
DA 2019-06-15
ER

PT B
AU Frank, A
   Becker, M
   Crysmann, B
   Kiefer, B
   Schafer, U
AF Frank, A
   Becker, M
   Crysmann, B
   Kiefer, B
   Schafer, U
GP ACL
TI Integrated shallow and deep parsing: TopP meets HPSG
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We present a novel, data-driven method for integrated shallow and deep parsing. Mediated by an XML-based multi-layer annotation architecture, we interleave a robust, but accurate stochastic topological field parser of German with a constraint-based HPSG parser. Our annotation-based method for dovetailing shallow and deep phrasal constraints is highly flexible, allowing targeted and fine-grained guidance of constraint-based parsing. We conduct systematic experiments that demonstrate substantial performance gains.(1).
C1 DFKI GmbH, D-66153 Saarbrucken, Germany.
EM anette.frank@dfki.de; M.Becker@ed.ac.uk; berthold.crysmann@dfki.de;
   bernd.kiefer@dfki.de; ulrich.schafer@dfki.de
CR Becker Markus, 2002, P COLING 2002 TAIP T, P71
   Brants Thorsten, 2000, P EUR RHOD GREEC
   Callmeier U., 2000, Natural Language Engineering, P99, DOI 10.1017/S1351324900002369
   CARROLL C, 2002, P COLING 2002, P134
   CRYSMANN B, 2002, 40 ANN M ASS COMP LI
   DAUM M, 2003, P EACL 2003 BUD
   DUCHIER D, 2001, P ACL 2001
   GROVER C, 2001, P 39 ACL TOUL FRANC, P252
   HOHLE TN, 1983, UNPUB TOPOLOGISCHE F
   Hwa R, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P45
   Muller S, 2000, ART INTEL, P238
   PRINS R, 2001, P IWPT BEIJ
   SCHAFER U, 2003, P SEALTS WORKSH HLT
   SCHMID H, 2000, 149 SFB 340 IMS
   SKUT W, 1998, ESSLLI 1998 WORKSH A
   USZKOREIT H, 2002, P COLING 2002 TAIP T, pR14
NR 16
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 104
EP 111
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500014
DA 2019-06-15
ER

PT B
AU Higashinaka, R
   Nakano, M
   Aikawa, K
AF Higashinaka, R
   Nakano, M
   Aikawa, K
GP ACL
TI Corpus-based discourse understanding in spoken dialogue systems
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper concerns the discourse understanding process in spoken dialogue systems. This process enables the system to understand user utterances based on the context of a dialogue. Since multiple candidates for the understanding result can be obtained for a user utterance due to the ambiguity of speech understanding, it is not appropriate to decide on a single understanding result after each user utterance. By holding multiple candidates for understanding results and resolving the ambiguity as the dialogue progresses, the discourse understanding accuracy can be improved. This paper proposes a method for resolving this ambiguity based on statistical information obtained from dialogue corpora. Unlike conventional methods that use hand-crafted rules, the proposed method enables easy design of the discourse understanding process. Experiment results have shown that a system that exploits the proposed method performs sufficiently and that holding multiple candidates for understanding results is effective.
C1 NTT Corp, Commun Sci Labs, Nippon Telegraph & Tel Publ Corp, Atsugi, Kanagawa 2430198, Japan.
EM rh@atom.brl.ntt.co.jp; nakano@atom.brl.ntt.co.jp; aik@idea.brl.ntt.co.jp
CR ALLEN J, 2001, P INT US INT 2001 IU, P1, DOI DOI 10.1145/359784.359822
   ALLEN JF, 1980, ARTIF INTELL, V15, P143, DOI 10.1016/0004-3702(80)90042-9
   BOBROW DG, 1977, ARTIF INTELL, V8, P155, DOI 10.1016/0004-3702(77)90018-2
   CARBERRY S, 2000, PLAN RECOGNITION NAT, P97
   CHUCARROLL J, 2000, P 6 C APPL NAT LANG, P97
   Clarkson P., 1997, P EUR 97 RHOD GREEC, P2707
   Cohen P. R., 1995, EMPIRICAL METHODS AR
   HIGASHINAKA R, 2002, P ICSLP, P829
   LEE A., 2001, P EUR C SPEECH COMM, V7, P1691
   MIYAZAKI N, 2002, SIG SLP 40 INFORMATI, P121
   NAGATA M, 1994, SPEECH COMMUN, V15, P193, DOI 10.1016/0167-6393(94)90071-X
   NAKANO M, 1999, P 37 ANN M ASS COMP, P200
   Reithinger Norbert, 1995, P 33 ANN M ASS COMP, P116, DOI 10.3115/981658.981674
   Rich C, 2001, AI MAG, V22, P15
   Seneff S, 2002, COMPUT SPEECH LANG, V16, P283, DOI [10.1016/S0885-2308(02)00011-6, 10.1016/SO885-2308(02)00011-6]
   Takano S, 2001, IEEE T SPEECH AUDI P, V9, P3, DOI 10.1109/89.890065
   Zue VW, 2000, P IEEE, V88, P1166, DOI 10.1109/5.880078
NR 17
TC 2
Z9 2
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 240
EP 247
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500031
DA 2019-06-15
ER

PT B
AU Imamura, K
   Sumita, E
   Matsumoto, Y
AF Imamura, K
   Sumita, E
   Matsumoto, Y
GP ACL
TI Feedback cleaning of machine translation rules using automatic
   evaluation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB When rules of transfer-based machine translation (MT) are automatically acquired from bilingual corpora, incorrect/redundant rules are generated due to acquisition errors or translation variety in the corpora. As a new countermeasure to this problem, we propose a feedback cleaning method using automatic evaluation of MT quality, which removes incorrect/redundant rules as a way to increase the evaluation score. BLEU is utilized for the automatic evaluation. The hill-climbing algorithm, which involves features of this task, is applied to searching for the optimal combination of rules. Our experiments show that the MT quality improves by 10% in test sentences according to a subjective evaluation. This is considerable improvement over previous methods.
C1 ATR Spoken Language Translat Res Labs, Kyoto, Japan.
CR AKIBA Y, 2001, P MACH TRANSL SUMM, V8, P15
   FURUSE O, 1994, P COLING 94, P105
   Imamura K., 2002, Proceedings of the 9th International Conference on Theoretical and Methodological Issues in Machine Translation (TMI-2002), P74
   Imamura Kenji, 2001, P 6 NAT LANG PROC PA, P377
   MENEZES A, 2001, P WORKSH EX BAS MACH, V8, P35
   MEYERS A, 2000, P COLING 2000, P537
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Su K. -Y., 1992, P 14 INT C COMP LING, V2, P433
   Takezawa T., 2002, P LREC, P147
   YASUDA K, 2001, P MACH TRANSL SUMM, V8, P373
   YASUDA K, 2003, P 10 C EUR CHAPT ASS, P371
NR 11
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 447
EP 454
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500057
DA 2019-06-15
ER

PT B
AU Jansche, M
AF Jansche, M
GP ACL
TI Parametric models of linguistic count data
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
ID TESTS
AB It is well known that occurrence counts of words in documents are often modeled poorly by standard distributions like the binomial or Poisson. Observed counts vary more than simple models predict, prompting the use of overdispersed models like Gamma-Poisson or Beta-binomial mixtures as robust alternatives. Another deficiency of standard models is due to the fact that most words never occur in a given document, resulting in large amounts of zero counts. We propose using zero-inflated models for dealing with this, and evaluate competing models on a Naive Bayes text classification task. Simple zero-inflated models can account for practically relevant variation, and can be easier to work with than overdispersed models.
C1 Ohio State Univ, Dept Linguist, Columbus, OH 43210 USA.
CR Church K., 1995, J NATURAL LANGUAGE E, V1, P163
   CHURCH KW, 2000, 18 INT C COMP LING, P180
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   DOMINGOS P, 1998, 13 INT C MACH LEARN, P105
   Ennis DM, 1998, J SENS STUD, V13, P389, DOI 10.1111/j.1745-459X.1998.tb00097.x
   Garg A., 2001, 12 EUR C MACH LEARN, P179
   JOHNSON NL, 1969, DISCRETE DISTRIBUTIO, V1
   LANG K, 1995, 12 INT C MACH LEARN, P331
   Lee J.C., 1997, J STAT COMPUT SIM, V63, P73
   LEWIS DD, 1998, 10 EUR C MACH LEARN, P4
   LOWE SA, 1999, 6 EUR C SPEECH COMM, P2443
   McCallum A, 1998, AAAI 98 WORKSH LEARN, P41
   McCallum A. K., 1996, BOW TOOLKIT STAT LAN
   Mosteller F., 1984, APPL BAYESIAN CLASSI
   Pawitan Y., 2001, ALL LIKELIHOOD STAT
NR 15
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 288
EP 295
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500037
DA 2019-06-15
ER

PT B
AU Kehagias, A
   Pavlina, F
   Petridis, V
AF Kehagias, A
   Pavlina, F
   Petridis, V
GP ACL
TI Linear text segmentation using a dynamic programming algorithm
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
DE text segmentation; document retrieval; information retrieval; machine
   learning
AB In this paper we introduce a dynamic programming algorithm to perform linear text segmentation by global minimization of a segmentation cost function which consists of: (a) within-segment word similarity and (b) prior information about segment length. The evaluation of the segmentation accuracy of the algorithm on Choi's text collection showed that the algorithm achieves the best segmentation accuracy so far reported in the literature.
C1 Aristotle Univ Thessaloniki, Dept Math Phys & Comp Sci, GR-54006 Thessaloniki, Greece.
CR Beeferman D., 1997, P 2 C EMP METH NAT L, P35
   Blei D.M., 2001, 200107 CRL COMPAQ
   Choi F., 2000, P 1 N AM CHAPT ASS C, P26
   CHOI FYY, 2001, P 6 C EMP METH NAT L, P107
   Francis W. N., 1982, FREQUENCY ANAL ENGLI
   Halliday M. A. K., 1976, COHESION ENGLISH
   HEARST MA, 1993, P 16 ANN INT ACM SIG, P59
   HEARST MA, 1994, P 32 ANN M ASS COMP, P9
   Heinonen O, 1998, P 17 INT C COMP LING, P1484
   Hirschberg J., 1993, Computational Linguistics, V19, P501
   Klavans Judith L., 1998, P 6 INT WORKSH VER L, P197
   Kozima H., 1993, P 6 C EUR CHAPT ASS, P232
   Kozima H., 1993, P 31 ANN M ASS COMP, P286, DOI DOI 10.1016/S0306-4573(02)00035-3
   Morris J., 1991, Computational Linguistics, V17, P21
   Passonneau Rebecca J, 1993, P 31 ANN M ASS COMP, P148
   PETRIDIS V, 2001, P IJCNN 01 NEUR NETW
   Ponte J., 1997, P 1 EUR C RES ADV TE, P120
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   REYNAR J., 1998, THESIS U PENNSYLVANI
   Reynar Jeffrey C, 1999, P 37 ANN M ASS COMP, V20, P357
   Roget P. M, 1977, ROGETS INT THESAURUS
   UTIYAMA M, 2001, P 9 C EUR CHAPT ASS, P491
   XU J, 1996, P 19 ANN INT ACM SIG, P4, DOI DOI 10.1145/243199.243202
   Yaari Y., 1997, P C REC ADV NAT LANG, P59
   Yamron J. P., 1999, P DARPA BROADC NEWS, P133
   YOUMANS G, 1991, LANGUAGE, V67, P763, DOI 10.2307/415076
NR 26
TC 2
Z9 2
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 171
EP 178
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200023
DA 2019-06-15
ER

PT B
AU Kim, JD
   Rim, HC
   Tsujii, J
AF Kim, JD
   Rim, HC
   Tsujii, J
GP ACL
TI Self-organizing Markov models and their application to part-of-speech
   tagging
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper presents a method to develop a class of variable memory Markov models that have higher memory capacity than traditional (uniform memory) Markov models. The structure of the variable memory models is induced from a manually annotated corpus through a decision tree learning algorithm. A series of comparative experiments show the resulting models outperform uniform memory Markov models in a part-of-speech tagging task.
C1 Univ Tokyo, Dept Comp Sci, Tokyo, Japan.
OI Kim, Jin-Dong/0000-0002-8877-3248
CR BRANTS T, 1998, TBIL S LOG LANG COMP
   BRANTS T, 2000, 6 APPL NATURAL LANGU
   de Mantaras RL, 1998, AI COMMUN, V11, P91
   DEMANTARAS RL, 1991, MACH LEARN, V6, P81, DOI 10.1023/A:1022694001379
   Gale William A., 1995, J QUANT LINGUIST, V2, P217, DOI DOI 10.1080/09296179508590051
   Jelinek F., 1980, P WORKSH PATT REC PR
   KIM JD, 1999, P JOINT SIGDAT C EMP
   PLA F, 2001, P INT C REC ADV NAT
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ratnaparkhi A., 1996, P C EMP METH NAT LAN
   Ron D, 1996, MACH LEARN, V25, P117, DOI 10.1023/A:1026490906255
   SCHRODER I, 2001, ICOPOST INGOS COLLEC
   Schutze Hinrich, 1994, P ANN M ASS COMP LIN
   Vapnik V. N., 1998, STAT LEARNING THEORY
NR 15
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 296
EP 302
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500038
DA 2019-06-15
ER

PT B
AU Koehn, P
   Knight, K
AF Koehn, P
   Knight, K
GP ACL
TI Feature-rich statistical translation of noun phrases
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We define noun phrase translation as a subtask of machine translation. This enables us to build a dedicated noun phrase translation subsystem that improves over the currently best general statistical machine translation methods by incorporating special modeling and special features. We achieved 65.5% translation accuracy in a German-English translation task vs. 53.2% with IBM Model 4.
C1 Univ So Calif, Dept Comp Sci, Inst Sci Informat, Los Angeles, CA 90089 USA.
CR ALONAIZAN Y, 2002, P ACL
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CAO Y, 2002, P COLING
   COLLINS M, 1997, P ACL 35
   GERMANN U, 2001, P ACL 39
   Koehn P., 2003, P HLT NAACL
   Koehn P., 2003, P EACL
   Malouf Robert, 2002, P CONLL
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Och F., 2002, P ACL
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Papineni  K., 2002, P ACL
   SCHMIDT H, 2000, P COLING
   UEFFING N, 2002, P EMNLP
NR 15
TC 2
Z9 3
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 311
EP 318
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500040
DA 2019-06-15
ER

PT B
AU Koller, A
   Niehren, J
   Thater, S
AF Koller, A
   Niehren, J
   Thater, S
GP ACL
TI Bridging the gap between underspecification formalisms: Hole semantics
   as dominance constraints
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We define a back-and-forth translation between Hole Semantics and dominance constraints, two formalisms used in underspecified semantics. There are fundamental differences between the two, but we show that they disappear on practically useful descriptions. Our encoding bridges a gap between two underspecification formalisms, and speeds up the processing of Hole Semantics.
C1 Univ Saarland, D-6600 Saarbrucken, Germany.
RI Akos, Koller/Q-4672-2019
CR Alshawi Hiyan, 1992, P 30 ANN M ASS COMP, P32
   ALTHAUS E, 2003, IN PRESS J ALGORITHM
   BOS J, 2002, THESIS SAARLAND U
   BOS J, 1996, P 10 AMST C, P133
   COPESTAKE A, 1999, UNPUB MINIMAL RECURS
   Egg M., 2001, Journal of Logic, Language and Information, V10, P457, DOI 10.1023/A:1017964622902
   ERK K, 2002, IN PRESS RES LANGUAG, V1
   GARDENT C, 1998, P 4 TAG WORKSH PHIL
   KOLLER A, 2000, GRAMMARS, V3
   Reyle U., 1993, Journal of Semantics, V10, P123, DOI 10.1093/jos/10.2.123
   Rogers J., 1994, Computational Intelligence, V10, P401, DOI 10.1111/j.1467-8640.1994.tb00005.x
   THIEL S, 2002, UNPUB LINEAR TIME AL
NR 12
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 195
EP 202
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200026
DA 2019-06-15
ER

PT B
AU Komatani, K
   Ueno, S
   Kawahara, T
   Okuno, HG
AF Komatani, K
   Ueno, S
   Kawahara, T
   Okuno, HG
GP ACL
TI Flexible guidance generation using user model in spoken dialogue systems
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We address appropriate user modeling in order to generate cooperative responses to each user in spoken dialogue systems. Unlike previous studies that focus on user's knowledge or typical kinds of users, the user model we propose is more comprehensive. Specifically, we set up three dimensions of user models: skill level to the system, knowledge level on the target domain and the degree of hastiness. Moreover, the models are automatically derived by decision tree learning using real dialogue data collected by the system. We obtained reasonable classification accuracy for all dimensions. Dialogue strategies based on the user modeling are implemented in Kyoto city bus information system that has been developed at our laboratory. Experimental evaluation shows that the cooperative responses adaptive to individual users serve as good guidance for novice users without increasing the dialogue duration for skilled users.
C1 Kyoto Univ, Grad Sch Informat, Kyoto 6068501, Japan.
RI Okuno, Hiroshi G/S-3130-2018
OI Okuno, Hiroshi G/0000-0002-8704-4318
CR CHUCARROLL J, 2000, P 6 C APPL NAT LANG, P97
   ECKERT W, 1997, P IEEE WORKSH AUT SP, P80
   ELZER S, 2000, P 4 INT C US MOD, P19
   HAZEN TJ, 2000, P ICSLP
   Kass R., 1988, Computational Linguistics, V14, P5
   Komatani K., 2000, P INT C COMP LING CO, P467
   LAMEL L, 1999, IEEE INT C AC SPEECH
   LITMAN DJ, 2000, P 17 NAT C ART INT
   OVER P, 1999, P 7 TEXT RETR C TREC
   Paris C. L., 1988, Computational Linguistics, V14, P64
   QUINLAND JR, 1993, C4 5 PROGRAMS MACHIN
   SADEK D, 1999, P ESCA WORKSH INT DI
   STURM J, 1999, P ESCA WORKSH INT DI
   VANBEEK P, 1987, P 25 ANN M ASS COMP, P215
NR 14
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 256
EP 263
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500033
DA 2019-06-15
ER

PT B
AU Lapata, M
   Lascarides, A
AF Lapata, M
   Lascarides, A
GP ACL
TI Detecting novel compounds: The role of distributional evidence
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Research on the discovery of terms from corpora has focused on word sequences whose recurrent occurrence in a corpus is indicative of their terminological status, and has not addressed the issue of discovering terms when data is sparse. This becomes apparent in the case of noun compounding, which is extremely productive: more than half of the candidate compounds extracted from a corpus are attested only once. We show how evidence about established (i.e., frequent) compounds can be used to estimate features that can discriminate rare valid compounds from rare nonce terms in addition to a variety of linguistic features than can be easily gleaned from corpora without relying on parsed text.
C1 Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England.
CR Bourigault D., 1999, P 9 C EUR CHAPT ASS, P15, DOI DOI 10.3115/977035.977039
   BRYANT Michael, 1994, P 15 INT C COMP LING, P622
   Burnard L., 1995, USERS GUIDE BRIT NAT
   CHRIST O, 1995, XKWIC USER MANUAL
   Church K. W., 1990, Computational Linguistics, V16, P22
   Clark S, 2002, COMPUT LINGUIST, V28, P187, DOI 10.1162/089120102760173643
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Copestake A., 1997, P 35 ANN M ASS COMP, P136
   Corley S, 2001, COMPUT HUMANITIES, V35, P81, DOI 10.1023/A:1002497503122
   Daille B., 1996, BALANCING ACT COMBIN, V1, P49
   DOWNING P, 1977, LANGUAGE, V53, P810, DOI 10.2307/412913
   Duda RO, 1973, PATTERN CLASSIFICATI
   ELWORTHY D, 1994, P 4 C APPL NAT LANG, P53
   JACQUEMIN C, 1996, LECT NOTES ARTIF INT, P425
   Justeson J. S., 1995, NAT LANG ENG, V1, P9, DOI DOI 10.1017/S1351324900000048
   Lauer M., 1995, THESIS MACQUARIE U
   Leonard Rosemary, 1984, INTERPRETATION ENGLI
   Levi J. N., 1978, SYNTAX SEMANTICS COM
   LIBERMAN M, 1992, LEXICAL MATTERS, P131
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Marsh E., 1984, P COLING84, P505
   MCDONALD DB, 1982, THESIS CARNEGIEMELLO
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Pustejovsky J., 1995, GENERATIVE LEXICON
   Quinlan R., 1993, C4 5 PROGRAMS MACHIN
   Resnik Philip, 1993, THESIS U PENNSYLVANI
   Witten I.H., 2000, DATA MINING PRACTICA
NR 27
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 235
EP 242
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200031
DA 2019-06-15
ER

PT B
AU Li, W
   Zhang, XH
   Niu, C
   Jiang, YK
   Srihari, R
AF Li, W
   Zhang, XH
   Niu, C
   Jiang, YK
   Srihari, R
GP ACL
TI An expert lexicon approach to identifying English phrasal verbs
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Phrasal Verbs are an important feature of the English language. Properly identifying them provides the basis for an English parser to decode the related structures. Phrasal verbs have been a challenge to Natural Language Processing (NLP) because they sit at the borderline between lexicon and syntax. Traditional NLP frameworks that separate the lexicon module from the parser make it difficult to handle this problem properly. This paper presents a finite state approach that integrates a phrasal verb expert lexicon between shallow parsing and deep parsing to handle morpho-syntactic interaction. With precision/recall combined performance benchmarked consistently at 95.8%-97.5%, the Phrasal Verb identification problem has basically been solved with the presented method.
C1 Cymfony Inc, Williamsville, NY 14221 USA.
CR Bolinger Dwight, 1971, PHRASAL VERB ENGLISH
   BREIDT E, 1994, OMPUTATIONAL LEXICOG, P19
   CHURCH K, 1988, P ANLP 1988
   Di Sciullo Anna Maria, 1987, DEFINITION WORD
   Fraser B., 1976, VERB PARTICLE COMBIN
   Pelli M., 1976, VERB PARTICLE CONSTR
   SAG IA, 2002, P 3 INT C INT TEXT P, P1
   SHAKED N, 1994, TREATMENT PHRASAL VE
   Silberztein M, 2000, THEOR COMPUT SCI, V231, P33, DOI 10.1016/S0304-3975(99)00015-8
   SMALL S, 1982, STRATEGIES NATURAL L
   SRIHARI R, 2003, P HLT NAACL WORKSH S
   VILLAVICIO A, 2002, P 9 INT C HEAD DRIV
NR 12
TC 2
Z9 2
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 513
EP 520
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500065
DA 2019-06-15
ER

PT B
AU Lita, LV
   Ittycheriah, A
   Roukos, S
   Kambhatla, N
AF Lita, LV
   Ittycheriah, A
   Roukos, S
   Kambhatla, N
GP ACL
TI tRuEcasIng
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Truecasing is the process of restoring case information to badly-cased or noncased text. This paper explores truecasing issues and proposes a statistical, language modeling based truecaser which achieves an daccuracy of similar to 98% on news articles. Task based evaluation shows a 26% F-measure improvement in named entity recognition when using truecasing. In the context of automatic content extraction, mention detection performance on automatic speech recognition text is also improved by a factor of 8. Truecasing also enhances machine translation output legibility and yields a BLEU score improvement of 80.2%. This paper argues for the use of truecasing as a valuable component in text processing applications.
C1 Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
CR *ACE, 2001, ACE PIL STUD TASK DE
   BILEL D, 1997, NYMBLE HIGH PERFORMA, P194
   Brill Eric, 2000, ACL
   CHIEU HL, 2002, TEACHING WEAKER CLAS
   GOLDING AR, 1996, ICML
   JONES MP, 1997, ANLP
   MIKHEEV A, 1999, KNOWLEDGE FREE METHO
   Papineni K., 2001, BLEU METHOD AUTOMATI
   Rabiner L. R., 1989, READINGS SPEECH RECO, P267, DOI 10.1109/5.18626
   WILLIAM A, 1994, CURRENT ISSUES COMPU, P429
   YAROWSKY D, 1994, ACL, P88
NR 11
TC 2
Z9 2
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 152
EP 159
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500020
DA 2019-06-15
ER

PT B
AU Marsi, E
   Reynaert, M
   van den Bosch, A
   Daelemans, W
   Hoste, V
AF Marsi, E
   Reynaert, M
   van den Bosch, A
   Daelemans, W
   Hoste, V
GP ACL
TI Learning to predict pitch accents and prosodic boundaries in Dutch
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
ID LANGUAGE
AB We train a decision tree inducer (CART) and a memory-based classifier (MBL) on predicting prosodic pitch accents and breaks in Dutch text, on the basis of shallow, easy-to-compute features. We train the algorithms on both tasks individually and on the two tasks simultaneously. The parameters of both algorithms and the selection of features are optimized per task with iterative deepening, an efficient wrapper procedure that uses progressive sampling of training data. Results show a consistent significant advantage of MBL over CART, and also indicate that task combination can be done at the cost of little generalization score loss. Tests on cross-validated data and on held-out data yield F-scores of MBL on accent placement of 84 and 87, respectively, and on breaks of 88 and 91, respectively. Accent placement is shown to outperform an informed baseline rule; reliably predicting breaks other than those already indicated by intra-sentential punctuation, however, appears to be more challenging.
C1 Tilburg Univ, ILK Computat Linguist & AI, NL-5000 LE Tilburg, Netherlands.
RI Daelemans, Walter/N-5785-2014; van den Bosch, Antal/G-5072-2011
OI van den Bosch, Antal/0000-0003-2493-656X
CR AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   BLACK AW, 1995, P SPRING M ACOUSTIC
   Breiman L., 1984, CLASSIFICATION REGRE
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Cutler A, 1997, LANG SPEECH, V40, P141, DOI 10.1177/002383099704000203
   Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670
   Daelemans W., 1996, P 4 WORKSH VER LARG, P14
   DAELEMANS W, 2002, P 3 INT C LANG RES E, P755
   DAELEMANS W, 2002, ILK02010 ILK TILB U
   FIX, 1981, 4 USAF SCH AV MED
   HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C
   Koehn P, 2000, INT CONF ACOUST SPEE, P1289, DOI 10.1109/ICASSP.2000.861813
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Ladd D. R., 1996, INTONATIONAL PHONOLO
   MARSI GJ, 2002, P INT C SPOK LANG PR, P1273
   PAN, 2000, P 35 ANN M ASS COMP
   Pan Shimei, 1999, P EMNLP VLC 99
   Provost F., 1999, P 5 ACM SIGKDD INT C, P23, DOI 10.1145/312129.312188
   RIJSBERGEN CV, 1979, INFORMATION RETRIEVA
   Salton G., 1989, AUTOMATIC TEXT PROCE
   Stanfill C., 1986, Communications of the ACM, V29, P1213, DOI 10.1145/7902.7906
   Taylor P, 1998, COMPUT SPEECH LANG, V12, P99, DOI 10.1006/csla.1998.0041
   Taylor P., 1999, EDINBURGH SPEECH TOO
   VANHERWIJNEN OM, 2001, P EUR 2001 SCAND, V1, P529
   WANG MQ, 1997, COMPUTER SPEECH LANG, V6, P175
NR 25
TC 2
Z9 2
U1 0
U2 3
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 489
EP 496
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500062
DA 2019-06-15
ER

PT B
AU Nerbonne, J
AF Nerbonne, J
GP ACL
TI Linguistic variation and computation
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Language variationists, study how languages vary along geographical or social lines or along lines of age and gender. Variationist data is available and challenging, in particular for DIALECTOLOGY, the study of geographical variation, which will be the focus of this paper, although we present approaches we expect to transfer smoothly to the study of variation correlating with other extralinguistic variables. Techniques from computational linguistics on the one hand, and standard statistical data reduction techniques on the other, not only shed light on this classic linguistic problem, but they also suggest avenues for exploring the question at more abstract levels, and perhaps for seeking the determinants of variation.
C1 Univ Groningen, BCN, NL-9700 AS Groningen, Netherlands.
CR Aldenderfer M. S., 1984, CLUSTER ANAL
   Almeida A., 1986, Z DIALEKTOL LINGUIST, V53, P158
   BENINCA P, 1987, DIALECT VARIATION TH
   BLANCQUAERT E, 1925, REEKS NEDERLANDSE DI
   Bloomfield L., 1933, LANGUAGE
   Chambers Jack K., 1980, DIALECTOLOGY
   Gale W. A., 1993, Computational Linguistics, V19, P75
   Goebl Hans, 1984, DIALEKTOMETRISCHE ST
   HEERINGA W, 2003, THESIS U GRONINGEN
   HEERINGA W, 2000, LANGUAGES CONTACT, P145
   HEERINGA W, 2002, LANG VAR CHANGE, V13, P375
   HEERINGA W, 2002, P 24 ANN M GES KLASS, P445
   Kessler B, 1995, P 7 C EUR CHAPT ASS, P60, DOI DOI 10.3115/976973.976983
   Kondrak G, 2000, P 1 N AM CHAPT ASS C, P288
   Kruskal J. B, 1978, MULTIDIMENSIONAL SCA
   Kurath Hans, 1961, PRONUNCIATION ENGLIS
   NERBONNE J, 2003, IN PRESS COMPUTERS H
   NERBONNE J, 1999, TIME WARPS STRING ED, P5
   NERBONNE J, 1998, TAAL TONGVAL, V50, P164
   Seguy Jean, 1971, REV LINGUIST ROMAN, V35, P335
   Trudgill P., 1983, DIALECT SOCIAL GEOGR
   VIEREGGE WH, 1984, P 10 INT C PHON SCI, P654
NR 22
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 3
EP 10
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200002
DA 2019-06-15
ER

PT B
AU Niehren, J
   Thater, S
AF Niehren, J
   Thater, S
GP ACL
TI Bridging the gap between underspecification formalisms: Minimal
   recursion semantics as dominance constraints
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Minimal Recursion Semantics (MRS) is the standard formalism used in large-scale HPSG grammars to model underspecified semantics. We present the first provably efficient algorithm to enumerate the readings of MRS structures, by translating them into normal dominance constraints.
C1 Univ Saarland, Programming Syst Lab, D-6600 Saarbrucken, Germany.
CR Alshawi Hiyan, 1992, P 30 ANN M ASS COMP, P32
   ALTHAUS E, 2003, IN PRESS J ALGORITHM
   BODIRSKY M, 2003, EFFICIENT ALGORITHM
   BOS J, 1996, AMST C, P133
   COPESTAKE A, C LANG RES EV
   COPESTAKE A, 1999, P 39 ACL TOUL FRANC, P132
   Egg M., 2001, Journal of Logic, Language and Information, V10, P457, DOI 10.1023/A:1017964622902
   KOLLER A, 2003, IN PRESS EACL 03
   Koller Alexander, 2001, LECT NOTES COMPUTER, V2014, P106
   POLLARD C, 1994, HEAD DRIVEN PHARSE S
   REYLE U, 1993, J SEMANTICS, V10
NR 11
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 367
EP 374
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500047
DA 2019-06-15
ER

PT B
AU Nissim, M
   Markert, K
AF Nissim, M
   Markert, K
GP ACL
TI Syntactic features and word similarity for supervised metonymy
   resolution
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We present a supervised machine learning algorithm for metonymy resolution, which exploits the similarity between examples of conventional metonymy. We show that syntactic head-modifier relations are a high precision feature for metonymy recognition but suffer from data sparseness. We partially overcome this problem by integrating a thesaurus and introducing simpler grammatical features, thereby preserving precision and increasing recall. Our algorithm generalises over two levels of contextual similarity. Resulting inferences exceed the complexity of inferences undertaken in word sense disambiguation. We also compare automatic and manual methods for syntactic feature extraction.
C1 Univ Edinburgh, Sch Informat, ICCS, Edinburgh EH8 9YL, Midlothian, Scotland.
CR Briscoe T, 1999, COMPUT LINGUIST, V25, P487
   Carletta J, 1996, COMPUT LINGUIST, V22, P249
   Carroll J. A., 2002, P 3 INT C LANG RES E, P1499
   Copestake A., 1995, J SEMANT, V12, P15, DOI DOI 10.1093/J0S/12.1.15
   Corley S, 2001, COMPUT HUMANITIES, V35, P81, DOI 10.1023/A:1002497503122
   Fass D, 1997, PROCESSING METAPHOR
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   GILDEA D, 2002, P 40 ANN M ASS COMP, P239
   Harabagiu S., 1998, WORKSH US WORDN NAT, P142
   HOBBS JR, 1993, ARTIF INTELL, V63, P69, DOI 10.1016/0004-3702(93)90015-4
   Kamei S., 1992, P 30 ANN M ASS COMP, P309
   Karov Y, 1998, COMPUT LINGUIST, V24, P41
   KRIPPENDORFF K, 1980, CONRENT ANAL INTRO I
   LAKOFF G, 1980, METAPHORS LIVE
   LIN DK, 1998, P INT C MACH LEARN M
   Markert K, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P204
   Markert K, 2002, ARTIF INTELL, V135, P145, DOI 10.1016/S0004-3702(01)00150-3
   Markert K., 2002, P 3 INT C LANG RES E, P1385
   MARTINEZ D, 2000, P EMNLP 2000
   MARTINEZ D, 2002, P COLING 2002
   NUNBERG G, 1978, THESIS CITY U NY NY
   Nunberg Geoffrey, 1995, J SEMANT, V12, P109, DOI DOI 10.1093/J0S/12.2.109
   Poesio M., 2000, GNOME ANNOTATION SCH
   Pustejovsky J., 1995, GENERATIVE LEXICON
   Stallard D., 1993, P 31 ANN M ASS COMP, P87
   Stern Gustaf, 1931, MEANING CHANGE MEANI
   Verspoor C. M., 1997, P 2 INT WORKSH COMP, P300
   Verspoor CM, 1996, PROCEEDINGS OF THE EIGHTEENTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P116
   YAROWSKY D, 1995, P 33 ANN M ASS COMP, P189, DOI DOI 10.3115/981658.981684
NR 29
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 56
EP 63
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500008
DA 2019-06-15
ER

PT B
AU Niu, C
   Li, W
   Ding, J
   Srihari, RK
AF Niu, C
   Li, W
   Ding, J
   Srihari, RK
GP ACL
TI A bootstrapping approach to named entity classification using successive
   learners
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper presents a new bootstrapping approach to named entity (NE) classification. This approach only requires a few common noun/pronoun seeds that correspond to the concept for the target NE type, e.g. he/she/man/woman for PERSON NE. The entire bootstrapping procedure is implemented as training two successive learners: (i) a decision list is used to learn the parsing-based high precision NE rules; (ii) a Hidden Markov Model is then trained to learn string sequence-based NE patterns. The second learner uses the training corpus automatically tagged by the first learner. The resulting NE system approaches supervised NE performance for some NE types. The system also demonstrates intuitive support for tagging user-defined NE types. The differences of this approach from the co-training-based NE bootstrapping are also discussed.
C1 Cymfony Inc, Williamsville, NY 14221 USA.
CR BECKWITH R, 1991, LEXICONS USING ON LI
   BIKEL DM, 1997, P ANLP 1997, P197
   Borthwick  A., 1998, P MUC 7
   COLLINS M, 1999, P 1999 JOINT SIGDAT
   Cucchiarelli A, 2001, COMPUT LINGUIST, V27, P123, DOI 10.1162/089120101300346822
   Cucerzan S., 1999, P 1999 JOINT SIGDAT, P90
   GALE W, 1992, P 4 DARPA SPEECH NAT, P233
   KIM J, 2002, COLING 2002
   Krupka G R, 1998, P MUC 7
   LIN D, 1998, COLING ACL 1998
   *MUC 7, 1998, P 7 MESS UND C MUC 7
   SEGAL R, 1994, P 12 NAT C ART INT
   SRIHARI R, 2000, P ANLP 2000 SEATTL
   Srihari R. K., 2003, P HLT NAACL 2003 WOR
   Thelen Michael, 2002, P EMNLP 2002
   YAROWKSY D, 1995, ACL 1995
NR 16
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 335
EP 342
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500043
DA 2019-06-15
ER

PT B
AU Park, SB
   Zhang, BT
AF Park, SB
   Zhang, BT
GP ACL
TI Text chunking by combining hand-crafted rules and memory-based learning
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper proposes a hybrid of hand-crafted rules and a machine learning method for chunking Korean. In the partially free word-order languages such as Korean and Japanese, a small number of rules dominate the performance due to their well-developed postpositions and endings. Thus, the proposed method is primarily based on the rules, and then the residual errors are corrected by adopting a memory-based machine learning method. Since the memory-based learning is an efficient method to handle exceptions in natural language processing, it is good at checking whether the estimates are exceptional cases of the rules and revising them. An evaluation of the method yields the improvement in F-score over the rules or various machine learning methods alone.
C1 Seoul Natl Univ, Sch Comp Sci & Engn, Seoul 151744, South Korea.
CR Cherkassky V., 1998, LEARNING DATA CONCEP
   *CONLL, 2000, SHAR TASK COMP NAT L
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Daelemans W, 1999, MACH LEARN, V34, P11, DOI 10.1023/A:1007585615670
   DAELEMANS W, 2001, TIMBL TILBURG MEMORY
   Golding AR, 1996, ARTIF INTELL, V87, P215, DOI 10.1016/0004-3702(95)00120-4
   Joachims T., 1998, MAKING LARGE SCALE S
   KIM KC, 1995, J KISS, V22, P1384
   Kudoh Taku, 2000, P CONLL 2000 LLL 200, P142
   PARK SB, 2001, P 19 INT C COMPUTER, P225
   Quinlan R., 1993, C4 5 PROGRAMS MACHIN
   RAMSHAW L, 1995, P 3 ACL WORKSH VER L, P80
   SHIN HP, 1999, P C HANG KOR LANG IN, P240
   YOON JT, 1999, CSTR99139 KAIST CORP
   ZHANG T, 2001, P 39 ANN M ASS COMP, P539
NR 15
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 497
EP 504
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500063
DA 2019-06-15
ER

PT B
AU Tiedemann, J
AF Tiedemann, J
GP ACL
TI Combining clues for word alignment
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB In this paper, a word alignment approach is presented which is based on a combination of clues. Word alignment clues indicate associations between words and phrases. They can be based on features such as frequency, part-of-speech, phrase type, and the actual wordform strings. Clues can be found by calculating similarity measures or learned from word aligned data. The clue alignment approach, which is proposed in this paper, makes it possible to combine association clues taking different kinds of linguistic information into account. It allows a dynamic tokenization into token units of varying size. The approach has been applied to an English/Swedish parallel text with promising results.
C1 Uppsala Univ, Dept Linguist, SE-75120 Uppsala, Sweden.
OI Tiedemann, Jorg/0000-0003-3065-7989
CR AHRENBERG L, 2002, P 3 INT C LANG RES E, P485
   AHRENBERG L, 1999, 15 1 UPPS DEP LING
   AHRENBERG L, 2000, P 2 INT C LANG RES E
   Ahrenberg Lars, 1998, P 36 ANN M ASS COMP, P29
   BALDRIDGE J, 2002, GROK OPEN SOURCE NAT
   Brants T., 2000, P 6 APPL NAT LANG PR
   DELAMED ID, 1998, 9806 IRCS U PENNS
   HEIN AS, 1999, 16 U UPPS DEP LING
   HIEMSTRA D, 1998, P 8 CLIN M, P41
   Megyesi B, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P151
   MEGYESI B, 2002, J MACHINE LEARNING R, P639
   Melamed I.D., 1997, P 2 C EMP METH NAT L
   Melamed ID, 1995, P 3 WORKSH VER LARG
   Merkel M., 1999, ANNOTATION STYLE GUI
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Smadja F, 1996, COMPUT LINGUIST, V22, P1
   TIEDEMANN J, 1999, P 12 NORD C COMP LIN, P216
   Tufis D., 2002, P 3 INT C LANG RES E, P458
   VOGEL S, 2000, VERBMOBIL FDN SPEECH
NR 19
TC 2
Z9 2
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 339
EP 346
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200044
DA 2019-06-15
ER

PT B
AU Yang, H
   Chua, TS
AF Yang, H
   Chua, TS
GP ACL
TI QUALIFIER: Question answering by lexical fabric and external resources
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB One of the major challenges in TREC-style question-answering (QA) is to overcome the mismatch in the lexical representations in the query space and document space. This is particularly severe in QA as exact answers, rather than documents, are required in response to questions. Most current approaches overcome the mismatch problem by employing either data redundancy strategy through the use of Web or linguistic resources. This paper investigates the integration of lexical relations and Web knowledge to tackle this problem. The results obtained on TREC11 QA corpus indicate that our approach is both feasible and effective.
C1 Natl Univ Singapore, Dept Comp Sci, Singapore 117543, Singapore.
CR *AAAI, 2002, AAAI SPR S SER
   *ACL EACL, 2002, WORKSH OP DOM QUEST
   BRILL E, 2002, P 2002 C EMP METH NA
   BRILL E, 2002, DATA INTENSIVE QUEST
   BUCHHOLZ S, 2002, P 10 TEXT RETR C
   CHEN J, 2001, P 10 TEXT RETR C
   CLARKE C, 2002, P 10 TEXT RETR C
   CLARKE CLA, 2001, P 24 ANN INT ACM SIG, P358
   Harabagiu S., 2001, P 9 TEXT RETR C TREC, P479
   HOVY E, 2001, P 10 TEXT RETR C
   Kwok C., 2001, P 10 WORLD WID WEB C, P150
   Li X., 2002, P 19 INT C COMP LING
   LIN CY, 2002, P 19 INT C COMP LING
   LIU J, 2001, P 37 M ASS COMP LING, P370
   MOLDOVAN DI, 2001, P ACL 2001 C JUL
   PASCA MA, 2001, P 24 ANN INT ACM SIG, P366
   PRAGER J, 2000, P 23 ANN INT ACM SIG, P184
   RADEV DR, 2002, 11 INT WORLD WID WEB
   VOORHEES EM, 2002, P 10 TEXT RETR C
   Witten I.H., 1999, MANAGING GIGABYTES
   YANG H, 2003, P 10 TEXT RETR C
NR 21
TC 2
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 363
EP 370
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200047
DA 2019-06-15
ER

PT S
AU Asaishi, T
AF Asaishi, Takuma
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI An analysis of the terminological structure of index terms in textbooks
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE terminology; textbook; network analysis
ID CONSISTENCY
AB The purpose of this study is to reveal the characteristics of the terminological structure formed by the index terms of junior-high school, high school and university-level textbooks. We first identify the types of concept of index terms, and then uncover the conceptual structure that underlies index terms. We found that, as the school level progresses, (1) the balance of concept types of index terms shift from concrete objects to their behaviours or features, (2) index terms as a whole shifts from a set of fragmented terms to a single indirectly-related group, (3) the core part of the index terms comes to be occupied by terms which represent concepts other than concrete objects. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Asaishi, Takuma] Univ Tokyo, Bunkyo Ku, Tokyo 1130033, Japan.
EM asaishi@p.u-tokyo.ac.jp
CR Chujo K, 2008, ENGLISH CORPUS STUDI, V115, P57
   Fukunaga T, 1990, J JAPAN INDEXERS ASS, V14, P1
   Hughes AV, 2011, J DOC, V67, P9, DOI 10.1108/00220411111105434
   Japan Indexers Association, 1983, IND MAN
   Japan Science and Technology Agency, 2008, STAND INF SCI TECHN
   Kageura K., 2002, DYNAMICS TERMINOLOGY
   Kageura K., 2008, MATH LINGUISTICS, V26, P241
   Kageura K, 2007, P 10 C PAC ASS COMP, P236
   Kamiyama T, 2008, BULLETING FACULTY ED, V58, P31
   Kurata K, 1993, J JAPAN INDEXERS ASS, V17, P1
   LANCASTER Frederick W, 1991, INDEXING ABSTRACTING
   National Language Research Institute, 1989, STUD VOC HIGH MIDDL
   Newman M., 2010, NETWORKS INTRO
   Nomura M, 1989, LIST STEMS JAPANESE
   Nozue T, 1992, J JAPAN INDEXERS ASS, V16, P1
   Saarti J, 2002, J DOC, V58, P49, DOI [10.1108/00220410210425403, 10.1108/0022041210425403]
   Sager J. C., 1990, PRACTICAL COURSE TER
   The Chicago manual of style, 2003, CHICAGO MANUAL STYLE
NR 18
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 209
EP 217
DI 10.1016/j.sbspro.2011.10.600
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700024
OA Other Gold
DA 2019-06-15
ER

PT S
AU Dankov, S
   Rzepka, R
   Araki, K
AF Dankov, Svetoslav
   Rzepka, Rafal
   Araki, Kenji
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI UIAR Common Sense: an augmented reality framework for creating games to
   collect common sense from users
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Augmented Reality Based Games; Human-Computer Interaction; Common Sense
   Acquisition
AB Augmented Reality (AR) applications have become widespread with the continued miniaturization of technology. With the increasing use of smart phones, which often provide increased processing power, enhanced and open software platforms, Augmented Reality has become instrumental in the way we perceive our surroundings and the information that it carries. Augmented Reality has also become a welcome visualization tool for many fields, not restricted to Human-Computer Interaction. In this paper we present a novel approach for building interactive interfaces using Augmented Reality and we give an example how one can use our framework for creating games to collect common sense knowledge from users. We present a software framework for ubiquitous Augmented Reality enhancement for human-computer interaction called UIAR (User Interface through AR). Our framework improves on four areas in Augmented Reality development that we currently see lacking. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Dankov, Svetoslav; Rzepka, Rafal; Araki, Kenji] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
EM dankov@media.eng.hokudai.ac.jp
RI Rzepka, Rafal/L-9585-2019
OI Rzepka, Rafal/0000-0002-8274-0875
CR A. Inc, 2009, ART
   Ahn L. V, 2006, P ACM CHI 2006 C HUM, V1, P75
   Billinghurst M, 2009, ARTOOLKIT
   Do-Lenh S, 2009, TEI2009 3 INT C TANG, P16
   Lee B, 2009, ICCIT 09 SEOUL
   Lenat D, 1990, COMMUN ACM, P30
   Lieberman H, 2007, IUIF07
   Mistry P., 2009, CHI 09 HUM FACT COMP
   Nyatla, 2009, NYART AS3
   REKIMOTO J, 2002, SIGCHI C HUM FACT CO, P113
   Saqoosha, 2009, FLARTOOLKIT
   Singh Push, 2002, P AAAI SPRING S ACQ
   Socolofsky E, 2009, FLARMANAGER
   Ulloa C, 2009, PAPERVISION3D 3D ENG
NR 14
TC 1
Z9 1
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 274
EP 280
DI 10.1016/j.sbspro.2011.10.608
PG 7
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700032
OA Other Gold, Green Published
DA 2019-06-15
ER

PT S
AU Kawamura, T
   Ohno, S
AF Kawamura, Tsuyoshi
   Ohno, Sumio
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI A study on the difference of emotional perception between Japanese and
   Chinese
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE emotional perception; impression; cultural dependency
AB In order to detect the difference of acoustic features in effective on emotional perception such as happiness, sadness, anger and fear between Japanese and Chinese. In addition, we also adopted some impressions as the middle layer of these estimation models by two steps. First, we produced a linear estimation model for each emotions with the values of impressions evaluated, and we also created the models to estimate impressions. We assessed the models created in different way on its accuracy and the standardized partial regression coefficients. As a result, happiness and anger show that they have same tendency on acoustic features contributed in estimating impressions. We assumed that they have little or none cultural dependency on perception of impressions at least between Japanese and Chinese. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Kawamura, Tsuyoshi] Tokyo Univ Technol, Grad Sch Bion Comp & Media Sci, Tokyo, Japan.
   [Ohno, Sumio] Tokyo Univ Technol, Sch Comp Sci, Tokyo, Japan.
RP Kawamura, T (reprint author), Tokyo Univ Technol, Grad Sch Bion Comp & Media Sci, Tokyo, Japan.
EM kawamura@so.cs.teu.ac.jp
FU Ministry of Science and technological Development Republic of Serbia
   [TR36005, 36006]
FX This work was partially supported by the Ministry of Science and
   technological Development Republic of Serbia,through the projects
   TR36005 and TR 36006, for the period 2011-2014.
CR Arimoto Y., 2005, P INTERSPEECH 2007, P2217
   Grimm M., 2005, AUT SPEECH REC UND 2, P381
   Jiang X., 2005, IEEE INT C COMM CIRC, V2
   Mori H, 2011, SPEECH COMMUN, V53, P36, DOI 10.1016/j.specom.2010.08.002
   Vladimir H., 2003, J SPEECH TECHNOL, V6, P311
NR 5
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 95
EP 104
DI 10.1016/j.sbspro.2011.10.587
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700011
OA Other Gold
DA 2019-06-15
ER

PT S
AU Lajis, AB
   Aziz, NA
AF Lajis, Adidah Binti
   Aziz, Normaziah Abdul
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Part-of-speech in a node-link scoring techniques for assessing learners'
   understanding
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Part-of-speech; node-link analysis; automated assessment; learners'
   understanding
AB Assessment is the process of which the quality of the candidate achievements can be judged. Automated assessment tools can be useful assistants to human examiners. This paper discusses a work on an automated assessment tool that applied a node-link analysis technique. The tool is able to assess short sentences answers. It uses Part-of-speech as important criteria during the node analysis process. Results have shown that using more relevant Part-of-speech gives a more reliable assessment results in judging a learners' understanding on a particular subject matter. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Lajis, Adidah Binti; Aziz, Normaziah Abdul] Int Islamic Univ Malaysia, Kulliyah Informat & Commun Technol, Dept Comp Sci, Kuala Lumpur 50728, Malaysia.
EM naa@iium.edu.my
OI LAJIS, ADIDAH/0000-0002-6416-3939
CR Adidah Lajis, 2010, P INT C COMP RES DEV
   Allen E. B., 1995, THESIS FLORIDA ATLAN
   Ausubel D. P., 1963, PSYCHOL MEANINGFUL V
   Bennett R., 2000, J TECHNOLOGY LEARNIN, V1, P3
   Biber D., 1999, LONGMAN GRAMMAR SPOK
   Bull J., 2002, ASCILITE 2002 AUCKL
   Canas A. J., 2003, SUMMARY LIT PERTAINI
   Canas A. J., 2006, 2 INT C CONC MAPP OR
   Cook SDN, 1999, ORGAN SCI, V10, P381, DOI 10.1287/orsc.10.4.381
   FISHER KM, 1990, J RES SCI TEACH, V27, P1001, DOI 10.1002/tea.3660271008
   Fleiss J., 1981, STAT METHODS RATES P
   Foltz P. W., 2000, Interactive Learning Environments, V8, P111, DOI 10.1076/1049-4820(200008)8:2;1-B;FT111
   Gentner D, 1998, COGNITION, V65, P263, DOI 10.1016/S0010-0277(98)00002-X
   Hsu C. K., 2002, IEEE 2 INT C ADV LEA
   Jonassen D. H., 2000, COMPUTERS MINDTOOLS
   Landauer T. K., 1997, 19 ANN M COGN SCI SC
   Lemaire B, 2001, J EDUC COMPUT RES, V24, P305, DOI 10.2190/G649-0R9C-C021-P6X3
   Losee RM, 1997, J AM SOC INFORM SCI, V48, P254, DOI 10.1002/(SICI)1097-4571(199703)48:3<254::AID-ASI6>3.0.CO;2-W
   MacFadyen H., 2007, WRITING CTR HYPERGRA
   Pena AN, 2008, PROFILE-BOGOTA, V9, P9
   Novak JD, 1984, LEARNING LEARN
   Sen S., 2004, NCGIA SPEC M
   Shah C., 2002, STUDY EVALUATING IMP
   Sternberg R. J., 1988, PSYCHOL HUMAN THOUGH
   Turney P, 2002, ERB1096 NAT RES COUN
   Turney P. D., 2002, 44929 ERB1094NRC
   Valerio A., 2006, 2 INT C ON CONC MAPP
   van Emden M. H., 1970, MACH INTELL, V5, P361
   Villalon J. J., 2008, 2008 IEEE WIC ACM IN
NR 29
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 131
EP 139
DI 10.1016/j.sbspro.2011.10.591
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700015
OA Other Gold
DA 2019-06-15
ER

PT S
AU Lee, J
AF Lee, John
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Verb Tense Generation
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Type your keywords here; separated by semicolons
AB Correct usage of verb tenses is important because they encode the temporal order of events in a text. However, tense systems vary from one language to another, and are difficult to master for machines and non-native speakers alike. We present a method to predict verb tenses based on syntactic and lexical features, as well as temporal expressions in the context. A statistical model trained on Conditional Random Fields significantly outperforms the baseline. This model may be used in post-editing verbs in machine translation output and texts written by non-native speakers. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Lee, John] City Univ Hong Kong, Dept Chinese Translat & Linguist, Halliday Ctr Intelligent Applicat Language Studie, Kowloon, Hong Kong, Peoples R China.
OI LEE, John Sie Yuen/0000-0003-2505-2678
CR Baker C. F., 2003, P ACL SAPP JAP
   Chambers N., 2008, P EMNLP
   Collins Michael, 1999, THESIS U PENNSYLVANI
   Dorr BJ, 1999, ADV COMPUT, V49, P1, DOI 10.1016/S0065-2458(08)60282-X
   Ehrich V., 1987, NATURAL LANGUAGE GEN
   Elson D. K., 2010, P 6 INT NAT LANG GEN
   Fum D., 1989, P 4 C EUR ASS COMP L
   Goldberg A., 1995, CONSTRUCTIONS CONSTR
   GROSZ BJ, 1995, COMPUTATIONAL LINGUI, V21
   KAMEYAMA M, 1993, P 31 ANN M ASS COMP, P70
   Knutsson O, 2007, COMPUT EDUC, V49, P1122, DOI 10.1016/j.compedu.2006.01.005
   Lapata M, 2006, J ARTIF INTELL RES, V27, P85, DOI 10.1613/jair.2015
   Leacock C., 2009, P 4 WORKSH INN US NL
   LEE JW, 2008, P INT S COMP ARCH, P89, DOI DOI 10.1109/ISCA.2008.31
   Levin B., 1993, ENGLISH VERB CLASSES
   MANI I, 2000, P 38 ANN M ASS COMP, P69
   Mani I, 2006, P 21 INT C COMP LING, P753
   Marcus M., 1993, COMPUTATIONAL LINGUI, V19
   MATTHIESSEN CMI, 1996, MEANING FORM SYSTEMI, P431
   McCallum Andrew, 2001, P ICML
   McCallum Andrew Kachites, 2002, MALLET MACHINE LEARN
   NERBONNE J, 1986, LINGUIST PHILOS, V9, P83
   Reichart R., 2010, P EMNLP CAMBR MA
   Reichenbach H., 1947, ELEMENTS SYMBOLIC LO
   Schiehlen M., 2000, P 18 INT C COMP LING
   Sha F., 2003, SHALLOW PARSING COND
   Wang C., 2006, ACM T SPEECH LANGUAG, V3
   Webber B. L., 1988, Computational Linguistics, V14, P61
   Ye Y., 2005, P IJCNLP
NR 29
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 122
EP 130
DI 10.1016/j.sbspro.2011.10.590
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700014
OA Other Gold
DA 2019-06-15
ER

PT S
AU Liang, B
   Utsuro, T
   Yamamoto, M
AF Liang, Bing
   Utsuro, Takehito
   Yamamoto, Mikio
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Identifying Bilingual Synonymous Technical Terms from Phrase Tables and
   Parallel Patent Sentences
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Bilingual Lexicon Acquisition; Synonyms; Phrase Tables; Statistical
   Machine Translation; Parallel Corpus
AB In the task of acquiring technical term translation equivalent pairs, we consider situations where a technical term is observed in many parallel patent sentences and is translated into many translation equivalents. This paper especially studies the issue of identifying synonymous translation equivalent pairs of technical terms. First, we collect candidates of synonymous translation equivalent pairs from parallel patent sentences. Then, we analyze features for identifying synonymous translation equivalent pairs. Finally, we apply the Support Vector Machines (SVMs) to the task of identifying bilingual synonymous technical terms, and achieve the performance of almost 98% precision and over 40% F-measure. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Liang, Bing; Utsuro, Takehito; Yamamoto, Mikio] Univ Tsukuba, Tsukuba, Ibaraki 3058573, Japan.
EM utsuro@iit.tsukuba.ac.jp
CR Fujii A., 2008, P 8 AMTA, P97
   Fung P., 1998, P 17 INT C COMP LING, V1, P414
   HUANG F, 2005, P HUM LANG TECHN C C, P483
   Itagaki M., 2007, P MT SUMM 11, P269
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   LIN D, 2003, P 18 INT JOINT C ART, P1492
   MATSUMOTO Y, 2000, HDB NATURAL LANGUAGE, P563
   Morishita Yohei, 2008, P 8 AMTA, P153
   Tonoike M., 2006, P 2 INT WORKSH WEB C, P11
   Tsunakawa T., 2008, P 3 IJCNLP, P457
   Utiyama Masao, 2007, P MT SUMM 11, P475
   Vapnik V. N., 1998, STAT LEARNING THEORY
NR 12
TC 1
Z9 2
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 50
EP 60
DI 10.1016/j.sbspro.2011.10.582
PG 11
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700006
OA Other Gold
DA 2019-06-15
ER

PT S
AU Murakami, J
   Hotta, H
AF Murakami, Jin'ichi
   Hotta, Haseo
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Japanese Speaker-Independent Homonyms Speech Recognition
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
AB Japanese has homonyms such as "hashi "( (Chop-sticks)) and " hashi "( (Bridge)). Word speech recognition has been studied for a long time, but homonym speech recognition in Japanese has not been studied. In this paper, we studied speaker-independent homonym speech recognition. For homonym speech recognition, pitch extraction has been normally used to estimate a pitch frequency.. However, we did not use pitch extraction in our study. Instead, we used an accent model that was a phoneme label with more length, Mora position, accent type and accent high or low. It means that we used the effect of pitch on formant. The results of the experiments were that 89% accuracy was obtained by using MFCC, full covariance HMM, and the accent model. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Murakami, Jin'ichi; Hotta, Haseo] Tottori Univ, Dept Informat & Knowledge Eng, Tottori 6808550, Japan.
EM murakami@ike.tottori-u.ac.jp
CR [Anonymous], 1998, NHK JAP ACC DICT
   Hirose Keikichi, 2003, EUR 2003, P3149
   Huang X. D., 1990, HIDDEN MARKOV MODELS
   Lee K-F., 1989, AUTOMATIC SPEECH REC
   Lyu Dau-Cheng, 2003, EUR 2003, P1861
   Murakami Jinichi, 1988, 1988 AUT M AC SOC JA, P89
   Yi-hao K., 2006, INTERSPEECH 2006, P1814
   Young Steve, 2002, HTK VERSION 3 2 REFE
NR 8
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 306
EP 313
DI 10.1016/j.sbspro.2011.10.612
PG 8
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700036
OA Other Gold
DA 2019-06-15
ER

PT S
AU Pais, S
   Dias, G
   Wegrzyn-Wolska, K
   Mahl, R
   Jouvelot, P
AF Pais, Sebastiao
   Dias, Gael
   Wegrzyn-Wolska, Katarzyna
   Mahl, Robert
   Jouvelot, Pierre
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Textual Entailment by Generality
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Asymmetric Association Measures; Informative Asymmetric Measure; Textual
   Entailment
AB Textual Entailment consists in determining if an entailment relation exists between two texts. In this paper, we present an Informative Asymmetric Measure called the Asymmetric InfoSimba (AIS), which we combine with different asym-metric association measures to recognize the specific case of Textual Entailment by Generality. In particular, the AIS proposes an unsupervised, language-independent, threshold free solution. This new measure is tested against the first Recognizing Textual Entailment dataset for an exhaustive number of asymmetric association measures and shows that the combination of the AIS with the Braun-Blanket steadily improves results against competitive measures such as the one proposed by [1]. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Pais, Sebastiao; Dias, Gael] HULTIG Univ Beira Interior, Covilha, Portugal.
   [Dias, Gael] Univ Caen Basse Normandie, DLU, GREYC, F-14032 Caen, France.
   [Wegrzyn-Wolska, Katarzyna] Ecole Super dIngenieurs Informat, Genie des Telecommun, SITR, Villejuif, France.
   [Mahl, Robert; Jouvelot, Pierre] Ecole Natl Superieure des Mines de Paris, CRI, Paris, France.
RP Pais, S (reprint author), HULTIG Univ Beira Interior, Covilha, Portugal.
EM sebastiao@hultig.di.ubi.pt; ddg@hultig.di.ubi.pt;
   katarzyna.wegrzyn@esigetel.fr; mahl@ensmp.fr;
   pierre.jouvelot@mines-paristech.fr
RI Pais, Sebastiao/J-4766-2017; Pais, Sebastiao/J-3781-2019
OI Pais, Sebastiao/0000-0003-2337-0779; Pais, Sebastiao/0000-0003-2337-0779
CR Bayer S., 2005, P PASCAL CHALL WORKS, P41
   Bos J., 2005, P 1 PASCAL CHALL WOR, P65
   Caraballo S A, 1999, P 37 ANN M ASS COMP, P120
   Cleuziou G., 2011, P 20 ACM C INF KNOWL
   Dagan I., 2005, P 1 CHALL WORKSH REC
   Delmonte R., 2005, P 1 CHALL WORKSH REC, P49
   Dias G., 2007, P 22 C ART INT AAAI, P1334
   Dias G., 2008, P 12 INT C NAT LANG, P147
   Glickman O., 2005, P PASCAL CHALL WORKS, P33
   Hearst A., 1992, P 14 C COMP LING, P539
   Herrera J., 2005, P PASCAL CHALL WORKS, P21
   Michelbacher L., 2007, P INT C REC ADV NAT, P1
   Mihalcea R., 2004, P C EMP METH NAT LAN
   Newman E., 2005, P PASCAL CHALL WORKS, P53
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Papineni K., 2001, BLEU METHOD AUTOMATI
   Pecina P., 2006, P COLING ACL MAIN C, P651
   PEREZ D, 2005, P 1 CHALL WORKSH REC, P9
   Riloff E, 1997, P 2 C EMP METH NAT L, P117
   Sanderson M, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P206, DOI 10.1145/312624.312679
   Tan PN, 2004, INFORM SYST, V29, P293, DOI 10.1016/S0306-4379(03)00072-3
NR 21
TC 1
Z9 1
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 258
EP 266
DI 10.1016/j.sbspro.2011.10.606
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700030
OA Other Gold
DA 2019-06-15
ER

PT S
AU Schwitter, R
AF Schwitter, Rolf
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Specifying Events and their Effects in Controlled Natural Language
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Controlled natural language; specifications; Event Calculus; commonsense
   knowledge
ID CALCULUS
AB This paper shows how a controlled natural language can be used to construct precise formal representations for reasoning about events and their effects. Specifications written in PENG Light are translated with the help of discourse representation structures into the input language of the Simplified Event Calculus. This logic-based formalism is declarative and can be used for various reasoning tasks, among them for question answering. Taking a simple scenario from the transport domain as a starting point, we illustrate how PENG Light can be used to specify the narrative part of the scenario and the commonsense knowledge that is required to reason about direct and indirect effects of events as well as about continuous change. There is no need to encode this scenario and the background axioms in a formal notation, since the relevant information can be expressed directly on the level of the controlled natural language. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Schwitter, Rolf] Macquarie Univ, N Ryde, NSW 2109, Australia.
EM rolf.Schwitter@mq.edu.au
OI Schwitter, Rolf/0000-0001-8998-7005
CR Fuchs NE, 1999, LECT NOTES COMPUT SC, V1559, P1, DOI 10.1007/3-540-48958-4_1
   KOWALSKI R, 1992, J LOGIC PROGRAM, V12, P121, DOI 10.1016/0743-1066(92)90041-Z
   KOWALSKI R, 1986, NEW GENERAT COMPUT, V4, P67, DOI 10.1007/BF03037383
   Miller R, 2002, LECT NOTES ARTIF INT, V2408, P452
   Mueller E. T, 2006, COMMONSENSE REASONIN
   Parsons T., 1994, EVENTS SEMANTICS ENG
   Schoenmackers S., 2010, P C EMP METH NAT LAN, P1088
   Schwarz RB, 2003, PROCESSING AND PROPERTIES OF STRUCTURAL NANOMATERIALS, P141
   Schwitter R., 2010, P 23 INT C COMP LING, P1113
   Shanahan M., 1997, SOLVING FRAME PROBLE
   White C, 2009, P ALTA 2009 SYDN AUS, P80
NR 11
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 12
EP 21
DI 10.1016/j.sbspro.2011.10.578
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700002
OA Other Gold
DA 2019-06-15
ER

PT S
AU Shamsa, R
   Mercer, RE
AF Shamsa, Rushdi
   Mercer, Robert E.
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Extracting Connected Concepts from Biomedical Texts using Fog Index
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Computational Linguistics; Text mining; Connected Concepts; Fog Index;
   Text Readability
AB In this paper, we establish Fog Index (FI) as a text filter to locate the sentences in texts that contain connected biomedical concepts of interest. To do so, we have used 24 random papers each containing any of the four pairs of connected concepts. For each pair, we categorize sentences based on whether they contain both, any or none of the concepts. We then use FI to measure the difficulty of the sentences of each category and find that sentences containing both of the concepts have low readability. We rank sentences of a text according to their FI and select 30 percent of the most di cult sentences. We use an association matrix to track the most frequent pairs of concepts in them. This matrix reports that the first filter produces some pairs that hold almost no connections. To remove these unwanted pairs, we use the Equally Weighted Harmonic Mean of their Positive Predictive Value (PPV) and Sensitivity as a second filter. Experimental results demonstrate the effectiveness of our method. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Shamsa, Rushdi; Mercer, Robert E.] Univ Western Ontario, Dept Comp Sci, London, ON N6A 5B7, Canada.
EM rshams@uwo.ca
CR Agarwal S, 2009, BIOINFORMATICS, V25, P3174, DOI 10.1093/bioinformatics/btp548
   Dai HJ, 2010, J COMPUT SCI TECH-CH, V25, P169
   Du y TM, 1982, J EDUC PSYCHOL, V74, P733
   Frunza O, 2010, 2010 WORKSH BIOM NAT, P91
   Goh OS, 2007, 3 INT C NAT COMP ICN, P480
   Gunning R, 1969, J BUS COMMUN, V6, P3, DOI DOI 10.1177/002194366900600202
   Kazama J., 2002, ACL 02 WORKSH NAT LA, V3, P1
   Krallinger M, 2008, GENOME BIOL, V9, P2
   Leroy G, 2003, J BIOMED INFORM, V36, P145, DOI 10.1016/S1532-0464(03)00039-X
   Lindsay RK, 1999, J AM SOC INFORM SCI, V50, P574, DOI 10.1002/(SICI)1097-4571(1999)50:7<574::AID-ASI3>3.0.CO;2-Q
   Perez-Iratxeta C, 2006, DISCOVERING BIOMOLEC, P74
   Rosario B, 2004, 42 ANN M ASS COMP LI
   Sherman A. L., 1893, ANAL LIT MANUAL OBJE
   Smith L., 2008, GENOME BIOL S2, V9, P2
   SWANSON DR, 1986, PERSPECT BIOL MED, V30, P7
   SWANSON DR, 1989, J AM SOC INFORM SCI, V40, P432, DOI 10.1002/(SICI)1097-4571(198911)40:6<432::AID-ASI5>3.0.CO;2-#
   Tsuruoka Y, 2005, LECT NOTES COMPUT SC, V3746, P382
   Unified Medical Language System (UMLS), 2011, UMLS TERM SERV UTS
   Yuan F, 2010, LECT NOTES ARTIF INT, V6216, P42, DOI 10.1007/978-3-642-14932-0_6
   Zhao S, 2004, INT JOINT WORKSH NAT, P84
NR 20
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 70
EP 76
DI 10.1016/j.sbspro.2011.10.584
PG 7
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700008
OA Other Gold
DA 2019-06-15
ER

PT S
AU Suzuki, T
   Hasegawa, S
   Hamamoto, T
   Aizawa, A
AF Suzuki, Takafumi
   Hasegawa, Shin
   Hamamoto, Takayuki
   Aizawa, Akiko
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Document recommendation using data compression
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Data compression; document recommendation; LZ78; PRDC; document
   classification
AB We propose a new method of content-based document recommendation using data compression. Though previous studies mainly used bags-of-words to calculate the similarity between the profile and target documents, users in fact focus on larger unit than words, when searching information from documents. In order to take this point into consideration, we propose a method of document recommendation using data compression. Experimental results using Japanese newspaper corpora showed that (a) data compression performed better than the bag-of-words method, especially when the number of topics was large; (b) our new method outperformed the previous data compression method; (c) a combination of data compression and bag-of-words can also improve performance. We conclude that our method better captures users' profiles and thus contributes to making a better document recommendation system. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Suzuki, Takafumi] Univ Tokyo, Fac Sociol, Bunkyo Ku, 5-28-20 Hakusan, Tokyo, Japan.
   [Hasegawa, Shin] Sony, Minato Ku, Tokyo, Japan.
   [Hamamoto, Takayuki] Tokyo Univ Sci, Fac Engn, Chiyoda Ku, Tokyo, Japan.
   [Aizawa, Akiko] Natl Inst Informat Digital Content & Med Sci Res, Chiyoda Ku, Tokyo, Japan.
RP Suzuki, T (reprint author), Univ Tokyo, Fac Sociol, Bunkyo Ku, 5-28-20 Hakusan, Tokyo, Japan.
CR Agata T, 2005, LIBR INFORM SC, P1
   Bertacchini M., 2007, P 4 C IB SEG INF CIB, P329
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Buscher G., 2008, P 31 ANN INT ACM SIG, P387
   Buscher G., 2008, P CHI, P3045
   Cebrian M., 2005, COMMUNICATIONS INFOR, V15, P367
   Cilibrasi R, 2005, IEEE T INFORM THEORY, V51, P1523, DOI 10.1109/TIT.2005.844059
   Hasegawa S., 2009, P JSAI, p3I2
   Helmer S., 2007, P 33 INT C VER LARG, P1022
   Ishihara M., 2008, J INFORM PROCESSING, V49, P4016
   Kimura H., 2006, 2006F1842006NL175 IP, P65
   Kramm M., 2007, P IEEE SITIS, P989
   Liu DR, 2008, J SYST SOFTWARE, V81, P1377, DOI 10.1016/j.jss.2007.10.027
   Mochihashi Daichi, 2009, P JOINT C 47 ANN M A, P100
   Mooney R J, 2000, P 5 ACM C DIG LIB, P195, DOI DOI 10.1145/336597.336662
   Nykter M., 2005, IEEE GENSIPS
   Sawai Y., 2008, J NATURAL LANGUAGE P, V15, P101
   Sayood K., 2006, INTRO DATA COMPRESSI
   Stamatatos E, 2009, J AM SOC INF SCI TEC, V60, P538, DOI 10.1002/asi.21001
   Sugiyama K., 2004, P 13 INT C WORLD WID, P675, DOI DOI 10.1145/988672.988764
   Tsatsaronis G., 2010, P 23 INT C COMP LING, P1074
   Watanabe T, 2002, IEEE T PATTERN ANAL, V24, P579, DOI 10.1109/34.1000234
   ZIV J, 1978, IEEE T INFORM THEORY, V24, P530, DOI 10.1109/TIT.1978.1055934
NR 23
TC 1
Z9 1
U1 1
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 150
EP 159
DI 10.1016/j.sbspro.2011.10.593
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700017
OA Other Gold
DA 2019-06-15
ER

PT S
AU Vempaty, PC
   Nagalla, SCP
AF Vempaty, Phani Chaitanya
   Nagalla, Satish Chandra Prasad
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Automatic Sandhi Spliting Method for Telugu, an Indian Language
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Sandhi; automata; linguistic
AB Developing better methods for segmenting continuous text into words is important for improving the processing of Indian languages. In this paper we discuss the methodology of building a tool for Sandhi splitting for Telugu, an Indian language. Sandhi is a process in which two or more words unite to form a compound word by undergoing some modification. This is due to the influence of adjacent words. We propose a method that uses simple finite state automata for finding the possible candidates for a given compound word. We then make use of some linguistically-driven empirical scoring mechanism for pruning and then compute the scores based on the joint probability between the possible syllables that undergo Sandhi. We made use of corpus of size 158k words as base words for building the finite state machines. We discuss our scoring mechanisms and our system performs with an accuracy of 80.30% on a test size of 500 words. We also discuss briefly about the errors made by our system and our reflections upon them. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Vempaty, Phani Chaitanya; Nagalla, Satish Chandra Prasad] Language Technol Researc Ctr IIIT Hyderabad, Hyderabad 500032, Andhra Pradesh, India.
EM srpchaitanya@students.iiit.ac.in; satish.nagalla@research.iiit.ac.in
CR Ambati Bharat Ram, 2009, P ICON09 NLP TOOLS C
   Brent MR, 1999, MACH LEARN, V34, P71, DOI 10.1023/A:1007541817488
   Chowdhury G G, 1999, INTRO MODERN INFORM
   Goldsmith J, 2001, COMPUT LINGUIST, V27, P153, DOI 10.1162/089120101750300490
   Ha Le An, 2003, P CORPUS LINGUISTICS
   Jean H.D, 1998, WORKSH PAR GROUND NA, P295
   Kawtrakul A., 1997, P 5 WORKSH VER LARG, P289
   Keshava S., 2006, CHALL WORKSH UNS SEG
   Kruengkrai C., 2006, P 5 INT C LANG RES E
   MEKNAVIN S, 1997, P NLPRS 97, P289
   Mittal Vipul, 2010, P ACL 2010 STUD RES
   Nagata Masaaki, 1994, P 15 INT C COMP LING, P201
   Nguyen H., 2005, 3 INT C COMP SCI RIV
   PAPAGEORGIOU CP, 1994, P HLT WORKSH, P283
   Peng F., 2004, P 20 INT C COMP LING
   Poowarawan Y., 1986, P 9 EL ENG C
   Schone P., 2001, P 2 M N AM CHAPT ASS
   Singh Smriti, 2006, P 44 ANN M ASS COMP
   Sproat Richard, 1996, ASS COMPUTATIONAL LI, V22
   Theeramunkong T., 2001, HUM LANG TECHN C P
NR 20
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 218
EP 225
DI 10.1016/j.sbspro.2011.10.601
PG 8
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700025
OA Other Gold
DA 2019-06-15
ER

PT S
AU Yokomoto, D
   Makita, K
   Utsuro, T
   Kawada, Y
   Fukuhara, T
AF Yokomoto, Daisuke
   Makita, Kensaku
   Utsuro, Takehito
   Kawada, Yasuhide
   Fukuhara, Tomohiro
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Utilizing Wikipedia in categorizing Topic related blogs into Facets
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Blog; Faceted Search; Wikipedia; Topic Analysis; Search Engine
AB Given a search query, most existing search engines simply return a ranked list of search results. However, it is often the case that those search result documents consist of a mixture of documents that are closely related to various sub-topics. This paper proposes a framework of categorizing blog posts according to their sub-topics. In our framework, the sub-topic of each blog post is identified by utilizing Wikipedia entries as a knowledge source and each Wikipedia entry title is considered as a sub-topic label. We achieve to quickly overview the distribution of sub-topics over the whole collected blog posts. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Yokomoto, Daisuke; Makita, Kensaku; Utsuro, Takehito] Univ Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.
   [Kawada, Yasuhide] Navix Co Ltd, Tokyo 1410031, Japan.
   [Fukuhara, Tomohiro] Natl Inst Adv Ind Sci & Technol, Tokyo 1350064, Japan.
RP Utsuro, T (reprint author), Univ Tsukuba, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.
EM utsuro@iit.tsukuba.ac.jp
CR Carmel D, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P139, DOI 10.1145/1571941.1571967
   de Winter Wouter, 2007, P ICWSM, P251
   Fujimura K., 2006, P 3 ANN WORKSH WEBL
   Harashima J., 2010, P 2 WORKSH NLPIX, P12
   Hu J., 2008, P 31 ANN INT ACM SIG, P179, DOI DOI 10.1145/1390334.1390367
   Li Chengkai, 2010, P 19 INT C WORLD WID, P651
   Macdonald C., 2009, P TREC 2009
   Shibata Tomohide, 2009, P WI IAT, P325
   Toda H., 2007, INT J HUMAN COMPUTER, P3
   Tunkelang D., 2009, SYNTHESIS LECTURES I
NR 10
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 169
EP 177
DI 10.1016/j.sbspro.2011.10.595
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700019
OA Other Gold
DA 2019-06-15
ER

PT B
AU Chen, WL
   Kazama, J
   Torisawa, K
AF Chen, Wenliang
   Kazama, Jun'ichi
   Torisawa, Kentaro
GP Assoc Computat Linguist
TI Bitext Dependency Parsing with Bilingual Subtree Constraints
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper proposes a dependency parsing method that uses bilingual constraints to improve the accuracy of parsing bilingual texts (bitexts). In our method, a target-side tree fragment that corresponds to a source-side tree fragment is identified via word alignment and mapping rules that are automatically learned. Then it is verified by checking the subtree list that is collected from large scale automatically parsed data on the target side. Our method, thus, requires gold standard trees only on the source side of a bilingual corpus in the training phase, unlike the joint parsing model, which requires gold standard trees on the both sides. Compared to the reordering constraint model, which requires the same training data as ours, our method achieved higher accuracy because of richer bilingual constraints. Experiments on the translated portion of the Chinese Treebank show that our system outperforms monolingual parsers by 2.93 points for Chinese and 1.64 points for English.
C1 [Chen, Wenliang; Kazama, Jun'ichi; Torisawa, Kentaro] Natl Inst Informat & Commun Technol, MASTAR Project, Language Infrastruct Grp, 3-5 Hikari Dai, Seika, Kyoto 6190289, Japan.
RP Chen, WL (reprint author), Natl Inst Informat & Commun Technol, MASTAR Project, Language Infrastruct Grp, 3-5 Hikari Dai, Seika, Kyoto 6190289, Japan.
EM chenwl@nict.go.jp; kazama@nict.go.jp; torisawa@nict.go.jp
CR Bies Ann, 2007, LDC2007T02
   Burkett David, 2008, P 2008 C EMP METH NA, P877
   CARRERAS X, 2007, P CONLL SHAR TASK SE, P957
   Chen W., 2009, P EMNLP 09 SING AUG, P570
   DeNero J., 2007, P 45 ANN M ASS COMP, P17
   Ding Yuan, 2005, ACL 05, P541
   Eisner J., 1996, P 16 INT C COMP LING, P340
   Huang Chu-Ren, 2009, LDC2009T14
   Huang Liang, 2009, P 2009 C EMP METH NA, P1222
   Koehn P, 2003, P HUM LANG TECHN C N, P54
   Kruengkrai Canasai, 2009, P JOINT C 47 ANN M A, V1, P513
   Liang P., 2006, P HUM LANG TECHN C N, P104
   McDonald R., 2005, P ACL
   McDonald R., 2006, P EACL2006
   Nakazawa T., 2006, P INT WORKSH SPOK LA, P64
   Nivre J., 2008, P ACL 08 HLT COL OH
   Nivre J., 2006, COLING ACL
   NIVRE J, 2003, P 8 INT WORKSH PARS, P149
   Smith David A., 2004, P EMNLP
   Xue Nianwen, 2002, COLING
   Yamada H., 2003, P 8 INT WORKSH PARS, V3, P195
   Zhao Hai, 2009, P JOINT C 47 ANN M A, P55
NR 22
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 21
EP 29
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300003
DA 2019-06-15
ER

PT B
AU Cohen, SB
   Smith, NA
AF Cohen, Shay B.
   Smith, Noah A.
GP Assoc Computat Linguist
TI Viterbi Training for PCFGs: Hardness Results and Competitiveness of
   Uniform Initialization
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID COMPLEXITY; MODELS
AB We consider the search for a maximum likelihood assignment of hidden derivations and grammar weights for a probabilistic context-free grammar, the problem approximately solved by " Viterbi training." We show that solving and even approximating Viterbi training for PCFGs is NP-hard. We motivate the use of uniformat- random initialization for Viterbi EM as an optimal initializer in absence of further information about the correct model parameters, providing an approximate bound on the log-likelihood.
C1 [Cohen, Shay B.; Smith, Noah A.] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
RP Cohen, SB (reprint author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
EM scohen@cs.cmu.edu; nasmith@cs.cmu.edu
CR ABE N, 1992, MACH LEARN, V9, P205, DOI 10.1007/BF00992677
   Abney S, 2008, CH CRC COMP SCI DATA, P1
   Aloise D, 2009, MACH LEARN, V75, P245, DOI 10.1007/s10994-009-5103-0
   Arthur David, 2007, P ACM SIAM S DISCR A
   Casacuberta F., 2000, P ICGI
   Charniak E., 1997, P AAAI
   Cohen S., 2009, P HLT NAACL
   Collins M, 2003, PLOUGHSHARES, V29, P29
   Day W. H. E., 1983, J THEORETICAL BIOL, V103
   DeNero J., 2008, P ACL
   Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534
   Goldwater S., 2005, P CONLL
   Goodman J. T., 1998, THESIS
   Grenander U., 1967, TECHNICAL REPORT
   Johnson M., 2006, ADV NIPS
   Johnson M., 2007, P NAACL
   Klein D., 2001, ADV NIPS
   Knight K, 1999, COMPUT LINGUIST, V25, P607
   Lloyd S., 1982, IEEE T INFORM THEORY
   Lyngso RB, 2002, J COMPUT SYST SCI, V65, P545, DOI 10.1016/S0022-0000(02)00009-0
   Mahajan M., 2009, P INT WORKSH ALG COM
   McClosky D., 2006, P HLT NAACL
   McClosky D., 2006, P COLING ACL
   McDonald Ryan, 2007, P IWPT
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   Sima'an K., 1996, P COLING
   Sipser M., 2006, INTRO THEORY COMPUTA
   Smith NA, 2007, COMPUT LINGUIST, V33, P477, DOI 10.1162/coli.2007.33.4.477
   Spitkovsky V. I., 2010, P CONLL
   Udupa R., 2006, P EACL
   Wang M., 2007, P EMNLP
   Yejin C., 2007, P HLT NAACL
NR 32
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1502
EP 1511
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300152
DA 2019-06-15
ER

PT B
AU Corlett, E
   Penn, G
AF Corlett, Eric
   Penn, Gerald
GP Assoc Computat Linguist
TI An Exact A*Method for Deciphering Letter-Substitution Ciphers
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Letter-substitution ciphers encode a document from a known or hypothesized language into an unknown writing system or an unknown encoding of a known writing system. It is a problem that can occur in a number of practical applications, such as in the problem of determining the encodings of electronic documents in which the language is known, but the encoding standard is not. It has also been used in relation to OCR applications. In this paper, we introduce an exact method for deciphering messages using a generalization of the Viterbi algorithm. We test this model on a set of ciphers developed from various web sites, and find that our algorithm has the potential to be a viable, practical method for efficiently solving decipherment problems.
C1 [Corlett, Eric; Penn, Gerald] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.
RP Corlett, E (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.
EM ecorlett@cs.toronto.edu; gpenn@cs.toronto.edu
CR Bauer Friedrich L., 2007, DECRYPTED SECRETS
   HART GW, 1994, COMMUN ACM, V37, P102, DOI 10.1145/182987.184078
   Knight K, 1999, COMPUT LINGUIST, V25, P607
   Knight Kevin, 2006, P JOINT C INT COMM C, P499
   NAGY G, 1987, IEEE T PATTERN ANAL, V9, P710, DOI 10.1109/TPAMI.1987.4767969
   Peleg Shmuel, 1979, COMMUN ACM, V22, P589
   Ravi S., 2008, P C EMP METH NAT LAN, P812
   VANDENBOSCH A, 2006, P 8 M ACL SPEC INT G, P41
NR 8
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1040
EP 1047
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300106
DA 2019-06-15
ER

PT B
AU Costa, F
   Branco, A
AF Costa, Francisco
   Branco, Antonio
GP Assoc Computat Linguist
TI Temporal information processing of a new language: fast porting with
   minimal resources
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We describe the semi-automatic adaptation of a TimeML annotated corpus from English to Portuguese, a language for which TimeML annotated data was not available yet. In order to validate this adaptation, we use the obtained data to replicate some results in the literature that used the original English data. The fact that comparable results are obtained indicates that our approach can be used successfully to rapidly create semantically annotated resources for new languages.
C1 [Costa, Francisco; Branco, Antonio] Univ Lisbon, P-1699 Lisbon, Portugal.
RP Costa, F (reprint author), Univ Lisbon, P-1699 Lisbon, Portugal.
OI Branco, Antonio/0000-0002-7174-4942
CR Ahn David, 2007, HLT NAACL, P420
   Hepple Mark, 2007, P SEMEVAL 2007 PRAG, P484
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Pustejovsky J, 2003, P CORP LING, P647
   Pustejovsky James, 2009, P WORKSH SEM EV REC, P112
   Verhagen Marc, 2007, P SEMEVAL 2007
   Witten IH, 2005, DATA MINING PRACTICA
NR 7
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 671
EP 677
PG 7
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300069
DA 2019-06-15
ER

PT B
AU Dickinson, M
AF Dickinson, Markus
GP Assoc Computat Linguist
TI Detecting Errors in Automatically-Parsed Dependency Relations
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We outline different methods to detect errors in automatically-parsed dependency corpora, by comparing so-called dependency rules to their representation in the training data and flagging anomalous ones. By comparing each new rule to every relevant rule from training, we can identify parts of parse trees which are likely erroneous. Even the relatively simple methods of comparison we propose show promise for speeding up the annotation process.
C1 [Dickinson, Markus] Indiana Univ, Bloomington, IN 47405 USA.
RP Dickinson, M (reprint author), Indiana Univ, Bloomington, IN 47405 USA.
EM md7@indiana.edu
CR Afonso S., 2002, P LREC 2002, P1698
   ATTARDI G., 2007, P HUM LANG TECHN ANN, P388
   BICK E, 2007, P CONLL SHAR TASK SE
   Boyd A., 2008, RES LANGUAGE COMPUTA, V6, P113
   Buchholz S, 2006, P 10 C COMP NAT LANG, P149
   Campbell D, 2002, P WORKSH NAT LANG PR, P37
   Dickinson Markus, 2009, P TLT 7 GRON NETH
   Dickinson Markus, 2008, P ACL 08 COL OH
   GILDEA D, 2001, P EMNLP 01 PITTSB PA
   Hall K., 2005, P 9 INT WORKSH PARS, P42
   Kromann Matthias Trautner, 2003, P TLT 03
   Kuhlmann M., 2009, P 12 C EUR CHAPT ASS, P478, DOI DOI 10.3115/1609067.1609120
   Loftsson H., 2009, P 12 C EUR ACL EACL, P523
   McDonald Ryan, 2006, P EACL 06 TRENT
   Nilsson J., 2005, 05067 MSI VAXJ U SCH
   Nivre J., 2007, Natural Language Engineering, P95, DOI 10.1017/S1351324906004505
   Och F., 2009, P HUM LANG TECHN 200, P245
   Owczarzak K, 2009, P JOINT C 47 ANN M A, P190
   Przepiorkowski Adam, 2006, SEMANTYKA KONFRONTAC, V3, P25
   Sekine Satoshi, 1997, P ANLP 96 WASH DC
   van der Beek Leonoor, 2002, P CLIN 2001 ROD
   van Noord Gertjan, 2009, P EACL 2009 WORKSH I, P33
   Wallis S., 2003, TREEBANKS BUILDING U, P61
   Wan S., 2009, P 12 C EUR CHAPT ACL, P852
NR 24
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 729
EP 738
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300075
DA 2019-06-15
ER

PT B
AU Duan, XY
   Zhang, M
   Li, HZ
AF Duan, Xiangyu
   Zhang, Min
   Li, Haizhou
GP Assoc Computat Linguist
TI Pseudo-word for Phrase-based Machine Translation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB The pipeline of most Phrase-Based Statistical Machine Translation (PB-SMT) systems starts from automatically word aligned parallel corpus. But word appears to be too fine-grained in some cases such as non-compositional phrasal equivalences, where no clear word alignments exist. Using words as inputs to PBSMT pipeline has inborn deficiency. This paper proposes pseudo-word as a new start point for PB-SMT pipeline. Pseudo-word is a kind of basic multi-word expression that characterizes minimal sequence of consecutive words in sense of translation. By casting pseudo-word searching problem into a parsing framework, we search for pseudo-words in a monolingual way and a bilingual synchronous way. Experiments show that pseudo-word significantly outperforms word for PB-SMT model in both travel translation domain and news translation domain.
C1 [Duan, Xiangyu; Zhang, Min; Li, Haizhou] ASTAR, Inst Infocomm Res, Singapore, Singapore.
RP Duan, XY (reprint author), ASTAR, Inst Infocomm Res, Singapore, Singapore.
EM Xduan@i2r.a-star.edu.sg; mzhang@i2r.a-star.edu.sg; hli@i2r.a-star.edu.sg
RI Li, Haizhou/Q-6438-2019
OI Li, Haizhou/0000-0001-9158-9401
CR Banerjee Satanjeev, 2005, P ACL WORKSH INTR EX, P65
   Blunsom P., 2009, P ACL IJCNLP SING
   Blunsom P., 2008, P NIPS 21 VANC CAN
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Chang P.-C., 2008, P 3 WORKSH STAT MACH, P224
   CHEN SF, 1998, TR1098 HARV U CTR RE
   Cherry C., 2007, P HLTNAACL WORKSH SY
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   DENG Y, 2005, P HLT EMNLP, P169
   Doddington George, 2002, P 2 INT C HUM LANG T, P138, DOI DOI 10.3115/1289189.1289273
   Jia Xu, 2008, P 22 INT C COMP LING, P1017
   Kneser R., 1995, P IEEE INT C AC SPEE, V1, P181, DOI DOI 10.1109/ICASSP.1995.479394
   Koehn P., 2007, P 45 ANN M ACL ACL 2
   Koehn P., 2003, P HLT NAACL EDM ALB, P81
   Koehn Philipp, 2004, P EMNLP
   Lambert P., 2005, P MT SUMM
   Ma Y., 2009, ACM T ASIAN LANGUAGE, V8
   Ma Y, 2007, P ACL, P304
   Marcu D, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P133
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Papineni K., 2001, BLEU METHOD AUTOMATI
   Paul M., 2008, P INT WORKSH SPOK LA
   PHAN XH, 2005, FLEXCRFS FLEXIBLE CO
   Stolcke  A., 2002, P ICSLP
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   Xu J, 2004, P 3 SIGHAN WORKSH CH, P122
   Zhang H., 2008, P ACL 2008, P97, DOI DOI 10.1002/PI.2498
   Zhang R, 2008, P 3 WORKSH STAT MACH, P216
NR 29
TC 1
Z9 1
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 148
EP 156
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300016
DA 2019-06-15
ER

PT B
AU Echizen-ya, H
   Araki, K
AF Echizen-ya, Hiroshi
   Araki, Kenji
GP Assoc Computat Linguist
TI Automatic Evaluation Method for Machine Translation using Noun-Phrase
   Chunking
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB As described in this paper, we propose a new automatic evaluation method for machine translation using noun-phrase chunking. Our method correctly determines the matching words between two sentences using corresponding noun phrases. Moreover, our method determines the similarity between two sentences in terms of the noun-phrase order of appearance. Evaluation experiments were conducted to calculate the correlation among human judgments, along with the scores produced using automatic evaluation methods for MT outputs obtained from the 12 machine translation systems in NTCIR7. Experimental results show that our method obtained the highest correlations among the methods in both sentence-level adequacy and fluency.
C1 [Echizen-ya, Hiroshi] Hokkai Gakuen Univ, Chuo Ku, S 26-Jo,W 11 Chome, Sapporo, Hokkaido 0640926, Japan.
   [Araki, Kenji] Hokkaido Univ, Kita Ku, Sapporo, Hokkaido 0600814, Japan.
RP Echizen-ya, H (reprint author), Hokkai Gakuen Univ, Chuo Ku, S 26-Jo,W 11 Chome, Sapporo, Hokkaido 0640926, Japan.
EM echi@eli.hokkai-s-u.ac.jp; araki@media.eng.hokudai.ac.jp
CR Banerjee Satanjeev, 2005, P ACL WORKSH INTR EX, P65
   Coughlin D., 2003, P MT SUMM 9 NEW ORL, P63
   Echizen-ya Hiroshi, 2009, P 3 WORKSH PAT TRANS, P9
   Ehara Terumasa, 2007, P MT SUMM 12 WORKSH, P13
   Ethizen-ya Hiroshi, 2007, P 11 MACH TRANSL SUM, P151
   Fujii A., 2008, P 7 NTCIR WORKSH M E, P389
   Leusch G, 2003, P MT SUMM 9 NEW ORL, P240
   Lin Chin-Yew, 2004, P ACL, P606
   Mehay D, 2007, P MT SUMM, P122
   Mutton Andrew, 2007, P 45 ANN M ASS COMP, P344
   NIST, 2002, AUT EV MACH TRANSL Q
   Oyamada Takashi, 2010, IPSJ SIG TECHNICAL R, V2010- NL- 195
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Pozar Michael, 2006, THESIS
   SHA F, 2003, P C N AM CHAPT ASS C, P134
   Su K. -Y., 1992, P 14 INT C COMP LING, V2, P433
   UTIYAMA M, 2003, P 41 ANN M ASS COMP, P72
NR 17
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 108
EP 117
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300012
DA 2019-06-15
ER

PT B
AU Fowler, TAD
   Penn, G
AF Fowler, Timothy A. D.
   Penn, Gerald
GP Assoc Computat Linguist
TI Accurate Context-Free Parsing with Combinatory Categorial Grammar
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID CCG
AB The definition of combinatory categorial grammar (CCG) in the literature varies quite a bit from author to author. However, the differences between the definitions are important in terms of the language classes of each CCG. We prove that a wide range of CCGs are strongly context-free, including the CCG of CCGbank and of the parser of Clark and Curran (2007). In light of these new results, we train the PCFG parser of Petrov and Klein (2007) on CCGbank and achieve state of the art results in supertagging accuracy, PARSEVAL measures and dependency accuracy.
C1 [Fowler, Timothy A. D.; Penn, Gerald] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.
RP Fowler, TAD (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.
EM tfowler@cs.toronto.edu; gpenn@cs.toronto.edu
CR Baldridge Jason, 2002, THESIS
   Bos J., 2004, P COLING, V4, P1240
   CLARK S, 2002, P 40 ANN M ASS COMP, P327
   Clark S, 2007, COMPUT LINGUIST, V33, P493, DOI 10.1162/coli.2007.33.4.493
   Hockenmaier J, 2007, COMPUT LINGUIST, V33, P355, DOI 10.1162/coli.2007.33.3.355
   Hoyt F., 2008, P ACL 08 HLT COL OH, P326
   Lambek J., 1958, AM MATH MONTHLY, V65, P154, DOI [DOI 10.2307/2310058, 10.2307/2310058]
   Petrov S., 2007, P NAACL HLT 2007, P404
   Steedman M., 2000, SYNTACTIC PROCESS
   VIJAYSHANKER K, 1994, MATH SYST THEORY, V27, P511, DOI 10.1007/BF01191624
   ZIELONKA W, 1981, Z MATH LOGIK, V27, P215, DOI 10.1002/malq.19810271306
NR 11
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 335
EP 344
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300035
DA 2019-06-15
ER

PT B
AU Huang, RH
   Riloff, E
AF Huang, Ruihong
   Riloff, Ellen
GP Assoc Computat Linguist
TI Inducing Domain-specific Semantic Class Taggers from (Almost) Nothing
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This research explores the idea of inducing domain-specific semantic class taggers using only a domain-specific text collection and seed words. The learning process begins by inducing a classifier that only has access to contextual features, forcing it to generalize beyond the seeds. The contextual classifier then labels new instances, to expand and diversify the training set. Next, a cross-category bootstrapping process simultaneously trains a suite of classifiers for multiple semantic classes. The positive instances for one class are used as negative instances for the others in an iterative bootstrapping cycle. We also explore a one-semantic-class-per-discourse heuristic, and use the classifiers to dynamically create semantic features. We evaluate our approach by inducing six semantic taggers from a collection of veterinary medicine message board posts.
C1 [Huang, Ruihong; Riloff, Ellen] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
RP Huang, RH (reprint author), Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
EM huangrh@cs.utah.edu; riloff@cs.utah.edu
CR ACE, 2008, NIST ACE EV SEBS
   ACE, 2007, NIST ACE EV WEBS
   ACE, 2005, NIST ACE EV WEBS
   Bikel D. M., 1997, P ANLP 97, P194, DOI DOI 10.3115/974557.974586
   Blum Avrim, 1998, P 11 ANN C COMP LEAR
   Carlson Andrew, 2009, HLT NAACL 2009 WORKS
   Collins M., 1999, P JOINT SIGDAT C EMP
   CUCERZAN S, 1999, P JOINT SIGDAT C EMP
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   Fleischman M.B., 2002, P COLING C AUG
   Joachims T, 1999, ADV KERNEL METHODS S
   Keerthi S., 2005, J MACHINE LEARNING R
   Komachi Mamoru, 2008, EMPIRICAL METHODS NA
   Kozareva Z., 2008, P 46 ANN M ASS COMP
   McClosky D., 2006, HLT NAACL 2006
   McIntosh T., 2009, P 47 ANN M ASS COMP
   Mihalcea R., 2004, CONLL 2004
   MILLER GA, 1990, INT J LEXICOGRAPHY
   Mueller C., 2002, P 40 ANN M ASS COMP
   Ng V., 2003, HLT NAACL 2003
   Ng V, 2007, P 45 ANN M ASS COMP
   Niu Cheng, 2003, P 41 ANN M ASS COMP, P335
   Pasca M., 2004, P 13 ACM C INF KNOWL, P137
   Phillips W, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P125
   RILOFF E, 1999, P 16 NAT C ART INT
   Riloff E, 1997, P 2 C EMP METH NAT L, P117
   Roark B., 1998, P 36 ANN M ASS COMP, P1110, DOI DOI 10.3115/980691.980751
   Thelen M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P214
   Toutanova K., 2003, P HLT NAACL 2003
   Yangarber R., 2003, P 41 ANN M ASS COMP
   Yarowsky D., 1995, P 33 ANN M ASS COMP
   Zitouni Imed, 2009, ACM T ASIAN LANG INF, V8, P1
NR 32
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 275
EP 285
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300029
DA 2019-06-15
ER

PT B
AU Iida, R
   Kobayashi, S
   Tokunaga, T
AF Iida, Ryu
   Kobayashi, Shumpei
   Tokunaga, Takenobu
GP Assoc Computat Linguist
TI Incorporating Extra-linguistic Information into Reference Resolution in
   Collaborative Task Dialogue
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper proposes an approach to reference resolution in situated dialogues by exploiting extra-linguistic information. Recently, investigations of referential behaviours involved in situations in the real world have received increasing attention by researchers (Di Eugenio et al., 2000; Byron, 2005; van Deemter, 2007; Spanger et al., 2009). In order to create an accurate reference resolution model, we need to handle extra-linguistic information as well as textual information examined by existing approaches (Soon et al., 2001; Ng and Cardie, 2002, etc.). In this paper, we incorporate extra-linguistic information into an existing corpus-based reference resolution model, and investigate its effects on reference resolution problems within a corpus of Japanese dialogues. The results demonstrate that our proposed model achieves an accuracy of 79.0% for this task.
C1 [Iida, Ryu; Kobayashi, Shumpei; Tokunaga, Takenobu] Tokyo Inst Technol, Meguro Ku, 2-12-1,Ookayama, Tokyo 1528552, Japan.
RP Iida, R (reprint author), Tokyo Inst Technol, Meguro Ku, 2-12-1,Ookayama, Tokyo 1528552, Japan.
EM ryu-i@cl.cs.titech.ac.jp; skobayashi@cl.cs.titech.ac.jp;
   take@cl.cs.titech.ac.jp
CR Byron D. K., 2005, CONTEXT 2005, P83
   Byron D. K., 1998, P 2 C DISC AN AN RES, P68
   Carletta J, 2010, BEHAV RES METHODS, V42, P254, DOI 10.3758/BRM.42.1.254
   Denis Pascal, 2008, P 2008 C EMP METH NA, P660
   Di Eugenio B, 2000, INT J HUM-COMPUT ST, V53, P1017, DOI 10.1006/ijhc.2000.0428
   Eckert M., 2000, J SEMANT, V17, P51, DOI DOI 10.1093/JOS/17.1.51
   Foster M. E., 2008, P 3 ACM IEEE INT C H, P295, DOI DOI 10.1145/1349822.1349861
   GROSZ BJ, 1995, COMPUT LINGUIST, V21, P203
   Iida R., 2003, P EACL WORKSH COMP T, P23
   Iida R., 2005, ACM T ASIAN LANGUAGE, V4, P417
   Janin A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P364
   Joachims T., 2002, P 8 ACM SIGKDD INT C, P133, DOI DOI 10.1145/775047.775067
   Mitkov R., 2002, STUDIES LANGUAGE LIN
   Muller Christoph, 2006, P 11 C EUR CHAPT ASS, P49
   Muller Christoph, 2007, P 45 ANN M ASS COMP, P816
   Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102
   Niyu G., 1998, P 6 WORKSH VER LARG, P161
   Poon Hoifung, 2008, P 2008 C EMP METH NA, P650
   Prasov Z, 2008, P 13 INT C INT US IN, P20
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Spanger P., 2009, P WORKSH PROD REF EX
   Strube M., 2003, P 41 ANN M ASS COMP, P168
   van Deemter K., 2007, TECHNICAL REPORT
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Yang X, 2003, P 41 ANN M ASS COMP, P176, DOI [10.3115/1075096.1075119, DOI 10.3115/1075096.1075119]
   YANG X, 2008, P 46 ANN M ASS COMP, P843
   Yang X., 2005, P 43 ANN M ASS COMP, P165
NR 27
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1259
EP 1267
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300128
DA 2019-06-15
ER

PT B
AU Jiang, WB
   Liu, Q
AF Jiang, Wenbin
   Liu, Qun
GP Assoc Computat Linguist
TI Dependency Parsing and Projection Based on Word-Pair Classification
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In this paper we describe an intuitionistic method for dependency parsing, where a classifier is used to determine whether a pair of words forms a dependency edge. And we also propose an effective strategy for dependency projection, where the dependency relationships of the word pairs in the source language are projected to the word pairs of the target language, leading to a set of classification instances rather than a complete tree. Experiments show that, the classifier trained on the projected classification instances significantly outperforms previous projected dependency parsers. More importantly, when this classifier is integrated into a maximum spanning tree (MST) dependency parser, obvious improvement is obtained over the MST baseline.
C1 [Jiang, Wenbin; Liu, Qun] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, POB 2704, Beijing 100190, Peoples R China.
RP Jiang, WB (reprint author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, POB 2704, Beijing 100190, Peoples R China.
EM jiangwenbin@ict.ac.cn; liuqun@ict.ac.cn
CR Berger A. L., 1996, COMPUTATIONAL LINGUI
   Carreras Xavier, 2006, P CONLL
   Carreras Xavier, 2008, P CONLL
   Charniak Eugine, 2005, P ACL
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   COLLINS M, 2000, P 17 INT C MACH LEAR, P175
   Collins Michael, 1996, P ACL
   Eisner J., 1996, P 16 INT C COMP LING, P340
   Ganchev Kuzman, 2009, P 47 ACL
   Huang Liang, 2005, P IWPT, P53
   Huang Liang, 2008, P ACL
   HWA R, 2005, J NATURAL LANGUAGE E, V11, P311
   Hwa Rebecca, 2002, P ACL
   Jiang Wenbin, 2009, P 47 ACL
   Jiang Wenbin, 2009, P IWPT
   Koo T., 2008, P ACL
   Kudo Taku, 2000, P EMNLP
   Liu Yang, 2009, P EMNLP
   Lu Yajuan, 2002, P COLING
   Manning C. D., 2004, P ACL
   Marcus Mitchell P, 1993, COMPUTATIONAL LINGUI
   Marinov Svetoslav, 2006, P 10 C COMP NAT LANG, P221
   McDonald R., 2005, P HLT EMNLP
   McDonald R., 2005, P 43 ANN M ASS COMP, P91, DOI DOI 10.3115/1219840.1219852
   McDonald R., 2006, P 11 C EUR CHAPT ASS, V6, P81
   Nivre J., 2004, P COLING
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   OCH FJ, 2000, P ACL
   Smith David, 2009, P EMNLP
   Uchimoto Kiyotaka, 1999, P EACL
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wu D., 1997, COMPUTATIONAL LINGUI
   Xue Nianwen, 2005, NATURAL LANGUAGE ENG
   YAMADA H, 2003, P IWPT
   Zhang Yue, 2008, P ACL
NR 35
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 12
EP 20
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300002
DA 2019-06-15
ER

PT B
AU Kaji, N
   Fujiwara, Y
   Yoshinaga, N
   Kitsuregawa, M
AF Kaji, Nobuhiro
   Fujiwara, Yasuhiro
   Yoshinaga, Naoki
   Kitsuregawa, Masaru
GP Assoc Computat Linguist
TI Efficient Staggered Decoding for Sequence Labeling
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID ALGORITHM
AB The Viterbi algorithm is the conventional decoding algorithm most widely adopted for sequence labeling. Viterbi decoding is, however, prohibitively slow when the label set is large, because its time complexity is quadratic in the number of labels. This paper proposes an exact decoding algorithm that overcomes this problem. A novel property of our algorithm is that it efficiently reduces the labels to be decoded, while still allowing us to check the optimality of the solution. Experiments on three tasks (POS tagging, joint POS tagging and chunking, and supertagging) show that the new algorithm is several orders of magnitude faster than the basic Viterbi and a state-of-the-art algorithm, CARPEDIEM (Esposito and Radicioni, 2009).
C1 [Kaji, Nobuhiro; Fujiwara, Yasuhiro; Yoshinaga, Naoki; Kitsuregawa, Masaru] Univ Tokyo, Inst Ind Sci, Meguro Ku, 4-6-1,Komaba, Tokyo 1538505, Japan.
RP Kaji, N (reprint author), Univ Tokyo, Inst Ind Sci, Meguro Ku, 4-6-1,Komaba, Tokyo 1538505, Japan.
EM kaji@tkl.iis.u-tokyo.ac.jp; fujiwara@tkl.iis.u-tokyo.ac.jp;
   ynaga@tkl.iis.u-tokyo.ac.jp; kisture@tkl.iis.u-tokyo.ac.jp
CR BRANTS T, 2000, P 6 C APPL NAT LANG, P224, DOI DOI 10.3115/974147.974178
   Charniak Eugene, 2006, P HUM LANG TECHN C N, P168
   COHN T, 2006, P 17 EUR C MACH LEAR, P606
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Dietterich TG, 2008, MACH LEARN, V73, P3, DOI 10.1007/s10994-008-5079-1
   Esposito R, 2009, J MACH LEARN RES, V10, P1851
   Felzenszwalb Pedro F., 2003, P NIPS, P409
   Jeong M., 2009, P C SHORT ACL IJCNLP, P281
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Liang Percy, 2008, P 25 INT C MACH LEAR, P592
   Lifshits Yury, 2007, COMPUTATIONAL PATTER, P4
   Lin D., 2009, P 47 ANN M ACL 4 IJC, P1030
   Matsuzaki T, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1671
   NINOMIYA T, 2006, P 2006 C EMP METH NA, P155
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   SARAWAGI S, 2004, P NIPS, P1185
   Sha Fei, 2003, P HLT NAACL EDM MAY, P134
   SIDDIQI SM, 2005, P 22 INT C MACH LEAR, P800
   SUTTON C, 2004, P ICML
   Taskar B., 2003, P NEUR INF PROC SYST, P25
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Tsuruolca Y., 2005, P C HUM LANG TECHN E, P467, DOI DOI 10.3115/1220575.1220634
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
NR 23
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 485
EP 494
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300050
DA 2019-06-15
ER

PT B
AU Khapra, MM
   Kulkarni, A
   Sohoney, S
   Bhattacharyya, P
AF Khapra, Mitesh M.
   Kulkarni, Anup
   Sohoney, Saurabh
   Bhattacharyya, Pushpak
GP Assoc Computat Linguist
TI All Words Domain Adapted WSD: Finding a Middle Ground between
   Supervision and Unsupervision
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In spite of decades of research on word sense disambiguation (WSD), all-words general purpose WSD has remained a distant goal. Many supervised WSD systems have been built, but the effort of creating the training corpus -annotated sense marked corpora -has always been amatter of concern. Therefore, attempts have been made to develop unsupervised and knowledge based techniques for WSD which do not need sense marked corpora. However such approaches have not proved effective, since they typically do not better Wordnet first sense baseline accuracy. Our research reported here proposes to stick to the supervised approach, but with far less demand on annotation. We show that if we have ANY sense marked corpora, be it from mixed domain or a specific domain, a small amount of annotation in ANY other domain can deliver the goods almost as if exhaustive sense marking were available in that domain. We have tested our approach across Tourism and Health domain corpora, using also the well known mixed domain SemCor corpus. Accuracy figures close to self domain training lend credence to the viability of our approach. Our contribution thus lies in finding a convenient middle ground between pure supervised and pure unsupervised WSD. Finally, our approach is not restricted to any specific set of target words, a departure from a commonly observed practice in domain specific WSD.
C1 [Khapra, Mitesh M.; Kulkarni, Anup; Sohoney, Saurabh; Bhattacharyya, Pushpak] Indian Inst Technol, Bombay 400076, Maharashtra, India.
RP Khapra, MM (reprint author), Indian Inst Technol, Bombay 400076, Maharashtra, India.
EM miteshk@cse.iitb.ac.in; anup@cse.iitb.ac.in;
   saurabhsohoney@cse.iitb.ac.in; pb@cse.iitb.ac.in
CR Agirre E., 2004, P 4 INT C LANG RES E
   Agirre Eneko, 2009, EACL 09, P42
   Agirre Eneko, 2009, DEW 09 P WORKSH SEM, P123
   Agirre Eneko, 2009, P IJCAI
   Banerjee S., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P136
   Escudero G, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P172
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Jiang J.J., 1997, P INT C RES COMP LIN, P19
   Khapra Mitesh, 2010, 5 INT C GLOB WORDN G
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   Koeling Rob, 2005, HLT 05, P419
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   McCarthy D., 2004, ACL 04, P279
   McCarthy D, 2007, COMPUT LINGUIST, V33, P553, DOI 10.1162/coli.2007.33.4.553
   MILLER GA, 1993, HUMAN LANGUAGE TECHN, P303
   Ng H. T., 1996, P 34 ANN M ASS COMP, P40, DOI DOI 10.3115/981863.981869
   Patwardhan S., 2003, CPAN WORDNET SIMILAR
   Seng Y., 2007, P 45 ANN M ASS COMP, P49
   SNYDER B, 2004, SENSEVAL 3, P41
   Weeber M, 2001, J AM MED INFORM ASSN, P746
NR 20
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1532
EP 1541
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300155
DA 2019-06-15
ER

PT B
AU Klebanov, BB
   Beigman, E
AF Klebanov, Beata Beigman
   Beigman, Eyal
GP Assoc Computat Linguist
TI A Game-Theoretic Model of Metaphorical Bargaining
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID EQUILIBRIUM
AB We present a game-theoretic model of bargaining over a metaphor in the context of political communication, find its equilibrium, and use it to rationalize observed linguistic behavior. We argue that game theory is well suited for modeling discourse as a dynamic resulting from a number of conflicting pressures, and suggest applications of interest to computational linguists.
C1 [Klebanov, Beata Beigman] Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.
   [Beigman, Eyal] Washington Univ, St Louis, MO 63130 USA.
RP Klebanov, BB (reprint author), Northwestern Univ, Kellogg Sch Management, Evanston, IL 60208 USA.
EM beata@northwestern.edu; beigman@wustl.edu
CR Allan James, 2002, TOPIC DETECTION TRAC
   Aumann R, 1990, EC DECISION MAKING G, P201
   AXELROD R, 1981, SCIENCE, V211, P1390, DOI 10.1126/science.7466396
   Barnden John A., 2002, P COLING, P121
   Birke J., 2006, P 11 C EUR CHAPT ASS, P329
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bolinger Dwight, 1980, LANGUAGETHE LOADED W
   Clark Robin, 2007, Journal of Logic, Language and Information, V16, P265, DOI 10.1007/s10849-006-9037-7
   Crisp P, 2007, METAPHOR SYMBOL, V22, P1
   DALE R, 1995, COGNITIVE SCI, V19, P233
   Dekker P., 2000, J SEMANT, V17, P217
   DOWNS A, 1957, THE JOURNAL OF POLIT, V65, P135
   Druckman JN, 2000, ANNU REV POLIT SCI, V3, P1, DOI 10.1146/annurev.polisci.3.1.1
   Entman RM, 2003, POLIT COMMUN, V20, P415, DOI 10.1080/10584600390244176
   Fass D., 1991, Computational Linguistics, V17, P49
   Fisman R, 2006, Q J ECON, V121, P673, DOI 10.1162/qjec.2006.121.2.673
   Freund Y., 1996, C P 9 ANN C COMP LEA, V1996, P325
   Gardent Claire, 2004, MULTIDISCIPLINARY AP
   Gedigian Matt, 2006, P 3 WORKSH SCAL NAT, P41, DOI DOI 10.3115/1621459.1621467
   Gentner D., 1983, MENTAL MODELS
   Glazer J, 2001, GAME ECON BEHAV, V36, P158, DOI 10.1006/game.2000.0824
   Greene S., 2009, P HUM LANG TECHN 200, P503
   Greif A, 2006, POLIT ECON I DECIS, P1, DOI 10.1017/CBO9780511791307
   Gruhal D, 2004, P 13 INT C WORLD WID, P491, DOI DOI 10.1145/988672.988739
   Hardie Andrew, 2007, P CORP LING C BIRM U
   Hobbs J. R., 1992, Communication from an Artificial Intelligence Perspective. Theoretical and Applied Issues. Proceedings of the NATO Advanced Research Workshop on Computational Theories of Communication and their Applications: Problems and Perspectives, P35
   Jager Gerhard, 2008, P 13 ANN M GES SEM S, P1
   Jurafsky Dan, 2009, P HUM LANG TECHN 200, P638, DOI DOI 10.3115/1620754.1620847
   Kittur A, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P453
   Klebanov Beata Beigman, 2008, P WORKSH HUM JUDG CO, P2
   Krishnakumaran Saisuresh, 2007, P WORKSH COMP APPR F, P13
   Lakoff G., 1980, METAPHORS WE LIVE BY
   Lakoff G., 2014, PEACE RES, V23, P25
   LEMKE CE, 1964, J SOC IND APPL MATH, V12, P413, DOI 10.1137/0112033
   Leuf B., 2001, WIKI WAY QUICK COLLA
   Lewis D., 1969, CONVENTION
   Luce R. D., 1957, GAMES DECISIONS
   Mas-Colell A, 1995, MICROECONOMIC THEORY
   Mason ZJ, 2004, COMPUT LINGUIST, V30, P23, DOI 10.1162/089120104773633376
   MORGAN N, 2001, P HLT, P246
   Musolff Andreas, 2000, MIRROR IMAGES EUROPE
   Narayanan S, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P121
   NASH JF, 1950, P NATL ACAD SCI USA, V36, P48, DOI 10.1073/pnas.36.1.48
   North DC, 1990, I I CHANGE EC PERFOR
   Paraboni I, 2007, COMPUT LINGUIST, V33, P229, DOI 10.1162/coli.2007.33.2.229
   Parikh Prashant, 2001, THE USE OF LANGUAGE
   Poole K. T., 1997, C POLITICAL EC HIST
   QUINN KM, 2006, AUTOMATED METHOD TOP
   Ranganath R., 2009, P 2009 C EMP METH NA, P334
   Reining Astrid, 2007, P HLT NAACL 07 WORKS, P5
   Ross I, 2007, CURR RES SEMANT PRAG, V18, P135
   RUBINSTEIN A, 1982, ECONOMETRICA, V50, P97, DOI 10.2307/1912531
   Schelling T. C., 1997, STRATEGY CONFLICT
   Selten R., 1975, International Journal of Game Theory, V4, P25, DOI 10.1007/BF01766400
   Selten R, 1965, Z GESAMTE STAATSWISS, V12, P301
   Shalev- Shwartz Shai, 2006, P 20 ANN C NEUR INF, P1265
   SIDDHARTHAN A, 2004, P 42 ANN M ASS COMP, P407
   SMITH JM, 1973, NATURE, V246, P15, DOI 10.1038/246015a0
   Somasundaran S, 2009, P JOINT C 47 ANN M A, V1, P226
   Torrance G W, 1989, Int J Technol Assess Health Care, V5, P559
   Van Rooij R., 2004, Journal of Logic, Language and Information, V13, P491, DOI 10.1007/s10849-004-2118-6
   van Rooij R, 2008, J ECON METHODOL, V15, P261, DOI 10.1080/13501780802321376
   Viegas Fernanda B., 2004, CHI 04, P575
   von Stengel B, 2007, ALGORITHMIC GAME THEORY, P53
   Vuong Ba-Quy, 2008, P INT C WEB SEARCH W, P171
NR 65
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 698
EP 709
PG 12
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300072
DA 2019-06-15
ER

PT B
AU Kuhlmann, M
   Koller, A
   Satta, G
AF Kuhlmann, Marco
   Koller, Alexander
   Satta, Giorgio
GP Assoc Computat Linguist
TI The Importance of Rule Restrictions in CCG
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Combinatory Categorial Grammar (CCG) is generally construed as a fully lexicalized formalism, where all grammars use one and the same universal set of rules, and cross-linguistic variation is isolated in the lexicon. In this paper, we show that the weak generative capacity of this 'pure' form of CCG is strictly smaller than that of CCG with grammar-specific rules, and of other mildly context-sensitive grammar formalisms, including Tree Adjoining Grammar (TAG). Our result also carries over to a multi-modal extension of CCG.
C1 [Kuhlmann, Marco] Uppsala Univ, Dept Linguist & Philol, Uppsala, Sweden.
   [Koller, Alexander] Univ Saarland, Cluster Excellence, Saarbrucken, Germany.
   [Satta, Giorgio] Univ Padua, Dept Informat Engn, Padua, Italy.
RP Kuhlmann, M (reprint author), Uppsala Univ, Dept Linguist & Philol, Uppsala, Sweden.
CR Baader F., 1998, TERM REWRITING ALL
   Baldridge J, 2003, EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P211
   Baldridge Jason, 2002, THESIS
   Bar-Hillel Yehoshua, 1964, LANGUAGE INFORM, P99
   Bos Johan, 2004, P 20 INT C COMP LING, P176
   Clark Stephen, 2007, COMPUT LINGUIST, V33, P4
   Curry H. B., 1958, STUDIES LOGIC FDN MA, V1
   Eisner Jason, 1996, P 34 ANN M ASS COMP, P79
   Hockenmaier J., 2002, P 40 ANN M ASS COMP, P335
   Hockenmaier Julia, 2008, P 9 INT WORKSH TREE
   Joshi Aravind K., 1997, HDB FORMAL LANGUAGES, V3, P69, DOI DOI 10.1007/978-3-642-59126-6_2
   Koller Alexander, 2009, P 12 C EUR CHAPT ASS, P460
   Moortgat Michael, 1997, HDB LOGIC LANGUAGE, P93, DOI [10.1016/B978-044481714-3/50005-9, DOI 10.1016/B978-044481714-3/50005-9]
   Reitter David, 2006, P 2006 C EMP METH NA, P308
   Steedman Mark, 2010, NONTRANSFOR IN PRESS
   Steedman Mark, 2001, SYNTACTIC PROCESS
   VIJAYSHANKER K, 1994, MATH SYST THEORY, V27, P511, DOI 10.1007/BF01191624
   WEIR DJ, 1988, P 26 ANN M ASS COMP, P278
NR 18
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 534
EP 543
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300055
DA 2019-06-15
ER

PT B
AU Kummerfeld, JK
   Roesner, J
   Dawborn, T
   Haggerty, J
   Curran, JR
   Clark, S
AF Kummerfeld, Jonathan K.
   Roesner, Jessika
   Dawborn, Tim
   Haggerty, James
   Curran, James R.
   Clark, Stephen
GP Assoc Computat Linguist
TI Faster Parsing by Supertagger Adaptation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID LOG-LINEAR MODELS; CCG
AB We propose a novel self-training method for a parser which uses a lexicalised grammar and supertagger, focusing on increasing the speed of the parser rather than its accuracy. The idea is to train the supertagger on large amounts of parser output, so that the supertagger can learn to supply the supertags that the parser will eventually choose as part of the highestscoring derivation. Since the supertagger supplies fewer supertags overall, the parsing speed is increased. We demonstrate the effectiveness of the method using a CCG supertagger and parser, obtaining significant speed increases on newspaper text with no loss in accuracy. We also show that the method can be used to adapt the CCG parser to new domains, obtaining accuracy and speed improvements for Wikipedia and biomedical text.
C1 [Kummerfeld, Jonathan K.; Dawborn, Tim; Haggerty, James; Curran, James R.] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
   [Roesner, Jessika] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.
   [Clark, Stephen] Univ Cambridge, Comp Lab, Cambridge CB3 0FD, England.
RP Curran, JR (reprint author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
EM james@it.usyd.edu.au; stephen.clark@cl.cam.ac.uk
OI Kummerfeld, Jonathan/0000-0001-5030-3016
CR Bangalore S, 1999, COMPUT LINGUIST, V25, P237
   Blunsom P., 2006, P 2006 C EMP METH NA, P164
   Briscoe Ted, 2006, P POST SESS 21 INT C
   CHEN J, 1999, P 1999 JOINT SIGDAT, P188
   Chen John, 2002, P TAG WORKSH VEN IT, P259
   CHINCHOR N, 1995, P 6 MESS UND C MUC 6, P39
   Clark S, 2004, P 20 INT C COMP LING, P282
   CLARK S, 2003, P 7 C NAT LANG LEARN, P49
   Clark S, 2007, COMPUT LINGUIST, V33, P493, DOI 10.1162/coli.2007.33.4.493
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Collins Michael, 2002, COMPUTATIONAL LINGUI, V31, P25
   Crammer K, 2003, J MACH LEARN RES, V3, P951, DOI 10.1162/jmlr.2003.3.4-5.951
   Cui W., 2017, P 5 INT C LANG RES E, P565
   Curran J, 2004, THESIS
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   Dumais Susan, 2002, P 25 INT ACMSIGIR C
   Gildea D., 2001, P 2001 C EMP METH NA
   Graff David, 1995, LDC95T21
   Hassan H, 2007, P 45 ANN M ASS COMP, P288
   Hockenmaier J, 2007, COMPUT LINGUIST, V33, P355, DOI 10.1162/coli.2007.33.3.355
   Hollingshead  Kristy, 2007, P 45 ANN M ASS COMP, P952
   Kaplan Ronald, 2003, P 4 INT WORKSH LING
   Kim JD, 2003, BIOINFORMATICS, V19, pi180, DOI 10.1093/bioinformatics/btg1023
   Lafferty J., 2001, CONDITIONAL RANDOM F, V2001, P282
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   McClosky D, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P337
   McClosky David, 2006, P HUM LANG TECHN C N
   McIntosh Tara, 2008, P AUSTR LANG TECHN W
   Nocedal J., 1999, NUMERICAL OPTIMIZATI
   PYYSALO S, 2007, P WORKSH BIOL TRANSL, P25
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   Rimell L., 2008, P C EMP METH NAT LAN, P475
   Rimell L, 2009, J BIOMED INFORM, V42, P852, DOI 10.1016/j.jbi.2008.12.004
   Sarkar A., 2007, COMPLEXITY LEXICAL D
   Sarkar A., 2001, P 2 M N AM CHAPT ASS, P1
   Sarkar Anoop, 2000, P COLING WORKSH EFF, P37
   STEEDMAN M, 2003, P 11 C EUR CHAPT ASS, P331
   van Noord Geertjan, 2009, P 12 C EUR CHAPT ASS, P817
   Zhang Yao-zhong, 2009, P 11 INT C PARS TECH, P210
NR 39
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 345
EP 355
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300036
DA 2019-06-15
ER

PT B
AU Liu, ZY
   Wang, HF
   Wu, H
   Li, S
AF Liu, Zhanyi
   Wang, Haifeng
   Wu, Hua
   Li, Sheng
GP Assoc Computat Linguist
TI Improving Statistical Machine Translation with Monolingual Collocation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper proposes to use monolingual collocations to improve Statistical Machine Translation (SMT). We make use of the collocation probabilities, which are estimated from monolingual corpora, in two aspects, namely improving word alignment for various kinds of SMT systems and improving phrase table for phrase-based SMT. The experimental results show that our method improves the performance of both word alignment and translation quality significantly. As compared to baseline systems, we achieve absolute improvements of 2.40 BLEU score on a phrase-based SMT system and 1.76 BLEU score on a parsing-based SMT system.
C1 [Liu, Zhanyi; Li, Sheng] Harbin Inst Technol, Harbin, Peoples R China.
   [Wang, Haifeng; Wu, Hua] Baidu Com Inc, Beijing, Peoples R China.
RP Liu, ZY (reprint author), Harbin Inst Technol, Harbin, Peoples R China.
EM zhanyiliu@gmail.com; wanghaifeng@baidu.com; wu_hua@baidu.com;
   lisheng@hit.edu.cn
CR Ahrenberg Lars, 2000, P 2 INT C LANG RES, P1255
   Al-Onaizan Yaser, 1999, J HOPK U WORKSH
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHERRY C, 2003, P 41 ANN M ASS COMP, P88
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Huang Fei, 2009, P JOINT C 47 ANN M A, P932
   KOEHN P, 2003, P HLT NAACL, P127
   Koehn P., 2004, P 2004 C EMP METH NA, P388
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Koehn Philipp, 2005, PROC INT WORKSH SPOK
   Liu Y, 2005, P 43 ANN M ASS COMP, P459
   Liu Z., 2009, P 2009 C EMP METH NA, V2, P487
   Marcu D, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P133
   McKeown Kathleen R., 2000, HDB NATURAL LANGUAGE, P507
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Resnik P., 2008, P ACL 08 HLT COL OH, P1003
   Stolcke A., 2002, P INT C SPOK LANG PR, P901
   Wu D, 1997, COMPUT LINGUIST, V23, P377
   Xiong D., 2009, P JOINT C 47 ANN M A, P315
   Zhu L, 2009, INT GEOSCI REMOTE SE, P25, DOI 10.1109/IGARSS.2009.5416922
NR 23
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 825
EP 833
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300085
DA 2019-06-15
ER

PT B
AU Maletti, A
AF Maletti, Andreas
GP Assoc Computat Linguist
TI A Tree Transducer Model for Synchronous Tree-Adjoining Grammars
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB A characterization of the expressive power of synchronous tree-adjoining grammars (STAGs) in terms of tree transducers (or equivalently, synchronous tree substitution grammars) is developed. Essentially, a STAG corresponds to an extended tree transducer that uses explicit substitution in both the input and output. This characterization allows the easy integration of STAG into toolkits for extended tree transducers. Moreover, the applicability of the characterization to several representational and algorithmic problems is demonstrated.
C1 [Maletti, Andreas] Univ Rovira & Virgili, Avinguda Catalunya 25, Tarragona 43002, Spain.
RP Maletti, A (reprint author), Univ Rovira & Virgili, Avinguda Catalunya 25, Tarragona 43002, Spain.
EM andreas.maletti@urv.cat
CR Aho Alfred V., 1972, THEORY PARSING TRANS, Vtwo
   ARNOLD A, 1982, THEOR COMPUT SCI, V20, P33, DOI 10.1016/0304-3975(82)90098-6
   Bar-Hillel Y., 1964, LANGUAGE INFORMATION, P116
   Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chiang David, 2006, P ACL
   COURCELLE B, 1982, THEOR COMPUT SCI, V17, P163, DOI 10.1016/0304-3975(82)90003-2
   ENGELFRIET J, 1985, J COMPUT SYST SCI, V31, P71, DOI 10.1016/0022-0000(85)90066-2
   Gecseg F., 1997, HDB FORMAL LANGUAGES, V3, P1, DOI DOI 10.1007/978-3-642-59126-6_
   Gecseg F., 1984, TREE AUTOMATA
   Graehl J, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P105
   Graehl J, 2008, COMPUT LINGUIST, V34, P391, DOI 10.1162/coli.2008.07-051-R2-03-57
   Knight K, 2005, LECT NOTES COMPUT SC, V3406, P1
   Knight K, 2007, MACH TRANSL, V21, P121, DOI 10.1007/s10590-008-9039-0
   Liang Huang, 2005, P 9 INT WORKSH PARS, P53
   Maletti A, 2008, INFORM COMPUT, V206, P1187, DOI 10.1016/j.ic.2008.03.019
   Maletti A, 2009, SIAM J COMPUT, V39, P410, DOI 10.1137/070699160
   May J, 2006, LECT NOTES COMPUT SC, V4094, P102
   Nederhof Mark- Jan, 2009, P INT C PARS TECHN I, P13
   Nesson Rebecca, 2008, P ACL, P604
   Rounds W. C., 1970, MATH SYST THEORY, V4, P257, DOI DOI 10.1007/BF01695769
   Shieber S.M., 1990, P 13 COLING, V3, P253
   Shieber S. M., 2007, P WORKSH SYNT STRUCT, P88
   Shieber Stuart M., 2004, PROC 7 INT WORKSHOP, P88
   Shieber Stuart M., 2006, P 11 C EUR CHAPT ASS, P377
   Thatcher J. W., 1970, JCSS, V4, P339
NR 25
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1067
EP 1076
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300109
DA 2019-06-15
ER

PT B
AU Mirkin, S
   Dagan, I
   Pado, S
AF Mirkin, Shachar
   Dagan, Ido
   Pado, Sebastian
GP Assoc Computat Linguist
TI Assessing the Role of Discourse References in Entailment Inference
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID TEXTUAL ENTAILMENT
AB Discourse references, notably coreference and bridging, play an important role in many text understanding applications, but their impact on textual entailment is yet to be systematically understood. On the basis of an in-depth analysis of entailment instances, we argue that discourse references have the potential of substantially improving textual entailment recognition, and identify a number of research directions towards this goal.
C1 [Mirkin, Shachar; Dagan, Ido] Bar Ilan Univ, Ramat Gan, Israel.
   [Pado, Sebastian] Univ Stuttgart, Stuttgart, Germany.
RP Mirkin, S (reprint author), Bar Ilan Univ, Ramat Gan, Israel.
EM mirkins@cs.biu.ac.il; dagan@cs.biu.ac.il; pado@ims.uni-stuttgart.de
RI Pado, Sebastian/F-4883-2016
OI Pado, Sebastian/0000-0002-7529-6825
CR Abad Azad, 2010, P LREC
   Adams Rod, 2007, P ACL PASCAL WORKSH
   Agichtein E., 2008, P TAC
   ASHER Nicholas, 1998, J SEMANT, V15, P83, DOI DOI 10.1093/J0S/15.1.83
   Balahur Alexandra, 2008, P TAC
   Bar-Haim Roy, 2008, P TAC
   Bar-Haim Roy, 2007, P AAAI
   Bentivogli Luisa, 2009, P TAC
   Bentivogli Luisa, 2009, P 5 INT C GEN APPR L
   Bos Johan, 2005, P EMNLP
   Burchardt A, 2009, NAT LANG ENG, V15, P527, DOI 10.1017/S1351324909990131
   Chambers Nathanael, 2009, P ACL IJCNLP
   Chambers Nathanael, 2007, P ACL PASCAL WORKSH
   Clark H. H., 1975, THEORETICAL ISSUES N, P169
   Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177
   Dali L., 2009, P WORKSH SEM SEARCH
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Giampiccolo Danilo, 2008, P TAC
   Giampiccolo Danilo, 2007, P ACL PASCAL WORKSH
   GRISHMAN R, 1996, P 16 C COMP LING
   Harabagiu S, 2007, INFORM PROCESS MANAG, V43, P1619, DOI 10.1016/j.ipm.2007.01.004
   Harmeling Stefan, 2009, J NATURAL LANGUAGE E, P459
   Hearst MA, 1997, COMPUT LINGUIST, V23, P33
   Hovy Eduard, 2006, P HLT NAACL
   Huang Jian, 2009, P ACL IJCNLP
   Li Fangtao, 2009, P ACL IJCNLP
   Lin Dekang, 1993, P ACL
   Lin Dekang, 2001, NAT LANG ENG, V4, P343
   MacCartney Bill, 2008, P EMNLP
   Markert K., 2003, P EACL WORKSH COMP T
   Na Seung-Hoon, 2009, P SIGIR
   Nielsen RD, 2009, NAT LANG ENG, V15, P479, DOI 10.1017/S135132490999012X
   POESIO M, 2004, P ACL
   Ponzetto Simone Paolo, 2006, P HLT
   Qiu Long, 2004, P LREC
   Romano Lorenza, 2006, P EACL
   Strassel Stephanie, 2008, P LREC
   Vicedo JL, 2006, TEXT SPEECH LANG TEC, V32, P71
   Wee Meng Soon, 2001, COMPUTATIONAL LINGUI, V27, P521
   ZANZOTTO FM, 2009, J NATURAL LANGUAGE E, V15, P551, DOI DOI 10.1017/S1351324909990143
   Zelenko Dmitry, 2004, P ACL WORKSH REF RES
NR 41
TC 1
Z9 1
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1209
EP 1219
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300123
DA 2019-06-15
ER

PT B
AU Spiegler, S
   Flach, PA
AF Spiegler, Sebastian
   Flach, Peter A.
GP Assoc Computat Linguist
TI Enhanced word decomposition by calibrating the decision threshold of
   probabilistic models and using a model ensemble
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID LANGUAGE
AB This paper demonstrates that the use of ensemble methods and carefully calibrating the decision threshold can significantly improve the performance of machine learning methods for morphological word decomposition. We employ two algorithms which come from a family of generative probabilistic models. The models consider segment boundaries as hidden variables and include probabilities for letter transitions within segments. The advantage of this model family is that it can learn from small datasets and easily generalises to larger datasets. The first algorithm PROMODES, which participated in the Morpho Challenge 2009 (an international competition for unsupervised morphological analysis) employs a lower order model whereas the second algorithm PROMODES-H is a novel development of the first using a higher order model. We present the mathematical description for both algorithms, conduct experiments on the morphologically rich language Zulu and compare characteristics of both algorithms based on the experimental results.
C1 [Spiegler, Sebastian; Flach, Peter A.] Univ Bristol, Intelligent Syst Lab, Bristol BS8 1TH, Avon, England.
RP Spiegler, S (reprint author), Univ Bristol, Intelligent Syst Lab, Bristol BS8 1TH, Avon, England.
EM spiegler@cs.bris.ac.uk; peter.flach@bristol.ac.uk
OI Flach, Peter/0000-0001-6857-5810
CR Amtrup J. W., 2003, Machine Translation, V18, P217, DOI 10.1007/s10590-004-2476-5
   Atwell E, 2006, P PASCAL CHALL WORKS
   Creutz M., 2006, THESIS
   DAVIS J, 2006, ICML 06, P233, DOI DOI 10.1145/1143844.1143874
   Gasser M., 1994, P 15 C COMP LING, V1, P214
   Goldsmith J, 2001, COMPUT LINGUIST, V27, P153, DOI 10.1162/089120101750300490
   Goldsmith J., 2009, HDB COMPUTATIONAL LI
   HAFER MA, 1974, INFORM STORAGE RET, V10, P371, DOI 10.1016/0020-0271(74)90044-8
   Harris ZS, 1955, LANGUAGE, V31, P190, DOI 10.2307/411036
   Hirsimaki T, 2006, COMPUT SPEECH LANG, V20, P515, DOI 10.1016/j.csl.2005.07.002
   Kettunen K, 2009, J DOC, V65, P267, DOI 10.1108/00220410910937615
   KURIMO M, 2009, CLEF 2009 WORKSH COR
   Monson C., 2009, CLEF 2009 WORKSH COR
   Monson Christian, 2008, THESIS
   Mooney R. J., 1996, SYMBOLIC CONNECTIONI, P370
   Muggleton S, 1999, LECT NOTES ARTIF INT, V1634, P234
   Oflazer K, 2001, COMPUT LINGUIST, V27, P59
   Optiz D., 1999, J ARTIF INTELL RES, V11, P169, DOI DOI 10.1613/JAIR.614
   Rumelhart D., 1986, LEARNING TENSES ENGL
   Shalonova K, 2009, IEEE T AUDIO SPEECH, V17, P956, DOI 10.1109/TASL.2009.2015694
   Snover M. G., 2001, P 39 ANN M ACL TOUL, P490
   Snover M. G., 2002, P ACL 02 WORKSH MORP, V6, P11
   Spiegler S., 2009, CLEF 2009 WORKSH COR
   Spiegler S., 2008, IEEE WORKSH SPOK LAN
   Spiegler S., 2010, UKWABELANA IN PRESS
   Spiegler S., 2010, LECT NOTES COMPUTER, V1
   SPROAT R, 1996, NAT LANG ENG, V2, P369
NR 27
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 375
EP 383
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300039
DA 2019-06-15
ER

PT B
AU Spitkovsky, VI
   Jurafsky, D
   Alshawi, H
AF Spitkovsky, Valentin I.
   Jurafsky, Daniel
   Alshawi, Hiyan
GP Assoc Computat Linguist
TI Profiting from Mark-Up: Hyper-Text Annotations for Guided Parsing
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We show how web mark-up can be used to improve unsupervised dependency parsing. Starting from raw bracketings of four common HTML tags (anchors, bold, italics and underlines), we refine approximate partial phrase boundaries to yield accurate parsing constraints. Conversion procedures fall out of our linguistic analysis of a newly available million-word hyper-text corpus. We demonstrate that derived constraints aid grammar induction by training Klein and Manning's Dependency Model with Valence (DMV) on this data set: parsing accuracy on Section 23 (all sentences) of the Wall Street Journal corpus jumps to 50.4%, beating previous state-of-theart by more than 5%. Web-scale experiments show that the DMV, perhaps because it is unlexicalized, does not benefit from orders of magnitude more annotated but noisier data. Our model, trained on a single blog, generalizes to 53.3% accuracy out-of-domain, against the Brown corpus - nearly 10% higher than the previous published best. The fact that web mark-up strongly correlates with syntactic structure may have broad applicability in NLP.
C1 [Spitkovsky, Valentin I.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
   [Spitkovsky, Valentin I.; Alshawi, Hiyan] Google Inc, Mountain View, CA USA.
   [Jurafsky, Daniel] Stanford Univ, Dept Linguist & Comp Sci, Stanford, CA 94305 USA.
RP Spitkovsky, VI (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM valentin@google.com; jurafsky@stanford.edu; hiyan@google.com
CR Abney Steven, 1991, PRINCIPLE BASED PARS
   Baker J. K., 1979, 97 M AC SOC AM
   Barr C., 2008, EMNLP
   Brants T., 2000, ANLP
   Briscoe T., 1994, TECHNICAL REPORT
   CHARNIAK E, 2005, ACL
   Charniak E., 2001, ACL
   Chen H.-H., 1995, WVLC
   Cohen S. B., 2009, NAACL HLT
   Collins M., 1999, THESIS
   Davidov D., 2009, CONLL
   Druck G., 2009, ACL IJCNLP
   Eisner J., 1999, ACL
   Finkel J. R., 2009, NAACL HLT
   Francis W. Nelson, 1979, MANUAL INFORM ACCOMP
   Gabrilovich Evgeniy, 2007, IJCAI
   Gildea D., 2001, EMNLP
   Halevy Alon, 2009, IEEE INTELLIGENT SYS, V24
   Headden III W. P., 2009, NAACL HLT
   HOLM S, 1979, SCANDINAVIAN JOURNAL, V6
   Inui N., 2001, PACLIC
   Klein D., 2004, ACL
   LEE CH, 1991, IEEE T SIGNAL PROCES, V39, P806, DOI 10.1109/78.80902
   Lu W.-H., 2004, ACM T INFORM SYSTEMS, V22
   Marcus M., 1993, COMPUTATIONAL LINGUI, V19
   McClosky D., 2006, NAACL HLT
   Mihalcea R., 2007, CIKM
   Mintz Mike, 2009, ACL IJCNLP
   Nie J.-Y., 2002, WEB INTELLIGENCE
   Pereira F., 1992, ACL
   Ratnaparkhi A., 1999, MACHINE LEARNING, V34
   Ravi S., 2008, EMNLP
   Reynar J. C., 1997, ANLP
   Riezler S., 2002, ACL
   Sassano M., 2005, IJCNLP
   Seginer Y., 2007, ACL
   Spitkovsky V. I., 2010, NAACL HLT
   Spitkovsky V. I., 2010, CONLL
   Tan B., 2008, WWW
   Toutanova K., 2000, EMNLP VLC
   Toutanova K., 2003, HLT NAACL
   Vadas D., 2007, ACL
   Watanabe Y., 2007, EMNLP CONLL
   Yeh E., 2009, TEXTGRAPHS
NR 44
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1278
EP 1287
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300130
DA 2019-06-15
ER

PT B
AU Titov, I
   Kozhevnikov, M
AF Titov, Ivan
   Kozhevnikov, Mikhail
GP Assoc Computat Linguist
TI Bootstrapping Semantic Analyzers from Non-Contradictory Texts
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We argue that groups of unannotated texts with overlapping and non-contradictory semantics represent a valuable source of information for learning semantic representations. A simple and efficient inference method recursively induces joint semantic representations for each group and discovers correspondence between lexical entries and latent semantic concepts. We consider the generative semantics-text correspondence model (Liang et al., 2009) and demonstrate that exploiting the noncontradiction relation between texts leads to substantial improvements over natural baselines on a problem of analyzing human-written weather forecasts.
C1 [Titov, Ivan; Kozhevnikov, Mikhail] Univ Saarland, Saarbrucken, Germany.
RP Titov, I (reprint author), Univ Saarland, Saarbrucken, Germany.
EM titov@mmci.uni-saarland.de; m.kozhevnikov@mmci.uni-saarland.de
CR Barzilay R, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P164
   Barzilay Regina, 2003, P C HUM LANG TECHN N
   Basu S, 2004, SIAM PROC S, P333
   Blum A., 1998, COLT, P209
   CARRERAS X, 2005, P CONLL 2005 ANN ARB
   Chen David L., 2008, P 25 INT C MACH LEAR, P128, DOI DOI 10.1145/1390156.1390173
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   DIACONIS P, 1983, SCI AM, V248, P116, DOI 10.1038/scientificamerican0583-116
   Dolan B., 2004, P 20 INT C COMP LING, DOI [10.3115/1220355.1220406, DOI 10.3115/1220355.1220406]
   Ge Ruifang, 2005, P 9 C COMP NAT LANG
   Graca Joao, 2008, ADV NEURAL INFORM PR
   Harris  Z., 1968, MATH STRUCTURES LANG
   Kate R.J., 2007, ASS ADV ARTIFICIAL I, P895
   Liang Percy, 2009, P ANN M ASS COMP LIN
   McCallum Andrew, 2007, 200760 TR U MASS
   Mooney Raymond J., 2007, P 8 INT C COMP LING, P982
   Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467
   Pearl J., 1982, P AM ASS ART INT NAT, P133, DOI DOI 10.1038/4580
   Poon H, 2009, P 2009 C EMP METH NA
   Radev Dragomir, 2000, 1 SIGDIAL WORKSH DIS, P74
   Shinyama Y., 2003, P 2 INT WORKSH PAR, P65
   Snyder B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1713
   Weeds J, 2005, COMPUT LINGUIST, V31, P439, DOI 10.1162/089120105775299122
   Zettlemoyer Luke, 2005, P 21 C UNC ART INT E
NR 24
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 958
EP 967
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300098
DA 2019-06-15
ER

PT B
AU Trogkanis, N
   Elkan, C
AF Trogkanis, Nikolaos
   Elkan, Charles
GP Assoc Computat Linguist
TI Conditional Random Fields for Word Hyphenation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Finding allowable places in words to insert hyphens is an important practical problem. The algorithm that is used most often nowadays has remained essentially unchanged for 25 years. This method is the TEX hyphenation algorithm of Knuth and Liang. We present here a hyphenation method that is clearly more accurate. The new method is an application of conditional random fields. We create new training sets for English and Dutch from the CELEX European lexical resource, and achieve error rates for English of less than 0.1% for correctly allowed hyphens, and less than 0.01% for Dutch. Experiments show that both the Knuth/ Liang method and a leading current commercial alternative have error rates several times higher for both languages.
C1 [Trogkanis, Nikolaos; Elkan, Charles] Univ Calif San Diego, Comp Sci & Engn, La Jolla, CA 92093 USA.
RP Trogkanis, N (reprint author), Univ Calif San Diego, Comp Sci & Engn, La Jolla, CA 92093 USA.
EM tronikos@gmail.com; elkan@cs.ucsd.edu
CR Bartlett S., 2008, P ACL 08 HLT, P568
   Beeton Barbara, 2002, TUGBOAT, V23
   Bottou Leon, 2008, STOCHASTIC GRADIENT
   Bouma G., 2003, Natural Language Engineering, P5, DOI 10.1017/S1351324903003073
   Culotta A., 2004, P HLT NAACL 2004, P109
   Damerau Fred J., 1964, U.S. patent, Patent No. 3537076
   FRIEDLAN.GD, 1968, IEEE SPECTRUM, V5, P48
   Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36
   Haralambous Yannis, 2006, TUGBOAT, V27, P98
   Huyser Steven L., 1976, SIGDOC ASTERISK J CO, V3, P9
   Jarvi T, 2009, IFIP ADV INF COMM TE, V303, P230
   Kristensen T, 2001, IEEE IJCNN, P1532, DOI 10.1109/IJCNN.2001.939592
   KUDO T, 2007, CRF YET ANOTHER CRF
   Lafferty J.D., 2001, P INT C MACH LEARN, V18, P282
   Liang F. M., 1983, THESIS
   Liang Franklin M., 2008, PATTERN GENERATION P
   Nocedal Jorge, 1999, NUMERICAL OPTIMIZATI, P222
   OCKER WA, 1971, IEEE T PROF COMMUN, VEW14, P53, DOI 10.1109/TEWS.1971.4322470
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Sejnowski T. J., 1988, NEUROCOMPUTING FDN R, P661
   Sha F., 2003, P 2003 C N AM CHAPT, V1, P134, DOI DOI 10.3115/1073445.1073473
   Sojka Petr, 1995, TUGBOAT, V16, P280
   Tsalidis Christos, 2004, CS0408059 ARXIV COMP
   Tutelaers P.T.H., 1999, AFBREKEN TEX HOE WER
   van den Bosch Antal, 1995, P 5 BELG DUTCH C MAC, P118
   Woestenburg Jaap C., 2006, TALOS LANGUAGE TECHN
NR 26
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 366
EP 374
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300038
DA 2019-06-15
ER

PT S
AU Wan, S
   Dras, M
   Dale, R
   Paris, C
AF Wan, Stephen
   Dras, Mark
   Dale, Robert
   Paris, Cecile
BE Krahmer, E
   Theune, M
TI Spanning Tree Approaches for Statistical Sentence Generation
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
DE Statistical Text-to-Text Generation; Spanning Tree Problem; Assignment
   Problem; Dependency Model; Argument Satisfaction
AB In abstractive summarisation, summaries can include novel sentences that are generated automatically. In order to improve the grammaticality of the generated sentences, we model a global (sentence) level syntactic structure. We couch statistical sentence generation as a spanning tree problem in order to search for the best dependency tree spanning a set of chosen words. We also introduce a new search algorithm for this task that models argument satisfaction to improve the linguistic validity of the generated tree. We treat the allocation of modifiers to heads as a weighted bipartite graph matching problem (also known as the assignment problem), a well studied problem in graph theory. Using BLEU to measure performance on a string regeneration task, we demonstrate an improvement over standard language model baselines, illustrating the benefit of the spanning tree approach incorporating an argument satisfaction model.
C1 [Wan, Stephen; Dale, Robert] Macquarie Univ, Ctr Language Technol, Dept Comp, Sydney, NSW 2113, Australia.
   [Wan, Stephen; Dras, Mark; Paris, Cecile] CSIRO, ICT Ctr, Marsfield, Australia.
RP Wan, S (reprint author), Macquarie Univ, Ctr Language Technol, Dept Comp, Sydney, NSW 2113, Australia.
RI Paris, Cecile/C-2334-2011
OI Paris, Cecile/0000-0003-3816-0176; Wan, Stephen/0000-0001-7505-1417;
   Dras, Mark/0000-0001-9908-7182; Dale, Robert/0000-0001-7864-6942
CR BANGALORE S, 2000, P 18 C COMP LING COL
   Bangalore Srinivas, 2000, P 1 INT C NAT LANG G, P1
   Bannard C., 2005, P 43 ANN M ASS COMP, P597, DOI DOI 10.3115/1219840.1219914
   Barzilay R, 2010, LECT NOTES ARTIF INT, V5790, P1, DOI 10.1007/978-3-642-15573-4_1
   Barzilay Regina, 1999, P 37 ANN M ASS COMP, P550, DOI DOI 10.1115/10146781014760
   Bikel DM, 2004, COMPUT LINGUIST, V30, P479, DOI 10.1162/0891201042544929
   CHARNIAK E, 1999, BLLIP 1987 89 WSJ CO
   CHU YJ, 1965, SCI SINICA, V14, P1396
   COLLINS C, 2004, P 42 ANN M ASS COMP, P231
   Collins M., 2005, P 43 ANN M ASS COMP, P531
   Collins M. J., 1996, P 34 ANN M ASS COMP
   Cormen T.H., 1990, INTRO ALGORITHMS
   Daume III H., 2004, P 2004 C EMP METH NA, P119
   EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032
   Filippova K., 2008, P C EMP METH NAT LAN, P177
   Filippova K., 2007, P 45 ANN M ASS COMP, P320
   JOHNSON M, 2007, P ANN M ASS COMP LIN
   Kuhn H. W., 1955, NAV RES LOG, V2, P83, DOI DOI 10.1002/NAV.3800020109
   Langkilde I, 1998, P 9 INT WORKSH NAT L, P248
   Lapata M., 2007, P 2007 JOINT C EMP M, P1
   Levin B., 1993, ENGLISH VERB CLASSES
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Marsi E, 2010, LECT NOTES ARTIF INT, V5790, P45, DOI 10.1007/978-3-642-15573-4_3
   McDonald R., 2005, P HUM LANG TECHN C C, P523
   MCDONALD R, 2007, P 10 INT C PARS TECH, P121
   PADO S, 2006, P 21 INT C COMP LING, P1161
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   SHEN D, 2007, P 2007 JOINT C EMP M, P12
   Soricut Radu, 2005, P 43 ANN M ASS COMP, P66
   Wan S., 2008, P 2008 C EMP METH NA, P543
   WAN S, 2003, P WORKSH MULT SUMM Q
   Winston W. L., 1994, OPERATIONS RES APPL
   Wong Y. W., 2007, P HUM LANG TECHN C N, P172
NR 33
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
EI 1611-3349
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 13
EP +
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600002
DA 2019-06-15
ER

PT B
AU Wu, XC
   Matsuzaki, T
   Tsujii, J
AF Wu, Xianchao
   Matsuzaki, Takuya
   Tsujii, Jun'ichi
GP Assoc Computat Linguist
TI Fine-grained Tree-to-String Translation Rule Extraction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Tree-to-string translation rules are widely used in linguistically syntax-based statistical machine translation systems. In this paper, we propose to use deep syntactic information for obtaining fine-grained translation rules. A head-driven phrase structure grammar (HPSG) parser is used to obtain the deep syntactic information, which includes a fine-grained description of the syntactic property and a semantic representation of a sentence. We extract fine-grained rules from aligned HPSG tree/ forest-string pairs and use them in our tree-to-string and string-to-tree systems. Extensive experiments on largescale bidirectional Japanese-English translations testified the effectiveness of our approach.
C1 [Wu, Xianchao; Matsuzaki, Takuya; Tsujii, Jun'ichi] Univ Tokyo, Dept Comp Sci, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1130033, Japan.
   [Tsujii, Jun'ichi] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England.
   [Tsujii, Jun'ichi] Manchester Interdisciplinary Bioctr, Natl Ctr Text Min NaCTeM, Manchester M1 7DN, Lancs, England.
RP Wu, XC (reprint author), Univ Tokyo, Dept Comp Sci, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1130033, Japan.
EM wxc@is.s.u-tokyo.ac.jp; matuzaki@is.s.u-tokyo.ac.jp;
   tsujii@is.s.u-tokyo.ac.jp
CR Birch A., 2007, P 2 WORKSH STAT MACH, P9
   Carpenter B., 1992, LOGIC TYPED FEATURE
   Chiang D, 2009, P HUM LANG TECHN 200, P218
   Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Galley M, 2004, P HLT NAACL
   Galley M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P961
   Hassan H, 2007, P 45 ANN M ASS COMP, P288
   Huang Liang, 2005, P IWPT
   Huang Liang, 2006, P 7 AMTA
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Liu Y., 2009, P JOINT C 47 ANN M A, V2, P558
   Liu Y, 2009, P ACL, P576
   Liu Y, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P609
   Matsuzaki T, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1671
   Mi H., 2008, P 2008 C EMP METH NA, P206
   MI H., 2008, P ACL 08 HLT, P192
   MIYAO Y, 2003, P INT C REC ADV NAT, P285
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Oepen S, 2007, P 11 INT C THEOR MET
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Riezler Stefan, 2006, P HUM LANG TECHN C N, P248
   Stolcke A., 2002, P INT C SPOK LANG PR, P901
   Utiyama Masao, 2007, P MT SUMM 11, P475
   Wu X Y., 2010, THESIS
   Zaidan O.F., 2009, PRAGUE B MATH LINGUI, V91, P79
   Zhang Hao, 2006, P HUM LANG TECHN C N, P256
   Zhu L, 2009, INT GEOSCI REMOTE SE, P25, DOI 10.1109/IGARSS.2009.5416922
NR 30
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 325
EP 334
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300034
DA 2019-06-15
ER

PT B
AU Abdalla, RM
   Teufel, S
AF Abdalla, Rashid M.
   Teufel, Simone
GP COLING
TI A Bootstrapping Approach to Unsupervised Detection of Cue Phrase
   Variants
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We investigate the unsupervised detection of semi-fixed cue phrases such as "This paper proposes a novel approach...(1)" from unseen text, on the basis of only a handful of seed cue phrases with the desired semantics. The problem, in contrast to bootstrapping approaches for Question Answering and Information Extraction, is that it is hard to find a constraining context for occurrences of semi-fixed cue phrases. Our method uses components of the cue phrase itself, rather than external context, to bootstrap. It successfully excludes phrases which are different from the target semantics, but which look superficially similar. The method achieves 88% accuracy, outperforming standard bootstrapping approaches.
C1 [Abdalla, Rashid M.; Teufel, Simone] Univ Cambridge, Comp Lab, Cambridge CB3 0FD, England.
RP Abdalla, RM (reprint author), Univ Cambridge, Comp Lab, 15 JJ Thomson Ave, Cambridge CB3 0FD, England.
EM rma33@cam.ac.uk; sht25@cam.ac.uk
CR AGICHTEIN E, 2000, P 5 ACM INT C DIG LI
   BARZILAY R, 2002, P EMNLP
   BRISCOE T, 2002, P LREC
   Burnard L., 1995, USERS REFERENCE GUID
   CARROLL J, 1999, P LING INT CORP LINC
   ESSEN U, 1992, P ICASSP
   HINDLE D, 1990, P ACL
   HOVY E, 1998, P TIPSTER TEXT PROGR
   Hyland K, 1998, J PRAGMATICS, V30, P437, DOI 10.1016/S0378-2166(98)00009-5
   JACQUEMIN C, 1997, P ACL
   KUPIEC J, 1995, P SIGIR 95
   Lee Lillian, 1999, P ACL
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lisacek Frederique, 2005, P SMBM
   Miller G. A, 1990, 5 PAPERS WORDNET
   MYERS G, 1992, J PRAGMATICS, V17, P295, DOI 10.1016/0378-2166(92)90013-2
   PADO S, 2003, P ACL
   Paice C. D., 1981, INFORM RETRIEVAL RES
   PEREIRA F, 1993, P ACL
   Ravichandran Deepak, 2002, P ACL
   RILOFF E, 1993, P AAAI 93
   TEUFEL S, 1998, P ACL 98 WORKSH DISC
   Teufel S., 1999, THESIS U EDINBURGH U
   Van Rijsbergen C.J., 1979, INFORM RETRIEVAL
   WU H, 2003, P ACL
NR 25
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 921
EP 928
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200116
DA 2019-06-15
ER

PT B
AU Cohen-Sygal, Y
   Wintner, S
AF Cohen-Sygal, Yael
   Wintner, Shuly
GP COLING
TI Partially Specified Signatures: a Vehicle for Grammar Modularity
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This work provides the essential foundations for modular construction of (typed) unification grammars for natural languages. Much of the information in such grammars is encoded in the signature, and hence the key is facilitating a modularized development of type signatures. We introduce a definition of signature modules and show how two modules combine. Our definitions are motivated by the actual needs of grammar developers obtained through a careful examination of large scale grammars. We show that Our definitions meet these needs by conforming to a detailed set of desiderata.
C1 [Cohen-Sygal, Yael; Wintner, Shuly] Univ Haifa, Dept Comp Sci, IL-31999 Haifa, Israel.
RP Cohen-Sygal, Y (reprint author), Univ Haifa, Dept Comp Sci, IL-31999 Haifa, Israel.
EM yaelc@cs.haifa.ac.il; shuly@cs.haifa.ac.il
CR Andrykowski MA, 1997, BONE MARROW TRANSPL, V20, P669, DOI 10.1038/sj.bmt.1700949
   BENDER EM, 2005, RES LANGUAGE COMPUTA, V3, P131
   Bender Emily M., 2002, P WORKSH GRAMM ENG E, V19, P8
   Candito Marie-Helene, 1996, COLING 96, P194
   CARPENTER B, 1992, CAMBRIDGE TRACTS THE
   Copestake A., 2000, P LREC ATH GREEC
   Copestake A., 2002, IMPLEMENTING TYPED F
   CRABBE B, 2004, CSLP
   Dalrymple M, 2001, SYNTAX SEMANTICS, V34, pIX
   HINRICHS EW, 2004, RES LANGUAGE COMPUTA, V2, P155
   Kaplan Ronald M., 2002, CHRONIC PHYS DIS BEH, P1
   KESELJ V, 2001, CS200105 U WAT DEP C
   KING TH, 2005, RES LANGUAGE COMPUTA, V3, P139
   MELNIK N, 2005, P HPSG 2005 LISB POR
   MELNIK N, 2006, COGNITIVE L IN PRESS, V17
   Oepen Stephan, 2002, COLLABORATIVE LANGUA
   PENN G, 2000, THESIS CARNEGIE MELL
   Pollard C., 1994, HEAD DRIVEN PHRASE S
   Winterwerp JC, 2002, PROCEED MARINE SCI, V5, P41
NR 19
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 145
EP 152
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200019
DA 2019-06-15
ER

PT B
AU Florian, R
   Jing, HY
   Kambhatla, N
   Zitouni, I
AF Florian, Radu
   Jing, Hongyan
   Kambhatla, Nanda
   Zitouni, Imed
GP COLING
TI Factorizing Complex Models: A Case Study in Mention Detection
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB As natural language understanding research advances towards deeper knowledge modeling, the tasks become more and more complex: we are interested in more nuanced word characteristics, more linguistic properties, deeper semantic and syntactic features. One such example, explored in this article, is the mention detection and recognition task in the Automatic Content Extraction project, with the goal of identifying named, nominal or pronominal references to real-world entities-mentions-and labeling them with three types of information: entity type, entity subtype and mention type. In this article, we investigate three methods of assigning these related tags and compare them on several data sets. A system based on the methods presented in this article participated and ranked very competitively in the ACE'04 evaluation.
C1 [Florian, Radu; Jing, Hongyan; Kambhatla, Nanda; Zitouni, Imed] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Florian, R (reprint author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM raduf@us.ibm.com; hjing@us.ibm.com; nanda@us.ibm.com;
   izitouni@us.ibm.com
CR Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chen S., 1999, CMUCS99108
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Florian R., 2004, P HUM LANG TECHN C N, P1
   FLORIAN R, 2001, P N AM ACL, P1
   FLORIAN R, 2002, P CONLL 2002 TAIP TA, P175
   HACIOGLU K, 2005, COMMUNICATION
   HACIOGLU K, 2005, P HUM LANG TECHN C C, P379
   Hajic J., 1998, P COLING ACL C MONTR, V1, P483, DOI DOI 10.3115/980845.980927
   Jing HY, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P200
   Klein Dan, 2003, NAACL 03 ACL 03
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   MCCALLUM A, 2000, P ICML 2000
   Miller G. A., 1995, COMMUNICATIONS ACM, V38
   *NIST, 2003, ACE EV PLAN
   *NIST, 2004, ACE EV PLAN
   RAMSHAW L, 1994, P ACL WORKSH COMB SY, P128
   Sang E. F. Tjong Kim, 2002, P CONLL 2002 TAIP TA, V20, P1, DOI DOI 10.3115/1118853.1118877
   SANG EFT, 1999, P EACL 99
   SANG EFT, 2003, P 7 C NAT LANG LEARN, P142
   SUTTON C, 2004, P 21 INT C MACH LEAR
   1995, 6 MESS UND C
   1997, 7 MESS UND C
NR 24
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 473
EP 480
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200060
DA 2019-06-15
ER

PT B
AU Foth, KA
   Menzel, W
AF Foth, Kilian A.
   Menzel, Wolfgang
GP COLING
TI Hybrid Parsing: Using Probabilistic Models as Predictors for a Symbolic
   Parser
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper we investigate the benefit of stochastic predictor components for the parsing quality which can be obtained with a rule-based dependency grammar. By including a chunker, a supertagger, a PP attacher, and a fast probabilistic parser we were able to improve upon the baseline by 3.2%, bringing the overall labelled accuracy to 91.1 % on the German NEGRA corpus. We attribute the successful integration to the ability of the underlying grammar model to combine uncertain evidence in a soft manner, thus avoiding the problem of error propagation.
C1 [Foth, Kilian A.; Menzel, Wolfgang] Univ Hamburg, Dept Informat, Hamburg, Germany.
RP Foth, KA (reprint author), Univ Hamburg, Dept Informat, Hamburg, Germany.
EM foth@informatik.uni-hamburg.de; menzel@informatik.uni-hamburg.de
CR Brants Sabine, 2002, P WORKSH TREEB LING
   Brants T., 2000, P 6 APPL NAT LANG PR
   BRANTS T, 1997, NEGRA ANNOTATIONSSCH
   CHARNIAK E, 2000, P NAACL 2000
   Clark S., 2004, P 20 INT C COMP LING
   Collins Michael, 1999, THESIS U PENNSYLVANI
   Daum Michael, 2004, P 4 INT C LANG RES E
   DUBEY A, 2005, P 43 ANN M ACL ANN A
   Foth K, 2004, P REC ADV DEP GRAMM
   Foth K. A., 2006, P 21 INT C COMP LING
   Foth KA, 2005, LECT NOTES ARTIF INT, V3438, P140
   HAGENSTROM J, 2002, P 2 INT WORKSH ROB M
   Malouf R., 2004, P IJCNLP 04 WORKSH S
   MARUYAMA H, 1990, P 28 M ASS COMP LING, P31
   McDonald R, 2005, P HUM LANG TECHN C C
   NIVRE J, 2003, P 8 INT WORKSH PARS, P149
   Schmid H., 1994, INT C NEW METH LANG
   SCHRODER I, 2001, P EUR REC ADV NAT LA, P235
   SCHRODER I, 2002, THESIS U HAMBURG GER
   Schroder I., 2000, 4 INT WORKSH PARS TE, P89
   SRINIVAS B, 1999, COMPUTATIONAL LINGUI, V25, P237
   VOLK M, 2002, P COLING 2002 TAIP
   Wang W., 2004, P ACL WORKSH INCR PA, P42
NR 23
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 321
EP 328
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200041
DA 2019-06-15
ER

PT B
AU Fraser, A
   Marcu, D
AF Fraser, Alexander
   Marcu, Daniel
GP COLING
TI Semi-Supervised Training for Statistical Word Alignment
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We introduce a semi-supervised approach to training for statistical machine translation that alternates the traditional Expectation Maximization step that is applied on a large training corpus with a discriminative step aimed at increasing word-alignment quality on a small, manually word-aligned sub-corpus. We show that our algorithm leads not only to improved alignments but also to machine translation outputs of higher quality.
C1 [Fraser, Alexander; Marcu, Daniel] Univ So Calif, ISI, Marina Del Rey, CA 90292 USA.
RP Fraser, A (reprint author), Univ So Calif, ISI, 4676 Admiralty Way,Suite 1001, Marina Del Rey, CA 90292 USA.
EM fraser@isi.edu; marcu@isi.edu
CR BASU S, 2004, KDD 04, P59
   BENTASKAR, 2005, P HUM LANG TECHN C C
   Brown P. F., 1993, Computational Linguistics, V19, P263
   CHERRY C, 2003, P 41 ANN M ASS COMP
   FRASER A, 2006, ISITR616 U SO CAL
   GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1
   Ittycheriah Abraham, 2005, P HUM LANG TECHN C C
   IVANOV Y, 2001, ICML WILL MA, P218
   Liu Y, 2005, P 43 ANN M ASS COMP, P459
   Melamed I. Dan, 1998, 9807 I RES COGN SCI
   MOORE RC, 2005, P HUM LANG TECHN C C
   Neal R. M., 1998, LEARNING GRAPHICAL M
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Osborne Miles, 2004, P 42 ANN M ASS COMP
   PAPINENI KA, 2001, RC22176W0109022 TJ W
   SEEGER M, 2000, TECHNICAL REPORT 200
   VOGEL S, 1996, COLING 96 16 INT C C, P836
NR 19
TC 1
Z9 1
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 769
EP 776
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200097
DA 2019-06-15
ER

PT B
AU Frunza, O
   Inkpen, D
AF Frunza, Oana
   Inkpen, Diana
GP COLING
TI Semi-Supervised Learning of Partial Cognates using Bilingual
   Bootstrapping
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Partial cognates are pairs of words in two languages that have the same meaning in some, but not all contexts. Detecting the actual meaning of a partial cognate in context can be useful for Machine Translation tools and for Computer-Assisted Language Learning tools. In this paper we propose a supervised and a semi-supervised method to disambiguate partial cognates between two languages: French and English. The methods use only automatically-labeled data; therefore they can be applied for other pairs of languages as well. We also show that our methods perform well when using corpora from different domains.
C1 [Frunza, Oana; Inkpen, Diana] Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
RP Frunza, O (reprint author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
EM ofrunza@site.uottawa.ca; diana@site.uottawa.ca
CR Carroll S. E., 1992, SECOND LANG RES, V8, P93, DOI DOI 10.1177/026765839200800201
   DIAB M, 2002, P 40 ANN M ASS COMP, P255
   GASS SM, 1987, STUDIES 2 LANGUAGE A, V9
   Hewson John, 1993, COMPUTER GENERATED D
   IDE N, 2000, COMPUT HUMANITIES, V34, P1
   JACQUES BM, 1994, J QUANT LINGUIST, V1, P35
   JOHN B, 1994, COMPUTATIONAL LINGUI, V20, P381
   KONDRAK G, 2004, P 7 CAN C ART INT LO, P44
   Kondrak G., 2001, P 2 M N AM CHAPT ASS, P103
   LeBlanc R., 1996, 25 YEARS 2 LANGUAGE, P69
   Li H, 2004, COMPUT LINGUIST, V30, P1, DOI 10.1162/089120104773633367
   MARTINEZLAGE JF, 1991, CHILD NERV SYST, V7, P448, DOI 10.1007/BF00263187
   Ringbom H., 1987, ROLE 1 LANGUAGE FORE
   Tufis D, 2004, P 20 INT C COMP LING, P1312
   van Heuven WJB, 1998, J MEM LANG, V39, P458, DOI 10.1006/jmla.1998.2584
   Yarowsky D, 1995, P ACL, P189, DOI DOI 10.3115/981658.981684
NR 16
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 441
EP 448
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200056
DA 2019-06-15
ER

PT B
AU Gorman, J
   Curran, JR
AF Gorman, James
   Curran, James R.
GP COLING
TI Scaling Distributional Similarity to Large Corpora
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Accurately representing synonymy using distributional similarity requires large volumes of data to reliably represent infrequent words. However, the naive nearest-neighbour approach to comparing context vectors extracted from large corpora scales poorly (O(n(2)) in the vocabulary size).
   In this paper, we compare several existing approaches to approximating the nearest-neighbour search for distributional similarity. We investigate the trade-off between efficiency and accuracy, and find that SASH (Houle and Sakuma, 2005) provides the best balance.
C1 [Gorman, James; Curran, James R.] Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
RP Gorman, J (reprint author), Univ Sydney, Sch Informat Technol, Sydney, NSW 2006, Australia.
EM jgorman2@it.usyd.edu.au; james@it.usyd.edu.au
CR Broder A. Z., 1997, P COMPR COMPL SEQ, P21, DOI DOI 10.1109/SEQUEN.1997.666900
   Charikar Moses S, 2002, P 34 ANN ACM S THEOR
   CURRAN J, 2002, P WORKSH ACL SPEC IN
   Curran JR., 2004, THESIS U EDINBURGH
   Goemans MX, 1995, J ACM, V42, P1115, DOI 10.1145/227683.227684
   GORMAN J, 2005, ACL SIGLEX 2005 WORK
   GORMAN J, 2005, AUSTR LANG TECHN WOR
   Grefenstette G., 1994, EXPLORATIONS AUTOMAT
   Houle ME, 2005, PROC INT CONF DATA, P619
   HOULE ME, 2003, P 9 ACM SIGKDD INT C, P547
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Kanerva P, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P1036
   Kanerva P., 1993, ASS NEURAL MEMORIES, V26, P50
   Karlgren J, 2001, FDN REAL WORLD INTEL, P294
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   Pantel P., 2002, P 8 ACM SIGKDD INT C, P613
   Ravichandran D., 2005, P 43 ANN M ASS COMP, P622
   Sahlgren M., 2005, J NATURAL LANGUAGE E, V11
   WALTER A, 1973, COMMUN ACM, V16, P230
   Weeds J, 2005, COMPUT LINGUIST, V31, P439, DOI 10.1162/089120105775299122
   YIANILOS PN, 1993, PROCEEDINGS OF THE FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P311
NR 21
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 361
EP 368
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200046
DA 2019-06-15
ER

PT B
AU Kuo, JS
   Li, HZ
   Yang, YK
AF Kuo, Jin-Shea
   Li, Haizhou
   Yang, Ying-Kuei
GP COLING
TI Learning Transliteration Lexicons from the Web
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents an adaptive learning framework for Phonetic Similarity Modeling (PSM) that supports the automatic construction of transliteration lexicons. The teaming algorithm starts with minimum prior knowledge about machine transliteration, and acquires knowledge iteratively from the Web. We study the active learning and the unsupervised learning strategies that minimize human supervision in terms of data labeling. The learning process refines the PSM and constructs a transliteration lexicon at the same time. We evaluate the proposed PSM and its learning algorithm through a series of systematic experiments, which show that the proposed framework is reliably effective on two independent databases.
EM jskuo@cht.com.tw; hzli@ieee.org; ykyang@mouse.ee.ntust.edu.tw
RI Li, Haizhou/Q-6438-2019
OI Li, Haizhou/0000-0001-9158-9401
CR BRILL E, 2001, P 10 TEXT RETRIEVAL, P393
   BRIN S, 1998, P 7 INT WORLD WID WE, P107
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Fung P., 1998, P 17 INT C COMP LING, V1, P414
   HUANG F, 2005, P HUM LANG TECHN C C, P483
   JURAFSKY D, 2000, SPEECH LANGUAGE PROC, P102
   Knight K, 1998, COMPUT LINGUIST, V24, P599
   Kuo J. S., 2005, P INT C CHIN COMP, P131
   KUO JS, 2004, COMPANION VOLUME, P102
   LAM W, 2004, P 27 ANN INT ACM SIG, P289
   Lee Chun-Jen, 2003, P HLT NAACL 2003 WOR, P96
   Lewis D. D., 1994, P 11 INT C MACH LEAR, P148
   Li Haizhou, 2004, P 42 ANN M ASS COMP, P159
   LU WH, 2002, ACM T ASIAN LANGUAGE, V1, P159
   MENG H, 2001, P AUT SPEECH REC UND, P311
   Nie Jian-Yun, 1999, P 22 ANN INT ACM SIG, P74
   Pagel V., 1998, P ICSLP, P2015
   Rapp R, 1999, P 37 ANN M ASS COMP, P519, DOI DOI 10.3115/1034678.1034756
   RICCARDI G, 2003, P 8 EUR
   VIRGA P, 2003, P 41 ACL WORKSH MULT, P57
   WAN S, 1998, P 17 COLING 36 ACL, P1352
NR 21
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1129
EP 1136
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200142
DA 2019-06-15
ER

PT B
AU Li, JY
   Sun, MS
   Zhang, M
AF Li, Jingyang
   Sun, Maosong
   Zhang, Xian
GP COLING
TI A Comparison and Semi-Quantitative Analysis of Words and
   Character-Bigrams as Features in Chinese Text Categorization
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID RETRIEVAL
AB Words and character-bigrams are both used as features in Chinese text processing tasks, but no systematic comparison or analysis of their values as features for Chinese text categorization has been reported heretofore. We carry out here a full performance comparison between them by experiments on various document collections (including a manually word-segmented corpus as a golden standard), and a semi-quantitative analysis to elucidate the characteristics of their behavior; and try to provide some preliminary clue for feature term choice (in most cases, character-bigrams are better than words) and dimensionality setting in text categorization systems.
C1 [Li, Jingyang; Sun, Maosong; Zhang, Xian] Tsinghua Univ, Dept Comp Sci & Tech, Natl Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.
RP Li, JY (reprint author), Tsinghua Univ, Dept Comp Sci & Tech, Natl Lab Intelligent Technol & Syst, Beijing 100084, Peoples R China.
EM lijingyang@gmail.com; sms@tsinghua.edu.cn; kevinn9@gmail.com
CR AIZAWA A, 2000, P 23 ANN INT ACM SIG, P104
   Baeza-Yates R., 1999, MODERN INFORM RETRIE
   Chang Chih-Chung, 2001, LIBSVM LIB SUPPORT V
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   FABRIZIO S, 2002, ACM COMPUT SURV, V34, P1, DOI DOI 10.1145/505282.505283
   JOACHIMS T, 1997, P 14 INT C MACH LEAR, P143
   Joachims T., 1998, P 10 EUR C MACH LEAR, P137
   LEONG MK, 1998, NIST SPECIAL PUBLICA, P551
   LI BL, 2003, P 4 INT C COMP LING, P602
   LIU Y, 1986, J CHINESE INFORM PRO, V1, P17
   Nie J-J, 2000, P 5 INT WORKSH INF R
   Nie JY, 1999, INFORM PROCESS MANAG, V35, P443, DOI 10.1016/S0306-4573(98)00051-X
   ROBERT WP, 1997, P ACM SIGIR 1997, P34
   Rogati M., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P659
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Vapnik VN, 1995, NATURE STAT LEARNING
   XUE DJ, 2003, P 4 INT C COMP LING, P594
   XUE DJ, 2003, J INTELLIGENT SYSTEM
   YANG Y, 1997, P 14 INT C MACH LEAR, P412, DOI DOI 10.1016/J.ESWA.2008.05.026
NR 19
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 545
EP 552
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200069
DA 2019-06-15
ER

PT B
AU Nakagawa, T
   Matsumoto, Y
AF Nakagawa, Tetsuji
   Matsumoto, Yuji
GP COLING
TI Guessing Parts-of-Speech of Unknown Words Using Global Information
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper, we present a method for guessing POS tags of unknown words using local and global information. Although many existing methods use only local information (i.e. limited window size or intra-sentential features), global information (extra-sentential features) provides valuable clues for predicting POS tags of unknown words. We propose a probabilistic model for POS guessing of unknown words using global information as well as local information, and estimate its parameters using Gibbs sampling. We also attempt to apply the model to semi-supervised learning, and conduct experiments on multiple corpora.
C1 [Nakagawa, Tetsuji] Oki Elect Ind Co Ltd, Ctr Corp Res & Dev, Chuo Ku, Osaka 5410053, Japan.
RP Nakagawa, T (reprint author), Oki Elect Ind Co Ltd, Ctr Corp Res & Dev, Chuo Ku, 2-5-7 Honmachi, Osaka 5410053, Japan.
EM nakagawa378@oki.com; matsu@is.naist.jp
CR Adams ME, 1996, P EDINBURGH MATH SOC, V39, P71, DOI 10.1017/S0013091500022793
   Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116
   ASAHARA M, 2003, CORPUS BASED JAPANES
   Baayen H, 1996, COMPUT LINGUIST, V22, P155
   CHEN C, 1997, P NAT LANG PROC PAC, P35
   Chen S., 1999, CMUCS99108
   Chieu H. L., 2002, P 19 INT C COMP LING, V1, P190
   Dong C., 1989, MATH PROGRAM, V45, P503
   Finkel J. R., 2005, P 43 ANN M ASS COMP, P363, DOI DOI 10.3115/1219840.1219885
   Klakow Dietrich, 1998, P ICSLP 98, P1695
   MacKay D. J, 2003, INFORM THEORY INFERE
   MARROQUIN JL, 1985, 839 AI MIT
   Mikheev A, 1997, COMPUT LINGUIST, V23, P405
   Mori Shinsuke, 1996, P 16 INT C COMP LING, P1119
   NAGATA M, 1999, P 37 ANN M ASS COMP, P277
   Orphanos G., 1999, P EACL 99, P134
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   Rosenfeld R, 2001, COMPUT SPEECH LANG, V15, P55, DOI 10.1006/csla.2000.0159
   Takamura H., 2005, P 43 ANN M ASS COMP, P133, DOI DOI 10.3115/1219840.1219857
   Uchimoto K, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P91
   Wang Shaojun, 2005, P INT C MACH LEARN, P948
   Yarowsky D, 1995, P ACL, P189, DOI DOI 10.3115/981658.981684
NR 22
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 705
EP 712
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200089
DA 2019-06-15
ER

PT B
AU Park, SB
   Tae, YS
   Park, SY
AF Park, Seong-Bae
   Tae, Yoon-Shik
   Park, Se-Young
GP COLING
TI Self-Organizing n-gram Model for Automatic Word Spacing
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID LANGUAGE MODEL
AB An automatic word spacing is one of the important tasks in Korean language processing and information retrieval. Since there are a number of confusing cases in word spacing of Korean, there are some mistakes in many texts including news articles. This paper presents a high-accurate method for automatic word spacing based on self-organizing n-gram model. This method is basically a variant of n-gram model, but achieves high accuracy by automatically adapting context size.
   In order to find the optimal context size, the proposed method automatically increases the context size when the contextual distribution after increasing it dose not agree with that of the current context. It also decreases the context size when the distribution of reduced context is similar to that of the current context. This approach achieves high accuracy by considering higher dimensional data in case of necessity, and the increased computational cost are compensated by the reduced context size. The experimental results show that the self-organizing structure of n-gram model enhances the basic model.
C1 [Park, Seong-Bae; Tae, Yoon-Shik; Park, Se-Young] Kyungpook Natl Univ, Dept Comp Engn, Taegu 702701, South Korea.
RP Park, SB (reprint author), Kyungpook Natl Univ, Dept Comp Engn, Taegu 702701, South Korea.
EM sbpark@sejong.knu.ac.kr; ystae@sejong.knu.ac.kr; sypark@sejong.knu.ac.kr
CR Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   Charniak E, 1993, STAT LANGUAGE LEARNI
   Chen S. F., 1996, P 34 ANN M ASS COMP, P310, DOI DOI 10.3115/981863.981904
   Dickinson M., 2005, P 43 ANN M ASS COMP, P322
   Jelinek F., 1980, P WORKSH PATT REC PR
   Joachims T., 1998, LS8 U DORTM, V24
   KANG SS, 2004, P 15 C KOR LANG INF, P227
   KANG SS, 2000, J KISS, V27, P441
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Kim J. W., 2003, P 41 ANN M ASS COMP, P296
   KIM KS, 1998, J KISS, V25, P1838
   LEE DG, 2002, P 3 WORKSH AS LANG R, P51
   Mitchell T. M., 1997, MACHINE LEARNING
   Mochihashi D., 2006, ADV NEURAL INFORM PR, V18, P907
   Park S-B., 2002, P 19 INT C MACH LEAR, P482
   QUINLAN RJ, 1993, C4 5 PROGRAM MACHINE
   Ron D, 1996, MACH LEARN, V25, P117, DOI 10.1023/A:1026490906255
   Rosenfeld R, 1996, COMPUT SPEECH LANG, V10, P187, DOI 10.1006/csla.1996.0011
   SCHUTZE H, 1994, P 32 ANN M ASS COMP, P181
   Siu MH, 2000, IEEE T SPEECH AUDI P, V8, P63, DOI 10.1109/89.817454
NR 20
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 633
EP 640
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200080
DA 2019-06-15
ER

PT B
AU Xia, YQ
   Wong, KF
   Li, WJ
AF Xia, Yunqing
   Wong, Kam-Fai
   Li, Wenjie
GP COLING
TI A Phonetic-Based Approach to Chinese Chat Text Normalization
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Chatting is a popular communication media on the Internet via ICQ, chat rooms, etc. Chat language is different from natural language due to its anomalous and dynamic natures, which renders conventional NLP tools inapplicable. The dynamic problem is enormously troublesome because it makes static chat language corpus outdated quickly in representing contemporary chat language. To address the dynamic problem, we propose the phonetic mapping models to present mappings between chat terms and standard words via phonetic transcription, i.e. Chinese Pinyin in our case. Different from character mappings, the phonetic mappings can be constructed from available standard Chinese corpus. To perform the task of dynamic chat language term normalization, we extend the source channel model by incorporating the phonetic mapping models. Experimental results show that this method is effective and stable in normalizing dynamic chat language terms.
C1 [Xia, Yunqing; Wong, Kam-Fai] Chinese Univ Hong Kong, Dept SEEM, Shatin, Hong Kong, Peoples R China.
RP Xia, YQ (reprint author), Chinese Univ Hong Kong, Dept SEEM, Shatin, Hong Kong, Peoples R China.
EM yqxia@se.cuhk.edu.hk; kfwong@se.cuhk.edu.hk; cswjli@comp.polyu.edu.hk
OI Li, Wenjie/0000-0002-7360-8864
CR Brown P. F., 1990, Computational Linguistics, V16, P79
   GIANFORTE G, 2003, CALL CTR CONTACT CTR
   GRAF D, 2005, LDC2005T14
   HEARDWHITE M, 2004, REPORT USE CHAT ED F
   JAMES F, 2000, 0007 RIACS
   KATZ SM, IEEE T ACOUSTICS SPE, V35, P400
   [李红莲 Li Honglian], 2003, [中文信息学报, Journal of Chinese Information Processing], V17, P60
   MCCULLAGH D, 2004, CNET NETWORKS   1124
   XIA Y, 2006, EACL 06 NEW TEXT WOR, P48
   XIA Y, 2006, CONSTRUCTING CHINESE
   XIA Y, 2005, 4 SIGHAN WORKSH IJCN, P95
NR 11
TC 1
Z9 1
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 993
EP 1000
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200125
DA 2019-06-15
ER

PT B
AU Zhang, Q
   Weng, FL
   Feng, Z
AF Zhang, Qi
   Weng, Fuliang
   Feng, Zhe
GP COLING
TI A Progressive Feature Selection Algorithm for Ultra Large Feature Spaces
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Recent developments in statistical modeling of various linguistic phenomena have shown that additional features give consistent performance improvements. Quite often, improvements are limited by the number of features a system is able to explore. This paper describes a novel progressive training algorithm that selects features from virtually unlimited feature spaces for conditional maximum entropy (CME) modeling. Experimental results in edit region identification demonstrate the benefits of the progressive feature selection (PFS) algorithm: the PFS algorithm maintains the same accuracy performance as previous CME feature selection algorithms (e.g., Zhou et al., 2003) when the same feature spaces are used. When additional features and their combinations are used, the PFS gives 17.66% relative improvement over the previously reported best result in edit region identification on Switchboard corpus (Kahn et al., 2005), which leads to a 20% relative error reduction in parsing the Switchboard corpus when gold edits are used as the upper bound.
C1 [Zhang, Qi] Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China.
RP Zhang, Q (reprint author), Fudan Univ, Dept Comp Sci, Shanghai 200433, Peoples R China.
EM qi_zhang@fudan.edu.cn; fuliang.weng@rtc.bosch.com;
   zhe.feng@rtc.bosch.com
CR Berger AL, 1996, COMPUT LINGUIST, V22, P39
   Charniak E, 2005, P 43 ANN M ASS COMP, P173, DOI DOI 10.3115/1219840.1219862
   CHARNIAK E, 2001, P 2 M N AM CHAPT ASS, P118
   Chen S., 1999, CMUCS99108
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   DellaPietra S, 1997, IEEE T PATTERN ANAL, V19, P380, DOI 10.1109/34.588021
   Goodman J., 2002, P 40 ANN M ASS COMP, P9
   JEREMY G, 2005, P 2005 C EMP METH NA, P233
   JOHNSON M, 2004, P 42 ANN M ASS COMP
   Koeling R., 2000, P CONLL 2000 LLL 200, P139
   *LDC, 2004, SIMPL METADATA ANN S
   Lin D., 2004, P 2004 C EMP METH NA, P174
   Liu ZW, 2005, NANO LETT, V5, P957, DOI 10.1021/nl0506094
   Malouf R., 2002, P 6 C NAT LANG LEARN, P49, DOI DOI 10.3115/1118853.1118871
   Ostendorf M, 2001, P ISCA WORKSH PROS S, P119
   Reynar J., 1994, P ARPA HUM LANG TECH, P250
   Reynar J. C., 1997, P 5 C APPL NAT LANG, P16
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Shriberg E., 1994, THESIS U CALIFORNIA
   Vapnik VN, 1995, NATURE STAT LEARNING
   WONG D, 2005, UWEETR20050003
   Zhang Q., 2005, P 9 INT WORKSH PARS, P179
   Zhou YQ, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P153
NR 23
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 561
EP 568
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200071
DA 2019-06-15
ER

PT B
AU Gregory, ML
   Johnson, M
   Charniak, E
AF Gregory, ML
   Johnson, M
   Charniak, E
GP acl
TI Sentence-internal prosody does not help parsing the way punctuation does
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
ID SPEECH
AB This paper investigates the usefulness of sentence-internal prosodic cues in syntactic parsing of transcribed speech. Intuitively, prosodic cues would seem to provide much the same information in speech as punctuation does in text, so we tried to incorporate them into our parser in much the same way as punctuation is. We compared the accuracy of a statistical parser on the LDC Switchboard treebank corpus of transcribed sentence-segmented speech using various combinations of punctuation and sentence-internal prosodic information (duration, pausing, and f0 cues). With no prosodic or punctuation information the parser's accuracy (as measured by F-score) is 86.9%, and adding punctuation increases its F-score to 88.2%. However, all of the ways we have tried of adding prosodic information decrease the parser's F-score to between 84.8% to 86.8%, depending on exactly which prosodic information is added. This suggests that for sentence-internal prosodic information to improve speech transcript parsing, either different prosodic cues will have to used or they will have be exploited in the parser in a way different to that used currently.
C1 Brown Univ, Providence, RI 02912 USA.
RP Gregory, ML (reprint author), Brown Univ, Providence, RI 02912 USA.
OI Johnson, Mark/0000-0003-4809-8441
CR ALTENBERG B, 1987, PEROSODIC PATTERNS S
   Baron D., 2002, P INT C SPOK LANG PR, P949
   BIES A, 1995, BRAKETTING GUIDELINE
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   CHARNIAK E, 2001, P 2 M N AM CHAPT ASS, P118
   CROFT W, 1995, LINGUISTICS, V33, P839, DOI 10.1515/ling.1995.33.5.839
   ENGEL D, 2002, P 2002 C EMP METH NA, P59
   FERRER L, 2002, P 7 INT C SPOK LANG, V3, P2061
   FERRER L, 2002, PROSODIC FRATURES SW
   Gregory Michelle L., 2001, P ISCA WORKSH PROS S, P77
   HAMAKER J, 2003, MANUALLY CORRECTED S
   HIRSCHBERG J, 1998, P INT C SPOKEN LANGU, V4, P1255
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   KMOPE R, 1998, PROSODY SPEECH UNDER
   Manning C.D., 1999, FDN STAT NATURAL LAN
   NEIMAN H, 1998, P INT WORKSH SPEECH, P17
   Noth E, 2000, IEEE T SPEECH AUDI P, V8, P519, DOI 10.1109/89.861370
   Schepman A, 2000, Q J EXP PSYCHOL-A, V53, P377, DOI 10.1080/027249800390538
   Shriberg E, 2000, SPEECH COMMUN, V32, P127, DOI 10.1016/S0167-6393(00)00028-5
NR 19
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 81
EP 88
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100011
DA 2019-06-15
ER

PT B
AU Lapata, M
   Lascarides, A
AF Lapata, M
   Lascarides, A
GP acl
TI Inferring sentence-internal temporal relations
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB In this paper we propose a data intensive approach for inferring sentence-internal temporal relations, which relies on a simple probabilistic model and assumes no manual coding. We explore various combinations of features, and evaluate performance against a gold-standard corpus and human subjects performing the same. task. The best model achieves 70.7% accuracy in inferring the temporal relation between two clauses and 97.4% accuracy in ordering them, assuming that the temporal relation is known.
C1 Univ Sheffield, Dept Comp Sci, Sheffield S1 4DP, S Yorkshire, England.
RP Lapata, M (reprint author), Univ Sheffield, Dept Comp Sci, Regent Court,211 Portobello St, Sheffield S1 4DP, S Yorkshire, England.
CR Asher Nicholas, 2003, LOGICS CONVERSATION
   BARZILAY R, 2003, THESIS COLUMBIA U
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   Dietterich TG, 1997, AI MAG, V18, P97
   DORR B, 1995, P 14 INT JOINT C ART, P1299
   FELLBAUM CHRISTIANE, 1998, WORDNET ELECT DATABA
   FERRO L, 2000, TIDES TEMPORAL ANNOT
   JOHNSON WE, 1932, MIND, V49, P409
   Kamp H., 1993, DISCOURSE LOGIC INTR
   Katz G., 2001, P 2001 ACL EACL WORK, P104
   LAPATA M, 1999, P JOINT SIGDAT C EMP, P266
   Levin B., 1993, ENGLISH VERB CLASSES
   MANI I, 2003, P 1 HUM LANG TECHN C
   Marcu D., 2002, P 40 ANN M ASS COMP, P368
   Quinlan R., 1993, C4 5 PROGRAMS MACHIN
   QUIRK R, 1985, COMPREHENSIVE GRAMAR
   Schilder F., 2001, P ACL 2001 WORKSH TE, P65
   SETZER A, 2001, P ACL WORKSH TEMP SP, P73
   Siegel S, 1988, NONPARAMETRIC STAT B
   SORICUT R, 2003, P 1 HUM LANG TECHN C, P228
   WEBBER BL, 1991, LANG COGNITIVE PROC, V6, P107, DOI 10.1080/01690969108406940
   Wiebe JM, 1998, J ARTIF INTELL RES, V9, P247, DOI 10.1613/jair.523
   Wilson G., 2001, P ACL WORKSH TEMP SP, V13, P81
NR 23
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 153
EP 160
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100020
DA 2019-06-15
ER

PT B
AU Porzel, R
   Baudis, M
AF Porzel, R
   Baudis, M
GP acl
TI The tao of CHI: Towards effective human-computer interaction
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB End-to-end evaluations of conversational dialogue systems with naive users are currently uncovering severe usability problems that result in low task completion rates. Preliminary analyses suggest that these problems are related to the system's dialogue management and turn-taking behavior. We present the results of experiments designed to take a detailed look at the effects of that behavior. Based on the resulting findings, we spell out a set of criteria which lie orthogonal to dialogue quality, but nevertheless constitute an integral part of a more comprehensive view on dialogue felicity as a function of dialogue quality and efficiency.
C1 European Media Lab GmbH, D-69118 Heidelberg, Germany.
RP Porzel, R (reprint author), European Media Lab GmbH, Schloss Wolfsbrunnenweg 33, D-69118 Heidelberg, Germany.
CR ALEXANDERSSON J, 2001, P IJCAI WORKSH KNOWL
   Allen J.F., 1996, P 34 ANN M ASS COMP
   ALLEN JF, 2001, P INT US INT SANT FE
   Aust H., 1995, SPEECH COMMUNICATION, V17
   BAILLY G, 2003, P EUR C SPEECH COMM
   Beringer N., 2002, P WORKSH MULT RES MU
   BERINGER N, 2003, C DEP LING U NIJM JU
   COX R, 2000, P IEEE, V88
   Darves  Charles, 2002, P 7 INT C SPOK LANG
   DIAZVERDEJO J, 2000, 2 INT C LANG RES EV
   DUNCAN S, 1974, LANGUAGE SOC, V3
   ENGEL R, 2002, P INT C SPEECH LANG
   FRANCONY JM, 1992, 3 C APPL NAT LANG PR
   Fraser  Norman, 1993, INTERACTING COMPUTER, V5
   GALLWITZ F, 1998, P 1998 INT S SPOK DI
   GORIN AL, 1997, SPEECH COMMUNICATION, V23
   GUREVYCH I, 2003, P HLT NAACL TEXT MEA
   HERZOG G, 2003, P HLT NAACL SEALTS W
   Jefferson G, 1983, TILBURG PAPERS LANGU, V28
   Johnston M., 2002, P 40 ANN M ASS COMP
   JOHNSTON M, 1998, P 17 INT C COMP LING
   KAURSE J, 1992, COMPUTER TALK
   Kritzenberger  Huberta, 1992, COMPUTER TALK, P122
   PORZEL R, 2003, P 3 IJCAI 2003 WORKS
   RAPP S, 2002, P 3 INT C LANG RES E
   RAPP S, 2000, P ECAI 2000 WORKSH A
   SACK S, 1974, LANGUAGE, V50
   SHANKAR TR, 2000, P HAW INT C SYST SCI
   SWEETSER E, 2003, P 8 INT C COGN LING
   WAHLSTER W, 2002, P FIRS INT WORKSH MA
   WAHLSTER W, 2001, P 7 EUR C SPEECH COM
   Wahlster W., 2003, P HUM COMP INT STAT
   WALKER M, 1997, P 35 ANN M ASS COMP
   WALKER MA, 2000, NATURAL LANGUAGE ENG, V6
   WEINHAMMER K, 2003, P INT C PHON SCI BAR
   Woodburn R., 1991, People and Computers VI. Proceedings of the HCI '91 Conference, P359
   Wooffitt R., 1997, HUMANS COMPUTERS WIZ
   Yngve V, 1970, 6 REG M CHIC LING SO
   ZOEPPRITZ M, 1985, 8505 IBM SCI CTR HEI
NR 39
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 209
EP 216
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100027
DA 2019-06-15
ER

PT B
AU Callaway, CB
AF Callaway, CB
GP ACL
TI Integrating discourse markers into a pipelined natural language
   generation architecture
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Pipelined Natural Language Generation (NLG) systems have grown increasingly complex as architectural modules were added to support language functionalities such as referring expressions, lexical choice, and revision. This has given rise to discussions about the relative placement of these new modules in the overall architecture. Recent work on another aspect of multi-paragraph text, discourse markers, indicates it is time to consider where a discourse marker insertion algorithm fits in. We present examples which suggest that in a pipelined NLG architecture, the best approach is to strongly tie it to a revision component. Finally, we evaluate the approach in a working multi-page system.
C1 ITC irst, I-38050 Trent, Italy.
CR Callaway C. B, 2001, P 17 IJCAI SEATTL WA, P1241
   Callaway CB, 2002, ARTIF INTELL, V139, P213, DOI 10.1016/S0004-3702(02)00230-8
   CALLAWAY CB, 1997, P IJCAI 97 NAG JAP, P952
   CLINE BE, 1994, THESIS VIRGINIA POLY
   DALIANIS H, 1993, P 4 EUR WORKSH NAT L
   Elhadad M, 1997, COMPUT LINGUIST, V23, P195
   ELHADAD M, 1990, COLING 90, P97
   GROTE B, 1999, P 7 EUR WORKSH NAT L
   HARVEY T, 1998, P 36 ANN M ASS COMP, P512
   HORACEK H, 2002, 2 INT NAT LANG GEN C, P105
   KANTROWITZ M, 1992, ASPECTS AUTOMATED NA, P247
   KNOTT A, 1996, J LANGUAGE SPEECH, P39
   MOONEY DJ, 1994, THESIS U DELAWARE NE
   POWER R, 1999, P 7 EUR WORKSH NAT L
   Quirk R., 1985, COMPREHENSIVE GRAMMA
   REAPE M, 1999, P 7 EUR WORKSH NAT L
   Reiter E., 1994, P 7 INT WORKSH NAT L, P163
   ROBIN J, 1994, THESIS COLUMBIA U
   Shaw J., 1998, P 9 INT WORKSH NAT L, P138
   Stede M., 1998, P JOINT 36 M ACL 17, P1238
   Tree JEF, 1999, DISCOURSE PROCESS, V27, P35, DOI 10.1080/01638539909545049
   WEBBER BL, 1998, P COLING ACL 98 WORK, P86
   YANG FJ, 2000, 5 ANN C HUM INT COMP, P27
NR 23
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 264
EP 271
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500034
DA 2019-06-15
ER

PT B
AU Carreras, X
   Marquez, L
   Padro, L
AF Carreras, X
   Marquez, L
   Padro, L
GP ACL
TI Named entity recognition for Catalan using Spanish resources
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB This work studies Named Entity Recognition (NER) for Catalan without making use of annotated resources of this language. The approach presented is based on machine learning techniques and exploits Spanish resources, either by first training models for Spanish and then translating them into Catalan, or by directly training bilingual models. The resulting models are retrained on unlabelled Catalan data using bootstrapping techniques. Exhaustive experimentation has been conducted on real data, showing competitive results for the obtained NER systems.
C1 Univ Politecn Catalunya, LSI Dept, TALP Res Ctr, E-08034 Barcelona, Spain.
RI Padro, Lluis/D-1877-2012; Padro, Lluis/A-1472-2018
OI Padro, Lluis/0000-0003-4738-5019
CR Aberdeen J., 1995, P 6 MESS UND C MUC 6, P141
   Abney S., 2002, P 40 ANN M ASS COMP
   Appelt D. E., 1995, P 6 MESS UND C MUC 6, P237
   BLACK W, 1998, P 7 MESS UND C
   Black W. J., 2002, P CONLL 2002 TAIP TA, P159
   BORTHWICK A, 1998, P 7 MESS UND C
   Carreras X., 2002, P CONLL 2002 TAIP TA, P167
   COLLINS M, 1999, P EMNLP VLC 99 COLL
   KRUPKA G, 1998, P 7 MESS UND C
   Malouf Robert, 2002, P CONLL 2002 TAIP TA, P187
   MCNAMEE P, 2002, P CONLL 2002 TAIP TA, P183
   MIKHEEV A, 1998, P 7 MESS UND C
   Sang E. F. Tjong Kim, 2002, P CONLL 2002 TAIP TA, V20, P1, DOI DOI 10.3115/1118853.1118877
   Schapire R. E., 2002, P MSRI WORKSH NONL E
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   TSUKAMOTO K, 2002, P CONLL 2002 TAIP TA, P191
   Weischedel R., 1997, P 5 C APPL NAT LANG
   Weischedel Ralph, 1995, P 6 MESS UND C MUC 6, P55
   YU SH, 1998, P 7 MESS UND C
NR 19
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 43
EP 50
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200007
DA 2019-06-15
ER

PT B
AU Chieu, HL
   Ng, HT
   Lee, YK
AF Chieu, HL
   Ng, HT
   Lee, YK
GP ACL
TI Closing the gap: Learning-based information extraction rivaling
   knowledge-englneeiIng methods
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB In this paper, we present a learning approach to the scenario template task of information extraction, where information filling one template could come from multiple sentences. When tested on the MUG 4 task, our learning approach achieves accuracy competitive to the best of the MUC-4 systems, which were all built with manually engineered rules. Our analysis reveals that our use of full parsing and state-of-the-art learning algorithms have contributed to the good performance. To our knowledge, this is the first research to have demonstrated that a learning approach to the full-scale information extraction task could achieve performance rivaling that of the knowledge-engineering approach.
C1 DSO Natl Labs, Singapore 118230, Singapore.
EM chaileon@dso.org.sg; nght@comp.nus.edu.sg; lyoongke@dso.org.sg
CR Califf ME, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P328
   CHARNIAK E, 1993, PROCEEDINGS OF THE ELEVENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P784
   Chieu H. L., 2002, P 19 INT C COMP LING, V1, P190
   CHIEU HL, 2002, P 18 NAT C ART INT A, P786
   Ciravegna F, 2001, P 17 INT JOINT C ART, P1251
   Collins Michael, 1999, THESIS U PENNSYLVANI
   Duda RO, 1973, PATTERN CLASSIFICATI
   FISHER D., 1995, P 6 MESS UND C MUC 6, P127
   Gildea D., 2000, P 38 ANN C ASS COMP, P512
   MILLER S, 1998, P MUC 7
   QUINLAND JR, 1993, C4 5 PROGR MACH LEAR
   RANTAPARKHI A, 1998, THESIS U PENNSYLVANI
   Rau L., 1992, P MUC 4, P94
   Roth D., 2001, P 17 INT JOINT C ART, P1257
   Soderland S, 1999, MACH LEARN, V34, P233, DOI 10.1023/A:1007562322031
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Vapnik VN, 1995, NATURE STAT LEARNING
NR 17
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 216
EP 223
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500028
DA 2019-06-15
ER

PT B
AU Clement, L
   Kinyon, A
AF Clement, L
   Kinyon, A
GP ACL
TI Generating parallel multilingual LFG-TAG grammars from a MetaGrammar
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We introduce a MetaGrammar, which allows us to automatically generate, from a single and compact MetaGrammar hierarchy, parallel Lexical Functional Grammars (LFG) and Tree-Adjoining Grammars (TAG) for French and for English: the grammar writer specifies in compact manner syntactic properties that are potentially framework-, and to some extent language-independent (such as subcategorization, valency alternations and realization of syntactic functions), from which grammars for several frameworks and languages are automatically generated offline(1).
CR ABEILLE A, 1999, P VEXT 99 VEN
   BENDER E, 2002, P GEE COLING TAIP
   BOULLIER P, 1998, PROPOSAL NATURAL LAN
   Bresnan Joan, 1982, MENTAL REPRESENTATIO, pxvii
   BUTT M, 2002, P GEE COLING TAIPEI
   BUTT M, 1999, P LFG 99
   Candito Marie, 1999, THESIS U PARIS 7
   CANDITO MH, 1996, P COLING 96 COP
   CLEMENT L, 2001, P LFG 01 HONG KONG
   CLEMENT L, 2003, P LFG 03 SAR SPRINGS
   DALRYMPLE M, 1995, P CNLP ED
   EVANS R, 2000, TREEE ADJOINING GRAM
   FLICKINGER D, 1987, THESIS STANFORD
   FRANK A, 2000, P FLG 00 BERK
   GAIFFE B, 2002, P TAG 6 VEN
   HEPPLE M, 2000, P 1 M SPEECH TECHN T
   JOSHI AK, 1987, MATH LANGUAGE
   JOSHI AK, 1989, P ACL 89 VANC
   KAMEYAMA M, 1986, UNPUB CHARACTERISING
   KAPLAN R, 1996, LFG GRAMMAR WRRITERS
   KAPLAN R, 1989, ALTERNATIVES CONCEPT
   KINYON A, 2003, P ESSLLJ WORKSH MULT
   KINYON A, 2003, P LNCEACL BUD
   KINYON A, 2003, THESIS U PENNSYLVANI
   KINYON A, 2002, P GEEECOLING TAIP
   KINYON A, 2000, P COLING00 STARR
   ROGERS J, 1994, COMPUT INTELL, V10, P4
   SRINIVAS B, 1997, THESIS U PENNSYLVANI
   Xia F., 2001, THESIS U PENNSYLVANI
NR 29
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 184
EP 191
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500024
DA 2019-06-15
ER

PT B
AU Cmejrek, M
   Curin, J
   Havelka, J
AF Cmejrek, M
   Curin, J
   Havelka, J
GP ACL
TI Czech-English dependency-based machine translation
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We present some preliminary results of a Czech-English translation system based on dependency trees. The fully automated process includes: morphological tagging, analytical and tectogrammatical parsing of Czech, tectogrammatical transfer based on lexical substitution using word-to-word translation dictionaries enhanced by the information from the English-Czech parallel corpus of WSJ, and a simple rule-based system for generation from English tectogrammatical representation. In the evaluation part, we compare results of the fully automated and the manually annotated processes of building the tectogrammatical representation.(1)
C1 Charles Univ, Inst Formal & Appl Linguist, Prague, Czech Republic.
RI Havelka, Jiri/D-2212-2013
CR ALONAIZAN Y, 1999, STAT MACHINE TRANSLA
   BOHMOVA A, 2001, PRAGUE B MATH LINGUI, V76
   Bohmova A., 2001, TREEBANKS BUILDING U
   Charniak E, 1999, CS9912
   GERMANN U, 2001, P 39 ANN M ASS COMP, P228
   HAJIC J, 1998, 37 J HOPK U CTR LANG
   HAJIC J, 2001, MANUAL ANAL LAYER TA
   Hajic J., 1998, P COLING ACL C MONTR, V1, P483, DOI DOI 10.3115/980845.980927
   HAJIC J, 2002, NATURAL LANGUAGE GEN
   HAJICOVA E, 2000, TR200009 UFAL MFF UK
   Minnen G., 2001, Natural Language Engineering, P207
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   Roukos Salim, 2001, RC22176 IBM
   ZABOKRTSKY Z, 2002, P LREC 2002 3 INT C, V5, P1513
NR 15
TC 1
Z9 1
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 83
EP 90
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200012
DA 2019-06-15
ER

PT B
AU Erk, K
   Kowalski, A
   Pado, S
   Pinkal, M
AF Erk, K
   Kowalski, A
   Pado, S
   Pinkal, M
GP ACL
TI Towards a resource for lexical semantics: A large German corpus with
   extensive semantic annotation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We describe the ongoing construction of a large, semantically annotated corpus resource as reliable basis for the large-scale acquisition of word-semantic information, e.g. the construction of domain-independent lexica. The backbone of the annotation are semantic roles in the frame semantics paradigm. We report experiences and evaluate the annotated data from the first project stage. On this basis, we discuss the problems of vagueness and ambiguity in semantic annotation.
C1 Univ Saarland, Dept Computat Linguist, D-6600 Saarbrucken, Germany.
RI Pado, Sebastian/F-4883-2016
OI Pado, Sebastian/0000-0002-7529-6825
CR Brants Sabine, 2002, P WORKSH TREEB LING
   CHARLES JF, 1968, UNIVERSALS LINGUIST, P1
   Erk K., 2003, P 5 INT WORKSH COMP, P106
   Hajicova Eva, 1998, P TSD 98, P45
   Johnson C. R., 2002, FRAMENET THEORY PRAC
   KILGARRIFF A, 2001, SENSEVAL 2
   KILGARRIFF A, 2000, COMPUTERS MANITIES, V34
   Krippendorff K., 1980, CONTENT ANAL
   Lowe John B., 1998, P COLING ACL
   MARCUS M, P ARPA HLT WORKSH
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   Pinkal Manfred, 1996, P SALT 96, P185
   WOJCIECH S, 1998, P LREC 98
   ZABOKRTSKY Z, 2000, P TSD 00
NR 14
TC 1
Z9 1
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 537
EP 544
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500068
DA 2019-06-15
ER

PT B
AU Erk, K
   Niehren, J
AF Erk, K
   Niehren, J
GP ACL
TI Well-nested parallelism constraints for ellipsis resolution
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB The Constraint Language for Lambda Structures (CLLS) is an expressive tree description language. It provides a uniform framework for underspecified semantics, covering scope, ellipsis, and anaphora. Efficient algorithms exist for the sublanguage that models scope. But so far no terminating algorithm exists for sublanguages that model ellipsis. We introduce well-nested parallelism constraints and show that they solve this problem.
C1 Univ Saarland, D-6600 Saarbrucken, Germany.
CR ALTHAUS E, 2002, IN PRESS J ALGORITHM
   BOS J, 1996, P 10 AMST COLL
   COMON H, 1992, P ICALP 92
   DALRYMPLE M, 1991, LINGUIST PHILOS, V14, P399, DOI 10.1007/BF00630923
   Egg M., 2001, Journal of Logic, Language and Information, V10, P457, DOI 10.1023/A:1017964622902
   ERK K, 2002, IN PRESS J LANGUAGE
   ERK K, 2001, P 13 AMST COLL
   Fiengo Robert, 1994, INDICES IDENTITY
   Hardt Daniel, 1993, THESIS U PENNSYLVANI
   Kehler A., 1995, THESIS HARVARD U
   KOLLER A, 2001, P LACL 01
   LAPPIN S, 1996, P COLING 96
   Makanin G.S., 1977, MAT SBORNIK, V103, P147
   MARCUS MP, 1983, P ACL 83
   PINKAL M, 1995, P 10 AMST COLL U AMS
   REYLE U, 1993, J SEMANTICS, V10
   Sag Ivan, 1976, THESIS MIT CAMBRIDGE
   WILLI AV, 1977, COMPREHENSIVE CHEM K, V8, P1
NR 18
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 115
EP 122
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200016
DA 2019-06-15
ER

PT B
AU Gao, JF
   Li, M
   Huang, CN
AF Gao, JF
   Li, M
   Huang, CN
GP ACL
TI Improved source-channel models for Chinese word segmentation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
ID ALGORITHM
AB This paper presents a Chinese word segmentation system that uses improved source-channel models of Chinese sentence generation. Chinese words are defined as one of the following four types: lexicon words, morphologically derived words, factoids, and named entities. Our system provides a unified approach to the four fundamental features of word-level Chinese language processing: (1) word segmentation, (2) morphological analysis, (3) factoid detection, and (4) named entity recognition. The performance of the system is evaluated on a manually annotated test set, and is also compared with several state-of-the-art systems, taking into account the fact that the definition of Chinese words often varies from system to system.
C1 Microsoft Res, Beijing 100080, Peoples R China.
CR Cheng KS, 1999, J AM SOC INFORM SCI, V50, P218, DOI 10.1002/(SICI)1097-4571(1999)50:3<218::AID-ASI4>3.0.CO;2-1
   CHIEN LF, 1997, SIGIR97, P27
   DAI, 1999, SIGIR99, P82
   Gao J., 2002, ACM T ASIAN LANGUAGE, V1, P3
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   LIN MY, 1993, ROCLING, V6, P119
   Packard JL, 2000, MORPHOLOGY CHINESE L
   Sproat R, 1996, COMPUT LINGUIST, V22, P377
   SPROAT R, 2002, COOLING 2002
   SUN J, 2002, COLING 2002
   Teahan WJ, 2000, COMPUT LINGUIST, V26, P375, DOI 10.1162/089120100561746
   WU ZM, 1993, J AM SOC INFORM SCI, V44, P532, DOI 10.1002/(SICI)1097-4571(199310)44:9<532::AID-ASI3>3.0.CO;2-M
NR 12
TC 1
Z9 1
U1 0
U2 2
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 272
EP 279
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500035
DA 2019-06-15
ER

PT B
AU Gao, JF
   Suzuki, H
AF Gao, JF
   Suzuki, H
GP ACL
TI Unsupervised learning of dependency structure for language modeling
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper presents a dependency language model (DLM) that captures linguistic constraints via a dependency structure, i.e., a set of probabilistic dependencies that express the relations between headwords of each phrase in a sentence by an acyclic, planar, undirected graph. Our contributions are three-fold. First, we incorporate the dependency structure into an n-gram language model to capture long distance word dependency. Second, we present an unsupervised learning method that discovers the dependency structure of a sentence using a bootstrapping procedure. Finally, we evaluate the proposed models on a realistic application (Japanese Kana-Kanji conversion). Experiments show that the best DLM achieves an 11.3% error rate reduction over the word trigram model.
C1 Microsoft Res Asia, Beijing 100080, Peoples R China.
CR CHARNIAK E, 2001, ACL EACL 2001, P124
   Chelba C, 2000, COMPUT SPEECH LANG, V14, P283, DOI 10.1006/csla.2000.0147
   Chelba C., 1997, P 5 EUR C SPEECH COM, V5, P2775
   COLLINS MJ, 1996, ACL, V34, P184
   EISNER J, 1999, ACL, V37, P457
   GAO J, 2002, ACM T ASIAN LANGUAGE
   GAO J, 2002, EMNLP, P248
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   ROARK B, 2001, COMPUTATIONAL LINGUI, P1
   ROSENFELD R, 1994, THESIS CARNEGIE MELL
   YURET D, 1998, THESIS MIT
NR 12
TC 1
Z9 2
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 521
EP 528
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500066
DA 2019-06-15
ER

PT B
AU Hockenmaier, J
AF Hockenmaier, J
GP ACL
TI Parsing with generative models of predicate-argument structure
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB The model used by the CCG parser of Hockenmaier and Steedman (2002b) would fail to capture the correct bilexical dependencies in a language with freer word order, such as Dutch. This paper argues that probabilistic parsers should therefore model the dependencies in the predicate-argument structure, as in the model of Clark et al. (2002), and defines a generative model for CCG derivations that captures these dependencies, including bounded and unbounded long-range dependencies.
C1 Univ Penn, IRCS, Philadelphia, PA 19104 USA.
CR CHARNIAK E, 2000, P 1 M NAACL SEATTL
   CLARK S, 2002, P 40 ANN M ACL
   COLLINS M, 1999, P 37 ANN M ACL
   Collins Michael, 1999, THESIS U PENNSYLVANI
   HOCKENMAIER J, 2002, P 40 ANN M ACL
   Hockenmaier Julia, 2002, P 3 INT C LANG RES E, P1974
   Hockenmaier Julia, 2003, THESIS U EDINBURGH
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   STEEDMAN M, 2000, SYNTHACTIC PROCESS
NR 9
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 359
EP 366
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500046
DA 2019-06-15
ER

PT B
AU Korhonen, A
   Preiss, J
AF Korhonen, A
   Preiss, J
GP ACL
TI Improving subcategorization acquisition using word sense disambiguation
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB We investigate the change in performance of automatic subcategorization acquisition when a word sense disambiguation (WSD) system is employed to guide the acquisition process. As a subgoal, this involves creating a probabilistic WSD system, which we evaluate on the SENSEVAL-2 English all-words task data. We carry out an evaluation of the enriched subcategorization acquisition system using 29 'difficult' English verbs which shows that WSD helps to improve the acquisition performance.
C1 Univ Cambridge, Comp Lab, Cambridge CB3 0FD, England.
EM Anna.Korhonen@cl.cam.ac.uk; Judita.Preiss@cl.cam.ac.uk
CR BOGURAEV BK, 1987, COMPUTATIONAL LINGUI, V13, P219
   Briscoe E. J., 1997, P 5 ACL C APPL NAT L, P356
   Carroll J., 1998, P 1 INT C LANG RES E, P447
   Carroll J. A., 2002, P 3 INT C LANG RES E, P1499
   Chen S. F., 1996, P 34 ANN M ASS COMP, P310, DOI DOI 10.3115/981863.981904
   ELWORTHY D, 1994, P 4 C APPL NAT LANG, P53
   GRISHMAN R, 1994, INT C COMPUTATIONAL, P268
   Korhonen A, 2002, THESIS U CAMBRIDGE
   KORHONEN A, 2002, P 6 C NAT LANG LEARN, P91
   Leech G., 1992, LANGUAGE RES, V28, P1
   Levin B., 1993, ENGLISH VERB CLASSES
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Mihalcea R, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P461
   MIHALCEA R, 2002, J NATURAL LANGUAGE E, P343
   Miller G., 1990, INT J LEXICOGR, V3, P235, DOI DOI 10.1093/IJL/3.4.235
   PALMER M, 2002, PREISS YAROSKY, P21
   PEDESEN T, 2002, PREISS YAROWSKI, P139
   PREISS J, 2002, P SENSEVAL 2 2 INT W
   PREISS J, 2002, P WORD SENS DIS WORK, P102
   PREISS J, 2002, P LREC, P1551
   ROLAND D, 2001, IN PRESS LEXICAL BAS
   ROLAND D, 2000, ACL WORKSH COMP CORP, P28
   SARKAR A, 2000, 19 INT C COMP LING, P691
   Stevenson M, 2001, COMPUT LINGUIST, V27, P321, DOI 10.1162/089120101317066104
   Yarowsky D, 2000, COMPUT HUMANITIES, V34, P179, DOI 10.1023/A:1002674829964
NR 25
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 48
EP 55
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500007
DA 2019-06-15
ER

PT B
AU Kornai, A
   Krellenstein, M
   Mulligan, M
   Twomey, D
   Veress, F
   Wysoker, A
AF Kornai, A
   Krellenstein, M
   Mulligan, M
   Twomey, D
   Veress, F
   Wysoker, A
GP ACL
TI Classifying the Hungarian Web
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB In this paper we present some lessons learned from building vizsla, the keyword search and topic classification system used on the largest Hungarian portal, [ origo. hu ]. Based on a simple statistical language model, and the large-scale supporting evidence from vizsla, we argue that in topic classification only positive evidence matters.
C1 Metacarta Inc, Cambridge, MA 02139 USA.
EM andras@kornai.com; m.krellenstein@elsevier.com; mulligan@alum.mit.edu;
   dtwomey@theworld.com; veress@cs.bu.edu; alecw@pobox.com
RI Kornai, Andras/S-3099-2019; Kornai, Andras/H-6815-2012
OI Kornai, Andras/0000-0001-6078-6840; Kornai, Andras/0000-0001-6078-6840
CR COLBATH S, 1998, PERC US INT C SAN FR, P220
   Duda R, 2001, PATTERN CLASSIFICATI
   Hiemstra D., 1998, P 7 TEXT RETR C TREC, P174
   HIGHLEYMAN WH, 1962, P IRE, V50, P1501, DOI 10.1109/JRPROC.1962.288194
   Kornai A, 2002, ADV SOFT COMP, P527
   KRELLENSTEIN M, 2002, P SIGIR 02
   McCallum A. K., 1996, BOW TOOLKIT STAT LAN
   Miller DRH, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P214, DOI 10.1145/312624.312680
   Ponte J. M., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P275, DOI 10.1145/290941.291008
   Robertson SE, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P16, DOI 10.1145/258525.258529
   ZHAI C, 2001, RES DEV INFORM RETRI, P334
NR 11
TC 1
Z9 1
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 203
EP 210
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200027
DA 2019-06-15
ER

PT B
AU Kruijff, GJ
   Duchier, D
AF Kruijff, GJ
   Duchier, D
GP ACL
TI Information structure in topological dependency grammar
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Topological Dependency Grammar (TDG) is a lexicalized dependency grammar formalism, able to model languages with a relatively free word order. In such languages, word order variation often has an important function: the realization of information structure. The paper discusses how to integrate information structure into TDG, and presents a constraint-based approac to modelling information structure and the various means to realize it, focusing on (possibly simultaneous use of) word order and tune.
C1 Univ Saarland, D-6600 Saarbrucken, Germany.
CR BALDRIDGE J, 2002, P 40 ANN M ASS COMP, P319
   COPESTAKE A, 1999, UNPUB MINIMAL RECURS
   DUCHIER D, 2001, MOL 8 P
   DUCHIER D, 2001, P ACL 01 TOUL FRANC
   HAJICOVA E, 1995, COMPUT LINGUIST, V21, P81
   Hajicova E., 1998, TOPIC FOCUS ARTICULA
   HOFFMAN B, 1995, P EACL 95 DUBL MARCH
   KRUIJFF GM, 2001, THESIS CHARLES U PRA
   KRUIJFFKORBAYOV.I, 2002, INFORMATION SHARING, P193
   KRUIJFFKORBAYOV.I, 2003, P EACL 03 BUD HUNG
   KURZ D, 2000, 13 ANN C HUM SENT PR
   PREVOST S, 1994, SPEECH COMMUN, V15, P139, DOI 10.1016/0167-6393(94)90048-5
   Sgall P, 1986, MEANING SENTENCE ITS
   Steedman M, 2000, LINGUIST INQ, V31, P649, DOI 10.1162/002438900554505
   Vallduvi E, 1996, LINGUISTICS, V34, P459, DOI 10.1515/ling.1996.34.3.459
   Vallduvi Enric, 1990, THESIS U PENNSYLVANI
NR 16
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 219
EP 226
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200029
DA 2019-06-15
ER

PT B
AU Merlo, P
AF Merlo, P
GP ACL
TI Generalised PP-Attachment disambiguation using corpus-based linguistic
   diagnostics
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We propose a new formulation of the PP attachment problem as a 4-way classification which takes into account the argument or adjunct status of the PP. Based on linguistic diagnostics, we train a 4-way classifier that reaches an average accuracy of 73.9% (baseline 66.2%). Compared to a sequence of binary classifiers, the 4-way classifier reaches better performance and individuates a verb's arguments more accurately, thus improving the acquisition of a crucial piece of information for many NLP applications.
C1 Univ Geneva, Dept Linguist, CH-1211 Geneva 4, Switzerland.
CR Aldezabal I, 2002, P SIGLEX WORKSH UNS, P42
   Bangalore S, 1999, COMPUT LINGUIST, V25, P237
   BIES A, 1995, BRACKETING GUIDELINE
   BUCHHOLZ S, 1999, DISTINGUISHING COMPL
   Collins M., 1995, P 3 WORKSH VER LARG, P27, DOI DOI 10.1177/0075424211421346
   DORR B, 1997, MACHINE TRANSLATION, V12, P1
   ESTEVEFERRER E, 2002, AUTOMATIC DISTINCTIO
   Grimshaw Jane, 1990, ARGUMENT STRUCTURE
   Hindle D., 1993, Computational Linguistics, V19, P103
   JACKENDOFF R, 1977, X1 SYNTAX STUDY PHRA
   KATZ SM, 1987, IEEE T ACOUST SPEECH, V35, P400, DOI 10.1109/TASSP.1987.1165125
   Korhonen Anna, 2002, P WORKSH ACL SPEC IN, P51, DOI DOI 10.3115/1118627.1118634
   Levin B., 1993, ENGLISH VERB CLASSES
   Marantz A., 1984, NATURE GRAMMATICAL R
   MARCUS M, 1994, PENN TREEBANK ANNOTA
   MERLO P, 1997, P 2 C EMP METH NAT L, P145
   MERLO P, 2001, P 5 COMP NAT LANG LE, P121
   Miller G. A, 1990, 5 PAPERS WORDNET
   Pollard C., 1987, CSLI LECT NOTES, DOI Center for the Study of Language and Information
   QUINLAN JR, 1992, SERIES MACHINE LEARN
   Quirk R., 1985, COMPREHENSIVE GRAMMA
   Reynar J., 1994, P ARPA HUM LANG TECH, P250
   Schutze C. T., 1995, MIT WORKING PAPERS L, V26, P95
   VILLAVICENCIO A, 2002, P 6 C NAT LANG LEARN, P84
NR 24
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 251
EP 258
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200033
DA 2019-06-15
ER

PT B
AU Preiss, J
AF Preiss, J
GP ACL
TI Using grammatical relations to compare parsers
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB We use the grammatical relations (GRs) described in Carroll et al. (1998) to compare a number of parsing algorithms. A first ranking of the parsers is provided by comparing the extracted GRs to a gold standard GR annotation of 500 Susanne sentences: this required an implementation of GR extraction software for Penn Treebank style parsers. In addition, we perform an experiment using the extracted GRs as input to the Lappin and Leass (1994) anaphora resolution algorithm. This produces a second ranking of the paxsers, and we investigate the number of errors that axe caused by the incorrect GRs.
C1 Univ Cambridge, Comp Lab, Cambridge CB2 1TN, England.
EM Judita.Preiss@cl.cam.ac.uk
CR Blaheta D., 2000, P 1 ANN M N AM CHAPT, P234
   Briscoe T., 1993, Computational Linguistics, V19, P25
   BUCHHOLZ, 2002, THESIS U TILBURG
   BUCHHOLZ S, 1999, P JOINT SIGDAT C EMP, P239
   Carroll J., 1998, P 1 INT C LANG RES E, P447
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   CLARK S, 2002, P LREC 2002 PARS WOR
   Collins P, 1997, AEROSPACE AM, V35, P8
   Daelemans W., 1996, P 4 WORKSH VER LARG, P14
   DAELEMANS W, 1996, P 6 BELG DUTCH C MAC, P3
   ELWORTHY D, 1994, P 4 C APPL NAT LANG, P53
   Lappin S., 1994, Computational Linguistics, V20, P535
   Leech G., 1992, LANGUAGE RES, V28, P1
   LIN D, 1995, IND PARSING SOFTWARE, P13
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   PREISS J, 2003, P WORKSH AN RES
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   SAMPSON G, 1995, ENGLISH COMPUTER
   Veenstra J., 2000, P CONLL 2000 LLL 200, P157
NR 19
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 291
EP 298
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200038
DA 2019-06-15
ER

PT B
AU Sakas, WG
AF Sakas, WG
GP ACL
TI A word-order database for testing computational models of language
   acquisition
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
ID TRIGGERS
AB An investment of effort over the last two years has begun to produce a wealth of data concerning computational psycholinguistic models of syntax acquisition. The data is generated by running simulations on a recently completed database of word order patterns from over 3,000 abstract languages. This article presents the design of the database which contains sentence patterns, grammars and derivations that can be used to test acquisition models from widely divergent paradigms. The domain is generated from grammars that are linguistically motivated by current syntactic theory and the sentence patterns have been validated as psychologically/developmentally plausible by checking their frequency of occurrence in corpora of child-directed speech. A small case-study simulation is also presented.
C1 CUNY Hunter Coll, Dept Comp Sci, PhD Programs Linguist & Comp Sci, New York, NY 10021 USA.
CR BERTOLO S, 2001, LANGUAGE ACQUISITION
   BERTOLO S, 1997, COGNITIVE SCI SOC
   Bertolo Stefano, 1997, P 5 M MATH LANG
   Berwick RC, 1996, LINGUIST INQ, V27, P605
   Briscoe T, 2000, LANGUAGE, V76, P245, DOI 10.2307/417657
   Chomsky N., 1981, LECT GOVT BINDING
   Chomsky N., 1995, MINIMALIST PROGRAM
   Cinque Guglielmo, 1999, ADVERBS FUNCTIONAL H
   Fodor JD, 1998, J PSYCHOLINGUIST RES, V27, P339, DOI 10.1023/A:1023255705029
   FODOR JD, 1998, LINGUIST INQ, P1
   FODOR JD, 2002, STRUCTURALLY DEFINED
   GIBSON E, 1994, LINGUIST INQ, V25, P407
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Hyams Nina M., 1986, LANGUAGE ACQUISITION
   JAIN S, 1991, SYSTEMS LEARN
   Kayne Richard, 1994, ANTISYMMETRY SYNTAX
   KOHL KT, 1999, ANAL FINITE PARAMETE
   MacWhinney B., 1995, CHILDES PROJECT TOOL
   NIYOGI P, 1998, INFORMATIONAL COMPLE
   PINKER S, 1979, COGNITION, V7, P217, DOI 10.1016/0010-0277(79)90001-5
   SAGAE K, 2001, P 7 INT WORKSH PARS
   SAKAS W, 2000, THESIS CITY U NEW YO
   SAKAS W, 2001, LANGUAGE ACQUISITION
   SAKAS WG, UNPUB GRAMMAR LANGUA
   SAKAS WG, 2002, P 24 ANN C COGN SCI
   SISKIND JM, 2003, DOCUMENTATION QTREE
   VILLAVICENCIO A, 2000, WORKSH LING THEOR GR
   WEXLER K, 1980, FORMAL PRINCIPLES LA
NR 28
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 415
EP 422
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500053
DA 2019-06-15
ER

PT B
AU Schuler, W
AF Schuler, W
GP ACL
TI Using model-theoretic semantic interpretation to guide statistical
   parsing and word recognition in a spoken language interface
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper describes an extension of the semantic grammars used in conventional statistical spoken language interfaces to allow the probabilities of derived analyses to be conditioned on the meanings or denotations of input utterances in the context of an interface's underlying application environment or world model. Since these denotations will be used to guide disambiguation in interactive applications, they must be efficiently shared among the many possible analyses that may be assigned to an input utterance This paper therefore presents a formal restriction on the scope of variables in a semantic grammar which guarantees that the denotations of all possible analyses of an input utterance can be calculated in polynomial time, without undue constraints on the expressivity of the derived semantics. Empirical tests show that this model-theoretic interpretation yields a statistically significant improvement on standard measures of parsing accuracy over a baseline grammar not conditioned on denotations.
C1 Univ Penn, Dept Comp & Informat Sci, Philadelphia, PA 19104 USA.
CR BECKER T, 1991, FIFTH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P21
   Billot S., 1989, P 27 ANN M ASS COMP, P143
   Church A., 1940, J SYMBOLIC LOGIC, V5, P56, DOI 10. 2307/2266170
   DOWDING J, 1994, P 32 ANN M ASS COMP
   Joshi Aravind K., 1985, NATURAL LANGUAGE PAR, P206
   MILLER S, 1996, P 34 ANN M ASS COMP, P55
   Montague R., 1973, APPROACHES NATURAL L, V49, P221, DOI DOI 10.1007/978-94-010-2506-5_10
   Pollard Carl, 1984, THESIS STANFORD U
   RAMBOW O, 1995, P 33 ANN M ASS COMP
   Reyle U., 1993, Journal of Semantics, V10, P123, DOI 10.1093/jos/10.2.123
   ROGERS J, 1994, P 32 ANN M ASS COMP
   Seneff S., 1998, P 5 INT C SPOK LANG
   STUART M, 1994, COMPUT INTELL, P10
   Weir David J, 1988, THESIS U PENNSYLVANI
   *XTAG RES GROUP, 1998, LEXIC TREE ADJ GRAMM
NR 15
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 529
EP 536
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500067
DA 2019-06-15
ER

PT B
AU Sudo, K
   Sekine, S
   Grishman, R
AF Sudo, K
   Sekine, S
   Grishman, R
GP ACL
TI An emproved extraction pattern representation model for automatic IE
   pattern acquisition
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB Several approaches have been described for the automatic unsupervised acquisition of patterns for information extraction. Each approach is based on a particular model for the patterns to be acquired, such as a predicate-argument structure or a dependency chain. The effect of these alternative models has not been previously studied. In this paper, we compare the prior models and introduce a new model, the Subtree model, based on arbitrary subtrees of dependency trees. We describe a discovery procedure for this model and demonstrate experimentally an improvement in recall using Subtree patterns.
C1 NYU, Dept Comp Sci, New York, NY 10003 USA.
CR ABE K, 2002, P 6 EUR C PRINC PRAC
   KUROHASHI S, 1994, P WORKSH SHAR NAT LA
   KUROHASHI S, 1997, JAPANESE MORPHOLOGIC
   *MUC 6, 1995, P 6 MESS UND C MUC 6
   MURATA M, 1999, INFORMATION RETRIEVA
   Nobata Chikashi, 2002, P 3 INT C LANG RES E
   RILOFF E, 1999, P 16 NAT C ART INT
   Riloff E., 1993, P 11 NAT C ART INT
   Riloff Ellen, 1996, P 13 NAT C ART INT
   Sudo K., 2001, P HUM LANG TECHN C H
   YANGARBER R, 2000, P 18 INT C COMP LING
NR 11
TC 1
Z9 1
U1 0
U2 1
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 224
EP 231
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500029
DA 2019-06-15
ER

PT B
AU Suzuki, J
   Hirao, T
   Sasaki, Y
   Maeda, E
AF Suzuki, J
   Hirao, T
   Sasaki, Y
   Maeda, E
GP ACL
TI Hierarchical directed acyclic graph kernel: Methods for structured
   natural language data
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper proposes the "Hierarchical DirectedAcyclic Graph (HDAG) Kernel" for structured natural language data. The HDAG Kernel directly accepts several levels of both chunks and their relations, and then efficiently computes the weighed sum of the number of common attribute sequences of the HDAGs. We applied the proposed method to question classification and sentence alignment tasks to evaluate its performance as a similarity measure and a kernel function. The results of the experiments demonstrate that the HDAG Kernel is superior to other kernel functions and baseline methods.
C1 NTT Corp, NTT Commun Sci Labs, Seika, Kyoto 6190237, Japan.
CR COLLINS M, 2001, UCSCRL0110 UC SANT C
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   HAUSSLER D, 1999, UCSCRL9910 UC SANT C
   HIRAO T, 2003, J NATURAL LANGUAGE P, V10, P81
   IKEHARA S, 1997, SEMANTIC ATTRIBUTE S, V1
   ISOZAKI H, 2002, P COLING 2002, P390
   Kudo T., 2002, P 6 C NAT LANG LEARN, V2002, P63
   Lodhi H, 2002, J MACH LEARN RES, V2, P419, DOI 10.1162/153244302760200687
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Vapnik VN, 1995, NATURE STAT LEARNING
   VOORHEES E. M., 1999, P 8 TEXT RETR C
NR 11
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 32
EP 39
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500005
DA 2019-06-15
ER

PT B
AU Tanaka-Ishii, K
   Hayakawa, D
   Takeichi, M
AF Tanaka-Ishii, K
   Hayakawa, D
   Takeichi, M
GP ACL
TI Acquiring vocabulary for predictive text entry through dynamic reuse of
   a small user corpus
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB As mobile computing and communications have become popular, predictive text entry systems have become an increasingly important technology. Existing methods still need refinement, though, with respect to personalization, especially how to acquire vocabulary not pre-registered in the system dictionary. In this paper, we report on an automatic method that dynamically obtains a user specific vocabulary from the user's unanalyzed documents. When a user makes an entry, the system dynamically extracts the corresponding chunks from the user text and suggests them along with words suggested by the dictionary. With our method, texts in a particular style or concerning a specific domain can be entered using a predictive text entry system. We verified that a large amount of words not registered in the dictionary can be entered using our method.
C1 Univ Tokyo, Bunkyo Ku, Tokyo, Japan.
CR Bell T., 1990, TEXT COMPRESSION
   *IBM, 2001, WATCHP 1 5
   *JUSTS, 2002, AT 16
   MANBER U, 1993, SIAM J COMPUTING
   MARUYAMA T, 2001, IPSJ NL SEM NOT, V146
   MATSUI T, 1999, ACM S US INT SOFTW T
   NAKAGAWA H, 2002, COMPUTERM 2002 P 2 I, P29
   TANAKAISHII K, 2000, HUM LANG TECHN C
   TANAKAISHII K, 2002, 19 INT C COMP LING, P988
   WARD D, 2000, ACM S US INT SOFTW T
   2000, NZCSRSC 95
NR 11
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 407
EP 414
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500052
DA 2019-06-15
ER

PT B
AU Uchimoto, K
   Nobata, C
   Yamada, A
   Sekine, S
   Isahara, H
AF Uchimoto, K
   Nobata, C
   Yamada, A
   Sekine, S
   Isahara, H
GP ACL
TI Morphological analysis of a large spontaneous speech corpus in Japanese
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper describes two methods for detecting word segments and their morphological information in a Japanese spontaneous speech corpus, and describes how to tag a large spontaneous speech corpus accurately by using the two methods. The first method is used to detect any type of word segments. The second method is used when there are several definitions for word segments and their POS categories, and when one type of word segments includes another type of word segments. In this paper, we show that by using semiautomatic analysis we achieve a precision of better than 99% for detecting and tagging short words and 97% for long words; the two types of words that comprise the corpus. We also show that better accuracy is achieved by using both methods than by using only the first.
C1 Commun Res Labs, Kyoto 6190289, Japan.
CR Argamon-Engelson S, 1999, J ARTIF INTELL RES, V11, P335, DOI 10.1613/jair.612
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620
   JAYNES ET, 1979, MAXIMUM ENTROPY FORM, P15
   KASHIOKA H, 1997, P NLPRS, P541
   Maekawa  K., 2000, P LREC, P947
   Mori Shinsuke, 1996, P 16 INT C COMP LING, P1119
   NAGATA M, 1999, P 37 ANN M ASS COMP, P277
   Uchimoto K, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P91
   UCHIMOTO K, 2002, P 19 INT C COMP LING, P1298
NR 10
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 479
EP 488
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500061
DA 2019-06-15
ER

PT B
AU Utsuro, T
   Horiuchi, T
   Hino, K
   Hamamoto, T
   Nakayama, T
AF Utsuro, T
   Horiuchi, T
   Hino, K
   Hamamoto, T
   Nakayama, T
GP ACL
TI Effect of cross-language IR in bilingual lexicon acquisition from
   comparable corpora
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB Within the framework of translation knowledge acquisition from WWW news sites, this paper studies issues on the effect of cross-language retrieval of relevant texts in bilingual lexicon acquisition from comparable corpora. We experimentally show that it is quite effective to reduce the candidate bilingual term pairs against which bilingual term correspondences are estimated, in terms of both computational complexity and the performance of precise estimation of bilingual term correspondences.
C1 Kyoto Univ, Grad Sch Informat, Sakyo Ku, Kyoto 6068501, Japan.
CR COLLIER N, 1998, P COLINGACL 98 MONTR, P263
   Fung P., 1998, P 17 INT C COMP LING, V1, P414
   Fung P., 1995, P 3 WORKSH VER LARG, P173
   KAJI H, 1996, P 16 INT C COMP LING, P23
   MATSUMOTO Y, 2000, HDB NATURAL LANGUAGE, P563
   Rapp R, 1999, P 37 ANN M ASS COMP, P519, DOI DOI 10.3115/1034678.1034756
   Rapp R., 1995, P 33 ANN M ASS COMP, P320, DOI DOI 10.3115/981658.981709
   Tanaka K, 1996, P 16 INT C COMP LING, V2, P580
   TANAKA T, 2002, P 19 INT C COMP LING, P981
   UTSURO T, 2002, MACHINE TRANSLATION, V2499, P165
NR 10
TC 1
Z9 1
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 355
EP 362
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200046
DA 2019-06-15
ER

PT B
AU Wang, G
   Chua, TS
   Wang, YC
AF Wang, G
   Chua, TS
   Wang, YC
GP ACL
TI Extracting key semantic terms from Chinese speech query for Web searches
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper discusses the challenges and proposes a solution to performing information retrieval on the Web using Chinese natural language speech query. The main contribution of this research is in devising a divide-and-conquer strategy to alleviate the speech recognition errors. It uses the query model to facilitate the extraction of main core semantic string (CSS) from the Chinese natural language speech query. It then breaks the CSS into basic components corresponding to phrases, and uses a multi-tier strategy to map the basic components to known phrases in order to further eliminate the errors. The resulting system has been found to be effective.
C1 Natl Univ Singapore, Singapore 117548, Singapore.
EM wanggang_sh@hotmail.com; chuats@comp.nus.edu.sg; ycwang@mail.sjtu.edu.cn
CR BAEZAYATES R, 1999, INTRO MODERN INFORMA
   CHEN B, 2001, P 7 EUR C SPEECH COM
   Cormen T.H., 1990, INTRO ALGORITHMS
   GANG W, 2002, THESIS NATL U SINGAP
   Hobbs JR, 1997, LANG SPEECH & COMMUN, P383
   JACOBS PS, 1993, ARTIF INTELL, V63, P143, DOI 10.1016/0004-3702(93)90016-5
   Kupiec J., 1993, P 16 ANN INT ACM SIG, P181
   LEE CJ, 1996, CHINA KOREA DYNAMIC, P1
   LIQIN, 1998, P INT S CHIN SPOK LA, P136
   MENG H, 2001, INT S INT MULT VID S
   NG K, 2000, P ICASSP 00 IST TURK
   PU HT, 2000, J COMPUTERS, P75
   Singhal A, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P34, DOI 10.1145/312624.312645
   Strzalkowski T., 1999, NATURAL LANGUAGE INF
   WANG HM, 2001, P IEEE INT C AC SPEE
   WANG YC, 1992, TECHNOLOGY BASIS CHI
   YING HN, 2002, REPORT QUERY LOG INT
   ZHOU GD, 1997, THESIS NATL U SINGAP
   ZHOU GD, 1997, DETECTION UNKNOWN CH, V11, P63
NR 19
TC 1
Z9 1
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 248
EP 255
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500032
DA 2019-06-15
ER

PT S
AU Abu Bakar, NSA
AF Abu Bakar, Normi Sham Awang
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Using Language-Based Search in Mining Large Software Repositories
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Data retrieval; Software repository; Language - based search;
   Automation; Software quality
AB Language component plays an important role in data/information retrieval. Data retrieval in software engineering is often hindered by the difficulty of getting data from commercial software. The emergence of the open source repositories has contributed tremendously in the collection of software data. This paper highlights the data retrieval method for mining software from a vast open source software repository, SourceForge. For the purpose of automating the data retrieval from the repository, a parser was written using the Python programming language, and based on the pattern matching algorithm. The retrieved data were later used to estimate the quality of the open source software. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Abu Bakar, Normi Sham Awang] Int Islamic Univ Malaysia, Kuala Lumpur 53100, Malaysia.
EM nsham@iium.edu.my
CR BELADY LA, 1976, IBM SYST J, V15, P225, DOI 10.1147/sj.153.0225
   BOYER RS, 1977, COMMUN ACM, V20, P762, DOI 10.1145/359842.359859
   Briand LC, 2007, LECT NOTES COMPUT SC, V4336, P21
   Conte S. D., 1986, SOFTWARE ENG METRICS
   Gusfield D., 1997, ALGORITHMS STRINGS T
   Harrison R., 1999, EMPIR SOFTW ENG, V4, P405
   Hassan A. E., 2008, ROAD AHEAD MINING SO, P48
   Lakhani K. R., 2005, PERSPECTIVES FREE OP, V1, P3
   Lee J. Y, 2008, ANAL FUNDAMENTAL EXA, P48
   O'Neil M., 2009, CYBERCHIEFS
   von Krogh G, 2007, J STRATEGIC INF SYST, V16, P236, DOI 10.1016/j.jsis.2007.06.001
NR 11
TC 0
Z9 0
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 160
EP 168
DI 10.1016/j.sbspro.2011.10.594
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700018
OA Other Gold
DA 2019-06-15
ER

PT S
AU Alam, YS
AF Alam, Yukiko Sasaki
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI A Subcategory-based Parser Directed to Generating Representations for
   Text Understanding
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Parsing; Subcategorization; PP attachment; Coordination attachment; Text
   understanding; Grammar writing
AB This paper describes a parser in progress which is directed to generating representations for text understanding. For the purpose of reducing the proliferation of unwanted parse trees, and collecting information necessary for generating the semantic representations, the parser uses rules based on phrasal and lexical subcategories. These designs alleviate parsing problems such as PP attachment and coordination attachment, while capable of displaying the dependency of various types of phrases and clauses, thus facilitating the writing of grammar. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Alam, Yukiko Sasaki] Hosei Univ, Dept Digital Media, Koganei, Tokyo 1848584, Japan.
CR Chantree Francis, 2005, P RANLP
   Charniak E., 1997, P AAAI
   Charniak Eugine, 2005, P ACL
   Collins Michael, 1999, THESIS U PENNSYLVANI
   Hara Kazuo, 2009, P ACL IJCNLP, P967
   Johnson M., 1994, Computational Linguistics, V20, P289
   Johnson M, 1998, COMPUT LINGUIST, V24, P613
   Klein D., 2003, P ACL
   Kurohashi S., 1994, Computational Linguistics, V20, P507
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Resnik P, 1999, J ARTIF INTELL RES, V11, P95, DOI 10.1613/jair.514
NR 11
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 194
EP 201
DI 10.1016/j.sbspro.2011.10.598
PG 8
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700022
OA Other Gold
DA 2019-06-15
ER

PT S
AU Koiti, H
   Hidetsugu, N
   Takashi, I
   Makoto, I
   Taiichi, H
   Atsushi, F
AF Koiti, Hasida
   Hidetsugu, Nanba
   Takashi, Inui
   Makoto, Iwayama
   Taiichi, Hashimoto
   Atsushi, Fujii
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Circulation of Collective Intelligence through Patents: An Early
   Progress Report
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Collective Intelligence; Patent; Annotation; Ontology; Retrieval
AB Patent applicants and/or examiners could annotate patent documents in terms of correspondences between claims and their working examples. Those annotations would make it easier to understand the documents so as to improve the quality of collaboration among inventors, patent attorneys, examiners, and users of technologies. Annotations to a patent document would also be used to generate queries for retrieving similar past documents, and annotations to past documents should raise the accuracy of retrieval. Domain ontologies could be generated from such annotations and queries, then in turn used to generate new annotations and queries, and so forth. Human collective intelligence would be circulated through this spiral generation of annotations, queries, and ontologies, continuously improving the productivity of application, examination, and use of patents. The paper reports on an early stage of research to realize this vision. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Koiti, Hasida] AIST, Koto Ku, Tokyo 1350064, Japan.
   [Hidetsugu, Nanba] Hiroshima City Univ, Hiroshima 7313194, Japan.
   [Takashi, Inui] Univ Tsukuba, Tsukuba, Ibaraki 3058573, Japan.
   [Makoto, Iwayama] Hitachi CRL, Kokubunji, Tokyo 1858601, Japan.
   [Taiichi, Hashimoto; Atsushi, Fujii] Tokyo Inst Technol, Tokyo 1528550, Japan.
RP Koiti, H (reprint author), AIST, Koto Ku, Tokyo 1350064, Japan.
EM hasida.k@aist.go.jp
FU IPCC
FX This work has been supported by a donation from IPCC. The authors also
   thank the examiners at IPCC for discussions to share their experiences
   of patent examination.
CR Hasida K., 2006, Patent No. 3856388
   Hearst M.A., 1992, P 14 INT C COMP LING, P539, DOI DOI 10.3115/992133.992154
   Izuha T., 2000, Patent No. [2000-339342, 2000339342]
   Komachi M., 2008, T JAPANESE SOC ARTIF, V23
   Konishi K., 2005, Patent No. [2005-234868, 2005234868]
   Nanba H., 2010, P 8 NTCIR WORKSH M E, P293
   Nanba H., 2010, P 3 INT CIKM WORKSH, P11
   Nanba H., 2007, P 6 NTCIR WORKSH, P414
   Pasca M., 2007, P 16 WORLD WID WEB C, P101, DOI DOI 10.1145/1242572.1242587
   Sekiguchi Y., 2010, DEIM FORUM
   Tsukiyama S., 1977, SIAM Journal on Computing, V6, P505, DOI 10.1137/0206036
   Uno Y., 2008, Patent No. [2008-152454, 2008152454]
NR 12
TC 0
Z9 1
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 113
EP 121
DI 10.1016/j.sbspro.2011.10.589
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700013
OA Other Gold
DA 2019-06-15
ER

PT S
AU Koo, H
AF Koo, Hahn
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI A Weighted Finite-State Transducer Implementation of Phoneme Rewrite
   Rules for English to Korean Pronunciation Conversion
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Pronunciation conversion; loanword phonology; transliteration;
   finte-state transducers
AB Words change their phonetic as well as orthographic form when they are borrowed and used by speakers of another language. A formal model that properly captures this change has theoretical implications in phonology and practical applications in speech processing and machine transliteration. This paper describes a method for developing a finite-state model that predicts how English words and named entities are pronounced in Korean. The model predicts nativized pronunciation using weighted finite-state transducers implementing context-dependent phoneme rewrite rules derived from English-to-Korean pronunciation pairs and syllable phonotactics in Korean. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Koo, Hahn] San Jose State Univ, San Jose, CA 95192 USA.
EM hahn.koo@sjsu.edu
CR Caseiro D. A, 2002, P 2002 IEEE WORKSH S
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Frisch SA, 2004, NAT LANG LINGUIST TH, V22, P179, DOI 10.1023/B:NALA.0000005557.78535.3c
   Hetherington L, 2004, P INTERSPEECH, P2609
   Jung S. Y., 2000, P 18 C COMP LING, V1, P383
   Kaplan R. M., 1994, Computational Linguistics, V20, P331
   Knight K, 1998, COMPUT LINGUIST, V24, P599
   Mohri M, 2000, THEOR COMPUT SCI, V231, P17, DOI 10.1016/S0304-3975(99)00014-6
   Mohri M, 1996, P 34 ANN M ASS COMP, P231
   Mohri M., 2001, ROBUSTNESS LANGUAGE, P165
   NIKL, 2008, SURV STAT LOANW US E
   Silverman Daniel, 1992, PHONOLOGY, V9, P289, DOI DOI 10.1017/S0952675700001627
   Tao Tao, 2006, P 2006 C EMP METH NA, P250
NR 13
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 202
EP 208
DI 10.1016/j.sbspro.2011.10.599
PG 7
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700023
OA Green Published, Other Gold
DA 2019-06-15
ER

PT S
AU Kotani, K
   Yoshimi, T
AF Kotani, Katsunori
   Yoshimi, Takehiko
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI A Scoring Method for Second Language Writing Based on Word Alignment
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE automatic scoring; second language writing evaluation; word alignment
   technique
ID MACHINE TRANSLATION
AB Automatic evaluation reduces the burden on second language (L2) teachers when checking for errors made by L2 learners. One evaluation approach is to automatically classify L2 learner sentences into either natural or unnatural sentences. However, because the distinction between natural and unnatural sentences is complex, such a binary classification cannot accurately reflect the naturalness of L2 learner sentences. To solve this problem, we developed a method that assigns scores (continuous values) to L2 learner sentences by examining the degree to which L2 learners use erroneous expressions arising from unnatural literal translations of phrases from a L2 learner's first language. Experimental results suggest that our scoring method is effective for the automatic evaluation of L2 learner sentences. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Kotani, Katsunori] Kansai Gaidai Univ, Hirakata, Osaka 5731001, Japan.
   [Yoshimi, Takehiko] Ryukoku Univ, Otsu, Shiga 5202194, Japan.
RP Kotani, K (reprint author), Kansai Gaidai Univ, Hirakata, Osaka 5731001, Japan.
EM kkotani@kansaigaidai.ac.jp
CR Baroni M., 2006, Literary & Linguistic Computing, V21, P259, DOI 10.1093/llc/fqi039
   CORSTONOLIVER S, 2001, P 39 ANN M ASS COMP, P148
   Kotani K., 2008, P INT C AS LANG PROC, P210
   Kotani K, 2010, LECT NOTES ARTIF INT, V6040, P351, DOI 10.1007/978-3-642-12842-4_42
   Kotani K, 2009, LECT NOTES ARTIF INT, V5459, P91, DOI 10.1007/978-3-642-00831-3_9
   Kudo T., 2002, P 6 C NAT LANG LEARN, V2002, P63
   Kudo T., TINYSVM
   KULESZA A, 2004, P 10 INT C THEOR MET, P75
   Lee J., 2007, P 2007 HUM LANG TECH, P93
   Lee KJ, 2011, COMPUT SPEECH LANG, V25, P246, DOI 10.1016/j.csl.2010.05.001
   The National Institute for Japanese Language, 2001, CONTR LING DAT JAP L
   Tomokiyo L. M, 2001, P 2 M N AM CHAPT ASS, P1
   Tsubaki H., 2008, P INT SPEECH COMM AS, P217
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Whitelock P., 2006, P INT WORKSH SPOK LA, P111
NR 15
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 42
EP 49
DI 10.1016/j.sbspro.2011.10.581
PG 8
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700005
OA Other Gold
DA 2019-06-15
ER

PT S
AU Lee, JG
   Kim, YM
   Park, J
   Cha, JW
AF Lee, Jong Gun
   Kim, Young-Min
   Park, Jungyeul
   Cha, Jeong-Won
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Recommending the Meanings of Newly Coined Words
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Newly Coined Word; Topic Model; Probabilistic Latent Semantic Analysis
AB In this paper, we investigate how to recommend the meanings of newly coined words, such as newly coined named entities and Internet jargon. Our approach automatically chooses a document explaining a given newly coined word among candidate documents from multiple web references using Probabilistic Latent Semantic Analysis [1]. Briefly, it involves finding the topic of a document containing the newly coined word and computing the conditional probability of the topic given each candidate document. We validate our methodology with two real datasets from MySpace forums and Twitter by referencing three web services, Google, Urbandictionary, and Wikipedia, and we show that we properly recommend the meanings of a set of given newly coined words with 69.5% and 80.5% accuracies based on our three recommendations, respectively. Moreover, we compare our approach against three baselines where one references the result from each web service and our approach outperforms them. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
EM jonggun.lee@orange-ftgroup.com; young-min.kim@univ-avignon.fr;
   park@elda.org; jcha@changwon.ac.kr
CR Agichtein E., 2006, SIGIR 06, P3
   Armbrust M., 2009, CLOUDS BERKELEY VIEW
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Hofmann T., 1999, P 15 C UNC ART INT, P289
   Joachims T, 2007, COMPUTER, V40, P34, DOI 10.1109/MC.2007.289
   WANG X, 2007, DAT MIN 2007 ICDM 20, P697, DOI DOI 10.1109/ICDM.2007.86
NR 6
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 267
EP 273
DI 10.1016/j.sbspro.2011.10.607
PG 7
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700031
OA Other Gold
DA 2019-06-15
ER

PT S
AU Lim, LT
   Ranaivo-Malancon, B
   Tang, EK
AF Lim, Lian Tze
   Ranaivo-Malancon, Bali
   Tang, Enya Kong
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Symbiosis between a Multilingual Lexicon and Translation Example Banks
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE multilingual processing; lexical resources; machine translation
AB We propose a symbiotic framework in which correspondences between electronic multilingual lexicons and translation example banks can be captured, so that their functions and contents may benefit and improve upon one another. Several mechanisms are used for this purpose: i.) two flexible annotation schemas, S-SSTC and SSTC+L, for supporting irregular multi-level correspondences across languages; ii.) an axis-based translation cluster structure for connecting translation equivalents; and iii.) translation profiles, for capturing contexts of translation equivalent instances in the corpora. There are two main contributions: i.) the design of SSTC+L, which allows the annotation of multi-word expressions and translation lexical gaps in the translation examples; and ii.) the overall framework facilitating the symbiotic flow of information between the multilingual lexicon and translation bank. We give illustrative examples to show how these mechanisms can be used for translation selection, addition of new language items, and verification of lexicon contents. Preliminary tests show there is potential in our approach. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Lim, Lian Tze; Ranaivo-Malancon, Bali; Tang, Enya Kong] Multimedia Univ, Fac Informat Technol, Cyberjaya 63100, Selangor, Malaysia.
EM liantze@gmail.com
OI Lim, Lian Tze/0000-0003-0796-8762
CR Al-Adhaileh M. H., 2002, P COLING 2002 WORKSH
   Boas HC, 2005, INT J LEXICOGR, V18, P445, DOI 10.1093/ijl/eci043
   Boitet C., 2002, P 2 WORKSH NLP XML N, P1
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dorr B. J., 1996, Machine Translation, V11, P37, DOI 10.1007/BF00349353
   DUMAIS ST, 1997, AAAI 97 SPRING S CRO, P18
   Edmonds P, 2002, COMPUT LINGUIST, V28, P105, DOI 10.1162/089120102760173625
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   ISO, 2008, 24613 ISO
   Janssen M., 2004, INT J LEXICOGR, V17, P136
   Lim L. T., 2009, P 11 INT C INF INT W, P732
   Lim L. T., 2011, POLIBITS, V43, P45
   Nguyen H.-T., 2007, P 7 INT S NAT LANG P
   Salton G., COMMUNICATIONS ACM, V18
   Sammer M., 2007, P MACH TRANSL SUMM 1, P399
   Uchida H, 2005, UNIVERSAL NETWORKING
   Zajac R., 1996, P AMTA 96 WORKSH INT
NR 17
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 61
EP 69
DI 10.1016/j.sbspro.2011.10.583
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700007
OA Other Gold
DA 2019-06-15
ER

PT S
AU Mohamad, NAA
   Hassan, TFNT
   Muda, TNT
   Aziz, NA
   Ishraf, AH
AF Mohamad, Nur Asmaa' Adila
   Hassan, Tg Fatin Najihah Tg
   Muda, Tg Norhuda Tg
   Aziz, Normaziah A.
   Ishraf, Ahmad Hasanul
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Multilingual Online Resources for Minority Languages of a Campus
   Community
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE multilingual language resources; online multilingual dictionary;
   dictionary management systems; minority languages; endangered languages
AB This paper discusses on an initiative of developing a repository on multilingual language resources for minority languages of a campus community. The choice of language is based on a survey amongst IIUM international students about the status of their mother language's resources and usages in the digital world. As a starting point, multilingual dictionaries of textual and speech for these identified languages are developed. This initiative is an effort to ensure that such minority languages will be protected from being endangered in this era of globalization. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Mohamad, Nur Asmaa' Adila; Hassan, Tg Fatin Najihah Tg; Muda, Tg Norhuda Tg; Aziz, Normaziah A.; Ishraf, Ahmad Hasanul] Int Islamic Univ Malaysia, Kulliyyah ICT, Dept Comp Sci, Kuala Lumpur 50728, Malaysia.
EM naa@iium.edu.my
CR [Anonymous], TRANSLATION SOFTWARE
   [Anonymous], 2010, OPEN TRANSLATION ENG
   [Anonymous], XAMPP WINDOWS
   Chapple Mike, DATABASE NORMALIZATI
   Christensen G., 2007, LANGUAGE POLICIES PR, P3
   Crystal D, 2000, LANGUAGE DEATH
   David, 2002, LANGUAGE ENDANGERMEN
   Forcada Mikel L., 2006, OPEN SOURCE MACHINE
   R Ton, 2000, PHP SIMPLE MYSQL SEA
NR 9
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 291
EP 298
DI 10.1016/j.sbspro.2011.10.610
PG 8
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700034
OA Other Gold
DA 2019-06-15
ER

PT S
AU Mohamed, H
   Omar, N
   Ab Aziz, MJ
   Ab Rahman, S
AF Mohamed, Hassan
   Omar, Nazlia
   Ab Aziz, Mohd Juzaidin
   Ab Rahman, Suhaimi
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Statistical Malay Dependency Parser for Knowledge Acquisition Based on
   Word Dependency Relation
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Parser; Dependency Parser; Malay Parser; Syntactic Relation; Dependency
   Grammar; Malay corpus
AB One of the common problems faced when processing information gathered from any natural language is the 'semantic gap' where the 'meaning' of the sentences is not exactly extracted. In Malay Natural Language Processing (NLP), as our knowledge, there is no existing Malay Parser that can be used to develop a knowledge acquisition feature to extract 'meaning' from Malay articles based-on syntactic relations. This relation is basically the relation between a word and its dependents. This paper will examine the Dependency Grammar (DG) for developing Malay Grammar Parser and discuss the possibilities of developing probabilistic dependency Malay parser using the projected syntactic relation from annotated English corpus. The English side of a parallel corpus, project the analysis to the second language (Malay). Thus, the rules for adaptation from English DG to Malay DG will be defined. The projected tree structure in Malay will be used in training a stochastic analyzer. The training will produce a set of tree lattices which contains chunks of dependency trees for Malay attached with their probability value. A decoder will be developed to test the lattices. A DG for a new Malay sentence is built by combining the pre-determined lattices according to their plausible highest probability of combination. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Mohamed, Hassan; Omar, Nazlia; Ab Aziz, Mohd Juzaidin] Univ Kebangsaan Malaysia, Sch Comp Sci, Bangi 43600, Selangor, Malaysia.
   [Ab Rahman, Suhaimi] Univ Tenaga Nas, Coll Informat Technol, Kajang 43000, Selangor, Malaysia.
RP Mohamed, H (reprint author), Univ Kebangsaan Malaysia, Sch Comp Sci, Bangi 43600, Selangor, Malaysia.
RI Omar, Nazlia/L-9901-2019
OI Mohamed, Hassan/0000-0002-1131-5548
CR Al-Adhaileh M. H., 2002, P 2002 COLING WORKSH, V16
   Gomez F., 2007, J KNOWLEDGE BASED SY, V20
   Goyal S., 2006, P COLING ACL 2006 MA, P301
   Ho C, 2010, LECT NOTES ARTIF INT, V6421, P413, DOI 10.1007/978-3-642-16693-8_43
   Hwa R., 2005, Natural Language Engineering, P311, DOI 10.1017/S1351324905003840
   Jurafsky D., 2009, SPEECH LANGUAGE PROC
   Mosleh H., 1999, MACHINE TRANSLATION, VVII, P244
   Spreyer K., 2009, P 13 C COMP NAT LANG, P12
   Turhan C., 2008, 5 INT C INF TECHN NE, P674
NR 9
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 188
EP 193
DI 10.1016/j.sbspro.2011.10.597
PG 6
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700021
OA Other Gold
DA 2019-06-15
ER

PT S
AU Okamoto, J
   Ishizaki, S
AF Okamoto, Jun
   Ishizaki, Shun
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Important Sentence Extraction Using Contextual Semantic Network
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Associative Concept Dictionary; Contextual Semantic Network; Important
   Score of Words; Important Sentence Extraction
AB In this paper, we propose a method for calculating important scores of sentences for text summarization. In this method, Contextual Semantic Network is used to calculate scores of importance for sentences included in input documents. The Contextual Semantic Network is constructed by using the Associative Concept Dictionary which includes semantic relations and distance information among the words in the documents. The concept dictionary was built using the results of association experiments which adopted basic nouns as stimulus words in Japanese elementary school textbooks. For evaluating the method, we compared the quality of the important score ranking obtained from our proposed method with that obtained from human subjects and that obtained from a conventional method using term frequency (tfidf). We used eight documents from the Japanese textbooks for the evaluation and carried out an experiment where 40 human subjects chose the five most important sentences from each of the eight documents. The results show that summarization accuracy can be improved by applying our method. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Okamoto, Jun] Keio Univ, Keio Res Inst SFC, Fujisawa, Kanagawa 2528520, Japan.
   [Ishizaki, Shun] Keio Univ, Grad Sch Media Governance, Fujisawa, Kanagawa 2528520, Japan.
RP Okamoto, J (reprint author), Keio Univ, Keio Res Inst SFC, Fujisawa, Kanagawa 2528520, Japan.
EM juno@sfc.keio.ac.jp
CR Hashida K., 1987, NEW RESULT ARTICIAL, P149
   Ishikawa K., 2002, J NLP, V9, P33
   Kudo T., 2002, P 6 C NAT LANG LEARN, V2002, P63
   Matsumoto Y., 1999, NAISTISTR99009
   Mochizuki H., 2000, LREC2000, P633
   Nagao K., 1998, COLING ACL, P917
   OKAMOTO J, 2001, J NATURAL LANGUAGE P, V8, P37
   Okamoto J., 2010, P 7 C INT LANG RES E
   Okamoto J., 2003, J NLP, V10, P139
   Watanabe H., 1996, 16 INT C COMP LING, P974
   Zechner K., 1996, P 16 INT C COMP LING, P986
NR 11
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 86
EP 94
DI 10.1016/j.sbspro.2011.10.586
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700010
OA Other Gold
DA 2019-06-15
ER

PT S
AU Rahnuma, KS
   Wahab, A
   Majid, HA
   Cruts, B
AF Rahnuma, Kazi Shahzabeen
   Wahab, Abdul
   Majid, Hariyati A.
   Cruts, Bjorn
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Analyzing Brain Activity in Understanding Cultural and Language
   Interaction for Depression and Anxiety
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Kernel Density Estimation (KDE); Multi-layer Perceptron (MLP);
   electroencephalogram (EEG); basic emotions; brain activity
ID LARGE NONCLINICAL SAMPLE; NORMATIVE DATA
AB Human brain has always been considered as a black box and is the source of all emotions. Analyzing cultural and language role through human emotion by looking at the brain activity can thus help us understand depression and stress better. This paper focuses on understanding and analyzing undergraduate students' emotions with different background and culture after completing their semester final examination. Brain wave signals were captured using EEG device and analyzed through proposing an affective computation model. EEG signal was collected from 8 healthy subjects from different states of Malaysia with different dialects where each subject was emotionally induced with audio and video emotion stimuli using the International Affective Pictures and System (IAPS). Features were extracted from the captured EEG signals using Kernel Density Estimation (KDE), which was then categorized into four basic emotions of happy, calm, sad and fear using the Multi-layer Perceptron (MLP). Results of the study show potential of using such analysis in understanding stress, anxiety and depression. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Rahnuma, Kazi Shahzabeen; Wahab, Abdul] Int Islamic Univ Malaysia IIUM, Dept Comp Sci, Kulliyyah Informat & Commun Technol, Kuala Lumpur, Malaysia.
   [Majid, Hariyati A.] IIUM, Dept Psychol, Kuala Lumpur, Malaysia.
   [Cruts, Bjorn] Brainmarker BV, Buchten, Netherlands.
RP Rahnuma, KS (reprint author), Int Islamic Univ Malaysia IIUM, Dept Comp Sci, Kulliyyah Informat & Commun Technol, Kuala Lumpur, Malaysia.
EM kshahzabeen@yahoo.com; abdulwahab@iiu.edu.my
CR Andrew J. C., 2005, NATURE REV NEUROSCIE, V6, P641
   COHEN S, 1983, J HEALTH SOC BEHAV, V24, P385, DOI 10.2307/2136404
   Crawford JR, 2003, BRIT J CLIN PSYCHOL, V42, P111, DOI 10.1348/014466503321903544
   Farquharson R. F., 1942, AM J PSYCHIAT, V98, P625
   Haak M, 2009, GAME-ON 2009: 10TH INTERNATIONAL CONFERENCE ON INTELLIGENT GAMES AND SIMULATION, P75
   Henry JD, 2005, BRIT J CLIN PSYCHOL, V44, P227, DOI 10.1348/014466505X29657
   Horlings, 2008, EMOTION RECOGNITION
   Jamal M., 2008, WORLD APPL SCI J, V5, P546
   Lang P. J., 2005, A6 U FLOR
   Lewthwaite M., 1996, INT J ADV COUNS, V19, P167, DOI DOI 10.1007/BF00114787
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Reeves B, 1996, MEDIA EQUATION PEOPL
   Sengupta K., 2004, IEEE COMP SOC C COMP, V2, P667
   Sheldrake R, 1999, ALTERN THER HEALTH M, V5, P88
   Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981
   van der Zee K, 2004, J PERS, V72, P1069, DOI 10.1111/j.0022-3506.2004.00290.x
   Verceridis D., 2006, SPEECH COMMUN, V48, P1162
NR 17
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 299
EP 305
DI 10.1016/j.sbspro.2011.10.611
PG 7
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700035
OA Other Gold
DA 2019-06-15
ER

PT S
AU Shah, A
   Saidin, AZ
   Taha, IF
   Zeki, AM
AF Shah, Asadullah
   Saidin, Aznan Zuhid
   Taha, Imad Fakhri
   Zeki, Akram M.
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Frequencies determination of characters for Bahasa Melayu: results of
   preliminary investigations
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Bahasa Melayu; Bahasa Indonesia; English language; absolute frequencies;
   relative frequencies; running average
AB Bahasa Melayu (Malay language) is a language spoken in Malaysia and many countries around it. It has rich literature and deep roots in culture. Bahasa Melayu language uses roman character set (i.e. A-Z) identical to English language. The written language uses the character set as building blocks to build word, sentences and phrases along with special punctuations and signs to create documents of interest. In this paper, results of preliminary investigation of Malay text documents are provided. For this purpose scanning of articles written upon various topics in Malay were carried out. Approximately 31 thousand characters from different articles are scanned. Preliminary observations indicate that on average, character "A" occurs 19%, character "N" occur 10%, character "E" occur "9%" and character "I" 8% in text. However, it is also observed from the data that, these are the characters from over all set with highest frequencies of occurrences and it is expected that during further investigation they will remain as higher frequency occurring characters. Furthermore, the results indicate that for Bahasa Melayu characters appearance in text is very close in character frequencies of Bahasa Indonesia, but having different appearance of characters than English language. The investigation also indicate that these two languages, Bahasa Melayu and Bahasa Indonesia share close phonetic structure but not English, though all three use same character set. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Shah, Asadullah; Taha, Imad Fakhri] Int Islamic Univ Malaysia, Kulliyyah ICT, Dept Comp Sci, Kuala Lumpur 53100, Malaysia.
   [Saidin, Aznan Zuhid; Zeki, Akram M.] Int Islamic Univ Malaysia, Kulliyyah ICT, Dept Informat Syst, Kuala Lumpur 53100, Malaysia.
RP Shah, A (reprint author), Int Islamic Univ Malaysia, Kulliyyah ICT, Dept Comp Sci, Kuala Lumpur 53100, Malaysia.
EM asadullah@kict.iium.edu.my
RI Al-Shaikhli, Imad/O-7340-2018
OI Al-Shaikhli, Imad/0000-0003-4706-0636; Saidin, Aznan
   Zuhid/0000-0003-2263-5499
FU International Islamic University under the Research Endowment Grant [EDW
   A11-084-0875]
FX This study was funded by the International Islamic University under the
   Research Endowment Grant (Type A) EDW A11-084-0875.
CR Trost S., 2011, CHARACTER FREQUENCY
   Wang A., 1984, INDIAN J STAT B, V46, P372
   Wikipedia, 2011, MOV AV
   Wikipedia, 2011, LETT FREQ
   WorldLingo, 2011, LETT FREQ
NR 5
TC 0
Z9 0
U1 1
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 233
EP 240
DI 10.1016/j.sbspro.2011.10.603
PG 8
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700027
OA Other Gold
DA 2019-06-15
ER

PT S
AU Shibata, M
   Funatsu, T
   Tomiura, Y
AF Shibata, Masahiro
   Funatsu, Toshiaki
   Tomiura, Yoichi
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Extraction of Alternative Candidates for Unnatural Adjective-Noun
   Co-occurrence Constructions of English
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE corpus construction; web documents; English education; writing support
   system; occurring environment
AB While it is already possible to construct a large-scale English corpus easily and inexpensively using web documents, such documents have problems of reliability with respect to their English quality. Thus, we have developed a system that automatically gathers English technical papers from the web, sorts them into those written by native speakers and those written by non-native speakers, and then uses them to construct a native speaker and non-native speaker corpus. We discuss a method of using the corpus for providing alternative candidates for appropriate adjectives against unnatural English adjective-noun co-occurrence constructions < a,n >. The appropriateness of adjective a' is evaluated based on the similarity of the occurring environments between a and a'. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Shibata, Masahiro] Kyushu Univ, Res Inst Informat Technol, Nishi Ku, Fukuoka, Japan.
   [Funatsu, Toshiaki] Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Fukuoka, Japan.
   [Tomiura, Yoichi] Kyushu Univ, Fac Informat Sci & Elect Engn, Fukuoka, Japan.
RP Shibata, M (reprint author), Kyushu Univ, Res Inst Informat Technol, Nishi Ku, Fukuoka, Japan.
EM shibata@lang.inf.kyushu-u.ac.jp
FU Japan Society of the Promotion of Science [20320082]
FX This Research is supported by a Grant-in-Aid for Scientific Research on
   Priority (B) (No.20320082) of the Japan Society of the Promotion of
   Science.
CR Frantzi K., 2000, International Journal on Digital Libraries, V3, P115, DOI 10.1007/s007999900023
   Hindle D., 1990, P 28 ANN M ASS COMP, P268
   Nakano Teiko, 2010, Proceedings IADIS International Conference e-Society 2010, P396
   Nakano T., 2010, P 8 IASTED INT C WEB, P173
   Nakano T., 2011, J NATURAL LANGUAGE P, V18, P3
   Shibata M., 2009, P PACLING 2009, P47
   Totsugi N., 2002, P 3 CASTEL J, P67
   Yi X., 2008, P 3 INT JOINT C NAT, P619
NR 8
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 32
EP 41
DI 10.1016/j.sbspro.2011.10.580
PG 10
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700004
OA Other Gold
DA 2019-06-15
ER

PT S
AU Tan, SS
   Tang, EK
   Ranaivo-Malancon, B
AF Tan, Saravadee Sae
   Tang, Enya Kong
   Ranaivo-Malancon, Bali
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Content-Structure Correspondence: A Generic Representation for
   Heterogeneous Structured Document
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Parsing; Subcategorization; PP attachment; Coordination attachment; Text
   understanding; Grammar writing
AB This on the web, most structured document collections consist of documents from different sources and marked up with different types of structures. The diversity of structures has lead to the emergence of heterogeneous structured documents. The heterogeneity of structured documents poses new challenges for document representation in structured document retrieval. The representation model needs to handle various types of structures as well as multiple structures in a single document. Furthermore, same information may be represented in different structures and information contained in different documents may be partial and inconsistent. Therefore, the linkage of semantically related elements in the document collections needs to be modelled in the representation model. In this paper, we introduce a generic and flexible structured document model to represent heterogeneous structured documents as well as the similar correspondences in the document collections. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Tan, Saravadee Sae; Tang, Enya Kong; Ranaivo-Malancon, Bali] Multimedia Univ, Fac Informat Technol, Selangor, Malaysia.
EM enyakong@mmu.edu.my; ranaivo@mmu.edu.my
CR Barbosa D, 2006, WORLD WIDE WEB, V9, P187, DOI 10.1007/s11280-006-8437-6
   Denoyer L., 2006, SIGIR Forum, V40, P64
   Gabriella K., 2008, PROCEDIA SOCIAL BEHA, P106
   Manning C. D., 2008, INTRO INFORM RETRIEV
   Schenkel R., 2008, P DAT BUS TECHN WEB, P277
   van Zwol R., 2007, P 29 EUR C IR RES EC, P621
NR 6
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 226
EP 232
DI 10.1016/j.sbspro.2011.10.602
PG 7
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700026
OA Other Gold
DA 2019-06-15
ER

PT S
AU Teraoka, T
   Okamoto, J
   Ishizaki, S
AF Teraoka, Takehiro
   Okamoto, Jun
   Ishizaki, Shun
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI Detecting Metonymic Expressions with Associative Information from Words
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Metonymy; Association Experiment; Associative Concept Dictionary; Verb
AB In natural language processing, metonymic expressions need to be detected and interpreted because sentences including metonymic expressions have different meanings from literal ones. Previous studies focused mainly on interpreting metonymic expressions, but not on detecting ones in sentences. The purposes of this study are to propose an associative approach for detecting them and to evaluate it. By using associative concept dictionaries and Japanese WordNet, we constructed an automatic system that can detect metonymic expressions. We evaluated the system by comparing it with a baseline system that also detects such expressions. As a result, our system showed higher rates of recall (80.0%), precision (72.0%), and F-measure (75.8%) than those of a baseline system. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Teraoka, Takehiro; Ishizaki, Shun] Keio Univ, Grad Sch Media & Governance, Fujisawa, Kanagawa 2528520, Japan.
   [Okamoto, Jun] Keio Univ, Keio Res Inst SFC, Fujisawa, Kanagawa 2528520, Japan.
RP Teraoka, T (reprint author), Keio Univ, Grad Sch Media & Governance, Fujisawa, Kanagawa 2528520, Japan.
EM teraoka@sfc.keio.ac.jp
CR Bouaud J., 1996, P 16 INT C COMP LING, V1, P137
   Fass D., 1991, Computational Linguistics, V17, P49
   Fass D., 1988, P 12 INT C COMP LING, P177
   Ikehara S, 1999, GOI TAIKEI JAPANESE
   ISAHARA H, 2008, P 6 INT C LANG RES E, P2420
   Iverson E., 1992, COMPUTATIONAL INTELL, V8, P477
   Kai M., 2001, METHOD TEACHING LEXI
   Morita Y., 1989, DICT BASIC JAPANESE
   Murata M., 2000, Journal of Japanese Society for Artificial Intelligence, V15, P503
   OKAMOTO J, 2001, J NATURAL LANGUAGE P, V8, P37
   Okamoto J., 2010, P 7 INT LANGUAGE RES, P1180
   Shirai S., 1998, INTRO GOI TAIKEI JAP, P47
   Suga T., 2006, P ANN M NAT LANG PRO, P817
   Teraoka T., 2008, P FORUM INFORM TECHN, V2, P229
   Teraoka T., 2010, P 7 INT C LANG RES E, P3851
   Utiyama M., 2000, J NATURAL LANGUAGE P, V7, P91
   Yamanashi M.-A., 1987, LANGUAGE ARTIFICIAL, P77
NR 17
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 105
EP 112
DI 10.1016/j.sbspro.2011.10.588
PG 8
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700012
OA Other Gold
DA 2019-06-15
ER

PT S
AU Nguyen, VV
   Nguyen, TP
   Nguyen, ML
   Shimazu, A
AF Vinh Van Nguyen
   Thai Phuong Nguyen
   Minh Le Nguyen
   Shimazu, Akira
BE Aziz, NA
   Hasida, K
   Rahman, AWA
   Saito, H
TI A Model Lexicalized Hierarchical Reordering for Phrase Based Translation
SO COMPUTATIONAL LINGUISTICS AND RELATED FIELDS
SE Procedia Social and Behavioral Sciences
LA English
DT Proceedings Paper
CT Conference of the Pacific-Association-for-Computational-Linguistics
   (PACLING)
CY JUL 19-21, 2011
CL Kuala Lumpur, MALAYSIA
SP Pacific Assoc Computat Linguist, Int Islam Univ Malaysia (IIUM)
DE Machine Translation; Statistical Machine Translation; Hierarchical
   Reordering Model
AB In this paper, we present a reordering model based on Maximum Entropy with local and non-local features. This model is extended from a hierarchical reordering model with PBSMT [1], which integrates rich syntactic information directly in decoder as local and non-local features of Maximum Entropy model. The advantages of this model are (1) maintaining the strength of phrase based approach with a hierarchical reordering model, (2) many kinds of rich linguistic information integrated in PBSMT as local and non-local features of MaxEntropy model. The experiment results with English-Vietnamese pair showed that our approach achieves significant improvements over the system which uses a lexical hierarchical reordering model [1]. (C) 2011 Published by Elsevier Ltd. Selection and/or peer-review under responsibility of PACLING Organizing Committee.
C1 [Vinh Van Nguyen; Thai Phuong Nguyen] VNU, Coll Technol, Hanoi, Vietnam.
   [Minh Le Nguyen; Shimazu, Akira] Japan Adv Inst Sci & Technol, Nomi 9231292, Japan.
RP Nguyen, VV (reprint author), VNU, Coll Technol, Hanoi, Vietnam.
EM vinhnv@vnu.edu.vn; thainp@vnu.edu.vn; nguyenml@jaist.ac.jp;
   shimazu@jaist.ac.jp
CR Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   Collins M., 2005, P 43 ANN M ASS COMP, P531
   Galley Michel, 2008, P 2008 C EMP METH NA, P848
   KOEHN P, 2003, P HLT NAACL, P127
   Koehn P., 2005, P MACH TRANSL EV WOR
   Koehn P., 2004, P 6 C ASS MACH TRANS, P115
   Koehn P., 2007, P ACL DEM SESS
   Nguyen P. T., 2007, INT J COMPUTER PROCE, V20, P1
   Nguyen V., 2009, P MT SUMM 2009
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   Och FJ, 2004, COMPUT LINGUIST, V30, P417, DOI 10.1162/0891201042544884
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   SHA F, 2003, P HLT NAACL, P213
   Stolcke A., 2002, P INT C SPOK LANG PR, V29, P901
   Tillman C., 2004, P HUM LANG TECHN C H, P101
   XIONG D, 2006, P 21 INT C COMP LING, P521
   Zens R, 2006, P WORKSH STAT MACH T, P55
   Zhang H., 2008, P 22 INT C COMP LING, P1081
NR 18
TC 0
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA SARA BURGERHARTSTRAAT 25, PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 1877-0428
J9 PROCD SOC BEHV
PY 2011
VL 27
BP 77
EP 85
DI 10.1016/j.sbspro.2011.10.585
PG 9
WC Linguistics; Social Sciences, Interdisciplinary
SC Linguistics; Social Sciences - Other Topics
GA BYP59
UT WOS:000299624700009
OA Other Gold
DA 2019-06-15
ER

PT B
AU Berg-Kirkpatrick, T
   Klein, D
AF Berg-Kirkpatrick, Taylor
   Klein, Dan
GP Assoc Computat Linguist
TI Phylogenetic Grammar Induction
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present an approach to multilingual grammar induction that exploits a phylogeny-structured model of parameter drift. Our method does not require any translated texts or token-level alignments. Instead, the phylogenetic prior couples languages at a parameter level. Joint induction in the multilingual model substantially outperforms independent learning, with larger gains both from more articulated phylogenies and as well as from increasing numbers of languages. Across eight languages, the multilingual approach gives error reductions over the standard monolingual DMV averaging 21.1% and reaching as high as 39%.
C1 [Berg-Kirkpatrick, Taylor; Klein, Dan] Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
RP Berg-Kirkpatrick, T (reprint author), Univ Calif Berkeley, Div Comp Sci, Berkeley, CA 94720 USA.
EM tberg@cs.berkeley.edu; klein@cs.berkeley.edu
CR Berg-Kirkpatrick T., 2010, N AM CHAPTER ASS COM
   Bikel D., 2000, 2 CHIN LANG PROC WOR
   Bouchard-Cote A., 2007, EMPIRICAL METHODS NA
   Buchholz S., 2006, C COMP NAT LANG LEAR
   Burkett D., 2008, EMPIRICAL METHODS NA
   Cohen S. B., 2009, N AM ASS COMPUTATION
   Collins M., 1999, THESIS
   Eisner J., 2002, ASS COMPUTATIONAL LI
   Finkel J. R., 2009, N AM CHAPTER ASS COM
   III H. Daume, 2007, ASS COMPUTATIONAL LI
   Klein D., 2004, ASS COMPUTATIONAL LI
   Kuhn J., 2004, ASS COMPUTATIONAL LI
   Kuzman G., 2009, ASS COMP LING INT JO
   Liang P., 2008, ADV NEURAL INFORM PR
   Liu Dong C, 1989, MATH PROGRAMMING
   Marcus Mitchell P, 1993, COMPUTATIONAL LINGUI
   Salakhutdinov R., 2003, INT C MACH LEARN
   Smith D. A., 2009, EMPIRICAL METHODS NA
   Snyder B., 2009, ASS COMP LING INT JO
   Snyder B., 2009, N AM CHAPTER ASS COM
   Xue N., 2002, INT C COMP LING
NR 21
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1288
EP 1297
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300131
DA 2019-06-15
ER

PT B
AU Chambers, N
   Jurafsky, D
AF Chambers, Nathanael
   Jurafsky, Dan
GP Assoc Computat Linguist
TI Improving the Use of Pseudo-Words for Evaluating Selectional Preferences
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper improves the use of pseudo-words as an evaluation framework for selectional preferences. While pseudo-words originally evaluated word sense disambiguation, they are now commonly used to evaluate selectional preferences. A selectional preference model ranks a set of possible arguments for a verb by their semantic fit to the verb. Pseudo-words serve as a proxy evaluation for these decisions. The evaluation takes an argument of a verb like drive (e.g. car), pairs it with an alternative word (e.g. car/rock), and asks a model to identify the original. This paper studies two main aspects of pseudo-word creation that affect performance results. (1) Pseudo-word evaluations often evaluate only a subset of the words. We show that selectional preferences should instead be evaluated on the data in its entirety. (2) Different approaches to selecting partner words can produce overly optimistic evaluations. We offer suggestions to address these factors and present a simple baseline that outperforms the state-of-the-art by 13% absolute on a newspaper domain.
C1 [Chambers, Nathanael; Jurafsky, Dan] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Chambers, N (reprint author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
EM natec@stanford.edu; jurafsky@stanford.edu
CR Baker Collin F., 1998, ACL 98, P86
   Bergsma Shane, 2008, EURO PM2008 EPMA MAN, P59
   Burnard Lou, 1995, USER REFERENCE GUIDE
   Dagan I, 1999, MACH LEARN, V34, P43, DOI 10.1023/A:1007537716579
   Erk Katrin, 2007, 45 ANN M ASS COMP LI
   Gale W. A., 1992, AAAI FALL S PROB APP, P54
   Gaustad Tanja, 2001, 39 ANN M ASS COMP LI
   Graff David, 2002, LINGUISTIC DATA CONS
   Keller F, 2003, COMPUT LINGUIST, V29, P459, DOI 10.1162/089120103322711604
   Lapata Maria, 1999, EUROPEAN CHAPTER ASS
   Nakov Preslav I., 2003, COMP VOL P HLT NACCL, P67
   PEREIRA F, 1993, 31ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P183
   Rooth Mats, 1999, 37 ANN M ACL COLL PA, P104
   Schutze Hinrich, 1992, AAAI FALL S PROB APP, P113
   Yeh Alexander, 2000, INT C COMP LING COLI
   Zapirain Beat, 2009, JOINT C 47 ANN M ASS
NR 16
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 445
EP 453
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300046
DA 2019-06-15
ER

PT B
AU Chen, BX
   Foster, G
   Kuhn, R
AF Chen, Boxing
   Foster, George
   Kuhn, Roland
GP Assoc Computat Linguist
TI Bilingual Sense Similarity for Statistical Machine Translation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID COOCCURRENCE
AB This paper proposes new algorithms to compute the sense similarity between two units (words, phrases, rules, etc.) from parallel corpora. The sense similarity scores are computed by using the vector space model. We then apply the algorithms to statistical machine translation by computing the sense similarity between the source and target side of translation rule pairs. Similarity scores are used as additional features of the translation model to improve translation performance. Significant improvements are obtained over a state-of-the-art hierarchical phrase-based machine translation system.
C1 [Chen, Boxing; Foster, George; Kuhn, Roland] Natl Res Council Canada, 283 Alexandre Tache Blvd, Gatineau, PQ J8X 3X7, Canada.
RP Chen, BX (reprint author), Natl Res Council Canada, 283 Alexandre Tache Blvd, Gatineau, PQ J8X 3X7, Canada.
EM Boxing.Chen@nrc.ca; George.Foster@nrc.ca; Roland.Kuhn@nrc.ca
CR Bangalore S, 2009, NEURAL INF PROCESS S, P185
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Bullinaria JA, 2007, BEHAV RES METHODS, V39, P510, DOI 10.3758/BF03193020
   Carpuat M., 2009, P NAACL HLT WORKSH S
   Carpuat M., 2007, P EMNLP PRAG
   Chan Y., 2007, P ACL PRAG
   Chiang D, 2009, P HUM LANG TECHN 200, P218
   Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Church K. W., 1990, Computational Linguistics, V16, P22
   Frakes W. B., 1992, INFORM RETRIEVAL DAT
   FUNG P, 1998, P 3 C ASS MACH TRANS, P1
   Gimenez J, 2009, NEURAL INF PROCESS S, P205
   Gimpel K., 2008, P WMT COL OH
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   He Z., 2008, P COLING MANCH UK
   Hindle D., 1990, P 28 ANN M ASS COMP, P268
   KOEHN P, 2003, P HLT NAACL, P127
   Koehn P., 2004, P 2004 C EMP METH NA, P388
   Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037//0033-295X.104.2.211
   Li Z., 2009, P WMT MARCH ATH GREE
   Lin D., 1998, P 17 INT C COMP LING, V2, P768, DOI DOI 10.3115/980432.980696
   Liu Q., 2008, P EMNLP HON HAW
   Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766
   Mauser A., 2009, P EMNLP SING
   OCH F, 2003, P ACL SAPP JAP
   Pado S, 2007, COMPUT LINGUIST, V33, P161, DOI 10.1162/coli.2007.33.2.161
   Pantel P., 2002, P 8 ACM SIGKDD INT C, P613
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Rapp R, 1999, P 37 ANN M ASS COMP, P519, DOI DOI 10.3115/1034678.1034756
   Salton  G., 1983, INTRO MODERN INFORM
   Turney P.D., 2001, P 12 EUR C MACH LEAR, V2167, P491, DOI DOI 10.1007/3-540-44795-4_
   Wu D., 2009, P NAACL HLT BOULD CO
   Yuret D., 2009, COMPUTATIONAL LINGUI, V1, P1
   Zens R., 2004, P NAACL HLT BOST MA
   Zhao B., 2004, P EMNLP JUL BARC SPA, P206
NR 36
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 834
EP 843
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300086
DA 2019-06-15
ER

PT B
AU Cheung, JCK
   Penn, G
AF Cheung, Jackie Chi Kit
   Penn, Gerald
GP Assoc Computat Linguist
TI Entity-based local coherence modelling using topological fields
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID REFERENTIAL COHERENCE
AB One goal of natural language generation is to produce coherent text that presents information in a logical order. In this paper, we show that topological fields, which model high-level clausal structure, are an important component of local coherence in German. First, we show in a sentence ordering experiment that topological field information improves the entity grid model of Barzilay and Lapata (2008) more than grammatical role and simple clausal order information do, particularly when manual annotations of this information are not available. Then, we incorporate the model enhanced with topological fields into a natural language generation system that generates constituent orders for German text, and show that the added coherence component improves performance slightly, though not statistically significantly.
C1 [Cheung, Jackie Chi Kit; Penn, Gerald] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.
RP Cheung, JCK (reprint author), Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.
EM jcheung@cs.toronto.edu; gpenn@cs.toronto.edu
CR Barzilay R, 2002, J ARTIF INTELL RES, V17, P35, DOI 10.1613/jair.991
   Barzilay R, 2008, COMPUT LINGUIST, V34, P1, DOI 10.1162/coli.2008.34.1.1
   Barzilay Regina, 2004, P NAACL HLT, V2004, P113
   Chen E., 2007, P EMNLP PRAG CZECH, P83
   Cheung J. C. K., 2009, P ACL IJCNLP 09, P64
   Dipper S., 2009, P C GERM SOC COMP LI, P69
   Elsner M., 2007, CS0704 BROWN U
   Filippova Katja, 2007, Journal of Logic, Language and Information, V16, P465, DOI 10.1007/s10849-007-9044-3
   Filippova  K., 2007, P 11 EUR WORKSH NAT, P139
   Filippova K., 2007, P 45 ANN M ASS COMP, P320
   Hohle T. N., 1983, THESIS
   Jacobs J, 2001, LINGUISTICS, V39, P641, DOI 10.1515/ling.2001.027
   Joachims T., 2002, LEARNING CLASSIFY TE
   Karamanis N, 2009, COMPUT LINGUIST, V35, P29, DOI 10.1162/coli.07-036-R2-06-22
   Kibble R, 2004, COMPUT LINGUIST, V30, P401, DOI 10.1162/0891201042544893
   Kubler Sandra, 2004, P 4 INT C LANG RES E, P2229
   Lapata M, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P545
   Lapata M, 2006, COMPUT LINGUIST, V32, P471, DOI 10.1162/coli.2006.32.4.471
   Moschitti Alessandro, 2008, P 46 ANN M ASS COMP, P9
   Ng V, 2002, P 40 ANN M ASS COMP, P104, DOI DOI 10.3115/1073083.1073102
   Petrov S., 2007, P NAACL HLT 2007, P404
   Poesio M, 2004, COMPUT LINGUIST, V30, P309, DOI 10.1162/0891201041850911
   Schmid H., 2008, P 22 INT C COMP LING, P777, DOI DOI 10.3115/1599081.1599179
   Sgall P, 1986, MEANING SENTENCE ITS
   Strube M, 1999, COMPUT LINGUIST, V25, P309
NR 25
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 186
EP 195
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300020
DA 2019-06-15
ER

PT B
AU Connor, M
   Gertner, Y
   Fisher, C
   Roth, D
AF Connor, Michael
   Gertner, Yael
   Fisher, Cynthia
   Roth, Dan
GP Assoc Computat Linguist
TI Starting From Scratch in Semantic Role Labeling
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID ABSTRACT KNOWLEDGE; INFANTS; GRAMMAR; SPEECH; WORDS; CUES
AB A fundamental step in sentence comprehension involves assigning semantic roles to sentence constituents. To accomplish this, the listener must parse the sentence, find constituents that are candidate arguments, and assign semantic roles to those constituents. Each step depends on prior lexical and syntactic knowledge. Where do children learning their first languages begin in solving this problem? In this paper we focus on the parsing and argumentidentification steps that precede Semantic Role Labeling (SRL) training. We combine a simplified SRL with an unsupervised HMM part of speech tagger, and experiment with psycholinguisticallymotivated ways to label clusters resulting from the HMM so that they can be used to parse input for the SRL system. The results show that proposed shallow representations of sentence structure are robust to reductions in parsing accuracy, and that the contribution of alternative representations of sentence structure to successful semantic role labeling varies with the integrity of the parsing and argumentidentification stages.
C1 [Connor, Michael; Gertner, Yael; Fisher, Cynthia; Roth, Dan] Univ Illinois, Chicago, IL 60680 USA.
RP Connor, M (reprint author), Univ Illinois, Chicago, IL 60680 USA.
EM connor2@uiuc.edu; ygertner@cyrus.psych.uiuc.edu;
   cfisher@cyrus.psych.uiuc.edu; danr@illinois.edu
CR Beal M.J., 2003, THESIS
   BLOOM L, 1973, WORD TIME USE SINGLE
   BLOOM L., 1970, LANGUAGE DEV FUNCTIO
   Brent MR, 2001, COGNITION, V81, pB33, DOI 10.1016/S0010-0277(01)00122-6
   Brill E., 1997, NATURAL LANGUAGE PRO
   Brown R., 1973, 1 LANGUAGE
   CARRERAS X, 2004, P 8 C COMP NAT LANG, P89
   Charniak E., 1997, P NAT C ART INT
   CLARK EV, 1978, CHILDS CONCEPTION LA
   Connor M., 2009, P ANN C COMP NAT LAN
   Connor M., 2008, P ANN C COMP NAT LAN, pxx
   DEMETRAS MJ, 1986, J CHILD LANG, V13, P275, DOI 10.1017/S0305000900008059
   Demuth K, 2006, LANG SPEECH, V49, P137, DOI 10.1177/00238309060490020201
   Fisher C, 1996, COGNITIVE PSYCHOL, V31, P41, DOI 10.1006/cogp.1996.0012
   Gao  Jianfeng, 2008, P C EMP METH NAT LAN, P344
   Gentner D., 2006, ACTION MEETS WORD CH, P544, DOI DOI 10.1093/ACPROF:OSO/9780195170009.001.0001
   Gertner Y., 2006, 31 ANN BOST U C LANG
   Gertner Y, 2006, PSYCHOL SCI, V17, P684, DOI 10.1111/j.1467-9280.2006.01767.x
   Gillette J, 1999, COGNITION, V73, P135, DOI 10.1016/S0010-0277(99)00036-0
   Goldwater S., 2007, ANN M ASS COMP LING, V45, P744
   Gomez RL, 1999, COGNITION, V70, P109, DOI 10.1016/S0010-0277(99)00003-7
   Haghighi A., 2006, P MAIN C HUM LANG TE, P320, DOI DOI 10.3115/1220835.1220876
   Johnson M, 2007, P 2007 JOINT C EMP M, P296
   KELLY MH, 1992, PSYCHOL REV, V99, P349, DOI 10.1037//0033-295X.99.2.349
   Lidz J, 2003, COGNITION, V87, P151, DOI 10.1016/S0010-0277(02)00230-5
   MacWhinney B., 2000, CHILDES PROJECT TOOL
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Meila Marina, 2002, 418 U WASH STAT DEP
   Mintz TH, 2003, COGNITION, V90, P91, DOI 10.1016/S0010-0277(03)00140-9
   Monaghan P, 2005, COGNITION, V96, P143, DOI 10.1016/j.cognition.2004.09.001
   Pinker S, 1984, LANGUAGE LEARNABILIT
   Punyakanok V., 2008, COMPUTATIONAL LINGUI, V34
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ravi Sujith, 2009, P JOINT C 47 ANN MA
   Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926
   Shi RS, 1998, J CHILD LANG, V25, P169, DOI 10.1017/S0305000997003395
   Shi RS, 1999, COGNITION, V72, pB11, DOI 10.1016/S0010-0277(99)00047-5
   Smith L, 2008, COGNITION, V106, P1558, DOI 10.1016/j.cognition.2007.06.010
   Toutanova K., 2007, P NIPS
   Yuan S., 2007, BIENN M SOC RES CHIL
   Yuan S, 2009, PSYCHOL SCI, V20, P619, DOI 10.1111/j.1467-9280.2009.02341.x
NR 41
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 989
EP 998
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300101
DA 2019-06-15
ER

PT B
AU Dubey, A
AF Dubey, Amit
GP Assoc Computat Linguist
TI The Influence of Discourse on Syntax A Psycholinguistic Model of
   Sentence Processing
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID COMPREHENSION; CONTEXT; INFORMATION; RESOLUTION
AB Probabilistic models of sentence comprehension are increasingly relevant to questions concerning human language processing. However, such models are often limited to syntactic factors. This paper introduces a novel sentence processing model that consists of a parser augmented with a probabilistic logic-based model of coreference resolution, which allows us to simulate how context interacts with syntax in a reading task. Our simulations show that a Weakly Interactive cognitive architecture can explain data which had been provided as evidence for the Strongly Interactive hypothesis.
CR ALTMANN G, 1988, COGNITION, V30, P191, DOI 10.1016/0010-0277(88)90020-0
   [Anonymous], 2009, P 29 M COGN SCI SOC
   Baldwin B., 1998, 1 INT C LANG RES EV
   Boston M. F., 2008, P 46 ANN M ASS COMP, P5
   Brants T., 2000, P 18 INT C COMP LING, P111
   Crocker MW, 2000, J PSYCHOLINGUIST RES, V29, P647, DOI 10.1023/A:1026560822390
   Dubey A., 2009, COGNITION, V109, P193
   Dubey Amit, 2010, P 23 ANN CUN C HUM S, P151
   Fodor J. D., 1985, NATURAL LANGUAGE PAR
   Gibson E, 1998, COGNITION, V68, P1, DOI 10.1016/S0010-0277(98)00034-1
   Grodner D, 2005, COGNITION, V95, P275, DOI 10.1016/j.cognition.2004.01.007
   Hale J, 2003, J PSYCHOLINGUIST RES, V32, P101, DOI 10.1023/A:1022492123056
   Hale J., 2001, P 2 M N AM CHAPT ASS
   HAVILAND SE, 1974, J VERB LEARN VERB BE, V13, P512, DOI 10.1016/S0022-5371(74)80003-4
   Huang Shujian, 2009, P 2009 C INT TEXT PR
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   Levy R., 2007, P 20 ANN C NEUR INF
   Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006
   McRae K, 1998, J MEM LANG, V38, P283, DOI 10.1006/jmla.1997.2543
   MITCHELL DC, 1992, J EXP PSYCHOL LEARN, V18, P69, DOI 10.1037//0278-7393.18.1.69
   Modjeska NN, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P176
   Narayanan Shrini, 1998, P 20 ANN C COGN SCI
   Pado Ulrike, 2006, P 28 ANN C COGN SCI, P657
   Poon H., 2008, P 2008 C EMP METH NA
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1
   Soon WM, 2001, COMPUT LINGUIST, V27, P521, DOI 10.1162/089120101753342653
   Spivey MJ, 1998, J EXP PSYCHOL LEARN, V24, P1521, DOI 10.1037//0278-7393.24.6.1521
   STOLCKE A, 1995, COMPUT LINGUIST, V21, P165
NR 29
TC 0
Z9 0
U1 0
U2 5
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1179
EP 1188
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300120
DA 2019-06-15
ER

PT B
AU Huang, F
   Yates, A
AF Huang, Fei
   Yates, Alexander
GP Assoc Computat Linguist
TI Open-Domain Semantic Role Labeling by Modeling Word Spans
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Most supervised language processing systems show a significant drop-off in performance when they are tested on text that comes from a domain significantly different from the domain of the training data. Semantic role labeling techniques are typically trained on newswire text, and in tests their performance on fiction is as much as 19% worse than their performance on newswire text. We investigate techniques for building open-domain semantic role labeling systems that approach the ideal of a train-once, use-anywhere system. We leverage recently-developed techniques for learning representations of text using latent-variable language models, and extend these techniques to ones that provide the kinds of features that are useful for semantic role labeling. In experiments, our novel system reduces error by 16% relative to the previous state of the art on out-of-domain text.
C1 [Huang, Fei; Yates, Alexander] Temple Univ, 1805 N Broad St,Wachman Hall 318, Philadelphia, PA 19122 USA.
RP Huang, F (reprint author), Temple Univ, 1805 N Broad St,Wachman Hall 318, Philadelphia, PA 19122 USA.
EM fei.huang@temple.edu; yates@temple.edu
CR Abend Omri, 2009, P ACL
   Bacchiani M, 2006, COMPUT SPEECH LANG, V20, P41, DOI 10.1016/j.csl.2004.12.12.001
   Ben-David S., 2007, ADV NEURAL INFORM PR, V20
   Ben-David Shai, 2009, MACHINE LEA IN PRESS
   Blitzer John, 2006, EMNLP
   Carreras Xavier, 2004, P C NAT LANG LEARN C
   Carreras Xavier, 2003, P RANLP 2003
   Carreras Xavier, 2005, P C NAT LANG LEARN C
   Cohn Trevor, 2005, P CONLL
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1
   Deschacht Koen, 2009, P C EMP METH NAT LAN
   Downey D., 2007, ACL
   Downey D., 2007, P 20 INT JOINT C ART
   Escudero G., 2000, EMNLP VLC
   Furstenau H., 2009, P 2009 C EMP METH NA, P11
   Furstenau Hagen, 2009, P 12 C EUR CHAPT ACL, P220
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Gildea Daniel, 2001, C EMP METH NAT LANG
   GRENAGER T, 2006, P C EMP METH NAT LAN
   Huang Fei, 2009, P ANN M ASS COMP LIN
   Kucera Henry, 1967, COMPUTATIONAL ANAL P
   Lafferty J., 2001, P INT C MACH LEARN
   Martha P., 2005, COMPUT LINGUIST, V31, P1, DOI DOI 10.1162/0891201053630264
   McClosky D, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P337
   Pradhan Sameer, 2005, P ANN C COMP NAT LAN
   Pradhan Sameer, 2007, P NAACL HLT ROCH NY, P556
   Punyakanok V, 2008, COMPUT LINGUIST, V34, P257, DOI 10.1162/coli.2008.34.2.257
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Swier R. S., 2004, P 2004 C EMP METH NA, P95
   Toutanova K, 2008, COMPUT LINGUIST, V34, P161, DOI 10.1162/coli.2008.34.2.161
   Weston J, 2008, P 25 INT C MACH LEAR
NR 31
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 968
EP 978
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300099
DA 2019-06-15
ER

PT B
AU Ittoo, A
   Bouma, G
AF Ittoo, Ashwin
   Bouma, Gosse
GP Assoc Computat Linguist
TI On Learning Subtypes of the Part-Whole Relation: Do Not Mix your Seeds
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB An important relation in information extraction is the part-whole relation. Ontological studies mention several types of this relation. In this paper, we show that the traditional practice of initializing minimally-supervised algorithms with a single set that mixes seeds of different types fails to capture the wide variety of part-whole patterns and tuples. The results obtained with mixed seeds ultimately converge to one of the part-whole relation types. We also demonstrate that all the different types of part-whole relations can still be discovered, regardless of the type characterized by the initializing seeds. We performed our experiments with a state-ofthe- art information extraction algorithm.
C1 [Ittoo, Ashwin; Bouma, Gosse] Univ Groningen, Groningen, Netherlands.
RP Ittoo, A (reprint author), Univ Groningen, Groningen, Netherlands.
EM r.a.ittoo@rug.nl; g.bouma@rug.nl
CR Artale A, 1996, DATA KNOWL ENG, V20, P347, DOI 10.1016/S0169-023X(96)00013-4
   Beamer B., 2008, P 23 NAT C ART INT, V2, P824
   Berland M., 1999, ANN M ASS COMP LING, V37, P57, DOI DOI 10.3115/1034678.1034697
   BOCK C, 1994, J OBJECT-ORIENT PROG, V7, P10
   Church K. W., 1990, Computational Linguistics, V16, P22
   Dunning T., 1993, COMPUTATIONAL LINGUI, V19, P74
   Fellbaum C., 1998, WORDNET ELECT LEXICA
   Gangemi A., 2002, LECT NOTES COMPUTER, P223
   Gerstl P, 1995, INT J HUM-COMPUT ST, V43, P865, DOI 10.1006/ijhc.1995.1079
   Girju R., 2003, P HLT NAACL, V3, P80
   Girju R, 2006, COMPUT LINGUIST, V32, P83, DOI 10.1162/089120106776173075
   HEARST MA, 1992, P 14 C COMP LING NAN, V2, P539, DOI DOI 10.3115/992133.992154
   Keet CM, 2006, LECT NOTES COMPUT SC, V4278, P1118
   KEET CM, 2008, APPL ONTOL, V3, P91
   Klein D., 2003, P 41 ANN M ASS COMP, V1, P423, DOI DOI 10.3115/1075096.1075150
   McIntosh T., 2009, P JOINT C 47 ANN M A, P396
   Miller G. A., 1993, P WORKSH HUM LANG TE, P303, DOI DOI 10.3115/1075671.1075742
   Nguyen D P T, 1999, P NAT C ART INT, V22, P1414
   Pantel P, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P113
   Pyysalo S, 2009, P NAT LANG PROC BIOM, P1
   Stevenson Mark, 2009, RES LANGUAGE COMPUTA, V3, P13
   van Hage WR, 2006, LECT NOTES COMPUT SC, V4273, P723
   van Noord G., 2006, TALN06 VERBUM EX MAC, P20
   Vossen P., 1998, EUROWORDNET MULTILIN
   WINSTON ME, 1987, COGNITIVE SCI, V11, P417, DOI 10.1016/S0364-0213(87)80015-0
   Wu F., 2007, P 16 ACM C INF KNOWL, P41, DOI DOI 10.1145/1321440.1321449
NR 26
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1328
EP 1336
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300135
DA 2019-06-15
ER

PT B
AU Koller, A
   Thater, S
AF Koller, Alexander
   Thater, Stefan
GP Assoc Computat Linguist
TI Computing weakest readings
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We present an efficient algorithm for computing the weakest readings of semantically ambiguous sentences. A corpus-based evaluation with a large-scale grammar shows that our algorithm reduces over 80% of sentences to one or two readings, in negligible runtime, and thus makes it possible to work with semantic representations derived by deep large-scale grammars.
C1 [Koller, Alexander] Univ Saarland, Cluster Excellence, D-66123 Saarbrucken, Germany.
   [Thater, Stefan] Univ Saarland, Dept Computat Linguist, D-66123 Saarbrucken, Germany.
RP Koller, A (reprint author), Univ Saarland, Cluster Excellence, D-66123 Saarbrucken, Germany.
EM koller@mmci.uni-saarland.de; stth@coli.uni-saarland.de
CR Althaus E, 2003, J ALGORITHMS, V48, P194, DOI 10.1016/S0196-6774(03)00050-6
   BARWISE J, 1981, LINGUIST PHILOS, V4, P159, DOI 10.1007/BF00350139
   Bos J., 2008, P 6 INT C LANG RES E
   Chaves R. P., 2003, P 8 ESSLLI STUD SESS
   Comon H., 2007, TREE AUTOMATA TECHNI
   Copestake A., 2005, J LANGUAGE COMPUTATI
   Flickinger D., 2005, P 12 INT C HPSG LISB
   Flickinger Dan, 2000, P 2 INT C LANG RES E
   Gabsdil M., 1999, P 1 INT WORKSH INF C
   Graehl J, 2008, COMPUT LINGUIST, V34, P391, DOI 10.1162/coli.2008.07-051-R2-03-57
   Higgins D., 2003, COMPUTATIONAL LINGUI, V29
   Hobbs J., 1983, P 21 ANN M ASS COMP
   KEMPSON RM, 1981, LINGUIST PHILOS, V4, P259, DOI 10.1007/BF00350141
   Knuth D. E., 1970, COMPUTATIONAL PROBLE, P263
   Koller A., 2005, ACL 05 DEMONSTRATION
   Koller A., 2010, P 21 INT C REWR TECH
   Koller A., 2003, P 10 EACL
   Koller A., 2008, P ACL 08 HLT
   Koller A., 2000, P 18 INT C COMP LING
   Lasersohn P., 1993, Journal of Semantics, V10, P113, DOI 10.1093/jos/10.2.113
   MacCartney B., 2008, P 22 INT C COMP LING
   Montague Richard, 1974, FORMAL PHILOS SELECT
   Monz C., 2001, LNAI, V2014
   Nipkow T., 1999, TERM REWRITING ALL
   Oepen S., 2002, P 19 INT C COMP LING
   Reyle Uwe, 1995, P 7 C EUR CHAPT ASS
   Rohrer Christian, 2002, P COLING 2002 WORKSH
   Van Deemter K, 1996, SEMANTIC AMBIGUITY U
   Vestre E., 1991, P EACL BERL
NR 29
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 30
EP 39
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300004
DA 2019-06-15
ER

PT B
AU Liu, SJ
   Li, CH
   Zhou, M
AF Liu, Shujie
   Li, Chi-Ho
   Zhou, Ming
GP Assoc Computat Linguist
TI Discriminative Pruning for Discriminative ITG Alignment
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB While Inversion Transduction Grammar (ITG) has regained more and more attention in recent years, it still suffers from the major obstacle of speed. We propose a discriminative ITG pruning framework using Minimum Error Rate Training and various features from previous work on ITG alignment. Experiment results show that it is superior to all existing heuristics in ITG pruning. On top of the pruning framework, we also propose a discriminative ITG alignment model using hierarchical phrase pairs, which improves both F-score and Bleu score over the baseline alignment system of GIZA++.
C1 [Liu, Shujie] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
   [Li, Chi-Ho; Zhou, Ming] Microsoft Res Asia, Beijing, Peoples R China.
RP Liu, SJ (reprint author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Peoples R China.
EM shujieliu@mtlab.hit.edu.cn; chl@microsoft.com; mingzhou@microsoft.com
CR Brown P. F., 1993, Computational Linguistics, V19, P263
   Cherry Colin, 2007, P SSST NAACL HLT 200, P17
   Cherry Colin, 2006, P ACL COLING
   Chiang D., 2007, COMPUTATIONAL LINGUI, V33
   DeNero John, 2009, P HUM LANG TECHN 200, P227
   Fraser Alexander, 2006, P COLING ACL, P769
   Haghighi Aria, 2009, P ACL, P923
   Huang Liang, 2005, P IWPT 2005, P173
   Klein Dan, 2001, P IWPT, P17
   Koehn P., 2004, P 2004 C EMP METH NA, P388
   Liu YG, 2005, LECT NOTES COMPUT SC, V3773, P81
   Moore R. C., 2005, P C HUM LANG TECHN E, P81, DOI DOI 10.3115/1220575.1220586
   Moore RC, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P513
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Vogel S., 1996, P 16 INT C COMP LING, P836
   Vogel Stephan, 2005, P MT SUMM
   Wu Dekai, 1997, COMPUTATIONAL LINGUI, V23
   Zhang Hao, 2005, P ACL
   Zhang Hao, 2008, P ACL, P314
NR 20
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 316
EP 324
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300033
DA 2019-06-15
ER

PT B
AU Mi, HT
   Liu, Q
AF Mi, Haitao
   Liu, Qun
GP Assoc Computat Linguist
TI Constituency to Dependency Translation with Forests
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Tree-to-string systems (and their forest-based extensions) have gained steady popularity thanks to their simplicity and efficiency, but there is a major limitation: they are unable to guarantee the grammaticality of the output, which is explicitly modeled in string-to-tree systems via targetside syntax. We thus propose to combine the advantages of both, and present a novel constituency-to-dependency translation model, which uses constituency forests on the source side to direct the translation, and dependency trees on the target side (as a language model) to ensure grammaticality. Medium-scale experiments show an absolute and statistically significant improvement of +0.7 BLEU points over a state-of-the-art forest-based tree-to-string system even with fewer rules. This is also the first time that a tree-to- tree model can surpass tree-to-string counterparts.
C1 [Mi, Haitao; Liu, Qun] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, POB 2704, Beijing 100190, Peoples R China.
RP Mi, HT (reprint author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, POB 2704, Beijing 100190, Peoples R China.
EM htmi@ict.ac.cn; liuqun@ict.ac.cn
CR Billot S., 1989, P 27 ANN M ASS COMP, P143
   Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Collins M., 2005, P 43 ANN M ASS COMP, P531
   Ding Y., 2005, P 43 ANN M ASS COMP, P541, DOI DOI 10.3115/1219840.1219907
   Fox Heidi J., 2002, P EMNLP 02
   Galley M, 2004, P HLT NAACL
   Galley M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P961
   Hellwig P., 2006, INT HDB CONT RES, VII
   Huang L., 2008, P ACL
   Huang Liang, 2005, P IWPT
   Huang Liang, 2009, COMPUT LINGUIST
   Huang Liang, 2007, P 45 ANN M ASS COMP, P144
   Huang Liang, 2006, P AMTA
   KOEHN P, 2003, P HLT NAACL, P127
   Koehn P., 2007, P 45 ANN M ACL INT P, P177, DOI DOI 10.3115/1557769.1557821
   Liu Y., 2007, P 45 ACL PRAG CZECH, P704
   Liu Y, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P609
   Liu Yang, 2009, P ACL IJCNLP AUG
   MAGERMAN DM, 1995, P 33 ANN M ASS COMP, P276
   Mi H., 2008, P 2008 C EMP METH NA, P206
   MI H., 2008, P ACL 08 HLT, P192
   Och F.J., 2003, P 41 ANN M ASS COMP, P160, DOI DOI 10.3115/1075096.1075117
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Papineni K., 2002, P 40 ANN M ASS COMP, P311, DOI DOI 10.3115/1073083.1073135
   Quirk Chris, 2005, P 43 ANN M ASS COMP, P271, DOI DOI 10.3115/1219840.1219874
   Shen Libin, 2008, P ACL 08 HLT JUN
   Stolcke Andreas, 2002, P ICSLP, V30, P901
   Wang Wei, 2006, P 2006 C EMP METH NA, P44
   Xiong D., 2007, P 2 WORKSH STAT MACH, P40
   XIONG DY, 2005, P IJCNLP 2005, P70
   Zhang Hao, 2006, P HLT NAACL
   Zhang Hui, 2009, P ACL IJCNLP 2009
   Zhang Min, 2007, P MT SUMM
NR 35
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1433
EP 1442
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300145
DA 2019-06-15
ER

PT S
AU Mitchell, M
AF Mitchell, Margaret
BE Krahmer, E
   Theune, M
TI A Flexible Approach to Class-Based Ordering of Prenominal Modifiers
SO EMPIRICAL METHODS IN NATURAL LANGUAGE GENERATION: DATA-ORIENTED METHODS
   AND EMPIRICAL EVALUATION
SE Lecture Notes in Artificial Intelligence
LA English
DT Proceedings Paper
CT 12th European workshop on Natural Language Generation/12th Conference of
   the European Association for Computational Linguistics
CY MAR 30-APR 03, 2009
CL Athens, GREECE
DE natural language processing; natural language generation; adjective
   ordering; modifier ordering
ID REFERRING EXPRESSIONS
AB This chapter introduces a class-based approach to ordering prenominal modifiers. Modifiers are grouped into broad classes based on where they tend to occur prenominally, and a framework is developed to order sets of modifiers based on their classes. This system is developed to generate several orderings for sets of modifiers with more flexible positional constraints, and lends itself to bootstrapping for the classification of previously unseen modifiers. The approach to modifier classification outlined here is useful for automated language generation tasks, and the proposed modifier classes may be useful within constraint-based grammars.
C1 Univ Aberdeen, Dept Comp Sci, Aberdeen, Scotland.
RP Mitchell, M (reprint author), Univ Aberdeen, Dept Comp Sci, Aberdeen, Scotland.
EM m.mitchell@abdn.ac.uk
CR BEHAGHEL O, 1930, DTSCH WORTSTELLUNG, V44
   Bever T. G, 1970, COGNITION DEV LANGUA
   Boleda Gemma, 2005, P ACL SIGLEX WORKSH, P77
   Brants T., 2006, WEB 1T 5 GRAM VERSIO
   CLARK HH, 1976, PSYCHOL LANGUAGE INT
   DAELEMANS W, 1992, P TWLT3 CONN NAT LAN
   DALE R, 1995, COGNITIVE SCI, V18, P233, DOI DOI 10.1207/S15516709COG1902_3
   DANKS JH, 1971, J VERB LEARN VERB BE, V10, P63, DOI 10.1016/S0022-5371(71)80095-6
   GREENBERG JH, 1963, SOME UNIVERSALS GRAM, P73
   GROUP TLS, 2009, SPECIALIST LEXICON
   Halliday M. A. K., 1999, CONSTRUING EXPERIENC
   Krahmer E, 2003, COMPUT LINGUIST, V29, P53, DOI 10.1162/089120103321337430
   MALOUF R, 2000, P 38 ANN M ASS COMP, P85
   MANNING CD, 1993, M ASS COMP LING, P235
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   Marcus Mitchell P., 1999, TREEBANK 3
   MARTIN JE, 1969, J VERB LEARN VERB BE, V8, P697, DOI 10.1016/S0022-5371(69)80032-0
   MARTIN JE, 1969, J VERB LEARN VERB BE, V8, P471, DOI 10.1016/S0022-5371(69)80091-5
   Miller G. A, 2006, WORDNET LEXICAL DATA
   MITCHELL M, 2009, P ENLG 2009
   MURRAY RW, 1983, LANGUAGE, V59, P514, DOI 10.2307/413901
   PANINI, 1950, ASTADHYAYI INDIA CA
   PECHMANN T, 1989, LINGUISTICS, V27, P89, DOI 10.1515/ling.1989.27.1.89
   Posner R., 1986, ICONICITY ESSAYS NAT, P305
   Sag Ivan A., 2003, SYNTACTIC THEORY FOR
   Shaw J., 1999, P 37 ANN M ASS COMP, P135
   TORRENT GB, 2003, P EACL 2003 STUD SES, P9
   TOUTANOVA K, 2000, JOINT SIGDAT C EMNLP
   Toutanova K., 2003, P HLT NAACL, P252, DOI DOI 10.3115/1073445.1073478
   van Deemter K, 2002, COMPUT LINGUIST, V28, P37, DOI 10.1162/089120102317341765
   Vendler Z., 1968, ADJECTIVES NOMINALIZ
   Whorf BL, 1945, LANGUAGE, V21, P1, DOI 10.2307/410199
   Wulff Stefanie, 2003, INT J CORPUS LINGUIS, V8, P245, DOI DOI 10.1075/IJCL.8.2.04WUL
   ZHANG Y, 2005, P 45 ACL ANN ARB, P152
   Ziff Paul, 1960, SEMANTIC ANAL
NR 35
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER-VERLAG BERLIN
PI BERLIN
PA HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
SN 0302-9743
BN 978-3-642-15572-7
J9 LECT NOTES ARTIF INT
PY 2010
VL 5790
BP 141
EP 162
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BVF27
UT WOS:000291366600008
DA 2019-06-15
ER

PT B
AU Ravi, S
   Baldridge, J
   Knight, K
AF Ravi, Sujith
   Baldridge, Jason
   Knight, Kevin
GP Assoc Computat Linguist
TI Minimized models and grammar-informed initialization for supertagging
   with highly ambiguous lexicons
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We combine two complementary ideas for learning supertaggers from highly ambiguous lexicons: grammar-informed tag transitions and models minimized via integer programming. Each strategy on its own greatly improves performance over basic expectation-maximization training with a bitag Hidden Markov Model, which we show on the CCGbank and CCG-TUT corpora. The strategies provide further error reductions when combined. We describe a new two-stage integer programming strategy that efficiently deals with the high degree of ambiguity on these datasets while obtaining the full effect of model minimization.
C1 [Ravi, Sujith; Knight, Kevin] Univ Southern Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
   [Baldridge, Jason] Univ Texas Austin, Dept Linguist, Austin, TX 78712 USA.
RP Ravi, S (reprint author), Univ Southern Calif, Inst Informat Sci, Marina Del Rey, CA 90292 USA.
EM sravi@isi.edu; jbaldrid@mail.utexas.edu; knight@isi.edu
CR Baldridge J., 2008, P 22 INT C COMP LING, P57
   Banko M., 2004, P 20 INT C COMP LING, P556
   Barron A, 1998, IEEE T INFORM THEORY, V44, P2743, DOI 10.1109/18.720554
   Bos J., 2009, P 8 WORKSH TREEB LIN, P27
   Clark S., 2006, P HUM LANG TECHN C A, P144
   Clark Stephen, 2007, COMPUT LINGUIST, V33, P4
   Creutz M., 2002, P WORKSH MORPH PHON, P21
   Goldberg Y., 2008, P ACL JUN, P746
   Goldsmith J, 2001, COMPUT LINGUIST, V27, P153, DOI 10.1162/089120101750300490
   Goldwater Sharon, 2007, P 45 ANN M ASS COMP, P744
   Hassan Hany, 2009, P 2009 C EMP METH NA, P1182
   Hockenmaier J, 2007, COMPUT LINGUIST, V33, P355, DOI 10.1162/coli.2007.33.3.355
   Joshi Aravind, 1988, NATURAL LANGUAGE PAR, P206
   Marcus M., 1993, COMPUTATIONAL LINGUI, V19
   Merialdo B., 1994, Computational Linguistics, V20, P155
   Pollard C., 1994, HEAD DRIVEN PHRASE S
   Ravi S., 2009, P JOINT C 47 ANN M A, P504
   Steedman M., 2000, SYNTACTIC PROCESS
   Toutanova Kristina, 2008, P ADV NEUR INF PROC, P1521
NR 19
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 495
EP 503
PG 9
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300051
DA 2019-06-15
ER

PT B
AU Sassano, M
   Kurohashi, S
AF Sassano, Manabu
   Kurohashi, Sadao
GP Assoc Computat Linguist
TI Using Smaller Constituents Rather Than Sentences in Active Learning for
   Japanese Dependency Parsing
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB We investigate active learning methods for Japanese dependency parsing. We propose active learning methods of using partial dependency relations in a given sentence for parsing and evaluate their effectiveness empirically. Furthermore, we utilize syntactic constraints of Japanese to obtain more labeled examples from precious labeled ones that annotators give. Experimental results show that our proposed methods improve considerably the learning curve of Japanese dependency parsing. In order to achieve an accuracy of over 88.3%, one of our methods requires only 34.4% of labeled examples as compared to passive learning.
C1 [Sassano, Manabu] Yahoo Japan Corp, Minato Ku, Midtown Tower,9-7-1 Akasaka, Tokyo 1076211, Japan.
   [Kurohashi, Sadao] Kyoto Univ, Grad Sch Informat, Sakyo Ku, Kyoto 6068501, Japan.
RP Sassano, M (reprint author), Yahoo Japan Corp, Minato Ku, Midtown Tower,9-7-1 Akasaka, Tokyo 1076211, Japan.
EM msassano@yahoo-corp.jp; kuro@i.kyoto-u.ac.jp
CR Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Haertel R., 2008, P 46 ANN M ASS COMP, P65
   Hashimoto Shinkichi, 1934, ESSENTIALS JAPANESE
   Hwa R, 2004, COMPUT LINGUIST, V30, P253, DOI 10.1162/0891201041850894
   Iwatate M., 2008, P 22 INT C COMP LING, P361
   Kudo T, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P18
   Kudo T., 2002, P 6 C NAT LANG LEARN, V2002, P63
   Kurohashi Sadao, 1998, P 1 INT C LANG RES E, P719
   Laws Florian, 2008, P 22 INT C COMP LING, P465
   LEWIS DD, 1994, P 17 ANN INT ACM SIG, P3
   McDonald R., 2005, P HUM LANG TECHN C C, P523
   NIVRE J, 2003, P 8 INT WORKSH PARS, P149
   Ohtake Kiyonori, 2006, P COLING ACL MAIN C, P635
   Osborne M., 2004, P EMNLP 2004, P9
   Ringger E., 2007, P LING ANN WORKSH AC, P101
   SASSANO M, 2004, P COLING 2004, P8
   SASSANO M, 2002, P 40 ANN M ASS COMP, P505
   Schohn G., 2000, P 17 INT C MACH LEAR, P839
   Seung H. S., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P287, DOI 10.1145/130385.130417
   TANG M, 2002, P 40 ANN M ASS COMP, P120
   Tong S., 2000, P 17 INT C MACH LEAR, P999
   UCHIMOTO K, 1999, P 9 C EUR CHAPT ASS, P196
   Yamada H., 2003, P 8 INT WORKSH PARS, V3, P195
   ZHU J, 2007, P 2007 JOINT C EMP M, P783
NR 24
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 356
EP 365
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300037
DA 2019-06-15
ER

PT B
AU Skala, M
   Krakovna, V
   Kramar, J
   Penn, G
AF Skala, Matthew
   Krakovna, Victoria
   Kramar, Janos
   Penn, Gerald
GP Assoc Computat Linguist
TI Generalized-Zero-Preserving Method for Compact Encoding of Concept
   Lattices
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB Constructing an encoding of a concept lattice using short bit vectors allows for efficient computation of join operations on the lattice. Join is the central operation any unification-based parser must support. We extend the traditional bit vector encoding, which represents join failure using the zero vector, to count any vector with less than a fixed number of one bits as failure. This allows non-joinable elements to share bits, resulting in a smaller vector size. A constraint solver is used to construct the encoding, and a variety of techniques are employed to find near-optimal solutions and handle timeouts. An evaluation is provided comparing the extended representation of failure with traditional bit vector techniques.
C1 [Skala, Matthew] Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
   [Krakovna, Victoria; Kramar, Janos] Univ Toronto, Dept Math, Toronto, ON M5S 1A1, Canada.
   [Penn, Gerald] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 1A1, Canada.
RP Skala, M (reprint author), Univ Waterloo, Sch Comp Sci, Waterloo, ON N2L 3G1, Canada.
EM mskala@cs.toronto.edu; vkrakovna@gmail.com; jkramar@gmail.com;
   gpenn@cs.toronto.edu
CR AITKACI H, 1989, ACM T PROGR LANG SYS, V11, P115, DOI 10.1145/59287.59293
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Callmeier U., 2000, Natural Language Engineering, P99, DOI 10.1017/S1351324900002369
   Carlsson M., 1997, Programming Languages: Implementations, Logics, and Programs. 9th International Symposium, PLILP'97, Including a Special Track on Declarative Programming Languages in Education. Proceedings, P191
   Cisco Systems, 2008, ECLIPSE 6 0 COMP SOF
   Copestake A., 2000, P 2 C LANG RES EV LR
   Fall Andrew, 1996, THESIS
   IBM, 2008, ILOG CPLEX 11 COMP S
   Markowsky G, 1980, ALGEBRA U, V11, P173
   Mellish C., 1992, Logic Programming, New Frontiers, P189
   Mellish Chris, 1991, TECHNICAL REPORT
   Penn G, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P64
   Penn G, 1999, LOGIC PROGRAMM, P124
   Sadler A, 2008, J HEURISTICS, V14, P23, DOI 10.1007/s10732-007-9028-0
   Talbot David, 2007, EMNLP CONLL, P468
   WEGNER P, 1960, COMMUN ACM, V3, P322, DOI 10.1145/367236.367286
NR 16
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 1512
EP 1521
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300153
DA 2019-06-15
ER

PT B
AU Villing, J
AF Villing, Jessica
GP Assoc Computat Linguist
TI Now, where was I? Resumption strategies for an in-vehicle dialogue
   system
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In-vehicle dialogue systems often contain more than one application, e.g. a navigation and a telephone application. This means that the user might, for example, interrupt the interaction with the telephone application to ask for directions from the navigation application, and then resume the dialogue with the telephone application. In this paper we present an analysis of interruption and resumption behaviour in human-human in-vehicle dialogues and also propose some implications for resumption strategies in an in-vehicle dialogue system.
C1 [Villing, Jessica] Gothenburg Univ, Grad Sch Language Technol, S-41124 Gothenburg, Sweden.
   [Villing, Jessica] Gothenburg Univ, Dept Philosophy Linguist & Theory Sci, S-41124 Gothenburg, Sweden.
RP Villing, J (reprint author), Gothenburg Univ, Grad Sch Language Technol, S-41124 Gothenburg, Sweden.
EM jessica@ling.gu.se
CR Brostrom Robert, 2006, P 2006 ITS WORLD C
   Larsen S, 2007, SCAND J HOSP TOUR, V7, P7, DOI 10.1080/15022250701226014
   Lindstrom Anders, 2008, P INT 2008, P4
   MATTES S, 2003, P IGFA
   Neale V. L., 2005, P 19 INT TECHN C ENH
   van Winsum W, 1999, TECHNICAL REPORT
   Villing Jessica, 2009, P SIMPE 4 WORKSH SPE, P14
   Villing Jessica, 2008, P GOTAL 6 INT C NAT, P12
   Yang Fan, 2009, IUI 09, P373
NR 9
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 798
EP 805
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300082
DA 2019-06-15
ER

PT B
AU Wu, ZL
   Markert, K
   Sharoff, S
AF Wu, Zhili
   Markert, Katja
   Sharoff, Serge
GP Assoc Computat Linguist
TI Fine-grained Genre Classification using Structural Learning Algorithms
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
ID SEMANTIC SIMILARITY
AB Prior use of machine learning in genre classification used a list of labels as classification categories. However, genre classes are often organised into hierarchies, e.g., covering the subgenres of fiction. In this paper we present a method of using the hierarchy of labels to improve the classification accuracy. As a testbed for this approach we use the Brown Corpus as well as a range of other corpora, including the BNC, HGC and Syracuse. The results are not encouraging: apart from the Brown corpus, the improvements of our structural classifier over the flat one are not statistically significant. We discuss the relation between structural learning performance and the visual and distributional balance of the label hierarchy, suggesting that only balanced hierarchies might profit from structural learning.
C1 [Wu, Zhili; Sharoff, Serge] Univ Leeds, Ctr Translat Studies, Leeds LS2 9JT, W Yorkshire, England.
   [Markert, Katja] Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
RP Wu, ZL (reprint author), Univ Leeds, Ctr Translat Studies, Leeds LS2 9JT, W Yorkshire, England.
EM z.wu@leeds.ac.uk; scskm@leeds.ac.uk; s.sharoff@leeds.ac.uk
CR Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628
   Cristianini N, 2002, ADV NEUR IN, V14, P367
   Crowston K., 2009, GENRES WEB COMPUTATI
   Dekel  O., 2004, P 21 INT C MACH LEAR, P27
   Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197
   Giesbrecht E., 2009, P 5 WEB CORP WORKSH, P27
   Jiang J. J, 1997, CMPLG9709008 CORR
   Joachims T., 1999, ADV KERNEL METHODS S, P41
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/s10994-009-5108-8, 10.1007/S10994-009-5108-8]
   Kanaris I, 2009, INFORM PROCESS MANAG, V45, P499, DOI 10.1016/j.ipm.2009.05.003
   Karlgren J., 1994, P 15 INT C COMP LING, V2, P1071
   Keerthi SS, 2008, P 14 ACM SIGKDD INT, P408
   Kessler B, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P32
   Kucera Henry, 1967, COMPUTATIONAL ANAL P
   Leacock C., 1998, COMBINING LOCAL CONT, P305
   Lee D., 2001, LANGUAGE LEARNING TE, V5, P37
   Lin D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P296
   Meyer zu Eissen S., 2004, P 27 GERM C ART INT
   Pedersen T, 2007, J BIOMED INFORM, V40, P288, DOI 10.1016/j.jbi.2006.06.004
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   Santini M., 2007, THESIS
   SHAO KT, 1990, SYST ZOOL, V39, P266, DOI 10.2307/2992186
   Sharoff S., 2010, P 7 LANG RES EV C LR
   Stubbe A., 2007, P REF CORP WEB GENR
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Vidulin V., 2007, P GENR EN SEARCH ENG
   Webber B, 2009, P JOINT C 47 ANN M A, V2, P674
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
NR 29
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 749
EP 759
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300077
DA 2019-06-15
ER

PT B
AU Xiao, T
   Zhu, JB
   Zhu, MH
   Wang, HZ
AF Xiao, Tong
   Zhu, Jingbo
   Zhu, Muhua
   Wang, Huizhen
GP Assoc Computat Linguist
TI Boosting-based System Combination for Machine Translation
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB In this paper, we present a simple and effective method to address the issue of how to generate diversified translation systems from a single Statistical Machine Translation (SMT) engine for system combination. Our method is based on the framework of boosting. First, a sequence of weak translation systems is generated from a baseline system in an iterative manner. Then, a strong translation system is built from the ensemble of these weak translation systems. To adapt boosting to SMT system combination, several key components of the original boosting algorithms are redesigned in this work. We evaluate our method on Chinese-to-English Machine Translation (MT) tasks in three baseline systems, including a phrase-based system, a hierarchical phrase-based system and a syntax-based system. The experimental results on three NIST evaluation test sets show that our method leads to significant improvements in translation accuracy over the baseline systems.
C1 [Xiao, Tong; Zhu, Jingbo; Zhu, Muhua; Wang, Huizhen] Northeastern Univ, Nat Language Proc Lab, Shenyang, Liaoning, Peoples R China.
RP Xiao, T (reprint author), Northeastern Univ, Nat Language Proc Lab, Shenyang, Liaoning, Peoples R China.
EM xiaotong@mail.neu.edu.cn; zhujingbo@mail.neu.edu.cn; zhumuhua@gmail.com;
   wanghuizhen@mail.neu.edu.cn
CR Chiang D., 2005, P 43 ANN M ASS COMP, P263, DOI DOI 10.3115/1219840.1219873
   Chiang D, 2007, COMPUT LINGUIST, V33, P201, DOI 10.1162/coli.2007.33.2.201
   Chiang David, 2008, P 2008 C EMP METH NA, P224
   Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537
   Collins M., 1999, P JOINT SIGDAT C EMP, P100
   Cowan Brooke, 2006, P 2006 C EMP METH NA, P232
   Ding Y., 2005, P 43 ANN M ASS COMP, P541, DOI DOI 10.3115/1219840.1219907
   Dorr Bonnie, 2006, P ASS MACH TRANSL AM, P223
   Duan Nan, 2009, P EMNLP 2009, P1096
   Eisner Jason, 2003, COMP VOL P 41 ANN M, P205
   FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Galley M, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P961
   Galley Michel, 2008, P 2008 C EMP METH NA, P848
   Hildebrand Almut Silja, 2008, 8 AMTA C, P254
   Huang L., 2007, P 45 ANN M ASS COMP, P144
   Koehn Philipp, 2004, P EMNLP, P388
   Koehn Philipp, 2003, P 2003 C N AM CHAPT, P48, DOI DOI 10.3115/1073445.1073462
   Lagarda Antonio, 2008, ANN M EUR ASS MACH T, P88
   Li Mu, 2009, P ACL IJCNLP 2009 SI, P585
   Liang P., 2006, P HUM LANG TECHN C N, P104
   Liu Y, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P609
   Macherey Wolfgang, 2007, EMNLP CONLL, P986
   Matusov E., 2006, P EACL, P33
   Och FJ, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P295
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Rosti A.-V., 2007, P 45 ANN M ASS COMP, P312
   Rudin C, 2007, ANN STAT, V35, P2723, DOI 10.1214/009053607000000785
   Schafrik RE, 2001, SUPERALLOYS 718, 625, 706 AND VARIOUS DERIVATIVES, P1
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   Wang Wei, 2006, P 2006 C EMP METH NA, P44
   Xiao Tong, 2009, P EMNLP 2009 SING, P362
   Xiong DY, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P521
   Zhang Hao, 2006, P HUM LANG TECHN C N, P256
NR 34
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 739
EP 748
PG 10
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300076
DA 2019-06-15
ER

PT B
AU Zhang, M
   Zhang, H
   Li, HZ
AF Zhang, Min
   Zhang, Hui
   Li, Haizhou
GP Assoc Computat Linguist
TI Convolution Kernel over Packed Parse Forest
SO ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL
   LINGUISTICS
LA English
DT Proceedings Paper
CT 48th Annual Meeting of the Association-for-Computational-Linguistics
   (ACL)
CY JUL 11-16, 2010
CL Uppsala, SWEDEN
SP Assoc Computat Linguist, Uppsala Univ
AB This paper proposes a convolution forest kernel to effectively explore rich structured features embedded in a packed parse forest. As opposed to the convolution tree kernel, the proposed forest kernel does not have to commit to a single best parse tree, is thus able to explore very large object spaces and much more structured features embedded in a forest. This makes the proposed kernel more robust against parsing errors and data sparseness issues than the convolution tree kernel. The paper presents the formal definition of convolution forest kernel and also illustrates the computing algorithm to fast compute the proposed convolution forest kernel. Experimental results on two NLP applications, relation extraction and semantic role labeling, show that the proposed forest kernel significantly outperforms the baseline of the convolution tree kernel.
C1 [Zhang, Min; Zhang, Hui; Li, Haizhou] ASTAR, Inst Infocomm Res, Singapore, Singapore.
RP Zhang, M (reprint author), ASTAR, Inst Infocomm Res, Singapore, Singapore.
EM mzhang@i2r.a-star.edu.sg; vishz@i2r.a-star.edu.sg; hli@i2r.a-star.edu.sg
RI Li, Haizhou/Q-6438-2019
OI Li, Haizhou/0000-0001-9158-9401
CR ACE, 2002, AUT CONT EXTR PROJ
   Aiolli Fabio, 2006, FAST ONLINE KERNEL L
   Aiolli Fabio, 2007, IEEE S COMP INT DAT
   Baker J. K., 1979, 97 M AC SOC AM
   Billot S., 1989, ACL 1989
   Bunescu Razvan, 2008, EMNLP 2008
   CARRERAS X, 2005, CONLL 2005
   Charniak E., 2005, ACL 2005
   Charniak E., 2001, ACL 2001
   Che Wanxiang, 2006, COLING ACL 2006
   Che WanXiang, 2008, ACM T ASIAN LANGUAGE
   COLLINS M, 2002, NIPS 2002
   Collins M., 1999, THESIS
   Dyer Christopher, 2008, ACL HLT 2008
   Finkel Jenny Rose, 2006, EMNLP 2006
   Freund Y, 1999, MACH LEARN, V37, P277, DOI 10.1023/A:1007662407062
   Guldea D., 2002, COLING 2002
   Haussler D., 1999, UCSCRL9910
   Huang Liang, 2008, ACL 2008
   Joachims T., 1998, ECML 1998
   Kashima H., 2003, ICML 2003
   Klein Dan, 2001, IWPT 2001
   Lari Karim, 1990, COMPUTER SPEECH LANG, V4
   Martha P., 2005, COMPUT LINGUIST, V31, P1, DOI DOI 10.1162/0891201053630264
   Mi Haitao, 2008, EMNLP 2008
   MOSCHITTI A, 2004, ACL 2004
   Moschitti Alessandro, 2006, HLT NAACL 2006
   Rosenblatt F., 1962, PRINCIPLES NEURODYNA
   Tomita M., 1987, Computational Linguistics, V13, P31
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Watkins C., 1999, ADV KERNEL METHODS
   Xue Nianwen, 2004, EMNLP 2004
   Yang Xiaofeng, 2006, COLING ACL 2006
   Zhang Dell, 2003, SIGIR 2003
   Zhang Hui, 2009, EMNLP 2009
   Zhang Hui, 2009, ACL IJCNLP 2009
   Zhang Min, 2006, COLING ACL 2006
   Zhang Min, 2007, ACL 2007
   Zhang Min, 2009, EMNLP 2009
   Zhang Min, 2008, ACL 2008
NR 40
TC 0
Z9 0
U1 1
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 978-1-932432-66-4
PY 2010
BP 875
EP 885
PG 11
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Language & Linguistics
SC Computer Science; Linguistics
GA BG7BY
UT WOS:000391195300090
DA 2019-06-15
ER

PT B
AU Abekawa, T
   Okumura, M
AF Abekawa, Takeshi
   Okumura, Manabu
GP COLING
TI Japanese Dependency Parsing Using Co-occurrence Information and a
   Combination of Case Elements
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper, we present a method that improves Japanese dependency parsing by using large-scale statistical information. It takes into account two kinds of information not considered in previous statistical (machine learning based) parsing methods: information about dependency relations among the case elements of a verb, and information about co-occurrence relations between a verb and its case element. This information can be collected from the results of automatic dependency parsing of large-scale corpora. The results of an experiment in which our method was used to rerank the results obtained using an existing machine learning based parsing method showed that our method can improve the accuracy of the results obtained using the existing method.
C1 [Abekawa, Takeshi] Univ Tokyo, Grad Sch Educ, Tokyo 1138654, Japan.
RP Abekawa, T (reprint author), Univ Tokyo, Grad Sch Educ, Tokyo 1138654, Japan.
EM abekawa@p.u-tokyo.ac.jp; oku@pi.titech.ac.jp
CR Charniak E, 2005, P 43 ANN M ASS COMP, P173, DOI DOI 10.3115/1219840.1219862
   Collins M, 2005, COMPUT LINGUIST, V31, P25, DOI 10.1162/0891201053630273
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   HENDERSON J, 2005, P 43 ANN M ACL, P181
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   KEHLER A, 2004, P HLT NAACL, P289
   Klein Dan, 2002, ADV NEURAL INFORM PR, V15, P3
   Kudo T., 2005, Transactions of the Information Processing Society of Japan, V46, P1082
   KUDO T, 2002, CONLL 2002, P63
   KUROHASHI S, 1998, JAPANESE MORPHOLOGIC
   Kurohashi S., 1994, P WORKSH SHAR NAT LA, P48
   Kurohashi Sadao, 1998, P 1 INT C LANG RES E, P719
   SASSANO M, 2004, P COLING 2004, P8
   SHIRAI K, 1998, P 3 C EMNLP, P80
   SHIRAI K, 1998, TR980004 TOK I TECHN
   TORISAWA K, 2001, P NLPRS2001, P211
   Uchimoto K., 1999, Transactions of the Information Processing Society of Japan, V40, P3397
   UCHIMOTO K, 2000, P 6 INT WORKSH PARS, P321
NR 18
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 833
EP 840
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200105
DA 2019-06-15
ER

PT B
AU Chatterjee, N
   Agrawal, S
AF Chatterjee, Niladri
   Agrawal, Saumya
GP COLING
TI Word Alignment in English-Hindi Parallel Corpus Using Recency-Vector
   Approach: Some Studies
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Word alignment using recency-vector based approach has recently become popular. One major advantage of these techniques is that unlike other approaches they perform well even if the size of the parallel corpora is small. This makes these algorithms worth-studying for languages where resources are scarce. In this work we studied the performance of two very popular recency-vector based approaches, proposed in (Fung and McKeown, 1994) and (Somers, 1998), respectively, for word alignment in English-Hindi parallel corpus. But performance of the above algorithms was not found to be satisfactory. However, subsequent addition of some new constraints improved the performance of the recency-vector based alignment technique significantly for the said corpus. The present paper discusses the new version of the algorithm and its performance in detail.
C1 [Chatterjee, Niladri] Indian Inst Technol, Dept Math, New Delhi 110016, India.
RP Chatterjee, N (reprint author), Indian Inst Technol, Dept Math, New Delhi 110016, India.
EM niladri_iitd@yahoo.com; saumya_agrawal2000@yahoo.co.in
CR AHRENBERG L, 2000, P 2 INT C LING RES E, V3, P1255
   Brown P. F., 1993, Computational Linguistics, V19, P263
   DAGAN KWC, 1993, P WORKSH VER LARG DA, P1
   FUNG P, 1994, TECHNOLOGY PARTNERSH, P81
   Gale W. A., 1991, P 4 DARPA WORKSH SPE, P152
   HUANG JX, 2000, P 38 ANN M ASS COMP, P392
   Ramanathan A., 2003, P WORKSH COMP LING S, P42
   SOMERS H, 1998, INT J CORPUS LINGUIS, V3, P115
   TIEDEMANN J, 2003, P 10 C EUR CHAPT ASS, P339
NR 9
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 649
EP 656
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200082
DA 2019-06-15
ER

PT B
AU Dubey, A
   Keller, F
   Sturt, P
AF Dubey, Amit
   Keller, Frank
   Sturt, Patrick
GP COLING
TI Integrating Syntactic Priming into an Incremental Probabilistic Parser,
   with an Application to Psycholinguistic Modeling
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB The psycholinguistic literature provides evidence for syntactic priming, i.e., the tendency to repeat structures. This paper describes a method for incorporating priming into an incremental probabilistic parser. Three models are compared, which involve priming of rules between sentences, within sentences, and within coordinate structures. These models simulate the reading time advantage for parallel structures found in human data, and also yield a small increase in overall parsing accuracy.
C1 [Dubey, Amit; Keller, Frank; Sturt, Patrick] Univ Edinburgh, Human Commun Res Ctr, Edinburgh EH8 9LW, Midlothian, Scotland.
RP Dubey, A (reprint author), Univ Edinburgh, Human Commun Res Ctr, 2 Buccleuch Pl, Edinburgh EH8 9LW, Midlothian, Scotland.
EM amit.dubey@ed.ac.uk; patrick.sturt@ed.ac.uk; frank.keller@ed.ac.uk
RI Sturt, Patrick/E-8496-2010
OI Sturt, Patrick/0000-0002-2055-6933
CR ANDERSON JD, 1991, ASIS MONOGR, P1
   BOCK JK, 1986, COGNITIVE PSYCHOL, V18, P355, DOI 10.1016/0010-0285(86)90004-6
   Church Kenneth W, 2000, P 18 C COMP LING COL, V1, P180
   Crocker MW, 2000, J PSYCHOLINGUIST RES, V29, P647, DOI 10.1023/A:1026560822390
   DUBEY A, 2005, P HUM LANG TECHN C C, P827
   Frazier L, 2000, J PSYCHOLINGUIST RES, V29, P343, DOI 10.1023/A:1005156427600
   FRAZIER L, 2001, COPY SYNTAX, V4, P1
   Hale J., 2001, P 2 C N AM CHAPT ASS
   Jurafsky D, 1996, COGNITIVE SCI, V20, P137, DOI 10.1016/S0364-0213(99)80005-6
   Keller F, 2003, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, PTS 1 AND 2, P646
   Klein D., 2003, P 41 M ASS COMP LING, P423, DOI DOI 10.3115/1075096.1075150
   KUHN R, 1990, IEEE T PATTERN ANAL, V12, P570, DOI 10.1109/34.56193
   Roark B., 1999, P 37 ANN M ASS COMP, P421
   STOLCKE A, 1995, COMPUT LINGUIST, V21, P165
   Sze Felix, 2015, CORPUS LINGUIST LING, V1, P190, DOI DOI 10.1515/CLLT.2005.1.1.113
NR 15
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 417
EP 424
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200053
DA 2019-06-15
ER

PT B
AU Feinstein, D
   Wintner, S
AF Feinstein, Daniel
   Wintner, Shuly
GP COLING
TI Highly constrained unification grammars
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Unification grammars are widely accepted as an expressive means for describing the structure of natural languages. In general, the recognition problem is undecidable for unification grammars. Even with restricted variants of the formalism, offline parsable grammars, the problem is computationally hard. We present two natural constraints on unification grammars which limit their expressivity. We first show that non-reentrant unification grammars generate exactly the class of context-free languages. We then relax the constraint and show that one-reentrant unification grammars generate exactly the class of tree-adjoining languages. We thus relate the commonly used and linguistically motivated formalism of unification grammars to more restricted, computationally tractable classes of languages.
C1 [Feinstein, Daniel; Wintner, Shuly] Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel.
RP Feinstein, D (reprint author), Univ Haifa, Dept Comp Sci, IL-31905 Haifa, Israel.
EM daniel@cs.haifa.ac.il; shuly@cs.haifa.ac.il
CR BARTON GE, 1987, COMPUT COMPLEX, P89
   Carpenter B., 1992, LOGIC TYPED FEATURE
   FEINSTEIN D, 2004, THESIS U HAIFA
   Gazdar G., 1988, Natural Language Parsing and Linguistic Theories, P69
   Jaeger E., 2005, Journal of Logic, Language and Information, V14, P199, DOI 10.1007/s10849-005-4511-1
   JOHNSON M., 1988, CSLI LECT NOTES, V16
   Johnson M, 1998, P COLING ACL 98 MONT, P619
   Joshi A, 2003, OXFORD HDB COMPUTATI, P483
   Joshi A. K., 1985, NATURAL LANGUAGE PAR, P206, DOI DOI 10.1017/CBO9780511597855
   KEIFER B, 2004, NEW DEV PARSING TECH, P229
   Pereira FCN, 1997, LANG SPEECH & COMMUN, P149
   Pollard Carl, 1984, THESIS STANFORD U
   RAYNER M, 2001, P EUROSPEECH 2001 AA
   SATTA G, 1994, P 20 ANN M ASS COMP, V20
   SAVITCH WJ, 1987, STUDIES LINGUISTICS, V33
   Shieber S. M., 1986, CSLI LECT NOTES, V4
   SHIEBER SM, 1992, CONSTRAINT BASED GRA
   Steedman M., 2000, SYNTACTIC PROCESS
   Vijay-Shanker K., 1993, Computational Linguistics, V19, P591
   VIJAYSHANKER K, 1994, MATH SYST THEORY, V27, P511, DOI 10.1007/BF01191624
   WEIR DJ, 1992, THEOR COMPUT SCI, V104, P235, DOI 10.1016/0304-3975(92)90124-X
NR 21
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1089
EP 1096
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200137
DA 2019-06-15
ER

PT B
AU Gao, JF
   Suzuki, H
   Yu, B
AF Gao, Jianfeng
   Suzuki, Hisami
   Yu, Bin
GP COLING
TI Approximation Lasso Methods for Language Modeling
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
ID REGRESSION
AB Lasso is a regularization method for parameter estimation in linear models. It optimizes the model parameters with respect to a loss function subject to model complexities. This paper explores the use of lasso for statistical language modeling for text input. Owing to the very large number of parameters, directly optimizing the penalized lasso loss function is impossible. Therefore, we investigate two approximation methods, the boosted lasso (BLasso) and the forward stagewise linear regression (FSLR). Both methods, when used with the exponential loss function, bear strong resemblance to the boosting algorithm which has been used as a discriminative training method for language modeling. Evaluations on the task of Japanese text input show that BLasso is able to produce the best approximation to the lasso solution, and leads to a significant improvement, in terms of character error rate, over boosting and the traditional maximum likelihood estimation.
C1 [Gao, Jianfeng; Suzuki, Hisami] Microsoft Res, Redmond, WA 98052 USA.
RP Gao, JF (reprint author), Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.
EM jfgao@microsoft.com; hisamis@microsoft.com; binyu@stat.berkeley.edu
CR BACCHIANI M, 2004, HLT NAACL, P21
   Collins M, 2005, COMPUT LINGUIST, V31, P25, DOI 10.1162/0891201053630273
   DONOHO D, 1995, J ROY STAT SOC, V57, P201
   Duda R, 2001, PATTERN CLASSIFICATI
   Efron B, 2004, ANN STAT, V32, P407
   FREUND YR, 1998, ICML 98
   Gao J., 2002, EMNLP 2002
   GAO J, 2005, HLT EMNLP 2005
   Hastie T, 2001, ELEMENTS STAT LEARNI
   Osborne MR, 2000, J COMPUT GRAPH STAT, V9, P319, DOI 10.2307/1390657
   OSBORNE MR, 2000, J NUMERICAL ANAL, V20
   ROARK B, 2004, ICASSP 2004
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   SUZUKI H, 2005, HLT EMNLP 2005
   Tibshirani R, 1996, J ROY STAT SOC B MET, V58, P267
   YUAN W, 2005, IJCNLP 05
   ZHAO P, 2004, BOOSTED LASSO
   Zhu J., 2003, NIPS, V16
NR 18
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 225
EP 232
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200029
DA 2019-06-15
ER

PT B
AU Gerdes, K
   Kahane, S
AF Gerdes, Kim
   Kahane, Sylvain
GP COLING
TI A polynomial parsing algorithm for the topological model Synchronizing
   Constituent and Dependency Grammars, Illustrated by German Word Order
   Phenomena
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper describes a minimal topology driven parsing algorithm for topological grammars that synchronizes a rewriting grammar and a dependency grammar, obtaining two linguistically motivated syntactic structures. The use of non-local slash and visitor features can be restricted to obtain a CKY type analysis in polynomial time. German long distance phenomena illustrate the algorithm, bringing to the fore the procedural needs of the analyses of syntax-topology mismatches in constraint based approaches like for example HPSG.
C1 [Gerdes, Kim] Univ Bordeaux 3, ERSS, CNRS, F-33405 Talence, France.
RP Gerdes, K (reprint author), Univ Bordeaux 3, ERSS, CNRS, F-33405 Talence, France.
EM kim.gerdes@u-bordeaux3.fr; sk@ccr.jussieu.fr
CR ALEXIS N, 1995, 4 INT WORKSH PARS TE
   ANDREAS K, 1995, THESIS OHIO STATE U
   Bech Gunnar, 1983, LINGUISTISCHE ARBEIT, V139
   Bech Gunnar, 1955, LINGUISTISCHE ARBEIT, V139
   BECKER T, 1991, LONG DISTANCE SCRAMB
   BOHNET B, 2001, P 8 EUR NAT NAT LANG
   BOJAR O, 2004, INT WORKSH CONSTR SO, P29
   BROKER N, 1998, SEPARATING SURFACE O, P174
   DEBUSMANN R, 2004, 2 INT MOZ OZ C CHARL
   DRACH E, 1937, GRUNAGEDANKEN DTSCH
   DUCHIER D, 2001, TOPOLOGICAL DEPENDEN, P180
   DUCHIER D, 2003, J RES LANGUAGE COMPU
   Eisner J., 2000, ADV PROBABILISTIC OT, V16, P29
   El Kassas Dina, 2004, JEP TALN WORKSH AR L, P259
   Frank A., 2003, PROJECTING LFG F STR, P217
   Gazdar Gerald, 1985, GEN PHRASE STRUCTURE
   GERDES K, 2001, WORD ORDER GERMAN FO, P220
   GERDES K, 2006, LINGUISTICAE INVESTI, V29, P101
   GERDES K, 2003, TOPOLOGIE COMME INTE, P125
   KAHANE S, 1998, P 36 ANN M ASS COMP, P646
   KIEFER B, 1999, BAG USEFUL TECHNIQUE, P473
   KOLLER A, 2002, GENERATION DEPENDENC
   NASR A, 2003, 1 INT C MEAN TEXT TH, P249
   NISHIDA K, 2001, COMPILING HPSG BASED, P199
   NIVRE J, 2005, P 43 ANN M ASS COMP, P99
   Pollard C., 1994, HEAD DRIVEN PHRASE S
   RICHARD H, 2000, DEPENDENCY GRAMMARS, V41, P15
   SYLVAIN K, 2006, POLARIZED UNIFICATIO
   YOO H, 2003, THESIS U PARIS 7
   YOO HY, 2004, DEPENDENCY ACCOUNT K
NR 30
TC 0
Z9 0
U1 0
U2 1
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1097
EP 1104
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200138
DA 2019-06-15
ER

PT B
AU Goldberg, Y
   Adler, M
   Elhadad, M
AF Goldberg, Yoav
   Adler, Meni
   Elhadad, Michael
GP COLING
TI Noun Phrase Chunking in Hebrew Influence of Lexical and Morphological
   Features
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present a method for Noun Phrase chunking in Hebrew. We show that the traditional definition of base-NPs as non-recursive noun phrases does not apply in Hebrew, and propose an alternative definition of Simple NPs. We review syntactic properties of Hebrew related to noun phrases, which indicate that the task of Hebrew SimpleNP chunking is harder than base-NP chunking in English. As a confirmation, we apply methods known to work well for English to Hebrew data. These methods give low results (F from 76 to 86) in Hebrew. We then discuss our method, which applies SVM induction over lexical and morphological features. Morphological features improve the average precision by similar to 0.5%, recall by similar to 1%, and F-measure by similar to 0.75, resulting in a system with average performance of 93% precision, 93.4% recall and 93.2 F-measure.*
C1 [Goldberg, Yoav; Adler, Meni; Elhadad, Michael] Ben Gurion Univ Negev, Dept Comp Sci, IL-84105 Beer Sheva, Israel.
RP Goldberg, Y (reprint author), Ben Gurion Univ Negev, Dept Comp Sci, POB 653, IL-84105 Beer Sheva, Israel.
EM yoavg@cs.bgu.ac.il; adlerm@cs.bgu.ac.il; elhadad@cs.bgu.ac.il
OI Elhadad, Michael/0000-0002-5629-2351
CR Abney Steven, 1991, PRINCIPLE BASED PARS
   ADLER M, 2006, P COLING ACL 2006 SI
   Allwein E. L., 2000, J MACHINE LEARNING R, V1, P113, DOI DOI 10.1162/15324430152733133
   CARDIE C, 1998, P COLING 98 MONTR
   Diab Mona, 2004, P HLT NAACL 2004 BOS
   JOACHIMS T, 1998, P ECML 98 CHEMN
   KUDO T, 2000, P CONLL 2000 LLL 200
   KUDO T, 2003, P ACL 2003 SAPP
   NABASH N, 2005, P ACL 2005 ANN ARB
   NETZERDAHAN Y, 1998, P INLG 98 ONT
   RAMSHAW LA, 1995, P 3 ACL WORKSH VER L
   SANG EFT, 2000, P CONLL 2000 LLL 200
   SHA F, 2003, MSCIS0235 CIS U PENN
   SIMAAN K, 2001, TRAITEMENT AUTOMATIQ, V42
   Vapnik VN, 1995, NATURE STAT LEARNING
   Zhang T, 2002, J MACH LEARN RES, V2, P615, DOI 10.1162/153244302320884560
NR 16
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 689
EP 696
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200087
DA 2019-06-15
ER

PT B
AU Hale, J
   Shafran, I
   Yung, L
   Dorr, B
   Harper, M
   Krasnyanskaya, A
   Lease, M
   Liu, Y
   Roark, B
   Snover, M
   Stewart, R
AF Hale, John
   Shafran, Izhak
   Yung, Lisa
   Dorr, Bonnie
   Harper, Mary
   Krasnyanskaya, Anna
   Lease, Matthew
   Liu, Yang
   Roark, Brian
   Snover, Matthew
   Stewart, Robin
GP COLING
TI PCFGs with Syntactic and Prosodic Indicators of Speech Repairs
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB A grammatical method of combining two kinds of speech repair cues is presented. One cue, prosodic disjuncture, is detected by a decision tree-based ensemble classifier that uses acoustic cues to identify where normal prosody seems to be interrupted (Lickley, 1996). The other cue, syntactic parallelism, codifies the expectation that repairs continue a syntactic category that was left unfinished in the reparandum (Levelt, 1983). The two cues are combined in a Treebank PCFG whose states are split using a few simple tree transformations. Parsing performance on the Switchboard and Fisher corpora suggests that these two cues help to locate speech repairs in a synergistic way.
C1 [Hale, John] Michigan State Univ, E Lansing, MI 48824 USA.
RP Hale, J (reprint author), Michigan State Univ, E Lansing, MI 48824 USA.
CR Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/BF00058655
   BUNTINE W, 1992, TECHNOLOGY 2002
   Charniak E., 2000, P NAACL 00
   CHARNIAK E, 2001, P 2 M N AM CHAPT ASS, P118
   Charniak  E., 2005, P HLT EMNLP, P233
   CHOMSKY N, 1957, ANUA LINGUARUM SERIE, V4
   CORE MG, 1999, P 37 ANN M ASS COMP, P413
   GODFREY JJ, 1992, P ICASSP, V1, P517
   GREGORY M, 2004, P N AM ASS COMP LING
   HARPER M, 2005, 2005 J HOPK SUMM WOR
   HEEMAN PA, 1999, COMPUTATIONAL LINGUI, V527, P571
   Johnson M., 2004, P RICH TRANSCR WORKS
   JOHNSON M, 2004, P 42 ANN M ASS COMP
   LEASE M, 2005, P ICASSP
   LEVELT WJM, 1983, COGNITION, V14, P41, DOI 10.1016/0010-0277(83)90026-4
   LICKLEY RJ, 1996, P INT C SPEECH LANG
   LIU Y, 2004, THESIS PURDUE U
   MARCUS M, 1994, P 1994 ARPA HUM LANG
   Marcus M.P., 1993, COMPUTATIONAL LINGUI, V19, P313, DOI DOI 10.1080/07494460903404410
   MCKELVIE D, 1998, SYNTAX DISFLUENCY SP
   MCKELVIE D, 1998, SDP SPOKEN DIALOG PA
   NAKATANI CH, 1994, J ACOUST SOC AM, V95, P1603, DOI 10.1121/1.408547
   Ostendorf M, 2001, P ISCA WORKSH PROS S, P119
   PRICE PJ, 1991, J ACOUST SOC AM, V90, P2956, DOI 10.1121/1.401770
   RATNAPARKHI A, 1996, P C EMP METH NAT LAN, P133
   Roark B., 2004, Natural Language Engineering, P1, DOI 10.1017/S1351324903003152
   Shriberg E, 2005, SPEECH COMMUN, V46, P455, DOI 10.1016/j.specom.2005.02.018
   SHRIBERG E, 1994, THESIS UC BERKELEY
   SILVERMAN HF, 1992, P INT C SPOK LANG PR, V2, P867
   SJLANDER K, 2001, SNACK SOUND VISUALIZ
   Sonmez K., 1998, P INT C SPOK LANG PR, V7, p[9192, 1998, 3189]
   SPILKER J, 2001, P ISCA WORKSH DISFL, P73
   SPILKER J, 2000, VERBMOBIL FDN SPEECH, P131
   STOLCKE A, 1996, P INT C AC SPEECH SI, P405
   Weischedel R. M., 1983, American Journal of Computational Linguistics, V9, P161
   WIELING M, 2005, COMMUNICATION
   WONG D, 2005, UWEETR20050003 EL EN
   Zhang Q., 2005, P 9 INT WORKSH PARS, P179
NR 38
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 161
EP 168
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200021
DA 2019-06-15
ER

PT B
AU Koller, A
   Thater, S
AF Koller, Alexander
   Thater, Stefan
GP COLING
TI An Improved Redundancy Elimination Algorithm for Underspecified
   Representations
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB We present an efficient algorithm for the redundancy elimination problem: Given an underspecified semantic representation (USR) of a scope ambiguity, compute an USR with fewer mutually equivalent readings. The algorithm operates on underspecified chart representations which are derived from dominance graphs; it can be applied to the USRs computed by large-scale grammars. We evaluate the algorithm on a corpus, and show that it reduces the degree of ambiguity significantly while taking negligible runtime.
C1 [Koller, Alexander; Thater, Stefan] Univ Saarland, Dept Computat Linguist, Saarbrucken, Germany.
RP Koller, A (reprint author), Univ Saarland, Dept Computat Linguist, Saarbrucken, Germany.
EM koller@coli.uni-sb.de; stth@coli.uni-sb.de
CR Althaus E, 2003, J ALGORITHMS, V48, P194, DOI 10.1016/S0196-6774(03)00050-6
   Bos J., 2005, REPRESENTATION INFER
   Chaves R. P., 2003, P 8 ESSLLI STUD SESS
   COPESTAKE A, 2004, J LANGUAGE IN PRESS
   EGG M, 2001, LOGIC LANGUAGE INFOR, V10
   Flickinger Daniel, 2002, COLLABORATIVE LANGUA
   FUCHSS R, 2004, P 42 ACL
   Koller A., 2005, ACL 05 DEMONSTRATION
   KOLLER A, 2006, P 5 INT WORKSH INF C
   Koller A., 2003, P 10 EACL
   Koller Alexander, 2005, P ACL 05 WORKSH SOFT
   NIEHREN J, 2003, P 41 ACL
   OEPEN S, 2002, P COLING 02
   Van Deemter K, 1996, SEMANTIC AMBIGUITY U
   VESTRE E, 1991, P 5 EACL BERL
NR 15
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 409
EP 416
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200052
DA 2019-06-15
ER

PT B
AU Li, Q
   Myaeng, SH
   Jin, Y
   Kang, BY
AF Li, Qing
   Myaeng, Sung-Hyon
   Jin, Yun
   Kang, Bo-yeong
GP COLING
TI Concept Unification of Terms in Different Languages for IR
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Due to the historical and cultural reasons, English phases, especially the proper nouns and new words, frequently appear in Web pages written primarily in Asian languages such as Chinese and Korean. Although these English terms and their equivalences in the Asian languages refer to the same concept, they are erroneously treated as independent index units in traditional Information Retrieval (IR). This paper describes the degree to which the problem arises in IR and suggests a novel technique to solve it. Our method firstly extracts an English phrase from Asian language Web pages, and then unifies the extracted phrase and its equivalence(s) in the language as one index unit. Experimental results show that the high precision of our conceptual unification approach greatly improves the IR performance.
C1 [Li, Qing; Myaeng, Sung-Hyon] Informat & Commun Univ, Taejon, South Korea.
RP Li, Q (reprint author), Informat & Commun Univ, Taejon, South Korea.
EM liqing@icu.ac.kr; myaeng@icu.ac.kr; wkim@cnu.ac.kr; comeng99@snu.ac.kr
CR Buckley C, 2000, INFORM PROCESS MANAG, V36, P109, DOI 10.1016/S0306-4573(99)00047-3
   CAO Y, 2002, P 19 COLING
   CHENG P, 2004, P ACM SIGIR
   DAVIS M, 1997, P TREC 5
   FUNG P, 1998, P COLING ACL 98
   HUANG F, 2005, P HUM LANG TECHN C H
   Jeong KS, 1999, INFORM PROCESS MANAG, V35, P523, DOI 10.1016/S0306-4573(98)00055-7
   Kang BJ, 2002, INFORM PROCESS MANAG, V38, P91, DOI 10.1016/S0306-4573(00)00065-0
   KANG IH, 2000, P COLING
   KIM SH, 1994, P 22 KISS SPRING C
   LEE JH, 1996, P SIGIR
   LEE JS, 2004, P 5 CHIN KOR JOINT S
   Munkres J., 1957, J SOC IND APPL MATH, V5
   NAGATA M, 2001, P ACL 2001 DD MT WOR
   RAPP R, 1999, P ACL
   ZHANG Y, 2005, P ACM SIGIR 05
   ZHANG Y, 2004, P ACM SIGIR 04
NR 17
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 641
EP 648
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200081
DA 2019-06-15
ER

PT B
AU Mori, S
   Takuma, D
   Kurata, G
AF Mori, Shinsuke
   Takuma, Daisuke
   Kurata, Gakuto
GP COLING
TI Phoneme-to-Text Transcription System with an Infinite Vocabulary
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB The noisy channel model approach is successfully applied to various natural language processing tasks. Currently the main research focus of this approach is adaptation methods, how to capture characteristics of words and expressions in a target domain given example sentences in that domain. As a solution we describe a method enlarging the vocabulary of a language model to an almost infinite size and capturing their context information. Especially the new method is suitable for languages in which words are not delimited by whitespace. We applied our method to a phoneme-to-text transcription task in Japanese and reduced about 10% of the errors in the results of an existing method.
C1 [Mori, Shinsuke; Takuma, Daisuke; Kurata, Gakuto] IBM Japan Ltd, Tokyo Res Lab, IBM Res, Yamato 2428502, Japan.
RP Mori, S (reprint author), IBM Japan Ltd, Tokyo Res Lab, IBM Res, 1623-14 Shimotsuruma, Yamato 2428502, Japan.
EM mori@fw.ipsj.or.jp
CR AHO AV, 1990, HDB THEORETICAL COMP, VA, P273
   BAZZI I, 2000, P ICSLP 2000
   Brown P. F., 1990, Computational Linguistics, V16, P79
   DEROUAULT AM, 1986, IEEE T PATTERN ANAL, V8, P742, DOI 10.1109/TPAMI.1986.4767855
   JELINEK F, 1985, SELF ORG LANGUAGE MO
   Jelinek F., 1991, ADV SPEECH SIGNAL PR, P651
   KERNIGHAN MD, 1990, P 13 INT C COMP LING, P205
   Kilgarriff A, 2003, COMPUT LINGUIST, V29, P333, DOI 10.1162/089120103322711569
   LUNDE K, 1998, CJKV INFORM PROCESSI
   Mori S., 1999, Transactions of the Information Processing Society of Japan, V40, P2946
   MORI SS, 2004, P ICSLP2004
   NAGATA M, 1996, EMNLP
   Nagata Masaaki, 1994, P 15 INT C COMP LING, P201
NR 13
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 729
EP 736
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200092
DA 2019-06-15
ER

PT B
AU Murray, GC
   Dorr, BJ
   Lin, J
   Hajic, J
   Pecina, P
AF Murray, G. Craig
   Dorr, Bonnie J.
   Lin, Jimmy
   Hajic, Jan
   Pecina, Pavel
GP COLING
TI Leveraging Reusability: Cost-effective Lexical Acquisition for
   Large-scale Ontology Translation
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Thesauri and ontologies provide important value in facilitating access to digital archives by representing underlying principles of organization. Translation of such resources into multiple languages is an important component for providing multilingual access. However, the specificity of vocabulary terms in most ontologies precludes fully-automated machine translation using general-domain lexical resources. In this paper, we present an efficient process for leveraging human translations when constructing domain-specific lexical resources. We evaluate the effectiveness of this process by producing a probabilistic phrase dictionary and translating a thesaurus of 56,000 concepts used to catalogue a large archive of oral histories. Our experiments demonstrate a cost-effective technique for accurate machine translation of large ontologies.
C1 [Murray, G. Craig; Dorr, Bonnie J.; Lin, Jimmy] Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA.
RP Murray, GC (reprint author), Univ Maryland, Inst Adv Comp Studies, College Pk, MD 20742 USA.
EM gcraigm@umd.edu; bdorr@umd.edu; jimmylin@umd.edu;
   hajic@ufal.mff.cuni.cz; pecina@ufal.mff.cuni.cz
RI Hajic, Jan/D-3429-2017; Pecina, Pavel/K-3770-2017
OI Hajic, Jan/0000-0002-3503-7730; Pecina, Pavel/0000-0002-1855-5931
CR Brown P. F., 1993, Computational Linguistics, V19, P263
   CHUN C, 2002, P 3 AS C INF TECHN A
   CMERJREK M, 2004, 4 INT C LANG RES EV
   Dejean H, 2005, ARTIF INTELL MED, V33, P111, DOI 10.1016/j.artmed.2004.07.015
   ECHIZENYA H, 2005, P ACL SIGLEX WORKSH, P87
   FUNG P, 2000, PARALLEL TEXT PROCES
   GUSTMAN, 2002, P JOINT C DIG LIB PO, P18
   KAJI H, 1996, P 16 INT C COMP LING, P23
   MURRAY GC, 2006, P 11 ANN C EUR ASS M
   NELSON SJ, 2004, MEDINFO 1, V11, P67
   Och F. J., 2003, Computational Linguistics, V29, P19, DOI 10.1162/089120103321337421
   PAPINENI K, 2002, P 40 ANN M ASS COMP, P331
   Rapp R, 1999, P 37 ANN M ASS COMP, P519, DOI DOI 10.3115/1034678.1034756
   Sadao KC, 2003, REV HIGH EDUC, V26, P397, DOI 10.1353/rhe.2003.0034
   Tanaka K, 1996, P 16 INT C COMP LING, V2, P580
   *USC, 2006, USC SHOAH FDN I VIS
   WANTANABE T, 2003, P MT SUMM 9, P410
NR 17
TC 0
Z9 0
U1 0
U2 2
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 945
EP 952
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200119
DA 2019-06-15
ER

PT B
AU Ohno, T
   Matsubara, S
   Kashioka, H
   Maruyama, T
   Inagaki, Y
AF Ohno, Tomohiro
   Matsubara, Shigeki
   Kashioka, Hideki
   Maruyama, Takehiko
   Inagaki, Yasuyoshi
GP COLING
TI Dependency Parsing of Japanese Spoken Monologue Based on Clause
   Boundaries
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Spoken monologues feature greater sentence length and structural complexity than do spoken dialogues. To achieve high parsing performance for spoken monologues, it Could prove effective to simplify the structure by dividing a sentence into suitable language units. This paper proposes a method for dependency parsing of Japanese monologues based on sentence segmentation. In this method, the dependency parsing is executed in two stages: at the clause level and the sentence level. First, the dependencies within a clause are identified by dividing a sentence into clauses and executing stochastic dependency parsing for each clause. Next, the dependencies over clause boundaries are identified stochastically, and the dependency structure of the entire sentence is thus completed. An experiment using a spoken monologue corpus shows this method to be effective for efficient dependency parsing of Japanese monologue sentences.
C1 [Ohno, Tomohiro] Nagoya Univ, Grad Sch Informat Sci, Nagoya, Aichi 4648601, Japan.
RP Ohno, T (reprint author), Nagoya Univ, Grad Sch Informat Sci, Nagoya, Aichi 4648601, Japan.
EM ohno@el.itc.nagoya-u.ac.jp
CR Charniak E., 2000, P 1 C N AM CHAPT ASS, P132
   Collins M., 1996, P 34 ANN M ASS COMP, V34, P184, DOI DOI 10.3115/981863.981888
   CORE MG, 1999, P 37 ANN M ASS COMP, P413
   DELMONTE R, 2003, P 8 EUROSPEECH, P1999
   FUJIO M, 1998, P 3 C EMP METH NAT L, P87
   HUANG J, 2002, P ICSLP, P917
   KASHIOKA H, 2004, P ICSLTOCOCOSDA 2004, P87
   KIM M, 2004, P 1 IJC NLP, P420
   Kudo T., 2002, P 6 C NAT LANG LEARN, V2002, P63
   Kurohashi S., 1994, Computational Linguistics, V20, P507
   Maekawa  K., 2000, P LREC, P947
   Matsumoto Y., 1999, NAISTISTR99009
   Nagao Makoto, 1997, P NLPRS 97, P451
   Ohno T, 2005, IEICE T INF SYST, VE88D, P545, DOI 10.1093/ietisy/e88-d.3.545
   Ohno Tomohiro, 2005, P 9 EUROSPEECH, P3449
   Rajeev A., 1992, P 30 ANN M ASS COMP, P15
   RATNAPARKHI A, 1997, P 2 C EMP METH NAT L, P1
   SHIRAI S, 1995, J INFORMATION PROCES, V36, P2353
   SHITAOKA K, 2004, P COLING, P1107
   Tanaka Hideki, 2004, J NATURAL LANGUAGE P, V11, P39
   UCHIMOTO K, 1999, P 9 C EUR CHAPT ASS, P196
   UTSURO T, 2000, P 1 C N AM CHAPT ACL, P110
NR 22
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 169
EP 176
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200022
DA 2019-06-15
ER

PT B
AU Prager, J
   Duboue, P
   Chu-Carroll, J
AF Prager, John
   Duboue, Pablo
   Chu-Carroll, Jennifer
GP COLING
TI Improving QA Accuracy by Question Inversion
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper demonstrates a conceptually simple but effective method of increasing the accuracy of QA systems on factoid-style questions. We define the notion of an inverted question, and show that by requiring that the answers to the original and inverted questions be mutually consistent, incorrect answers get demoted in confidence and correct ones promoted. Additionally, we show that lack of validation can be used to assert no-answer (nil) conditions. We demonstrate increases of performance on TREC and other question-sets, and discuss the kinds of future activities that can be particularly beneficial to approaches such as ours.
C1 [Prager, John; Duboue, Pablo; Chu-Carroll, Jennifer] IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Prager, J (reprint author), IBM Corp, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM jprager@us.ibm.com; duboue@us.ibm.com; jencc@us.ibm.com
CR BRILL E, 2002, P EMNLP 2002
   CHUCARROLL J, 2003, P 11 TREC
   Clarke C. L. A., 2001, P 10 TEXT TETR C TRE, P673
   HENDRIX G, 1977, DEV NATURAL LANGUAGE, P292
   Lenat D. B., 1995, COMMUNICATIONS ACM, V38
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   MOLDOVAN D, 2002, LEXICAL CHAINS QUEST
   MOLDOVAN D, 2001, P ACL
   MORICEAU V, 2006, EACL WORKSH KNOWL RE
   PRAGER J, 2002, LREC 2002 WORKSH QUE
   Prager J M, 2004, NEW DIRECTIONS QUEST
   Prager J. M., 2004, P 42 ACL BARC SPAIN, P575, DOI 10.3115/1218955.1219028
   RADEV D, P ANLP 2000 SEATTL W, P150
   VOORHEES E, 2003, P 11 TREC GAITH MD
   Warren D. H. D., 1982, American Journal of Computational Linguistics, V8, P110
   WINOGRAD T, 1972, COGNITIVE PSYCHOL, V3
   Witten IH, 2005, DATA MINING PRACTICA
NR 17
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1073
EP 1080
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200135
DA 2019-06-15
ER

PT B
AU Rotaru, M
   Litman, DJ
AF Rotaru, Mihai
   Litman, Diane J.
GP COLING
TI Dependencies between Student State and Speech Recognition Problems in
   Spoken Tutoring Dialogues
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Speech recognition problems are a reality in current spoken dialogue systems. In order to better understand these phenomena, we study dependencies between speech recognition problems and several higher level dialogue factors that define our notion of student state: frustration/anger, certainty and correctness. We apply Chi Square (chi(2)) analysis to a corpus of speech-based computer tutoring dialogues to discover these dependencies both within and across turns. Significant dependencies are combined to produce interesting insights regarding speech recognition problems and to propose new strategies for handling these problems. We also find that tutoring, as a new domain for speech applications, exhibits interesting tradeoffs and new factors to consider for spoken dialogue design.
C1 [Rotaru, Mihai; Litman, Diane J.] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
RP Rotaru, M (reprint author), Univ Pittsburgh, Pittsburgh, PA 15260 USA.
EM mrotaru@cs.pitt.edu; litman@cs.pitt.edu
CR ANG J, 2002, P ICSLP
   BULYKO I, 2005, SPEECH COMMUNICATION, V45
   CHASE L, 1997, P EUR
   FORBESRILEY K, 2005, P SIGDIAL
   FRAMPTON M, 2005, P IJCAI WORKSH KNOW
   Gabsdil M., 2004, P ACL
   HIRSCHBERG J, 2004, SPEECH COMMUNICATION, V43
   KEARNS M, 2002, P NAT C ART INT AAAI
   LISCOMBE J, 2005, P INT
   LITMAN D, 2004, P SIGDIAL WORKSH DIS
   PONBARRY H, 2004, P ITS WORKSH DIAL BA
   ROTARU M, 2005, P EUR
   SKANTZE G, 2005, SPEECH COMMUNICATION, V45
   SOLTAU H, 2000, P ICASSP
   SWERTS M, 2005, J MEMORY LANGUAGE, V53
   SWERTS M, 2000, P ICSLP
   VANLEHN K, 2002, P INT TUT SYST ITS
   WALKER M, 2001, P ACL
   Walker M. A., 2000, NATURAL LANGUAGE ENG
NR 19
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 193
EP 200
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200025
DA 2019-06-15
ER

PT B
AU Serasset, G
   Brunet-Manquat, F
   Chiocchetti, E
AF Serasset, Gilles
   Brunet-Manquat, Francis
   Chiocchetti, Elena
GP COLING
TI Multilingual Legal Terminology on the Jibiki Platform: The LexALP
   Project
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB This paper presents the particular use of "Jibiki" (Papillon's web server development platform) for the LexALP(1) project. LexALP's goal is to harmonise the terminology on spatial planning and sustainable development used within the Alpine Convention(2), so that the member states are able to cooperate and communicate efficiently in the four official languages (French, German, Italian and Slovene). To this purpose, LexALP uses the Jibiki platform to build a term bank for the contrastive analysis of the specialised terminology used in six different national legal systems and four different languages. In this paper we present how a generic platform like Jibiki can cope with a new kind of dictionary.
C1 [Serasset, Gilles; Brunet-Manquat, Francis] Univ Grenoble 1, Lab CLIPS IMAG, F-38041 Grenoble 9, France.
RP Serasset, G (reprint author), Univ Grenoble 1, Lab CLIPS IMAG, BP 53, F-38041 Grenoble 9, France.
EM Gilles.Serasset@imag.fr; Francis.Brunet-Manquat@imag.fr;
   Elena.Chiocchetti@eurac.edu
OI Serasset, Gilles/0000-0003-2761-7353
CR Arntz Reiner, 1993, TERMINOLOGY APPL INT, P5
   FELBER H, 1994, ALFA, V8, P163
   Felber Helmut, 1987, MANUEL TERMINOLOGIE
   MANGEOT M, 2001, THESIS U J FOURIER G
   Mangeot-Lerebours M., 2003, TAL, V44, P151
   SERASSET G, 2004, COLING 2004 MULTILIN, P73
   SERASSET G, 1994, COLING 94, V1, P278
   STREITER O, 2006, TERMINOLOGY SCI RES, V16
   STREITER O, 2004, LINGUISTICA ANTVERPI, V3
NR 9
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 937
EP 944
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200118
DA 2019-06-15
ER

PT B
AU Suzuki, H
   Toutanova, K
AF Suzuki, Hisami
   Toutanova, Kristina
GP COLING
TI Learning to Predict Case Markers in Japanese
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB Japanese case markers, which indicate the grammatical relation of the complement NP to the predicate, often pose challenges to the generation of Japanese text, be it done by a foreign language learner, or by a machine translation (MT) system. In this paper, we describe the task of predicting Japanese case markers and propose machine learning methods for solving it in two settings: (i) monolingual, when given information only from the Japanese sentence; and (ii) bilingual, when also given information from a corresponding English source sentence in an MT context. We formulate the task after the well-studied task of English semantic role labelling, and explore features from a syntactic dependency structure of the sentence. For the monolingual task, we evaluated our models on the Kyoto Corpus and achieved over 84% accuracy in assigning correct case markers for each phrase. For the bilingual task, we achieved an accuracy of 92% per phrase using a bilingual dataset from a technical domain. We show that in both settings, features that exploit dependency information, whether derived from gold-standard annotations or automatically assigned, contribute significantly to the prediction of case markers.
C1 [Suzuki, Hisami; Toutanova, Kristina] Microsoft Res, Redmond, WA 98052 USA.
RP Suzuki, H (reprint author), Microsoft Res, 1 Microsoft Way, Redmond, WA 98052 USA.
EM hisamis@microsoft.com; kristout@microsoft.com
CR BALDWIN T, 2004, P 2 WORKSH TEXT MEAN
   Blaheta D., 2000, P 1 ANN M N AM CHAPT, P234
   CLARKSON PR, 1997, P ESCA EUR, P2007
   Collins M., 2000, P ICML
   GAMON M, 2002, P ACL
   Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983
   Hacioglu K, 2004, P COLING
   KAWAHARA D, 2000, P 18 INT C COMP LING, P432
   Kurohashi S., 1997, P 3 ANN M ASS NAT LA, P115
   Marquez Lluis, 2005, P CONLL 2005
   MASUOKA T, 1992, KISO NIHONGO BUNPOU
   Murata M, 2005, Proceedings of the 2005 IEEE International Conference on Natural Language Processing and Knowledge Engineering (IEEE NLP-KE'05), P774
   Och F. J., 2000, P 38 ANN M ASS COMP, P440
   Palmer M., 2005, COMPUTATIONAL LINGUI, V31
   Pradhan SS, 2004, P HLT NAACL
   Quirk C., 2005, P ACL
   Teramura H., 1991, NIHONGO NO SHINTAKUS, VIII
   Toutanova K., 2005, P 43 ANN M ASS COMP, p[589, 596]
   UCHIMOTO K, 2002, P COLING 2002, P1037
NR 19
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1049
EP 1056
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200132
DA 2019-06-15
ER

PT B
AU Turian, J
   Melamed, ID
AF Turian, Joseph
   Melamed, I. Dan
GP COLING
TI Advances in Discriminative Parsing
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB The present work advances the accuracy and training speed of discriminative parsing. Our discriminative parsing method has no generative component, yet surpasses a generative baseline on constituent parsing, and does so with minimal linguistic cleverness. Our model can incorporate arbitrary features of the input and parse state, and performs feature selection incrementally over an exponential feature space during training. We demonstrate the flexibility of our approach by testing it with several parsing strategies and various feature sets. Our implementation is freely available at: http://nlp.cs.nyu.edu/parser/.
C1 [Turian, Joseph; Melamed, I. Dan] NYU, Dept Comp Sci, New York, NY 10003 USA.
RP Turian, J (reprint author), NYU, Dept Comp Sci, 550 1St Ave, New York, NY 10003 USA.
EM turian@cs.nyu.edu; melamed@cs.nyu.edu
CR Bikel Daniel M., 2004, COMPUTATIONAL LINGUI, V30
   BLACK E, 1991, SPEECH NATURAL LANGU
   BOD R, 2003, EACL
   CHARNIAK E, 2005, ACL
   CLARK S, 2004, ACL
   COLLINS M, 2003, COMPUTATIONAL LINGUI, V29
   Collins M., 1999, THESIS
   COLLINS M, 2002, MACHINE LEARNING, V48
   Collins Michael, 2004, ACL
   EISNER J, 2005, IWPT
   HENDERSON J, 2004, ACL
   KAPLAN RM, 2004, HLT NAACL
   KUDO T, 2005, ACL
   MAGERMAN DM, 1995, ACL
   Ng A. Y., 2004, ICML
   Perkins S., 2003, J MACHINE LEARNING R, V3
   Ratnaparkhi A., 1999, MACHINE LEARNING, V34
   Ratnaparkhi A., 1996, EMNLP
   Russell S. J., 1995, ARTIFICIAL INTELLIGE
   SAGAE K, 2005, IWPT
   Schapire R., 1999, MACHINE LEARNING, V37
   Taskar B., 2004, EMNLP
   TAYLOR A, 2003, TREEBANKS BUILDING U, pCH1
   TURIAN J, 2005, IWPT
   TURIAN J, 2006, HLT NAACL WORKSH COM
NR 25
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 873
EP 880
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200110
DA 2019-06-15
ER

PT B
AU Wu, M
   Strzalkowski, T
AF Wu, Min
   Strzalkowski, Tomek
GP COLING
TI Utilizing Co-Occurrence of Answers in Question Answering
SO COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 21st International Conference on Computational Linguistics/44th Annual
   Meeting of the Association for Computational Linguistics
CY JUL 17-21, 2006
CL Sydney, AUSTRALIA
SP Assoc Computat Linguist
AB In this paper, we discuss how to utilize the co-occurrence of answers in building an automatic question answering system that answers a series of questions on a specific topic in a batch mode. Experiments show that the answers to the many of the questions in the series usually have a high degree of co-occurrence in relevant document passages. This feature sometimes can't be easily utilized in an automatic QA system which processes questions independently. However it can be utilized in a QA system that processes questions in a batch mode. We have used our pervious TREC QA system as baseline and augmented it with new answer clustering and co-occurrence maximization components to build the batch QA system. The experiment results show that the QA system running under the batch mode get significant performance improvement over our baseline TREC QA system.
C1 [Wu, Min; Strzalkowski, Tomek] SUNY Albany, ILS Inst, Albany, NY 12222 USA.
RP Wu, M (reprint author), SUNY Albany, ILS Inst, 1400 Washington Ave,SS261, Albany, NY 12222 USA.
EM minwu@cs.albany.edu; tomek@csc.albany.edu
CR CHUCARROL J, 2003, P 11 TREC
   CUI H, 2005, P 13 TREC
   HAN KS, 2005, P 13 TREC
   HARABAGIU S, 2004, P 12 TREC
   HOVY EL, 2001, P 9 TREC
   Katz Boris, 2003, P EACL 2003 WORKSH N
   LIN J, CHI 2003
   MOLDOVAN D, 2001, P ACL
   MONZ C, 2004, P SIGIR WORKSH INF R
   PRAGER J, 2000, P 23 ANN INT ACM SIG, P184
   PRAGER J, 2004, P 42 ACL
   RAVICHANDRAN D, 2002, P 40 ACL
   SOUBBOTIN M, 2003, P 11 TREC
   VOORHEES E, 2005, P HLT 2005
NR 14
TC 0
Z9 0
U1 0
U2 0
PU ASSOC COMPUTATIONAL LINGUISTICS-ACL
PI STROUDSBURG
PA 209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA
BN 978-1-932432-65-7
PY 2006
BP 1169
EP 1176
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
SC Computer Science
GA BNG36
UT WOS:000274500200147
DA 2019-06-15
ER

PT B
AU Kaji, N
   Okamoto, M
   Kurohashi, S
AF Kaji, N
   Okamoto, M
   Kurohashi, S
GP acl
TI Paraphrasing predicates from written language to spoken language using
   the web
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB There are a lot of differences between expressions used in written language and spoken language. It is one of the reasons why speech synthesis applications are prone to produce unnatural speech. This paper represents a method of paraphrasing unsuitable expressions for spoken language into suitable ones. Those two expressions can be distinguished based on the occurrence probability in written and spoken language corpora which are automatically collected from the Web. Experimental results indicated the effectiveness of our method. The precision of the collected corpora was 94%, and the accuracy of learning paraphrases was 76%.
C1 Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, Tokyo 1138656, Japan.
RP Kaji, N (reprint author), Univ Tokyo, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
RI Kaji, Noritada/M-8432-2019
CR BARZILAY R, 2001, P 39 ANN M ASS COMP, P50
   Barzilay Regina, 2003, P HLT NAACL 2003
   Bulyko M. Ostendorf, 2003, P HLT NAACL, P7
   DUCLAYE F, 2003, P 10 C EACL WORKSH N
   Edmonds P, 2002, COMPUT LINGUIST, V28, P105, DOI 10.1162/089120102760173625
   FUKUHARA T, 2001, WORKSH NOT JSAI SYNS, P22
   HAYASHI M, 1999, ABU TECHNICAL REV
   HERMJAKOB U, 2002, P TREC 2002 C
   Inkpen D. Z., 2001, P WORKSH WORDNET OTH, P47
   INUI K, 2003, P 2 INT WORKSH PAR, P9
   INUI K, 2001, P NLPRS 2001
   Kaji N., 2002, P 40 ANN M ASS COMP, P215
   KAWAHARA D, 2001, P 1 INT C HUM LANG T, P204
   KILGARRIFF A, 2001, INT J CORPUS LINGUIS
   LIN D, 2001, J NATURAL LANGUAGE E, V7, P343
   Maekawa  K., 2000, P LREC, P947
   Nadamoto A, 2001, SEVENTH INTERNATIONAL CONFERENCE ON DATABASE SYSTEMS FOR ADVANCED APPLICATIONS, PROCEEDINGS, P164
   OHISHI H, 1970, HANASHI KOTOBA
   Pang Bo, 2003, P HLT NAACL 2003
   Shinyama Y., 2002, P HLT 2002
   TADIKA J, 1997, REIKAI SHOUGAKU KOKU
   Takezawa T., 2002, P LREC, P147
   TAMBOURATZIS G, 2000, P WORKSH COMP CORP 2
   Vapnik VN, 1995, NATURE STAT LEARNING
NR 24
TC 0
Z9 0
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 241
EP 248
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100031
DA 2019-06-15
ER

PT B
AU Lange, R
   Greiff, WR
   Moran, J
   Ferro, L
AF Lange, R
   Greiff, WR
   Moran, J
   Ferro, L
GP acl
TI A probabilistic Rasch analysis of question answering evaluations
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
AB The field of Psychometrics routinely grapples with the question of what it means to measure the inherent ability of an organism to perform a given task, and for the last forty years, the field has increasingly relied on probabilistic methods such as the Rasch model for test construction and the analysis of test results. Because the underlying issues of measuring ability apply to human language technologies as well, such probabilistic methods can be advantageously applied to the evaluation of those technologies. To test this claim, Rasch measurement was applied to the results of 67 systems participating in the Question Answering track of the 2002 Text REtrieval Conference (TREC) competition. Satisfactory model fit was obtained, and the paper illustrates the theoretical and practical strengths of Rasch scaling for evaluating systems as well as questions. Most important, simulations indicate that a test invariant metric can be defined by carrying forward 20 to 50 equating questions, thus placing the yearly results on a common scale.
CR Bond T. G., 2001, APPL RASCH MODEL FUN
   FISHER GH, 1995, RASCH MODELS FDN REC, P15
   Hambleton R. K., 1985, ITEM RESPONSE THEORY
   LANGE R, 2003, MODEL SAILPLANE COMP
   Lange Rense, 2002, Journal of Alzheimer's Disease, V4, P77
   LINACRE JM, 2003, WINSTEPS RASCH MEASU
   Papineni K, 2002, P HUM LANG TECHN C S, P124
   Rasch G., 1960, PROBABILISTIC MODELS
   Stout W, 2002, PSYCHOMETRIKA, V67, P485, DOI 10.1007/BF02295128
   VANRIJSBERGEN CJ, 1979, INFORMATION RETRIEVA
   Voorhees E. M., 1999, P 8 TEXT RETR C TREC, P500
   Wright B. D., 1979, BEST TEST DESIGN
NR 12
TC 0
Z9 0
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 65
EP 72
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100009
DA 2019-06-15
ER

PT B
AU Vechtomova, O
   Karamuftuoglu, M
AF Vechtomova, O
   Karamuftuoglu, M
GP acl
TI Comparison of two interactive search refinement techniques
SO HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH
   AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE MAIN CONFERENCE
LA English
DT Proceedings Paper
CT Human Language Technology Conference of the North American Chapter of
   the Association-for-Computational-Linguistics
CY MAY 02-07, 2004
CL Boston, MA
ID INFORMATION-RETRIEVAL; PROBABILISTIC MODEL; QUERY EXPANSION
AB The paper presents two approaches to interactively refining user search formulations and their evaluation in the new High Accuracy Retrieval from Documents (HARD) track of TREC-12. One method consists of asking the user to select a number of sentences that may represent relevant documents, and then using the documents, whose sentences were selected for query expansion. The second method consists of showing to the user a list of noun phrases, extracted from the initial document set, and then expanding the query with the terms from the phrases selected by the user.
C1 Univ Waterloo, Dept Management Sci, Waterloo, ON N2L 3G1, Canada.
RP Vechtomova, O (reprint author), Univ Waterloo, Dept Management Sci, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
CR ALLAN J, 2004, P 12 TEXT RETR C NOV
   Beaulieu M, 1997, J DOC, V53, P8, DOI 10.1108/EUM0000000007187
   Brill E, 1995, COMPUT LINGUIST, V21, P543
   Church K. W., 1991, LEXICAL ACQUISITION, P115
   Jones K. S., 2000, Information Processing & Management, V36, P809
   Jones K. S., 2000, Information Processing & Management, V36, P779
   Koenemann J., 1996, P SIGCHI C HUM FACT, P205, DOI DOI 10.1145/238386.238487
   KWOK L, 2003, P 12 TEXT RETR C NOV
   RAMSHAW LA, 1995, P 3 ACL WORKSH VER L
   Robertson SE, 2000, INFORM PROCESS MANAG, V36, P95, DOI 10.1016/S0306-4573(99)00046-1
   Ruthven I., 2003, P 26 ANN INT ACM SIG, P213, DOI DOI 10.1145/860435.860475
   Tombros A., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P2, DOI 10.1145/290941.290947
   Vechtomova O, 2003, INFORM RETRIEVAL, V6, P251, DOI 10.1023/A:1023936321956
   VECHTOMOVA O, 2003, P 12 TEXT RETR C NOV
NR 14
TC 0
Z9 0
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-23-X
PY 2004
BP 225
EP 232
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Statistics & Probability
SC Computer Science; Mathematics
GA BAP35
UT WOS:000223117100029
DA 2019-06-15
ER

PT B
AU Aizawa, A
AF Aizawa, A
GP ACL
TI Analysis of source identified text corpora: Exploring the statistics of
   the reused text and authorship
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper aims at providing a view of text recycled, within a short time, by the authors themselves. We first present a simple and general method for extracting reused term sequences, and then analyze several author-identified text collections to compare the statistical quantities. The ratio of recycling is also measured for each collection. Finally, related research topics are introduced together with some discussion of future research directions.
C1 Natl Inst Informat, Chiyoda Ku, Tokyo 1018430, Japan.
CR Broder A., 1997, P 6 INT WORLD WID WE, P391, DOI [DOI 10.1016/S0169-7552(97)00031-7, 10.1016/S0169-7552(97)00031-7]
   Chowdhury A, 2002, ACM T INFORM SYST, V20, P171, DOI 10.1145/506309.506311
   GarciaMolina H, 1996, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED INFORMATION SYSTEMS, P68, DOI 10.1109/PDIS.1996.568668
   HARMAN D, 1993, TIPSTAR COMPLETE
   MATSUMOTO Y, 1997, NAISTISTR97007
   *NAT CTR SCI INF S, 1999, NTCIR TEST COLL, V1
   *REUT, 2000, REUT CORP, V1
   Sanderson  M., 1997, TR19975 U GLASG DEP
   Somers Harlod, 2000, HDB NATURAL LANGUAGE, P545
   TSUBOI Y, 2002, SIGNL148, P17
   Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P46, DOI 10.1145/290941.290956
   1999, 1998 MAINICHI DAILY
NR 12
TC 0
Z9 0
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 383
EP 390
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500049
DA 2019-06-15
ER

PT B
AU Bechet, D
   Foret, A
AF Bechet, D
   Foret, A
GP ACL
TI k-valued non-associative Lambek categorial grammars are not learnable
   from strings
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper is concerned with learning categorial grammars in Gold's model. In contrast to k-valued classical categorial grammars, k-valued Lambek grammars are not learnable from strings. This result was shown for several variants but the question was left open for the weakest one, the non-associative variant NL.
   We show that the class of rigid and k-valued NL grammars is unlearnable from strings, for each k; this result is obtained by a specific construction of a limit point in the considered class, that does not use product operator.
   Another interest of our construction is that it provides limit points for the whole hierarchy of Lambek grammars, including the recent pregroup grammars.
   Such a result aims at clarifying the possible directions for future learning algorithms: it expresses the difficulty of learning categorial grammars from strings and the need for an adequate structure on examples.
C1 Inst Natl Rech Informat & Automat, IRISA, F-35042 Rennes, France.
CR AARTS E, 1995, MATH LOGIC QUART, V41, P476, DOI 10.1002/malq.19950410405
   ANGLUIN D, 1980, INFORM CONTROL, V45, P117, DOI 10.1016/S0019-9958(80)90285-5
   Bar-Hillel Y, 1953, LANGUAGE, V29, P47, DOI 10.2307/410452
   Buszkowski W., 1990, STUDIA LOGICA, V49, P431
   Buszkowski W., 2001, LOGICAL ASPECTS COMP
   DEGROOTE P, 1999, LECT NOTES ARTIFICIA, V1617
   DEGROOTE P, 2002, STUDIA LOGICA
   DUDAUSOFRONIE, 2001, 13 AMST C
   FLORENCIO CC, 2002, LACL
   FORET A, 2002, LECT NOTES ARTIFICIA, V2484
   FORET A, 2002, COLING 2002 19 INT C
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   Kanazawa M., 1998, STUDIES LOGIC LANGUA
   Kandulski M., 1988, CATEGORIAL GRAMMAR, P141
   Lambek J., 1958, AM MATH MONTHLY, V65, P154, DOI [DOI 10.2307/2310058, 10.2307/2310058]
   LAMBEK J, 1999, LOGICAL ASPECTS COMP, V1582
   Lambek Joachim, 1961, STRUCTURE LANGUAGE I, VXII, P166
   NICOLAS J, 1999, RR3632 INRIA
   PENTUS M, 1993, LOGIC COMPUTER SCI
   RETORE C, 2001, 3 WORKSH LEARN LANG
   SHINOHARA T, 1990, 1990 WORKSH COMP LEA, P97
   ter Meulen A., 1997, HDB LOGIC LANGUAGE
NR 22
TC 0
Z9 0
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 351
EP 358
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500045
DA 2019-06-15
ER

PT B
AU Bender, O
   Macherey, K
   Och, FJ
   Ney, H
AF Bender, O
   Macherey, K
   Och, FJ
   Ney, H
GP ACL
TI Comparison of alignment templates and maximum entropy models for natural
   language understanding
SO EACL 2003: 10TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION
   FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 10th Conference of the European Chapter of the
   Association-for-Computational-Linguistics (EACL 2003)
CY APR 12-17, 2003
CL Budapest, HUNGARY
SP Assoc Computat Linguist, European Chapter, Lingiist Syst BV, Xerox Res Ctr Europe, ATALA, European Language Resources Assoc
AB In this paper we compare two approaches to natural language understanding (NLU). The first approach is derived from the field of statistical machine translation (MT), whereas the other uses the maximum entropy (ME) framework. Starting with an annotated corpus, we describe the problem of NLU as a translation from a source sentence to a formal language target sentence. We mainly focus on the quality of the different alignment and ME models and show that the direct ME approach outperforms the alignment templates method.
C1 Rhein Westfal TH Aachen, Rhein Westfal TH Aachen, Dept Comp Sci, Lehrstuhl Informat 6, D-52056 Aachen, Germany.
EM bender@informatik.rwth-aachen.de; k.macherey@informatik.rwth-aachen.de;
   och@informatik.rwth-aachen.de; ney@informatik.rwth-aachen.de
CR AUST H, 1995, SPEECH COMMUN, V17, P249, DOI 10.1016/0167-6393(95)00028-M
   BENNACEF SK, 1994, P ICSLP, P1271
   Berger AL, 1996, COMPUT LINGUIST, V22, P39
   BORTHWICK A, 1998, P 7 MESS UND C MUC 7
   Brown P. F., 1993, Computational Linguistics, V19, P263
   Chen S., 1999, CMUCS99108
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   EPSTEIN M, 1996, P INT C AC SPEECH SI, V1, P176
   ISSAR S, 1993, EUR C SPEECH COMM TE, V3, P2147
   LEVIN E, 1995, EUR C SPEECH COMM TE, V2, P555
   Macherey K., 2001, EUR C SPEECH COMM TE, P2205
   MILLER S, 1994, P 32 ANN M ASS COMP, P25
   Ney H., 1999, P JOINT SIGDAT C EMP, P20
   Papineni KA, 1998, INT CONF ACOUST SPEE, P189, DOI 10.1109/ICASSP.1998.674399
   PAPINENI KA, 1997, EUR C SPEECH COMM TE, P1435
   VOGEL S, 1996, INT C COMP LING AUG, V2, P836
   ZHOU B, 2002, P INT C SPOK LANG PR, P1897
NR 17
TC 0
Z9 0
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-00-0
PY 2003
BP 11
EP 18
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics
SC Computer Science; Linguistics
GA BAN69
UT WOS:000222995200003
DA 2019-06-15
ER

PT B
AU Cao, YB
   Li, H
   Lian, L
AF Cao, YB
   Li, H
   Lian, L
GP ACL
TI Uncertainty reduction in collaborative bootstrapping: Measure and
   algorithm
SO 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS,
   PROCEEDINGS OF THE CONFERENCE
LA English
DT Proceedings Paper
CT 41st Annual Meeting of the Association-for-Computational-Linguistics
CY JUL 07-12, 2003
CL Sapporo, JAPAN
SP Assoc Computat Linguist, Microsoft, JUSTSYSTEM, NTT, OKI, Natl Inst Informat, Fuji Xerox, IBM Japan, CRL, Hokuto Syst, Fujitsu, Toshiba, NEC, Matsushita Elect, Hitachi, JAIST, Hiroshima City Univ, Kyoto Univ, Natl Inst Japanese Language, Tokushima Univ, Tottori Univ, NAIST, ATR
AB This paper proposes the use of uncertainty reduction in machine learning methods such as co-training and bilingual boot-strapping, which are referred to, in a general term, as 'collaborative bootstrapping' The paper indicates that uncertainty reduction is an important factor for enhancing the performance of collaborative bootstrapping. It proposes a new measure for representing the degree of uncertainty correlation of the two classifiers in collaborative bootstrapping and uses the measure in analysis of collaborative bootstrapping. Furthermore, it proposes a new algorithm of collaborative bootstrapping on the basis of uncertainty reduction. Experimental results have verified the correctness of the analysis and have demonstrated the significance of the new algorithm.
C1 Microsoft Res Asia, Sigma Ctr 5F, Beijing 100080, Peoples R China.
CR Abney S., 2002, P 40 ANN M ASS COMP
   Blum Avrim, 1998, P 11 ANN C COMP LEAR
   Cardie C, 2001, P 2001 C EMP METH NA
   COLLINS M, 1999, P 1999 JOINT SIGDAT
   Dasgupta S., 2001, P NEUR INF PROC SYST
   JOACHIMS T, 1997, P 14 INT C MACH LEAR
   Lewis D., 1994, P 17 INT ACM SIGIR C
   LI C, 2002, P 40 ANN M ASS COMP
   MUSLEA I, 2000, P 17 NAT C ART INT
   Nigam K., 2000, P 9 INT C INF KNOWL
   Yarowsky D., 1995, P 33 ANN M ASS COMP
NR 11
TC 0
Z9 0
U1 0
U2 0
PU ASSOCIATION COMPUTATIONAL LINGUISTICS
PI SOMERSET
PA PO BOX 6090, SOMERSET, NJ 08875 USA
BN 1-932432-09-4
PY 2003
BP 327
EP 334
PG 8
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Linguistics; Statistics & Probability
SC Computer Science; Linguistics; Mathematics
GA BAP08
UT WOS:000223097500042
DA 2019-06-15
ER

EF